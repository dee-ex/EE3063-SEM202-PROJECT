{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noinit_noise_4depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "58e32748-8a2e-4f66-c8cd-d0bdc3ef1e37"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 14s 5ms/step - loss: 1.7643 - accuracy: 0.3989 - val_loss: 0.6024 - val_accuracy: 0.8431\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8681 - accuracy: 0.7241 - val_loss: 0.4527 - val_accuracy: 0.8728\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.7808 - val_loss: 0.3950 - val_accuracy: 0.8854\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6152 - accuracy: 0.8104 - val_loss: 0.3676 - val_accuracy: 0.8909\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5736 - accuracy: 0.8236 - val_loss: 0.3490 - val_accuracy: 0.8972\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5343 - accuracy: 0.8376 - val_loss: 0.3370 - val_accuracy: 0.8991\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5249 - accuracy: 0.8408 - val_loss: 0.3289 - val_accuracy: 0.9014\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5023 - accuracy: 0.8478 - val_loss: 0.3223 - val_accuracy: 0.9041\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.8507 - val_loss: 0.3156 - val_accuracy: 0.9072\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4760 - accuracy: 0.8569 - val_loss: 0.3112 - val_accuracy: 0.9085\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.8643 - val_loss: 0.3061 - val_accuracy: 0.9108\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4398 - accuracy: 0.8683 - val_loss: 0.3013 - val_accuracy: 0.9122\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.8697 - val_loss: 0.2974 - val_accuracy: 0.9128\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.8726 - val_loss: 0.2942 - val_accuracy: 0.9153\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4185 - accuracy: 0.8752 - val_loss: 0.2899 - val_accuracy: 0.9159\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4173 - accuracy: 0.8763 - val_loss: 0.2874 - val_accuracy: 0.9170\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4021 - accuracy: 0.8809 - val_loss: 0.2828 - val_accuracy: 0.9172\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3987 - accuracy: 0.8802 - val_loss: 0.2830 - val_accuracy: 0.9178\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3923 - accuracy: 0.8817 - val_loss: 0.2802 - val_accuracy: 0.9186\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3882 - accuracy: 0.8842 - val_loss: 0.2776 - val_accuracy: 0.9193\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3799 - accuracy: 0.8855 - val_loss: 0.2740 - val_accuracy: 0.9199\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8896 - val_loss: 0.2707 - val_accuracy: 0.9206\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3768 - accuracy: 0.8886 - val_loss: 0.2691 - val_accuracy: 0.9212\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3783 - accuracy: 0.8900 - val_loss: 0.2668 - val_accuracy: 0.9216\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3608 - accuracy: 0.8930 - val_loss: 0.2637 - val_accuracy: 0.9224\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3614 - accuracy: 0.8933 - val_loss: 0.2635 - val_accuracy: 0.9227\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3485 - accuracy: 0.8959 - val_loss: 0.2605 - val_accuracy: 0.9240\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3440 - accuracy: 0.8985 - val_loss: 0.2570 - val_accuracy: 0.9252\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3485 - accuracy: 0.8973 - val_loss: 0.2560 - val_accuracy: 0.9256\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.9004 - val_loss: 0.2548 - val_accuracy: 0.9259\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.9007 - val_loss: 0.2529 - val_accuracy: 0.9269\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.9042 - val_loss: 0.2503 - val_accuracy: 0.9268\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.9009 - val_loss: 0.2493 - val_accuracy: 0.9282\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3310 - accuracy: 0.9041 - val_loss: 0.2480 - val_accuracy: 0.9289\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3229 - accuracy: 0.9052 - val_loss: 0.2457 - val_accuracy: 0.9294\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.9056 - val_loss: 0.2436 - val_accuracy: 0.9288\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.9083 - val_loss: 0.2448 - val_accuracy: 0.9301\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3113 - accuracy: 0.9078 - val_loss: 0.2397 - val_accuracy: 0.9303\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.9068 - val_loss: 0.2400 - val_accuracy: 0.9311\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.9090 - val_loss: 0.2379 - val_accuracy: 0.9325\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3058 - accuracy: 0.9101 - val_loss: 0.2368 - val_accuracy: 0.9330\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.9111 - val_loss: 0.2355 - val_accuracy: 0.9325\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9143 - val_loss: 0.2342 - val_accuracy: 0.9330\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2887 - accuracy: 0.9132 - val_loss: 0.2319 - val_accuracy: 0.9337\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2888 - accuracy: 0.9144 - val_loss: 0.2313 - val_accuracy: 0.9333\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2935 - accuracy: 0.9112 - val_loss: 0.2291 - val_accuracy: 0.9349\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9156 - val_loss: 0.2280 - val_accuracy: 0.9356\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2900 - accuracy: 0.9147 - val_loss: 0.2274 - val_accuracy: 0.9357\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2894 - accuracy: 0.9145 - val_loss: 0.2264 - val_accuracy: 0.9352\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.9187 - val_loss: 0.2240 - val_accuracy: 0.9357\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 4ms/step - loss: 2.2756 - accuracy: 0.1520 - val_loss: 1.6620 - val_accuracy: 0.6210\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.7045 - accuracy: 0.4142 - val_loss: 0.8917 - val_accuracy: 0.7747\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1876 - accuracy: 0.5892 - val_loss: 0.6075 - val_accuracy: 0.8344\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9398 - accuracy: 0.6832 - val_loss: 0.4859 - val_accuracy: 0.8632\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8013 - accuracy: 0.7384 - val_loss: 0.4173 - val_accuracy: 0.8803\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7070 - accuracy: 0.7778 - val_loss: 0.3758 - val_accuracy: 0.8899\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6418 - accuracy: 0.8044 - val_loss: 0.3452 - val_accuracy: 0.8985\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5753 - accuracy: 0.8257 - val_loss: 0.3220 - val_accuracy: 0.9044\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5412 - accuracy: 0.8384 - val_loss: 0.3044 - val_accuracy: 0.9086\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5219 - accuracy: 0.8500 - val_loss: 0.2894 - val_accuracy: 0.9117\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.8600 - val_loss: 0.2781 - val_accuracy: 0.9175\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4543 - accuracy: 0.8686 - val_loss: 0.2637 - val_accuracy: 0.9196\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4302 - accuracy: 0.8787 - val_loss: 0.2547 - val_accuracy: 0.9234\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4166 - accuracy: 0.8808 - val_loss: 0.2456 - val_accuracy: 0.9267\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - accuracy: 0.8860 - val_loss: 0.2364 - val_accuracy: 0.9299\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8930 - val_loss: 0.2283 - val_accuracy: 0.9320\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3617 - accuracy: 0.8987 - val_loss: 0.2226 - val_accuracy: 0.9337\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3534 - accuracy: 0.9013 - val_loss: 0.2156 - val_accuracy: 0.9363\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.9059 - val_loss: 0.2117 - val_accuracy: 0.9364\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.9087 - val_loss: 0.2064 - val_accuracy: 0.9387\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3160 - accuracy: 0.9141 - val_loss: 0.2013 - val_accuracy: 0.9404\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3116 - accuracy: 0.9145 - val_loss: 0.1982 - val_accuracy: 0.9413\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2947 - accuracy: 0.9205 - val_loss: 0.1944 - val_accuracy: 0.9427\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.9208 - val_loss: 0.1896 - val_accuracy: 0.9441\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9217 - val_loss: 0.1869 - val_accuracy: 0.9447\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.9272 - val_loss: 0.1832 - val_accuracy: 0.9457\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.9287 - val_loss: 0.1798 - val_accuracy: 0.9476\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2544 - accuracy: 0.9327 - val_loss: 0.1780 - val_accuracy: 0.9488\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2425 - accuracy: 0.9340 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2371 - accuracy: 0.9365 - val_loss: 0.1745 - val_accuracy: 0.9496\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2318 - accuracy: 0.9381 - val_loss: 0.1708 - val_accuracy: 0.9503\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2301 - accuracy: 0.9372 - val_loss: 0.1697 - val_accuracy: 0.9514\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2178 - accuracy: 0.9414 - val_loss: 0.1686 - val_accuracy: 0.9524\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2136 - accuracy: 0.9428 - val_loss: 0.1675 - val_accuracy: 0.9517\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2057 - accuracy: 0.9434 - val_loss: 0.1647 - val_accuracy: 0.9531\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2038 - accuracy: 0.9451 - val_loss: 0.1624 - val_accuracy: 0.9532\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9481 - val_loss: 0.1607 - val_accuracy: 0.9543\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1899 - accuracy: 0.9483 - val_loss: 0.1603 - val_accuracy: 0.9545\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1880 - accuracy: 0.9479 - val_loss: 0.1599 - val_accuracy: 0.9545\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1807 - accuracy: 0.9504 - val_loss: 0.1568 - val_accuracy: 0.9547\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9517 - val_loss: 0.1566 - val_accuracy: 0.9552\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1676 - accuracy: 0.9554 - val_loss: 0.1560 - val_accuracy: 0.9555\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1606 - accuracy: 0.9555 - val_loss: 0.1552 - val_accuracy: 0.9571\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1623 - accuracy: 0.9558 - val_loss: 0.1564 - val_accuracy: 0.9568\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1569 - accuracy: 0.9572 - val_loss: 0.1546 - val_accuracy: 0.9577\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1542 - accuracy: 0.9565 - val_loss: 0.1539 - val_accuracy: 0.9578\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1546 - accuracy: 0.9590 - val_loss: 0.1519 - val_accuracy: 0.9579\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9604 - val_loss: 0.1523 - val_accuracy: 0.9583\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1418 - accuracy: 0.9615 - val_loss: 0.1517 - val_accuracy: 0.9592\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1412 - accuracy: 0.9609 - val_loss: 0.1512 - val_accuracy: 0.9594\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.1909 - accuracy: 0.2005 - val_loss: 1.2314 - val_accuracy: 0.7174\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3679 - accuracy: 0.5362 - val_loss: 0.6653 - val_accuracy: 0.8252\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9467 - accuracy: 0.6905 - val_loss: 0.5054 - val_accuracy: 0.8595\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7754 - accuracy: 0.7516 - val_loss: 0.4307 - val_accuracy: 0.8777\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6773 - accuracy: 0.7884 - val_loss: 0.3855 - val_accuracy: 0.8877\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6114 - accuracy: 0.8120 - val_loss: 0.3554 - val_accuracy: 0.8971\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5574 - accuracy: 0.8294 - val_loss: 0.3367 - val_accuracy: 0.9003\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5163 - accuracy: 0.8442 - val_loss: 0.3193 - val_accuracy: 0.9059\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.8523 - val_loss: 0.3003 - val_accuracy: 0.9103\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.8588 - val_loss: 0.2902 - val_accuracy: 0.9136\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4333 - accuracy: 0.8705 - val_loss: 0.2808 - val_accuracy: 0.9168\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4256 - accuracy: 0.8751 - val_loss: 0.2704 - val_accuracy: 0.9208\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - accuracy: 0.8824 - val_loss: 0.2607 - val_accuracy: 0.9238\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3947 - accuracy: 0.8853 - val_loss: 0.2551 - val_accuracy: 0.9239\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8895 - val_loss: 0.2471 - val_accuracy: 0.9281\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3612 - accuracy: 0.8940 - val_loss: 0.2394 - val_accuracy: 0.9291\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3528 - accuracy: 0.8998 - val_loss: 0.2352 - val_accuracy: 0.9300\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.9040 - val_loss: 0.2302 - val_accuracy: 0.9320\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3289 - accuracy: 0.9050 - val_loss: 0.2252 - val_accuracy: 0.9329\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.9070 - val_loss: 0.2198 - val_accuracy: 0.9352\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3099 - accuracy: 0.9110 - val_loss: 0.2158 - val_accuracy: 0.9355\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3031 - accuracy: 0.9118 - val_loss: 0.2130 - val_accuracy: 0.9362\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2974 - accuracy: 0.9146 - val_loss: 0.2080 - val_accuracy: 0.9377\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2879 - accuracy: 0.9169 - val_loss: 0.2042 - val_accuracy: 0.9402\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2828 - accuracy: 0.9172 - val_loss: 0.2026 - val_accuracy: 0.9407\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.9187 - val_loss: 0.1996 - val_accuracy: 0.9417\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.9226 - val_loss: 0.1969 - val_accuracy: 0.9415\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2572 - accuracy: 0.9264 - val_loss: 0.1937 - val_accuracy: 0.9435\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.9255 - val_loss: 0.1924 - val_accuracy: 0.9437\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2557 - accuracy: 0.9264 - val_loss: 0.1900 - val_accuracy: 0.9442\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2433 - accuracy: 0.9297 - val_loss: 0.1873 - val_accuracy: 0.9463\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.9331 - val_loss: 0.1854 - val_accuracy: 0.9463\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2301 - accuracy: 0.9346 - val_loss: 0.1841 - val_accuracy: 0.9460\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2316 - accuracy: 0.9328 - val_loss: 0.1814 - val_accuracy: 0.9476\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2292 - accuracy: 0.9335 - val_loss: 0.1795 - val_accuracy: 0.9472\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.9338 - val_loss: 0.1793 - val_accuracy: 0.9481\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9387 - val_loss: 0.1758 - val_accuracy: 0.9488\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2147 - accuracy: 0.9384 - val_loss: 0.1738 - val_accuracy: 0.9490\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9393 - val_loss: 0.1746 - val_accuracy: 0.9480\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9399 - val_loss: 0.1719 - val_accuracy: 0.9500\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1957 - accuracy: 0.9444 - val_loss: 0.1707 - val_accuracy: 0.9496\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1998 - accuracy: 0.9415 - val_loss: 0.1684 - val_accuracy: 0.9507\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1917 - accuracy: 0.9456 - val_loss: 0.1678 - val_accuracy: 0.9512\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1939 - accuracy: 0.9441 - val_loss: 0.1673 - val_accuracy: 0.9510\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1799 - accuracy: 0.9484 - val_loss: 0.1654 - val_accuracy: 0.9519\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1787 - accuracy: 0.9473 - val_loss: 0.1649 - val_accuracy: 0.9518\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1802 - accuracy: 0.9478 - val_loss: 0.1634 - val_accuracy: 0.9527\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1802 - accuracy: 0.9487 - val_loss: 0.1623 - val_accuracy: 0.9528\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9493 - val_loss: 0.1620 - val_accuracy: 0.9524\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1694 - accuracy: 0.9514 - val_loss: 0.1618 - val_accuracy: 0.9520\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7808 - accuracy: 0.3853 - val_loss: 0.5470 - val_accuracy: 0.8550\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8347 - accuracy: 0.7203 - val_loss: 0.4230 - val_accuracy: 0.8798\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6822 - accuracy: 0.7809 - val_loss: 0.3787 - val_accuracy: 0.8892\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6064 - accuracy: 0.8128 - val_loss: 0.3528 - val_accuracy: 0.8937\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5594 - accuracy: 0.8278 - val_loss: 0.3378 - val_accuracy: 0.8989\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5244 - accuracy: 0.8391 - val_loss: 0.3249 - val_accuracy: 0.9028\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5009 - accuracy: 0.8454 - val_loss: 0.3145 - val_accuracy: 0.9073\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.8519 - val_loss: 0.3063 - val_accuracy: 0.9088\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4738 - accuracy: 0.8572 - val_loss: 0.2988 - val_accuracy: 0.9127\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8620 - val_loss: 0.2926 - val_accuracy: 0.9144\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4411 - accuracy: 0.8675 - val_loss: 0.2873 - val_accuracy: 0.9158\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.8670 - val_loss: 0.2803 - val_accuracy: 0.9167\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4157 - accuracy: 0.8758 - val_loss: 0.2762 - val_accuracy: 0.9182\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4035 - accuracy: 0.8754 - val_loss: 0.2713 - val_accuracy: 0.9194\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3964 - accuracy: 0.8827 - val_loss: 0.2661 - val_accuracy: 0.9212\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3875 - accuracy: 0.8838 - val_loss: 0.2612 - val_accuracy: 0.9218\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3821 - accuracy: 0.8848 - val_loss: 0.2566 - val_accuracy: 0.9230\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3639 - accuracy: 0.8906 - val_loss: 0.2536 - val_accuracy: 0.9243\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3671 - accuracy: 0.8908 - val_loss: 0.2484 - val_accuracy: 0.9262\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3564 - accuracy: 0.8921 - val_loss: 0.2469 - val_accuracy: 0.9268\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3566 - accuracy: 0.8949 - val_loss: 0.2409 - val_accuracy: 0.9274\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3554 - accuracy: 0.8934 - val_loss: 0.2390 - val_accuracy: 0.9294\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8961 - val_loss: 0.2339 - val_accuracy: 0.9290\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.9016 - val_loss: 0.2299 - val_accuracy: 0.9315\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.9021 - val_loss: 0.2279 - val_accuracy: 0.9325\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3167 - accuracy: 0.9052 - val_loss: 0.2253 - val_accuracy: 0.9332\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.9078 - val_loss: 0.2237 - val_accuracy: 0.9327\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.9056 - val_loss: 0.2217 - val_accuracy: 0.9338\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3085 - accuracy: 0.9080 - val_loss: 0.2200 - val_accuracy: 0.9352\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.9105 - val_loss: 0.2152 - val_accuracy: 0.9372\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.9111 - val_loss: 0.2141 - val_accuracy: 0.9373\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2922 - accuracy: 0.9099 - val_loss: 0.2120 - val_accuracy: 0.9378\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2910 - accuracy: 0.9131 - val_loss: 0.2109 - val_accuracy: 0.9377\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.9125 - val_loss: 0.2075 - val_accuracy: 0.9392\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2822 - accuracy: 0.9150 - val_loss: 0.2069 - val_accuracy: 0.9388\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2801 - accuracy: 0.9159 - val_loss: 0.2043 - val_accuracy: 0.9394\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2674 - accuracy: 0.9217 - val_loss: 0.2020 - val_accuracy: 0.9405\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2723 - accuracy: 0.9167 - val_loss: 0.2017 - val_accuracy: 0.9396\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2728 - accuracy: 0.9167 - val_loss: 0.1989 - val_accuracy: 0.9411\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2564 - accuracy: 0.9214 - val_loss: 0.1973 - val_accuracy: 0.9420\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2621 - accuracy: 0.9205 - val_loss: 0.1967 - val_accuracy: 0.9417\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2548 - accuracy: 0.9220 - val_loss: 0.1948 - val_accuracy: 0.9430\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2581 - accuracy: 0.9213 - val_loss: 0.1917 - val_accuracy: 0.9429\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.9243 - val_loss: 0.1909 - val_accuracy: 0.9438\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2448 - accuracy: 0.9257 - val_loss: 0.1909 - val_accuracy: 0.9432\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2566 - accuracy: 0.9249 - val_loss: 0.1882 - val_accuracy: 0.9439\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2425 - accuracy: 0.9233 - val_loss: 0.1872 - val_accuracy: 0.9437\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2489 - accuracy: 0.9242 - val_loss: 0.1866 - val_accuracy: 0.9448\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2347 - accuracy: 0.9295 - val_loss: 0.1851 - val_accuracy: 0.9447\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2370 - accuracy: 0.9274 - val_loss: 0.1839 - val_accuracy: 0.9451\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8379 - accuracy: 0.4710 - val_loss: 0.4130 - val_accuracy: 0.8715\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8020 - accuracy: 0.7498 - val_loss: 0.3734 - val_accuracy: 0.8865\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6719 - accuracy: 0.7929 - val_loss: 0.3489 - val_accuracy: 0.8960\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6180 - accuracy: 0.8091 - val_loss: 0.3327 - val_accuracy: 0.8996\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5601 - accuracy: 0.8286 - val_loss: 0.3223 - val_accuracy: 0.9028\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.8346 - val_loss: 0.3151 - val_accuracy: 0.9049\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5056 - accuracy: 0.8460 - val_loss: 0.3059 - val_accuracy: 0.9069\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4850 - accuracy: 0.8507 - val_loss: 0.3022 - val_accuracy: 0.9089\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4723 - accuracy: 0.8574 - val_loss: 0.2975 - val_accuracy: 0.9107\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.8601 - val_loss: 0.2924 - val_accuracy: 0.9134\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4392 - accuracy: 0.8662 - val_loss: 0.2856 - val_accuracy: 0.9138\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4379 - accuracy: 0.8681 - val_loss: 0.2806 - val_accuracy: 0.9156\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4265 - accuracy: 0.8702 - val_loss: 0.2781 - val_accuracy: 0.9153\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4173 - accuracy: 0.8730 - val_loss: 0.2726 - val_accuracy: 0.9170\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - accuracy: 0.8780 - val_loss: 0.2699 - val_accuracy: 0.9178\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3977 - accuracy: 0.8825 - val_loss: 0.2666 - val_accuracy: 0.9202\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3928 - accuracy: 0.8814 - val_loss: 0.2613 - val_accuracy: 0.9213\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3891 - accuracy: 0.8827 - val_loss: 0.2588 - val_accuracy: 0.9209\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3788 - accuracy: 0.8851 - val_loss: 0.2581 - val_accuracy: 0.9213\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3715 - accuracy: 0.8863 - val_loss: 0.2521 - val_accuracy: 0.9240\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3606 - accuracy: 0.8894 - val_loss: 0.2496 - val_accuracy: 0.9240\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8922 - val_loss: 0.2470 - val_accuracy: 0.9246\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3545 - accuracy: 0.8920 - val_loss: 0.2435 - val_accuracy: 0.9256\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3449 - accuracy: 0.8958 - val_loss: 0.2403 - val_accuracy: 0.9275\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3468 - accuracy: 0.8962 - val_loss: 0.2394 - val_accuracy: 0.9270\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8983 - val_loss: 0.2357 - val_accuracy: 0.9281\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3289 - accuracy: 0.9007 - val_loss: 0.2326 - val_accuracy: 0.9291\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8982 - val_loss: 0.2311 - val_accuracy: 0.9306\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.9009 - val_loss: 0.2306 - val_accuracy: 0.9302\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.9025 - val_loss: 0.2267 - val_accuracy: 0.9312\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3070 - accuracy: 0.9067 - val_loss: 0.2247 - val_accuracy: 0.9317\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3124 - accuracy: 0.9068 - val_loss: 0.2230 - val_accuracy: 0.9323\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3051 - accuracy: 0.9085 - val_loss: 0.2232 - val_accuracy: 0.9327\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3101 - accuracy: 0.9074 - val_loss: 0.2218 - val_accuracy: 0.9336\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2973 - accuracy: 0.9090 - val_loss: 0.2186 - val_accuracy: 0.9333\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2941 - accuracy: 0.9108 - val_loss: 0.2165 - val_accuracy: 0.9345\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.9107 - val_loss: 0.2171 - val_accuracy: 0.9338\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.9103 - val_loss: 0.2143 - val_accuracy: 0.9354\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2886 - accuracy: 0.9110 - val_loss: 0.2130 - val_accuracy: 0.9361\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2887 - accuracy: 0.9111 - val_loss: 0.2111 - val_accuracy: 0.9360\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2798 - accuracy: 0.9170 - val_loss: 0.2079 - val_accuracy: 0.9366\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.9144 - val_loss: 0.2082 - val_accuracy: 0.9374\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.9161 - val_loss: 0.2061 - val_accuracy: 0.9382\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.9168 - val_loss: 0.2048 - val_accuracy: 0.9386\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2735 - accuracy: 0.9178 - val_loss: 0.2027 - val_accuracy: 0.9387\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2693 - accuracy: 0.9183 - val_loss: 0.2030 - val_accuracy: 0.9384\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.9186 - val_loss: 0.2013 - val_accuracy: 0.9397\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2647 - accuracy: 0.9198 - val_loss: 0.2021 - val_accuracy: 0.9398\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2602 - accuracy: 0.9210 - val_loss: 0.1995 - val_accuracy: 0.9398\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2614 - accuracy: 0.9217 - val_loss: 0.1980 - val_accuracy: 0.9408\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.2645 - accuracy: 0.1628 - val_loss: 1.9478 - val_accuracy: 0.5447\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7923 - accuracy: 0.4444 - val_loss: 0.8913 - val_accuracy: 0.7869\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1166 - accuracy: 0.6358 - val_loss: 0.5837 - val_accuracy: 0.8429\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8436 - accuracy: 0.7327 - val_loss: 0.4754 - val_accuracy: 0.8695\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7115 - accuracy: 0.7805 - val_loss: 0.4207 - val_accuracy: 0.8816\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6474 - accuracy: 0.8065 - val_loss: 0.3847 - val_accuracy: 0.8897\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5940 - accuracy: 0.8233 - val_loss: 0.3594 - val_accuracy: 0.8953\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5477 - accuracy: 0.8366 - val_loss: 0.3414 - val_accuracy: 0.9001\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5217 - accuracy: 0.8472 - val_loss: 0.3258 - val_accuracy: 0.9032\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4886 - accuracy: 0.8553 - val_loss: 0.3134 - val_accuracy: 0.9085\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4628 - accuracy: 0.8638 - val_loss: 0.3019 - val_accuracy: 0.9108\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4512 - accuracy: 0.8695 - val_loss: 0.2902 - val_accuracy: 0.9148\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4281 - accuracy: 0.8760 - val_loss: 0.2805 - val_accuracy: 0.9170\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4146 - accuracy: 0.8809 - val_loss: 0.2715 - val_accuracy: 0.9203\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8835 - val_loss: 0.2652 - val_accuracy: 0.9214\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3818 - accuracy: 0.8909 - val_loss: 0.2579 - val_accuracy: 0.9241\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8910 - val_loss: 0.2494 - val_accuracy: 0.9262\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3663 - accuracy: 0.8952 - val_loss: 0.2445 - val_accuracy: 0.9276\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8998 - val_loss: 0.2377 - val_accuracy: 0.9291\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3342 - accuracy: 0.9053 - val_loss: 0.2321 - val_accuracy: 0.9306\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.9072 - val_loss: 0.2289 - val_accuracy: 0.9315\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3249 - accuracy: 0.9057 - val_loss: 0.2229 - val_accuracy: 0.9329\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3123 - accuracy: 0.9096 - val_loss: 0.2177 - val_accuracy: 0.9343\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3072 - accuracy: 0.9126 - val_loss: 0.2140 - val_accuracy: 0.9347\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2916 - accuracy: 0.9175 - val_loss: 0.2088 - val_accuracy: 0.9372\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2893 - accuracy: 0.9176 - val_loss: 0.2039 - val_accuracy: 0.9381\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2817 - accuracy: 0.9205 - val_loss: 0.2014 - val_accuracy: 0.9388\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.9228 - val_loss: 0.1963 - val_accuracy: 0.9398\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2601 - accuracy: 0.9279 - val_loss: 0.1925 - val_accuracy: 0.9408\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2625 - accuracy: 0.9259 - val_loss: 0.1904 - val_accuracy: 0.9416\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2473 - accuracy: 0.9283 - val_loss: 0.1867 - val_accuracy: 0.9424\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2472 - accuracy: 0.9286 - val_loss: 0.1848 - val_accuracy: 0.9432\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2426 - accuracy: 0.9312 - val_loss: 0.1819 - val_accuracy: 0.9442\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2306 - accuracy: 0.9354 - val_loss: 0.1802 - val_accuracy: 0.9438\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.9344 - val_loss: 0.1774 - val_accuracy: 0.9459\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2321 - accuracy: 0.9334 - val_loss: 0.1747 - val_accuracy: 0.9455\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9390 - val_loss: 0.1724 - val_accuracy: 0.9464\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2131 - accuracy: 0.9383 - val_loss: 0.1710 - val_accuracy: 0.9471\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2113 - accuracy: 0.9388 - val_loss: 0.1687 - val_accuracy: 0.9477\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2100 - accuracy: 0.9409 - val_loss: 0.1676 - val_accuracy: 0.9486\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2058 - accuracy: 0.9405 - val_loss: 0.1647 - val_accuracy: 0.9495\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2056 - accuracy: 0.9413 - val_loss: 0.1641 - val_accuracy: 0.9492\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2032 - accuracy: 0.9424 - val_loss: 0.1614 - val_accuracy: 0.9504\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1956 - accuracy: 0.9436 - val_loss: 0.1598 - val_accuracy: 0.9506\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1935 - accuracy: 0.9455 - val_loss: 0.1579 - val_accuracy: 0.9514\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1802 - accuracy: 0.9494 - val_loss: 0.1577 - val_accuracy: 0.9513\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1814 - accuracy: 0.9480 - val_loss: 0.1554 - val_accuracy: 0.9532\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1718 - accuracy: 0.9503 - val_loss: 0.1555 - val_accuracy: 0.9528\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1712 - accuracy: 0.9514 - val_loss: 0.1539 - val_accuracy: 0.9541\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1743 - accuracy: 0.9488 - val_loss: 0.1522 - val_accuracy: 0.9548\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 4ms/step - loss: 2.2734 - accuracy: 0.1666 - val_loss: 2.1211 - val_accuracy: 0.5238\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.0283 - accuracy: 0.3945 - val_loss: 1.4445 - val_accuracy: 0.6334\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4333 - accuracy: 0.5445 - val_loss: 0.8266 - val_accuracy: 0.7929\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0397 - accuracy: 0.6636 - val_loss: 0.6115 - val_accuracy: 0.8426\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8578 - accuracy: 0.7286 - val_loss: 0.5150 - val_accuracy: 0.8617\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7488 - accuracy: 0.7689 - val_loss: 0.4578 - val_accuracy: 0.8761\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6721 - accuracy: 0.7961 - val_loss: 0.4211 - val_accuracy: 0.8825\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6235 - accuracy: 0.8137 - val_loss: 0.3960 - val_accuracy: 0.8873\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5826 - accuracy: 0.8279 - val_loss: 0.3755 - val_accuracy: 0.8917\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5528 - accuracy: 0.8371 - val_loss: 0.3609 - val_accuracy: 0.8967\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5333 - accuracy: 0.8427 - val_loss: 0.3465 - val_accuracy: 0.8991\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5129 - accuracy: 0.8519 - val_loss: 0.3352 - val_accuracy: 0.9031\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4805 - accuracy: 0.8576 - val_loss: 0.3251 - val_accuracy: 0.9067\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4744 - accuracy: 0.8603 - val_loss: 0.3157 - val_accuracy: 0.9087\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4522 - accuracy: 0.8672 - val_loss: 0.3070 - val_accuracy: 0.9106\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4299 - accuracy: 0.8750 - val_loss: 0.3006 - val_accuracy: 0.9124\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4244 - accuracy: 0.8753 - val_loss: 0.2916 - val_accuracy: 0.9141\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4229 - accuracy: 0.8769 - val_loss: 0.2852 - val_accuracy: 0.9155\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4132 - accuracy: 0.8813 - val_loss: 0.2804 - val_accuracy: 0.9173\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3971 - accuracy: 0.8838 - val_loss: 0.2727 - val_accuracy: 0.9181\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3847 - accuracy: 0.8891 - val_loss: 0.2677 - val_accuracy: 0.9210\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3789 - accuracy: 0.8911 - val_loss: 0.2622 - val_accuracy: 0.9213\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8910 - val_loss: 0.2569 - val_accuracy: 0.9230\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3535 - accuracy: 0.8968 - val_loss: 0.2522 - val_accuracy: 0.9248\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3562 - accuracy: 0.8959 - val_loss: 0.2463 - val_accuracy: 0.9267\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3496 - accuracy: 0.8993 - val_loss: 0.2423 - val_accuracy: 0.9275\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.9008 - val_loss: 0.2381 - val_accuracy: 0.9290\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3366 - accuracy: 0.9013 - val_loss: 0.2340 - val_accuracy: 0.9293\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3205 - accuracy: 0.9073 - val_loss: 0.2303 - val_accuracy: 0.9308\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.9061 - val_loss: 0.2260 - val_accuracy: 0.9324\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3145 - accuracy: 0.9080 - val_loss: 0.2231 - val_accuracy: 0.9334\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3022 - accuracy: 0.9136 - val_loss: 0.2191 - val_accuracy: 0.9337\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3097 - accuracy: 0.9105 - val_loss: 0.2173 - val_accuracy: 0.9335\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2927 - accuracy: 0.9149 - val_loss: 0.2131 - val_accuracy: 0.9347\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2854 - accuracy: 0.9183 - val_loss: 0.2103 - val_accuracy: 0.9362\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2881 - accuracy: 0.9161 - val_loss: 0.2069 - val_accuracy: 0.9365\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2807 - accuracy: 0.9174 - val_loss: 0.2045 - val_accuracy: 0.9371\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2717 - accuracy: 0.9208 - val_loss: 0.2013 - val_accuracy: 0.9389\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9210 - val_loss: 0.2000 - val_accuracy: 0.9381\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.9220 - val_loss: 0.1971 - val_accuracy: 0.9395\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2570 - accuracy: 0.9234 - val_loss: 0.1950 - val_accuracy: 0.9394\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2579 - accuracy: 0.9247 - val_loss: 0.1922 - val_accuracy: 0.9410\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2516 - accuracy: 0.9234 - val_loss: 0.1901 - val_accuracy: 0.9426\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2583 - accuracy: 0.9258 - val_loss: 0.1884 - val_accuracy: 0.9433\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2470 - accuracy: 0.9275 - val_loss: 0.1866 - val_accuracy: 0.9427\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2436 - accuracy: 0.9288 - val_loss: 0.1851 - val_accuracy: 0.9448\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2324 - accuracy: 0.9301 - val_loss: 0.1829 - val_accuracy: 0.9449\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2304 - accuracy: 0.9331 - val_loss: 0.1806 - val_accuracy: 0.9462\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2337 - accuracy: 0.9303 - val_loss: 0.1793 - val_accuracy: 0.9452\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2323 - accuracy: 0.9326 - val_loss: 0.1782 - val_accuracy: 0.9461\n",
            "{'loss': [1.372363805770874, 0.8165368437767029, 0.6728535294532776, 0.6032323241233826, 0.5688677430152893, 0.5299872756004333, 0.5128726959228516, 0.4951273202896118, 0.47620972990989685, 0.4684918224811554, 0.45493122935295105, 0.4421171545982361, 0.43682536482810974, 0.4211525619029999, 0.4173133969306946, 0.4107823073863983, 0.40048208832740784, 0.39494600892066956, 0.3924899399280548, 0.3847332298755646, 0.3833297789096832, 0.3755543529987335, 0.37190550565719604, 0.3644997477531433, 0.364623486995697, 0.357505738735199, 0.35087645053863525, 0.3459518551826477, 0.3432827591896057, 0.33740416169166565, 0.33446866273880005, 0.33211615681648254, 0.33014363050460815, 0.32489773631095886, 0.3214266300201416, 0.3184221684932709, 0.3142458498477936, 0.3120745122432709, 0.3082659840583801, 0.3050917685031891, 0.30382317304611206, 0.3009631931781769, 0.2959771156311035, 0.2951939105987549, 0.29094213247299194, 0.29011011123657227, 0.2848302125930786, 0.2834104001522064, 0.2815782427787781, 0.27747970819473267], 'accuracy': [0.542354166507721, 0.7412916421890259, 0.7884791493415833, 0.8151666522026062, 0.8267291784286499, 0.8386874794960022, 0.8447916507720947, 0.8502083420753479, 0.8554166555404663, 0.8592708110809326, 0.8632500171661377, 0.8668749928474426, 0.8706874847412109, 0.874916672706604, 0.8758958578109741, 0.8781458139419556, 0.8815208077430725, 0.8823958039283752, 0.882895827293396, 0.8856458067893982, 0.8865625262260437, 0.8888333439826965, 0.890375018119812, 0.8927083611488342, 0.8921666741371155, 0.8945000171661377, 0.8957708477973938, 0.898729145526886, 0.8977708220481873, 0.9008749723434448, 0.901354193687439, 0.9025416374206543, 0.9022499918937683, 0.9056041836738586, 0.9054999947547913, 0.9067916870117188, 0.9070416688919067, 0.9083958268165588, 0.9084166884422302, 0.909375011920929, 0.9114791750907898, 0.9117916822433472, 0.9134374856948853, 0.9123749732971191, 0.9144583344459534, 0.9140416383743286, 0.9155416488647461, 0.9159374833106995, 0.917062520980835, 0.9184166789054871], 'val_loss': [0.6023520827293396, 0.4527301490306854, 0.3950183391571045, 0.36759069561958313, 0.3489563763141632, 0.3369697332382202, 0.3288933038711548, 0.3222692012786865, 0.3155827522277832, 0.3111826777458191, 0.3061361014842987, 0.3012705147266388, 0.2973785102367401, 0.29421767592430115, 0.28985753655433655, 0.2874205708503723, 0.2828119397163391, 0.2830272316932678, 0.28023001551628113, 0.27763819694519043, 0.2740013897418976, 0.27067556977272034, 0.26912546157836914, 0.26683613657951355, 0.2637471556663513, 0.263489305973053, 0.26052096486091614, 0.25697755813598633, 0.2559620440006256, 0.2548482120037079, 0.25286516547203064, 0.2502604126930237, 0.24931439757347107, 0.24803267419338226, 0.24568648636341095, 0.24358561635017395, 0.24477262794971466, 0.23971520364284515, 0.24002505838871002, 0.23790156841278076, 0.23675446212291718, 0.23552000522613525, 0.23419152200222015, 0.23186036944389343, 0.2313372939825058, 0.22914384305477142, 0.22800800204277039, 0.22739170491695404, 0.22636598348617554, 0.22395335137844086], 'val_accuracy': [0.8430833220481873, 0.8728333115577698, 0.8854166865348816, 0.890916645526886, 0.8971666693687439, 0.8990833163261414, 0.9014166593551636, 0.9040833115577698, 0.9071666598320007, 0.9085000157356262, 0.9108333587646484, 0.9121666550636292, 0.9128333330154419, 0.9153333306312561, 0.9159166812896729, 0.9169999957084656, 0.9172499775886536, 0.9177500009536743, 0.918583333492279, 0.9192500114440918, 0.9199166893959045, 0.9205833077430725, 0.9211666584014893, 0.921583354473114, 0.9224166870117188, 0.9227499961853027, 0.9240000247955322, 0.925166666507721, 0.9255833625793457, 0.9259166717529297, 0.9269166588783264, 0.9267500042915344, 0.9281666874885559, 0.9289166927337646, 0.9294166564941406, 0.9288333058357239, 0.9300833344459534, 0.9303333163261414, 0.9310833215713501, 0.9325000047683716, 0.9330000281333923, 0.9325000047683716, 0.9330000281333923, 0.9336666464805603, 0.9333333373069763, 0.9349166750907898, 0.9355833530426025, 0.9356666803359985, 0.9351666569709778, 0.9356666803359985]}\n",
            "{'loss': [2.159947395324707, 1.5502105951309204, 1.116816759109497, 0.8963947892189026, 0.7734526991844177, 0.6865757703781128, 0.6264168620109558, 0.5785170197486877, 0.5365610122680664, 0.5066630244255066, 0.4767926037311554, 0.45648425817489624, 0.43109944462776184, 0.40901872515678406, 0.4002336859703064, 0.3755221366882324, 0.364558607339859, 0.3524702489376068, 0.3363340497016907, 0.32559794187545776, 0.3170583248138428, 0.3063795864582062, 0.2917976379394531, 0.28548333048820496, 0.2773315906524658, 0.2656126916408539, 0.2587718665599823, 0.25076064467430115, 0.24505572021007538, 0.23529992997646332, 0.2293022871017456, 0.22615456581115723, 0.21530430018901825, 0.21194052696228027, 0.2030867487192154, 0.2010330855846405, 0.19278298318386078, 0.18913815915584564, 0.18271340429782867, 0.1820097714662552, 0.17682752013206482, 0.16997255384922028, 0.1644875854253769, 0.16173140704631805, 0.15582624077796936, 0.15284663438796997, 0.14768578112125397, 0.14489196240901947, 0.14128464460372925, 0.14024397730827332], 'accuracy': [0.2175000011920929, 0.4646041691303253, 0.6177708506584167, 0.7027708292007446, 0.750041663646698, 0.7854791879653931, 0.8102083206176758, 0.8258958458900452, 0.840499997138977, 0.8534583449363708, 0.8634166717529297, 0.870395839214325, 0.8769583106040955, 0.882687509059906, 0.887624979019165, 0.8932499885559082, 0.8979791402816772, 0.901562511920929, 0.9072708487510681, 0.909208357334137, 0.9131458401679993, 0.9142500162124634, 0.9212083220481873, 0.9225000143051147, 0.9230625033378601, 0.9274166822433472, 0.9290624856948853, 0.9320416450500488, 0.9333124756813049, 0.9358541369438171, 0.9384375214576721, 0.9379166960716248, 0.9421250224113464, 0.9430833458900452, 0.9439791440963745, 0.9466458559036255, 0.9479374885559082, 0.9478750228881836, 0.9499791860580444, 0.9507083296775818, 0.9517291784286499, 0.9539583325386047, 0.9546041488647461, 0.9565416574478149, 0.9574791789054871, 0.957937479019165, 0.9597083330154419, 0.9605833292007446, 0.9609583616256714, 0.9612500071525574], 'val_loss': [1.6619617938995361, 0.891658365726471, 0.6074750423431396, 0.4858720004558563, 0.4172552525997162, 0.3757697343826294, 0.34523552656173706, 0.3220153748989105, 0.3044312000274658, 0.28941118717193604, 0.2780602276325226, 0.26367267966270447, 0.25473421812057495, 0.24557846784591675, 0.23644642531871796, 0.22828279435634613, 0.22263675928115845, 0.21558156609535217, 0.2116864025592804, 0.2064218968153, 0.20126305520534515, 0.19816064834594727, 0.19437754154205322, 0.18964235484600067, 0.18686062097549438, 0.18322698771953583, 0.17981596291065216, 0.17799077928066254, 0.17592407763004303, 0.17451399564743042, 0.17076095938682556, 0.16966579854488373, 0.16856221854686737, 0.16745474934577942, 0.16474002599716187, 0.16244155168533325, 0.16066060960292816, 0.1602688729763031, 0.159901961684227, 0.15683895349502563, 0.1566345989704132, 0.15601645410060883, 0.15523728728294373, 0.1564358025789261, 0.15456663072109222, 0.15390191972255707, 0.15194210410118103, 0.15230709314346313, 0.15174922347068787, 0.15116363763809204], 'val_accuracy': [0.6209999918937683, 0.7746666669845581, 0.8344166874885559, 0.8631666898727417, 0.8803333044052124, 0.8899166584014893, 0.8985000252723694, 0.9044166803359985, 0.9085833430290222, 0.9116666913032532, 0.9175000190734863, 0.9195833206176758, 0.9234166741371155, 0.9266666769981384, 0.9299166798591614, 0.9319999814033508, 0.9337499737739563, 0.9363333582878113, 0.9364166855812073, 0.9386666417121887, 0.940416693687439, 0.9412500262260437, 0.9427499771118164, 0.9440833330154419, 0.9446666836738586, 0.9456666707992554, 0.9475833177566528, 0.9488333463668823, 0.9487500190734863, 0.9495833516120911, 0.9503333568572998, 0.9514166712760925, 0.9524166584014893, 0.9516666531562805, 0.953083336353302, 0.953249990940094, 0.9543333053588867, 0.9545000195503235, 0.9545000195503235, 0.9546666741371155, 0.9551666378974915, 0.9555000066757202, 0.9570833444595337, 0.9568333625793457, 0.9576666951179504, 0.9577500224113464, 0.9579166769981384, 0.9583333134651184, 0.9592499732971191, 0.9594166874885559]}\n",
            "{'loss': [1.977102518081665, 1.2337852716445923, 0.9009888768196106, 0.7447819113731384, 0.6499784588813782, 0.5935230255126953, 0.5447162985801697, 0.5122202038764954, 0.4820789694786072, 0.4626564681529999, 0.43444034457206726, 0.4207269549369812, 0.40283435583114624, 0.38998839259147644, 0.3746253550052643, 0.3617948293685913, 0.3497583866119385, 0.33829134702682495, 0.33119481801986694, 0.31801679730415344, 0.30868032574653625, 0.3027200400829315, 0.29640498757362366, 0.2855946719646454, 0.2806641757488251, 0.27602511644363403, 0.2692483365535736, 0.2593420743942261, 0.255545049905777, 0.2519752085208893, 0.2445795089006424, 0.23785439133644104, 0.2360386699438095, 0.23081646859645844, 0.22889576852321625, 0.22229309380054474, 0.2148480862379074, 0.21585713326931, 0.2076254040002823, 0.20187754929065704, 0.20080801844596863, 0.19917809963226318, 0.1908252090215683, 0.19096620380878448, 0.18434560298919678, 0.1800551563501358, 0.18199212849140167, 0.17769505083560944, 0.1756373643875122, 0.17284581065177917], 'accuracy': [0.30645832419395447, 0.5865208506584167, 0.7071666717529297, 0.7628541588783264, 0.7965208292007446, 0.8190624713897705, 0.8348541855812073, 0.8472499847412109, 0.8580833077430725, 0.8618333339691162, 0.8718541860580444, 0.8766458630561829, 0.8834583163261414, 0.8854374885559082, 0.89041668176651, 0.8936458230018616, 0.8984166383743286, 0.901354193687439, 0.9043124914169312, 0.909208357334137, 0.9104791879653931, 0.9133958220481873, 0.9150624871253967, 0.9179375171661377, 0.9180833101272583, 0.9194375276565552, 0.9226041436195374, 0.9254999756813049, 0.9261875152587891, 0.9278333187103271, 0.9300000071525574, 0.9317708611488342, 0.9329583048820496, 0.9324583411216736, 0.9343541860580444, 0.9363333582878113, 0.9382083415985107, 0.9379374980926514, 0.9407708048820496, 0.9412916898727417, 0.9430000185966492, 0.942395806312561, 0.945645809173584, 0.9435833096504211, 0.9465416669845581, 0.9483333230018616, 0.9466666579246521, 0.9491249918937683, 0.9488541483879089, 0.9502500295639038], 'val_loss': [1.2314369678497314, 0.6653218865394592, 0.5054271817207336, 0.4306967258453369, 0.38550540804862976, 0.35535958409309387, 0.33667951822280884, 0.3192608952522278, 0.3003334403038025, 0.29024043679237366, 0.2807844877243042, 0.27035626769065857, 0.26068973541259766, 0.25510233640670776, 0.24712136387825012, 0.23941434919834137, 0.2351965308189392, 0.2301533967256546, 0.22516202926635742, 0.2198270708322525, 0.21582308411598206, 0.21298958361148834, 0.20797140896320343, 0.2041717767715454, 0.20258694887161255, 0.19961251318454742, 0.19685029983520508, 0.1936762034893036, 0.19235551357269287, 0.1899985522031784, 0.18729794025421143, 0.1853628158569336, 0.18414346873760223, 0.18137036263942719, 0.17949533462524414, 0.17926014959812164, 0.17576251924037933, 0.17382338643074036, 0.17458805441856384, 0.17191003262996674, 0.17073285579681396, 0.16844207048416138, 0.16784586012363434, 0.16729940474033356, 0.1654270887374878, 0.16488869488239288, 0.1634119600057602, 0.16230198740959167, 0.16196058690547943, 0.16184598207473755], 'val_accuracy': [0.7174166440963745, 0.825166642665863, 0.859499990940094, 0.8776666522026062, 0.887666642665863, 0.8970833420753479, 0.9003333449363708, 0.905916690826416, 0.9102500081062317, 0.9135833382606506, 0.9168333411216736, 0.9208333492279053, 0.9238333106040955, 0.9239166378974915, 0.9280833601951599, 0.9290833473205566, 0.9300000071525574, 0.9319999814033508, 0.9329166412353516, 0.9352499842643738, 0.9355000257492065, 0.9361666440963745, 0.937749981880188, 0.9402499794960022, 0.940666675567627, 0.9417499899864197, 0.9415000081062317, 0.9434999823570251, 0.9436666369438171, 0.9441666603088379, 0.9462500214576721, 0.9462500214576721, 0.9459999799728394, 0.9475833177566528, 0.9471666812896729, 0.9480833411216736, 0.9487500190734863, 0.9490000009536743, 0.9480000138282776, 0.949999988079071, 0.9495833516120911, 0.9506666660308838, 0.9511666893959045, 0.9509999752044678, 0.9519166946411133, 0.9518333077430725, 0.9526666402816772, 0.952833354473114, 0.9524166584014893, 0.9520000219345093]}\n",
            "{'loss': [1.3433654308319092, 0.7892165780067444, 0.6604716777801514, 0.5951785445213318, 0.5584101676940918, 0.5223425626754761, 0.5057254433631897, 0.4787226617336273, 0.4665496051311493, 0.44822055101394653, 0.4394817650318146, 0.4278661012649536, 0.41435757279396057, 0.4053555428981781, 0.39661937952041626, 0.38802507519721985, 0.38211435079574585, 0.3683324456214905, 0.3650865852832794, 0.35894110798835754, 0.35262784361839294, 0.347837895154953, 0.3430459797382355, 0.3322988450527191, 0.3276032507419586, 0.32018017768859863, 0.31425413489341736, 0.31393179297447205, 0.3093849718570709, 0.29895246028900146, 0.29656049609184265, 0.29283544421195984, 0.2883208692073822, 0.2847355008125305, 0.2849751114845276, 0.2801688611507416, 0.27105432748794556, 0.26962167024612427, 0.27083611488342285, 0.2626478970050812, 0.2588768005371094, 0.25849494338035583, 0.25825047492980957, 0.2517586052417755, 0.24940840899944305, 0.25101587176322937, 0.24321898818016052, 0.24150468409061432, 0.24132516980171204, 0.23801228404045105], 'accuracy': [0.5417500138282776, 0.7386041879653931, 0.7889583110809326, 0.8144583106040955, 0.8287083506584167, 0.840458333492279, 0.8450000286102295, 0.8542708158493042, 0.8581041693687439, 0.863937497138977, 0.8680833578109741, 0.8693125247955322, 0.8759375214576721, 0.8769583106040955, 0.8818749785423279, 0.8851041793823242, 0.8849999904632568, 0.8888541460037231, 0.8910416960716248, 0.8917083144187927, 0.8949791789054871, 0.895270824432373, 0.8964583277702332, 0.9006249904632568, 0.9011458158493042, 0.9036874771118164, 0.9054999947547913, 0.9057291746139526, 0.9078750014305115, 0.9097291827201843, 0.9103958606719971, 0.9116666913032532, 0.9125208258628845, 0.9130625128746033, 0.9135208129882812, 0.9160833358764648, 0.9193958044052124, 0.918833315372467, 0.9180416464805603, 0.9204166531562805, 0.9222291707992554, 0.9210208058357239, 0.921999990940094, 0.9236875176429749, 0.9246666431427002, 0.9254375100135803, 0.9246666431427002, 0.9268541932106018, 0.9271875023841858, 0.9278541803359985], 'val_loss': [0.54698646068573, 0.42301109433174133, 0.3786713778972626, 0.3528176546096802, 0.33776310086250305, 0.3249175250530243, 0.31445008516311646, 0.30633991956710815, 0.298846036195755, 0.29256001114845276, 0.28726524114608765, 0.28029918670654297, 0.2761826515197754, 0.27125421166419983, 0.26614755392074585, 0.26123887300491333, 0.256639301776886, 0.25363367795944214, 0.2483779639005661, 0.24691025912761688, 0.24086421728134155, 0.23898950219154358, 0.23392702639102936, 0.2299492210149765, 0.22788095474243164, 0.225315660238266, 0.22365963459014893, 0.22169947624206543, 0.21999900043010712, 0.21517901122570038, 0.2141234129667282, 0.2119711935520172, 0.21085292100906372, 0.2075309455394745, 0.2069404572248459, 0.20425036549568176, 0.20199653506278992, 0.2017143964767456, 0.1988649219274521, 0.1973007172346115, 0.19671474397182465, 0.19475644826889038, 0.19165880978107452, 0.19086767733097076, 0.190861776471138, 0.18817457556724548, 0.18717999756336212, 0.18659254908561707, 0.1850716918706894, 0.1839124709367752], 'val_accuracy': [0.8550000190734863, 0.8798333406448364, 0.8892499804496765, 0.893666684627533, 0.8989166617393494, 0.9028333425521851, 0.9073333144187927, 0.9088333249092102, 0.9126666784286499, 0.9144166707992554, 0.9157500267028809, 0.9166666865348816, 0.9181666374206543, 0.9194166660308838, 0.9212499856948853, 0.921833336353302, 0.9229999780654907, 0.9243333339691162, 0.9261666536331177, 0.9267500042915344, 0.9274166822433472, 0.9294166564941406, 0.9290000200271606, 0.9315000176429749, 0.9325000047683716, 0.9331666827201843, 0.9326666593551636, 0.9338333606719971, 0.9352499842643738, 0.937166690826416, 0.937333345413208, 0.937833309173584, 0.937749981880188, 0.9391666650772095, 0.9387500286102295, 0.9394166469573975, 0.940500020980835, 0.9395833611488342, 0.9410833120346069, 0.9419999718666077, 0.9417499899864197, 0.9430000185966492, 0.9429166913032532, 0.9438333511352539, 0.9431666731834412, 0.9439166784286499, 0.9436666369438171, 0.9447500109672546, 0.9446666836738586, 0.9450833201408386]}\n",
            "{'loss': [1.30808424949646, 0.7706721425056458, 0.6554964780807495, 0.6008186340332031, 0.5606344938278198, 0.5265187621116638, 0.5019262433052063, 0.479611337184906, 0.46818411350250244, 0.4515571594238281, 0.4384130537509918, 0.4356588125228882, 0.41875556111335754, 0.41486498713493347, 0.40533193945884705, 0.3966227173805237, 0.3864792585372925, 0.38703709840774536, 0.37329328060150146, 0.36886727809906006, 0.3606918454170227, 0.35654398798942566, 0.3514033257961273, 0.3467755615711212, 0.34156328439712524, 0.3332310616970062, 0.33631184697151184, 0.3320755958557129, 0.3239173889160156, 0.31716179847717285, 0.3152863681316376, 0.3171987533569336, 0.3054164946079254, 0.30567264556884766, 0.30046266317367554, 0.29861417412757874, 0.2939547598361969, 0.29686468839645386, 0.2871180772781372, 0.2846444249153137, 0.2829858660697937, 0.28150156140327454, 0.2782416045665741, 0.2746802270412445, 0.2755541205406189, 0.2683520019054413, 0.2666327655315399, 0.263939768075943, 0.2625431716442108, 0.2619909942150116], 'accuracy': [0.6022291779518127, 0.7612500190734863, 0.7965624928474426, 0.8148333430290222, 0.8282708525657654, 0.8375833630561829, 0.8480208516120911, 0.8530208468437195, 0.8572916388511658, 0.8613749742507935, 0.8658958077430725, 0.8671875, 0.8717708587646484, 0.8740000128746033, 0.8789583444595337, 0.8815208077430725, 0.88260418176651, 0.8842499852180481, 0.8859583139419556, 0.8870208263397217, 0.8889583349227905, 0.8909375071525574, 0.8934375047683716, 0.8956249952316284, 0.8960416913032532, 0.8978750109672546, 0.8975625038146973, 0.8982916474342346, 0.901645839214325, 0.9039583206176758, 0.9045416712760925, 0.9046458601951599, 0.9077708125114441, 0.9079999923706055, 0.9088333249092102, 0.9085000157356262, 0.9104583263397217, 0.9112499952316284, 0.9114791750907898, 0.913770854473114, 0.9156666398048401, 0.9141666889190674, 0.9150416851043701, 0.9159791469573975, 0.9179166555404663, 0.9178333282470703, 0.918874979019165, 0.9201458096504211, 0.9196458458900452, 0.9208750128746033], 'val_loss': [0.4130074083805084, 0.373384028673172, 0.3489179015159607, 0.33269432187080383, 0.32234519720077515, 0.31511104106903076, 0.30590373277664185, 0.3022293746471405, 0.29745200276374817, 0.2923881411552429, 0.2855876386165619, 0.280624121427536, 0.2781452536582947, 0.27257344126701355, 0.2698902487754822, 0.2666357755661011, 0.2612636387348175, 0.25877416133880615, 0.2580958902835846, 0.2520960569381714, 0.24961334466934204, 0.247038796544075, 0.24345053732395172, 0.24029988050460815, 0.23935982584953308, 0.23566249012947083, 0.23258119821548462, 0.2311469316482544, 0.23057705163955688, 0.2266666293144226, 0.22468723356723785, 0.22303098440170288, 0.22320961952209473, 0.22176527976989746, 0.21855786442756653, 0.21649101376533508, 0.21713456511497498, 0.21429581940174103, 0.212951198220253, 0.21112896502017975, 0.2078884094953537, 0.20816218852996826, 0.20611082017421722, 0.20480354130268097, 0.20271489024162292, 0.20302844047546387, 0.20129656791687012, 0.20205263793468475, 0.19954654574394226, 0.1980138123035431], 'val_accuracy': [0.8715000152587891, 0.8865000009536743, 0.8960000276565552, 0.8995833396911621, 0.9028333425521851, 0.9049166440963745, 0.9069166779518127, 0.9089166522026062, 0.9107499718666077, 0.9134166836738586, 0.9138333201408386, 0.9155833125114441, 0.9153333306312561, 0.9169999957084656, 0.9177500009536743, 0.9202499985694885, 0.9213333129882812, 0.9209166765213013, 0.9213333129882812, 0.9240000247955322, 0.9240000247955322, 0.9245833158493042, 0.9255833625793457, 0.9275000095367432, 0.9269999861717224, 0.9280833601951599, 0.9290833473205566, 0.9305833578109741, 0.9302499890327454, 0.9312499761581421, 0.9317499995231628, 0.9323333501815796, 0.9327499866485596, 0.9335833191871643, 0.9332500100135803, 0.934499979019165, 0.9338333606719971, 0.9354166388511658, 0.9360833168029785, 0.9359999895095825, 0.9365833401679993, 0.937416672706604, 0.9381666779518127, 0.9385833144187927, 0.9386666417121887, 0.9384166598320007, 0.9396666884422302, 0.9398333430290222, 0.9398333430290222, 0.940833330154419]}\n",
            "{'loss': [2.1971986293792725, 1.58153235912323, 1.0289819240570068, 0.8133593201637268, 0.6949465274810791, 0.6303638815879822, 0.5807535648345947, 0.5442615747451782, 0.5124062895774841, 0.48490938544273376, 0.4626619815826416, 0.44649240374565125, 0.42944955825805664, 0.4103582799434662, 0.3967309892177582, 0.381183922290802, 0.3679761290550232, 0.3570079207420349, 0.34398698806762695, 0.3350858986377716, 0.3280254602432251, 0.3187297284603119, 0.3054119050502777, 0.29967939853668213, 0.2893489897251129, 0.2842848598957062, 0.27701377868652344, 0.2684084475040436, 0.2618171274662018, 0.26068761944770813, 0.24931836128234863, 0.24499578773975372, 0.2379792481660843, 0.2340918332338333, 0.22941626608371735, 0.22582106292247772, 0.2191309630870819, 0.21446624398231506, 0.21084624528884888, 0.20892316102981567, 0.204570010304451, 0.1995791494846344, 0.19522324204444885, 0.1916469931602478, 0.1882191002368927, 0.1845611333847046, 0.1818905472755432, 0.17346882820129395, 0.17176900804042816, 0.1732238531112671], 'accuracy': [0.24027083814144135, 0.5041666626930237, 0.6666041612625122, 0.7442916631698608, 0.7849166393280029, 0.8108124732971191, 0.8255000114440918, 0.8382083177566528, 0.8504166603088379, 0.8566250205039978, 0.8645625114440918, 0.8704583048820496, 0.8758958578109741, 0.8817291855812073, 0.8840208053588867, 0.8901666402816772, 0.8932499885559082, 0.8967916369438171, 0.9006041884422302, 0.9042916893959045, 0.906208336353302, 0.9085833430290222, 0.9116250276565552, 0.9141250252723694, 0.9174166917800903, 0.9178958535194397, 0.921875, 0.9241874814033508, 0.9257500171661377, 0.9254791736602783, 0.9277708530426025, 0.929604172706604, 0.9324374794960022, 0.9337916374206543, 0.9343125224113464, 0.9347291588783264, 0.9372708201408386, 0.9383124709129333, 0.9392083287239075, 0.9414166808128357, 0.9417916536331177, 0.9430624842643738, 0.9441249966621399, 0.9447500109672546, 0.9462916851043701, 0.9479374885559082, 0.9478333592414856, 0.9492708444595337, 0.9501875042915344, 0.9494166374206543], 'val_loss': [1.9478275775909424, 0.8912937641143799, 0.5837304592132568, 0.4753551483154297, 0.4206746816635132, 0.3847098648548126, 0.35940760374069214, 0.3413502275943756, 0.3257719874382019, 0.3134457767009735, 0.30190855264663696, 0.2902315557003021, 0.28047874569892883, 0.2714950442314148, 0.2652027904987335, 0.25794440507888794, 0.2494182288646698, 0.24449501931667328, 0.23774220049381256, 0.23213385045528412, 0.2288743555545807, 0.22286130487918854, 0.21770526468753815, 0.21395401656627655, 0.20878255367279053, 0.20385712385177612, 0.20135241746902466, 0.19630318880081177, 0.19248440861701965, 0.19035081565380096, 0.1867155283689499, 0.18480336666107178, 0.18188083171844482, 0.18019694089889526, 0.17741355299949646, 0.174697607755661, 0.172420933842659, 0.17098703980445862, 0.16874659061431885, 0.16760297119617462, 0.1646880954504013, 0.16411881148815155, 0.1613648533821106, 0.15978963673114777, 0.15792366862297058, 0.1576651781797409, 0.15542270243167877, 0.15550637245178223, 0.15391771495342255, 0.15221159160137177], 'val_accuracy': [0.5446666479110718, 0.7869166731834412, 0.8429166674613953, 0.8694999814033508, 0.8815833330154419, 0.8896666765213013, 0.8952500224113464, 0.9000833630561829, 0.903166651725769, 0.9085000157356262, 0.9108333587646484, 0.9148333072662354, 0.9169999957084656, 0.9203333258628845, 0.9214166402816772, 0.9240833520889282, 0.9261666536331177, 0.9275833368301392, 0.9290833473205566, 0.9305833578109741, 0.9315000176429749, 0.9329166412353516, 0.934333324432373, 0.9346666932106018, 0.937166690826416, 0.9380833506584167, 0.9388333559036255, 0.9398333430290222, 0.940750002861023, 0.9415833353996277, 0.9424166679382324, 0.9431666731834412, 0.9441666603088379, 0.9438333511352539, 0.9459166526794434, 0.9455000162124634, 0.9464166760444641, 0.9470833539962769, 0.9477499723434448, 0.9485833048820496, 0.9495000243186951, 0.9491666555404663, 0.9504166841506958, 0.9505833387374878, 0.9514166712760925, 0.9513333439826965, 0.953166663646698, 0.952833354473114, 0.9540833234786987, 0.9548333287239075]}\n",
            "{'loss': [2.2338192462921143, 1.8968862295150757, 1.3133628368377686, 0.9828510880470276, 0.8263149261474609, 0.7263469099998474, 0.6569553017616272, 0.6092799305915833, 0.577459990978241, 0.5469463467597961, 0.5231137871742249, 0.5023250579833984, 0.4830038249492645, 0.4674817621707916, 0.45261311531066895, 0.43824303150177, 0.4261611998081207, 0.4140135645866394, 0.406912237405777, 0.39262449741363525, 0.387359619140625, 0.37864771485328674, 0.3700408935546875, 0.3593413829803467, 0.3525698781013489, 0.3452100157737732, 0.33556264638900757, 0.3328131437301636, 0.3232842683792114, 0.32122883200645447, 0.3136960566043854, 0.30448049306869507, 0.3014901876449585, 0.2959328591823578, 0.28703805804252625, 0.28543543815612793, 0.2786824405193329, 0.27193978428840637, 0.27106979489326477, 0.27005162835121155, 0.2628096044063568, 0.25847434997558594, 0.2533538043498993, 0.24861790239810944, 0.24457789957523346, 0.24094119668006897, 0.23834967613220215, 0.2356852889060974, 0.23478926718235016, 0.23140709102153778], 'accuracy': [0.23089583218097687, 0.42929166555404663, 0.5761250257492065, 0.6842291951179504, 0.7408124804496765, 0.776770830154419, 0.8013333082199097, 0.8161041736602783, 0.8292916417121887, 0.8385416865348816, 0.8448541760444641, 0.8516666889190674, 0.8588958382606506, 0.8626041412353516, 0.8675416707992554, 0.8725625276565552, 0.8757083415985107, 0.8779374957084656, 0.8810625076293945, 0.8854166865348816, 0.8876041769981384, 0.8914166688919067, 0.8915833234786987, 0.8944791555404663, 0.8972499966621399, 0.8999375104904175, 0.9008333086967468, 0.9038749933242798, 0.9068333506584167, 0.9077083468437195, 0.9082708358764648, 0.9127916693687439, 0.9120416641235352, 0.9135000109672546, 0.9178333282470703, 0.9167291522026062, 0.9184374809265137, 0.9203749895095825, 0.9211249947547913, 0.921791672706604, 0.9230833053588867, 0.9246666431427002, 0.9238125085830688, 0.9276041388511658, 0.9282708168029785, 0.929604172706604, 0.9291666746139526, 0.9311249852180481, 0.9307916760444641, 0.9328333139419556], 'val_loss': [2.121082067489624, 1.4445408582687378, 0.8265870809555054, 0.6114629507064819, 0.5149573683738708, 0.45777657628059387, 0.421058714389801, 0.39603978395462036, 0.37546077370643616, 0.3609168827533722, 0.3465089201927185, 0.3352149724960327, 0.3250895142555237, 0.3157065808773041, 0.3070484399795532, 0.3005519211292267, 0.29157811403274536, 0.2851576805114746, 0.2803680896759033, 0.27274569869041443, 0.26772406697273254, 0.262209951877594, 0.2569176256656647, 0.2521880865097046, 0.24634157121181488, 0.24226999282836914, 0.23810921609401703, 0.2340155690908432, 0.23026145994663239, 0.22597888112068176, 0.22312314808368683, 0.21914272010326385, 0.21730297803878784, 0.21308381855487823, 0.2102811336517334, 0.20691217482089996, 0.20453955233097076, 0.20134368538856506, 0.2000373750925064, 0.19707918167114258, 0.1950167417526245, 0.19222742319107056, 0.19010548293590546, 0.18840360641479492, 0.18663151562213898, 0.18509016931056976, 0.18288667500019073, 0.18063387274742126, 0.17927099764347076, 0.17823567986488342], 'val_accuracy': [0.5238333344459534, 0.6334166526794434, 0.7929166555404663, 0.8425833582878113, 0.8616666793823242, 0.8760833144187927, 0.8824999928474426, 0.887333333492279, 0.8917499780654907, 0.8967499732971191, 0.8990833163261414, 0.903083324432373, 0.9066666960716248, 0.9087499976158142, 0.9105833172798157, 0.9124166369438171, 0.9140833616256714, 0.9154999852180481, 0.9173333048820496, 0.9180833101272583, 0.9210000038146973, 0.9213333129882812, 0.9229999780654907, 0.924833357334137, 0.9266666769981384, 0.9275000095367432, 0.9290000200271606, 0.9293333292007446, 0.9308333396911621, 0.9324166774749756, 0.9334166646003723, 0.9336666464805603, 0.9334999918937683, 0.9346666932106018, 0.9361666440963745, 0.9365000128746033, 0.9370833039283752, 0.9389166831970215, 0.9380833506584167, 0.9394999742507935, 0.9394166469573975, 0.9409999847412109, 0.9425833225250244, 0.9433333277702332, 0.9427499771118164, 0.9447500109672546, 0.9449166655540466, 0.9461666941642761, 0.9452499747276306, 0.9460833072662354]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}