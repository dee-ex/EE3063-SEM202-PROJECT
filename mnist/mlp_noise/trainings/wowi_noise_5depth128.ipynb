{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "331b5496-eb51-427e-c62f-42622ad74db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 16s 5ms/step - loss: 1.9929 - accuracy: 0.3042 - val_loss: 0.8570 - val_accuracy: 0.7893\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1992 - accuracy: 0.6100 - val_loss: 0.6309 - val_accuracy: 0.8347\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9682 - accuracy: 0.6972 - val_loss: 0.5343 - val_accuracy: 0.8518\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8468 - accuracy: 0.7355 - val_loss: 0.4811 - val_accuracy: 0.8633\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7694 - accuracy: 0.7622 - val_loss: 0.4423 - val_accuracy: 0.8714\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7232 - accuracy: 0.7832 - val_loss: 0.4198 - val_accuracy: 0.8748\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6835 - accuracy: 0.7948 - val_loss: 0.3980 - val_accuracy: 0.8821\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6491 - accuracy: 0.8044 - val_loss: 0.3832 - val_accuracy: 0.8857\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6361 - accuracy: 0.8127 - val_loss: 0.3691 - val_accuracy: 0.8893\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5987 - accuracy: 0.8237 - val_loss: 0.3588 - val_accuracy: 0.8923\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5843 - accuracy: 0.8265 - val_loss: 0.3494 - val_accuracy: 0.8945\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5697 - accuracy: 0.8336 - val_loss: 0.3418 - val_accuracy: 0.8986\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5527 - accuracy: 0.8382 - val_loss: 0.3345 - val_accuracy: 0.8997\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5506 - accuracy: 0.8423 - val_loss: 0.3282 - val_accuracy: 0.9043\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5174 - accuracy: 0.8519 - val_loss: 0.3226 - val_accuracy: 0.9042\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5117 - accuracy: 0.8554 - val_loss: 0.3215 - val_accuracy: 0.9054\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5026 - accuracy: 0.8579 - val_loss: 0.3154 - val_accuracy: 0.9073\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4968 - accuracy: 0.8578 - val_loss: 0.3098 - val_accuracy: 0.9086\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4791 - accuracy: 0.8651 - val_loss: 0.3069 - val_accuracy: 0.9098\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4802 - accuracy: 0.8663 - val_loss: 0.3050 - val_accuracy: 0.9114\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4696 - accuracy: 0.8684 - val_loss: 0.3012 - val_accuracy: 0.9123\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4629 - accuracy: 0.8713 - val_loss: 0.3000 - val_accuracy: 0.9129\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4636 - accuracy: 0.8705 - val_loss: 0.2960 - val_accuracy: 0.9138\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4519 - accuracy: 0.8762 - val_loss: 0.2923 - val_accuracy: 0.9150\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4368 - accuracy: 0.8771 - val_loss: 0.2880 - val_accuracy: 0.9159\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.8795 - val_loss: 0.2872 - val_accuracy: 0.9170\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4290 - accuracy: 0.8783 - val_loss: 0.2842 - val_accuracy: 0.9181\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.8805 - val_loss: 0.2840 - val_accuracy: 0.9184\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4112 - accuracy: 0.8837 - val_loss: 0.2793 - val_accuracy: 0.9200\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4003 - accuracy: 0.8887 - val_loss: 0.2793 - val_accuracy: 0.9194\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4037 - accuracy: 0.8889 - val_loss: 0.2756 - val_accuracy: 0.9210\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - accuracy: 0.8876 - val_loss: 0.2753 - val_accuracy: 0.9200\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3941 - accuracy: 0.8908 - val_loss: 0.2709 - val_accuracy: 0.9220\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3991 - accuracy: 0.8893 - val_loss: 0.2709 - val_accuracy: 0.9221\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3851 - accuracy: 0.8928 - val_loss: 0.2683 - val_accuracy: 0.9233\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3912 - accuracy: 0.8921 - val_loss: 0.2630 - val_accuracy: 0.9247\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8938 - val_loss: 0.2649 - val_accuracy: 0.9246\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3804 - accuracy: 0.8971 - val_loss: 0.2624 - val_accuracy: 0.9260\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3836 - accuracy: 0.8964 - val_loss: 0.2620 - val_accuracy: 0.9268\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3776 - accuracy: 0.8972 - val_loss: 0.2591 - val_accuracy: 0.9256\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3650 - accuracy: 0.9005 - val_loss: 0.2572 - val_accuracy: 0.9276\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.9013 - val_loss: 0.2548 - val_accuracy: 0.9283\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3597 - accuracy: 0.9015 - val_loss: 0.2533 - val_accuracy: 0.9287\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3485 - accuracy: 0.9072 - val_loss: 0.2526 - val_accuracy: 0.9293\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.9055 - val_loss: 0.2509 - val_accuracy: 0.9301\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3521 - accuracy: 0.9043 - val_loss: 0.2505 - val_accuracy: 0.9302\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.9067 - val_loss: 0.2476 - val_accuracy: 0.9307\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.9074 - val_loss: 0.2453 - val_accuracy: 0.9327\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3427 - accuracy: 0.9066 - val_loss: 0.2435 - val_accuracy: 0.9324\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.9096 - val_loss: 0.2424 - val_accuracy: 0.9338\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.3168 - accuracy: 0.1212 - val_loss: 2.1655 - val_accuracy: 0.4013\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1585 - accuracy: 0.2143 - val_loss: 1.6808 - val_accuracy: 0.5318\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8372 - accuracy: 0.3405 - val_loss: 1.2016 - val_accuracy: 0.6545\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5227 - accuracy: 0.4617 - val_loss: 0.9140 - val_accuracy: 0.7453\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2942 - accuracy: 0.5449 - val_loss: 0.7408 - val_accuracy: 0.7946\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1171 - accuracy: 0.6169 - val_loss: 0.6327 - val_accuracy: 0.8177\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0151 - accuracy: 0.6570 - val_loss: 0.5616 - val_accuracy: 0.8409\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9248 - accuracy: 0.6923 - val_loss: 0.5077 - val_accuracy: 0.8643\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8472 - accuracy: 0.7219 - val_loss: 0.4636 - val_accuracy: 0.8759\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7937 - accuracy: 0.7443 - val_loss: 0.4315 - val_accuracy: 0.8832\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7443 - accuracy: 0.7614 - val_loss: 0.3973 - val_accuracy: 0.8973\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7125 - accuracy: 0.7762 - val_loss: 0.3695 - val_accuracy: 0.9021\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.7952 - val_loss: 0.3453 - val_accuracy: 0.9083\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6393 - accuracy: 0.8036 - val_loss: 0.3270 - val_accuracy: 0.9127\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6201 - accuracy: 0.8142 - val_loss: 0.3066 - val_accuracy: 0.9175\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5879 - accuracy: 0.8253 - val_loss: 0.2916 - val_accuracy: 0.9203\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5584 - accuracy: 0.8364 - val_loss: 0.2771 - val_accuracy: 0.9242\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5410 - accuracy: 0.8376 - val_loss: 0.2694 - val_accuracy: 0.9280\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5216 - accuracy: 0.8474 - val_loss: 0.2581 - val_accuracy: 0.9296\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4955 - accuracy: 0.8573 - val_loss: 0.2470 - val_accuracy: 0.9332\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4731 - accuracy: 0.8630 - val_loss: 0.2411 - val_accuracy: 0.9343\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4688 - accuracy: 0.8684 - val_loss: 0.2321 - val_accuracy: 0.9362\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.8750 - val_loss: 0.2252 - val_accuracy: 0.9399\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.8795 - val_loss: 0.2203 - val_accuracy: 0.9405\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4120 - accuracy: 0.8835 - val_loss: 0.2153 - val_accuracy: 0.9425\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4040 - accuracy: 0.8837 - val_loss: 0.2094 - val_accuracy: 0.9437\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8876 - val_loss: 0.2057 - val_accuracy: 0.9452\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3813 - accuracy: 0.8925 - val_loss: 0.2036 - val_accuracy: 0.9458\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8957 - val_loss: 0.1980 - val_accuracy: 0.9473\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8986 - val_loss: 0.1983 - val_accuracy: 0.9469\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3463 - accuracy: 0.9045 - val_loss: 0.1962 - val_accuracy: 0.9473\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3452 - accuracy: 0.9040 - val_loss: 0.1880 - val_accuracy: 0.9507\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.9061 - val_loss: 0.1881 - val_accuracy: 0.9503\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3165 - accuracy: 0.9105 - val_loss: 0.1872 - val_accuracy: 0.9503\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3046 - accuracy: 0.9141 - val_loss: 0.1830 - val_accuracy: 0.9521\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3001 - accuracy: 0.9140 - val_loss: 0.1855 - val_accuracy: 0.9523\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2970 - accuracy: 0.9167 - val_loss: 0.1842 - val_accuracy: 0.9528\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2828 - accuracy: 0.9211 - val_loss: 0.1862 - val_accuracy: 0.9528\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2821 - accuracy: 0.9213 - val_loss: 0.1796 - val_accuracy: 0.9538\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2659 - accuracy: 0.9235 - val_loss: 0.1771 - val_accuracy: 0.9543\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2660 - accuracy: 0.9252 - val_loss: 0.1807 - val_accuracy: 0.9540\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2591 - accuracy: 0.9292 - val_loss: 0.1782 - val_accuracy: 0.9548\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2584 - accuracy: 0.9291 - val_loss: 0.1779 - val_accuracy: 0.9559\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2430 - accuracy: 0.9321 - val_loss: 0.1779 - val_accuracy: 0.9560\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2353 - accuracy: 0.9336 - val_loss: 0.1726 - val_accuracy: 0.9567\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2262 - accuracy: 0.9357 - val_loss: 0.1759 - val_accuracy: 0.9572\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.9359 - val_loss: 0.1784 - val_accuracy: 0.9563\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2301 - accuracy: 0.9362 - val_loss: 0.1750 - val_accuracy: 0.9567\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2235 - accuracy: 0.9376 - val_loss: 0.1803 - val_accuracy: 0.9557\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9409 - val_loss: 0.1780 - val_accuracy: 0.9572\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2568 - accuracy: 0.1608 - val_loss: 1.6750 - val_accuracy: 0.5403\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7273 - accuracy: 0.3966 - val_loss: 0.9984 - val_accuracy: 0.7088\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2827 - accuracy: 0.5511 - val_loss: 0.7337 - val_accuracy: 0.8022\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0408 - accuracy: 0.6504 - val_loss: 0.5784 - val_accuracy: 0.8443\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8963 - accuracy: 0.7078 - val_loss: 0.4995 - val_accuracy: 0.8627\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7920 - accuracy: 0.7468 - val_loss: 0.4489 - val_accuracy: 0.8770\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7319 - accuracy: 0.7729 - val_loss: 0.4108 - val_accuracy: 0.8882\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6638 - accuracy: 0.7965 - val_loss: 0.3811 - val_accuracy: 0.8940\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6308 - accuracy: 0.8089 - val_loss: 0.3594 - val_accuracy: 0.8987\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.8258 - val_loss: 0.3375 - val_accuracy: 0.9049\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5616 - accuracy: 0.8357 - val_loss: 0.3235 - val_accuracy: 0.9084\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5287 - accuracy: 0.8436 - val_loss: 0.3087 - val_accuracy: 0.9118\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5090 - accuracy: 0.8542 - val_loss: 0.2934 - val_accuracy: 0.9148\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4971 - accuracy: 0.8573 - val_loss: 0.2828 - val_accuracy: 0.9183\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4709 - accuracy: 0.8659 - val_loss: 0.2719 - val_accuracy: 0.9201\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4475 - accuracy: 0.8743 - val_loss: 0.2621 - val_accuracy: 0.9229\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4441 - accuracy: 0.8763 - val_loss: 0.2554 - val_accuracy: 0.9250\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4135 - accuracy: 0.8840 - val_loss: 0.2473 - val_accuracy: 0.9274\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4040 - accuracy: 0.8884 - val_loss: 0.2402 - val_accuracy: 0.9302\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.8920 - val_loss: 0.2328 - val_accuracy: 0.9325\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3709 - accuracy: 0.8972 - val_loss: 0.2271 - val_accuracy: 0.9335\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3701 - accuracy: 0.8989 - val_loss: 0.2232 - val_accuracy: 0.9348\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3632 - accuracy: 0.8976 - val_loss: 0.2191 - val_accuracy: 0.9367\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.9056 - val_loss: 0.2123 - val_accuracy: 0.9385\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.9083 - val_loss: 0.2105 - val_accuracy: 0.9388\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.9070 - val_loss: 0.2071 - val_accuracy: 0.9413\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.9122 - val_loss: 0.2027 - val_accuracy: 0.9418\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.9138 - val_loss: 0.2021 - val_accuracy: 0.9427\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2969 - accuracy: 0.9197 - val_loss: 0.1970 - val_accuracy: 0.9434\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3030 - accuracy: 0.9177 - val_loss: 0.1940 - val_accuracy: 0.9446\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.9177 - val_loss: 0.1915 - val_accuracy: 0.9442\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2794 - accuracy: 0.9233 - val_loss: 0.1878 - val_accuracy: 0.9452\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.9224 - val_loss: 0.1858 - val_accuracy: 0.9467\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2657 - accuracy: 0.9268 - val_loss: 0.1838 - val_accuracy: 0.9475\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2670 - accuracy: 0.9267 - val_loss: 0.1820 - val_accuracy: 0.9466\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2581 - accuracy: 0.9278 - val_loss: 0.1802 - val_accuracy: 0.9476\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2516 - accuracy: 0.9315 - val_loss: 0.1782 - val_accuracy: 0.9478\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2429 - accuracy: 0.9331 - val_loss: 0.1784 - val_accuracy: 0.9485\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2461 - accuracy: 0.9343 - val_loss: 0.1766 - val_accuracy: 0.9494\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2335 - accuracy: 0.9360 - val_loss: 0.1733 - val_accuracy: 0.9499\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2337 - accuracy: 0.9360 - val_loss: 0.1730 - val_accuracy: 0.9498\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2238 - accuracy: 0.9404 - val_loss: 0.1686 - val_accuracy: 0.9514\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2274 - accuracy: 0.9384 - val_loss: 0.1692 - val_accuracy: 0.9517\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2189 - accuracy: 0.9412 - val_loss: 0.1684 - val_accuracy: 0.9524\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2157 - accuracy: 0.9414 - val_loss: 0.1672 - val_accuracy: 0.9525\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9416 - val_loss: 0.1671 - val_accuracy: 0.9519\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2144 - accuracy: 0.9422 - val_loss: 0.1652 - val_accuracy: 0.9526\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2007 - accuracy: 0.9449 - val_loss: 0.1653 - val_accuracy: 0.9530\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1928 - accuracy: 0.9471 - val_loss: 0.1645 - val_accuracy: 0.9525\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.9458 - val_loss: 0.1638 - val_accuracy: 0.9546\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 1.9571 - accuracy: 0.3269 - val_loss: 0.6546 - val_accuracy: 0.8290\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0556 - accuracy: 0.6467 - val_loss: 0.4808 - val_accuracy: 0.8662\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8549 - accuracy: 0.7208 - val_loss: 0.4201 - val_accuracy: 0.8784\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7736 - accuracy: 0.7537 - val_loss: 0.3883 - val_accuracy: 0.8867\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7074 - accuracy: 0.7800 - val_loss: 0.3678 - val_accuracy: 0.8921\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6611 - accuracy: 0.7973 - val_loss: 0.3536 - val_accuracy: 0.8956\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6290 - accuracy: 0.8101 - val_loss: 0.3380 - val_accuracy: 0.8991\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.8223 - val_loss: 0.3239 - val_accuracy: 0.9034\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5766 - accuracy: 0.8288 - val_loss: 0.3160 - val_accuracy: 0.9052\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5632 - accuracy: 0.8328 - val_loss: 0.3063 - val_accuracy: 0.9072\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5386 - accuracy: 0.8410 - val_loss: 0.2974 - val_accuracy: 0.9109\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5217 - accuracy: 0.8471 - val_loss: 0.2942 - val_accuracy: 0.9124\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5048 - accuracy: 0.8527 - val_loss: 0.2868 - val_accuracy: 0.9145\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4926 - accuracy: 0.8545 - val_loss: 0.2793 - val_accuracy: 0.9165\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4740 - accuracy: 0.8613 - val_loss: 0.2744 - val_accuracy: 0.9183\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4597 - accuracy: 0.8644 - val_loss: 0.2711 - val_accuracy: 0.9191\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4519 - accuracy: 0.8693 - val_loss: 0.2666 - val_accuracy: 0.9212\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4404 - accuracy: 0.8735 - val_loss: 0.2605 - val_accuracy: 0.9212\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4323 - accuracy: 0.8754 - val_loss: 0.2580 - val_accuracy: 0.9214\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.8762 - val_loss: 0.2530 - val_accuracy: 0.9233\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4213 - accuracy: 0.8768 - val_loss: 0.2508 - val_accuracy: 0.9230\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4074 - accuracy: 0.8808 - val_loss: 0.2467 - val_accuracy: 0.9252\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - accuracy: 0.8822 - val_loss: 0.2454 - val_accuracy: 0.9262\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3978 - accuracy: 0.8862 - val_loss: 0.2386 - val_accuracy: 0.9279\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3910 - accuracy: 0.8859 - val_loss: 0.2379 - val_accuracy: 0.9277\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8919 - val_loss: 0.2346 - val_accuracy: 0.9287\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3833 - accuracy: 0.8918 - val_loss: 0.2325 - val_accuracy: 0.9295\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3738 - accuracy: 0.8917 - val_loss: 0.2290 - val_accuracy: 0.9305\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3577 - accuracy: 0.8956 - val_loss: 0.2279 - val_accuracy: 0.9308\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3598 - accuracy: 0.8976 - val_loss: 0.2257 - val_accuracy: 0.9320\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3505 - accuracy: 0.9014 - val_loss: 0.2239 - val_accuracy: 0.9321\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3480 - accuracy: 0.9006 - val_loss: 0.2206 - val_accuracy: 0.9340\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3547 - accuracy: 0.8988 - val_loss: 0.2195 - val_accuracy: 0.9353\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3437 - accuracy: 0.9013 - val_loss: 0.2169 - val_accuracy: 0.9348\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.9078 - val_loss: 0.2131 - val_accuracy: 0.9377\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.9048 - val_loss: 0.2131 - val_accuracy: 0.9376\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.9081 - val_loss: 0.2127 - val_accuracy: 0.9362\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3254 - accuracy: 0.9080 - val_loss: 0.2113 - val_accuracy: 0.9358\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3151 - accuracy: 0.9085 - val_loss: 0.2083 - val_accuracy: 0.9378\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3140 - accuracy: 0.9117 - val_loss: 0.2055 - val_accuracy: 0.9391\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3076 - accuracy: 0.9114 - val_loss: 0.2016 - val_accuracy: 0.9396\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3116 - accuracy: 0.9122 - val_loss: 0.2028 - val_accuracy: 0.9395\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2912 - accuracy: 0.9154 - val_loss: 0.1999 - val_accuracy: 0.9415\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2923 - accuracy: 0.9156 - val_loss: 0.2007 - val_accuracy: 0.9406\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.9125 - val_loss: 0.1959 - val_accuracy: 0.9417\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2874 - accuracy: 0.9181 - val_loss: 0.1979 - val_accuracy: 0.9422\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.9185 - val_loss: 0.1952 - val_accuracy: 0.9430\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2794 - accuracy: 0.9208 - val_loss: 0.1942 - val_accuracy: 0.9426\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2765 - accuracy: 0.9205 - val_loss: 0.1931 - val_accuracy: 0.9432\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2827 - accuracy: 0.9211 - val_loss: 0.1923 - val_accuracy: 0.9431\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2281 - accuracy: 0.3840 - val_loss: 0.4620 - val_accuracy: 0.8622\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0115 - accuracy: 0.6779 - val_loss: 0.4079 - val_accuracy: 0.8799\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8251 - accuracy: 0.7362 - val_loss: 0.3838 - val_accuracy: 0.8863\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7318 - accuracy: 0.7716 - val_loss: 0.3604 - val_accuracy: 0.8945\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6766 - accuracy: 0.7933 - val_loss: 0.3499 - val_accuracy: 0.8965\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6344 - accuracy: 0.8088 - val_loss: 0.3386 - val_accuracy: 0.8998\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.8240 - val_loss: 0.3282 - val_accuracy: 0.9013\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5737 - accuracy: 0.8276 - val_loss: 0.3214 - val_accuracy: 0.9048\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5601 - accuracy: 0.8321 - val_loss: 0.3109 - val_accuracy: 0.9071\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5403 - accuracy: 0.8379 - val_loss: 0.3089 - val_accuracy: 0.9094\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.8480 - val_loss: 0.3009 - val_accuracy: 0.9114\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5088 - accuracy: 0.8526 - val_loss: 0.2955 - val_accuracy: 0.9122\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4924 - accuracy: 0.8560 - val_loss: 0.2919 - val_accuracy: 0.9130\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4844 - accuracy: 0.8594 - val_loss: 0.2867 - val_accuracy: 0.9142\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4821 - accuracy: 0.8617 - val_loss: 0.2854 - val_accuracy: 0.9146\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4565 - accuracy: 0.8677 - val_loss: 0.2823 - val_accuracy: 0.9162\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.8708 - val_loss: 0.2756 - val_accuracy: 0.9183\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4413 - accuracy: 0.8720 - val_loss: 0.2727 - val_accuracy: 0.9187\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4413 - accuracy: 0.8712 - val_loss: 0.2700 - val_accuracy: 0.9192\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4269 - accuracy: 0.8783 - val_loss: 0.2661 - val_accuracy: 0.9204\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4187 - accuracy: 0.8805 - val_loss: 0.2620 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4094 - accuracy: 0.8845 - val_loss: 0.2616 - val_accuracy: 0.9225\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4087 - accuracy: 0.8820 - val_loss: 0.2576 - val_accuracy: 0.9237\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4000 - accuracy: 0.8824 - val_loss: 0.2564 - val_accuracy: 0.9240\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3904 - accuracy: 0.8871 - val_loss: 0.2531 - val_accuracy: 0.9243\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3898 - accuracy: 0.8900 - val_loss: 0.2510 - val_accuracy: 0.9249\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3936 - accuracy: 0.8902 - val_loss: 0.2493 - val_accuracy: 0.9269\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8911 - val_loss: 0.2453 - val_accuracy: 0.9278\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3728 - accuracy: 0.8930 - val_loss: 0.2417 - val_accuracy: 0.9288\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3679 - accuracy: 0.8940 - val_loss: 0.2413 - val_accuracy: 0.9289\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3689 - accuracy: 0.8959 - val_loss: 0.2394 - val_accuracy: 0.9295\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3594 - accuracy: 0.8951 - val_loss: 0.2388 - val_accuracy: 0.9293\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3613 - accuracy: 0.8961 - val_loss: 0.2361 - val_accuracy: 0.9301\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3598 - accuracy: 0.8991 - val_loss: 0.2330 - val_accuracy: 0.9313\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.9023 - val_loss: 0.2301 - val_accuracy: 0.9336\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.9033 - val_loss: 0.2312 - val_accuracy: 0.9318\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3406 - accuracy: 0.9033 - val_loss: 0.2276 - val_accuracy: 0.9335\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3421 - accuracy: 0.9028 - val_loss: 0.2280 - val_accuracy: 0.9332\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3373 - accuracy: 0.9061 - val_loss: 0.2283 - val_accuracy: 0.9327\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.9064 - val_loss: 0.2250 - val_accuracy: 0.9344\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3220 - accuracy: 0.9080 - val_loss: 0.2232 - val_accuracy: 0.9348\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.9066 - val_loss: 0.2200 - val_accuracy: 0.9343\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.9081 - val_loss: 0.2171 - val_accuracy: 0.9360\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3164 - accuracy: 0.9094 - val_loss: 0.2206 - val_accuracy: 0.9352\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.9107 - val_loss: 0.2172 - val_accuracy: 0.9373\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3132 - accuracy: 0.9100 - val_loss: 0.2148 - val_accuracy: 0.9370\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.9136 - val_loss: 0.2139 - val_accuracy: 0.9369\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2945 - accuracy: 0.9171 - val_loss: 0.2117 - val_accuracy: 0.9383\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2987 - accuracy: 0.9150 - val_loss: 0.2088 - val_accuracy: 0.9398\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3001 - accuracy: 0.9157 - val_loss: 0.2098 - val_accuracy: 0.9398\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2882 - accuracy: 0.1378 - val_loss: 2.2025 - val_accuracy: 0.3860\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1537 - accuracy: 0.2779 - val_loss: 1.8483 - val_accuracy: 0.5796\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8445 - accuracy: 0.4079 - val_loss: 1.1570 - val_accuracy: 0.6982\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4024 - accuracy: 0.5356 - val_loss: 0.7959 - val_accuracy: 0.7902\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1319 - accuracy: 0.6254 - val_loss: 0.6358 - val_accuracy: 0.8302\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9819 - accuracy: 0.6835 - val_loss: 0.5492 - val_accuracy: 0.8500\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8733 - accuracy: 0.7247 - val_loss: 0.4900 - val_accuracy: 0.8692\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7947 - accuracy: 0.7512 - val_loss: 0.4458 - val_accuracy: 0.8803\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7459 - accuracy: 0.7785 - val_loss: 0.4069 - val_accuracy: 0.8869\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7015 - accuracy: 0.7926 - val_loss: 0.3817 - val_accuracy: 0.8933\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6555 - accuracy: 0.8066 - val_loss: 0.3621 - val_accuracy: 0.8978\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6202 - accuracy: 0.8227 - val_loss: 0.3435 - val_accuracy: 0.9029\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5948 - accuracy: 0.8297 - val_loss: 0.3246 - val_accuracy: 0.9068\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5774 - accuracy: 0.8363 - val_loss: 0.3099 - val_accuracy: 0.9116\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5337 - accuracy: 0.8461 - val_loss: 0.2993 - val_accuracy: 0.9135\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5172 - accuracy: 0.8518 - val_loss: 0.2869 - val_accuracy: 0.9165\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4955 - accuracy: 0.8617 - val_loss: 0.2775 - val_accuracy: 0.9207\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4822 - accuracy: 0.8656 - val_loss: 0.2685 - val_accuracy: 0.9228\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4690 - accuracy: 0.8698 - val_loss: 0.2608 - val_accuracy: 0.9258\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4474 - accuracy: 0.8783 - val_loss: 0.2541 - val_accuracy: 0.9269\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4342 - accuracy: 0.8787 - val_loss: 0.2452 - val_accuracy: 0.9302\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4230 - accuracy: 0.8839 - val_loss: 0.2382 - val_accuracy: 0.9324\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4060 - accuracy: 0.8847 - val_loss: 0.2318 - val_accuracy: 0.9343\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3913 - accuracy: 0.8925 - val_loss: 0.2266 - val_accuracy: 0.9360\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3835 - accuracy: 0.8945 - val_loss: 0.2194 - val_accuracy: 0.9367\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3805 - accuracy: 0.8959 - val_loss: 0.2147 - val_accuracy: 0.9385\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3587 - accuracy: 0.9037 - val_loss: 0.2116 - val_accuracy: 0.9395\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.9041 - val_loss: 0.2065 - val_accuracy: 0.9408\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3417 - accuracy: 0.9065 - val_loss: 0.2034 - val_accuracy: 0.9425\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3349 - accuracy: 0.9100 - val_loss: 0.2000 - val_accuracy: 0.9426\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3312 - accuracy: 0.9105 - val_loss: 0.1954 - val_accuracy: 0.9440\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3171 - accuracy: 0.9155 - val_loss: 0.1923 - val_accuracy: 0.9448\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3157 - accuracy: 0.9152 - val_loss: 0.1910 - val_accuracy: 0.9463\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3031 - accuracy: 0.9189 - val_loss: 0.1891 - val_accuracy: 0.9463\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2989 - accuracy: 0.9201 - val_loss: 0.1849 - val_accuracy: 0.9470\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3008 - accuracy: 0.9177 - val_loss: 0.1834 - val_accuracy: 0.9479\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2763 - accuracy: 0.9252 - val_loss: 0.1812 - val_accuracy: 0.9480\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.9253 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2808 - accuracy: 0.9246 - val_loss: 0.1752 - val_accuracy: 0.9496\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2693 - accuracy: 0.9276 - val_loss: 0.1741 - val_accuracy: 0.9506\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2638 - accuracy: 0.9294 - val_loss: 0.1725 - val_accuracy: 0.9513\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2556 - accuracy: 0.9306 - val_loss: 0.1694 - val_accuracy: 0.9515\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2500 - accuracy: 0.9335 - val_loss: 0.1683 - val_accuracy: 0.9520\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2520 - accuracy: 0.9324 - val_loss: 0.1674 - val_accuracy: 0.9529\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2483 - accuracy: 0.9326 - val_loss: 0.1648 - val_accuracy: 0.9541\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2378 - accuracy: 0.9372 - val_loss: 0.1640 - val_accuracy: 0.9528\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2329 - accuracy: 0.9367 - val_loss: 0.1610 - val_accuracy: 0.9542\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2323 - accuracy: 0.9378 - val_loss: 0.1614 - val_accuracy: 0.9539\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2333 - accuracy: 0.9371 - val_loss: 0.1607 - val_accuracy: 0.9550\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2315 - accuracy: 0.9371 - val_loss: 0.1593 - val_accuracy: 0.9547\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2881 - accuracy: 0.1482 - val_loss: 2.2360 - val_accuracy: 0.4655\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2095 - accuracy: 0.3014 - val_loss: 1.9886 - val_accuracy: 0.4838\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9172 - accuracy: 0.3868 - val_loss: 1.3659 - val_accuracy: 0.6438\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4956 - accuracy: 0.4950 - val_loss: 1.0042 - val_accuracy: 0.7477\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2464 - accuracy: 0.5750 - val_loss: 0.7993 - val_accuracy: 0.8018\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0613 - accuracy: 0.6460 - val_loss: 0.6795 - val_accuracy: 0.8273\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9568 - accuracy: 0.6891 - val_loss: 0.5861 - val_accuracy: 0.8500\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8652 - accuracy: 0.7238 - val_loss: 0.5237 - val_accuracy: 0.8647\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8053 - accuracy: 0.7552 - val_loss: 0.4775 - val_accuracy: 0.8730\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7475 - accuracy: 0.7713 - val_loss: 0.4391 - val_accuracy: 0.8802\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7018 - accuracy: 0.7892 - val_loss: 0.4151 - val_accuracy: 0.8853\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.8018 - val_loss: 0.3953 - val_accuracy: 0.8898\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6317 - accuracy: 0.8140 - val_loss: 0.3803 - val_accuracy: 0.8925\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6105 - accuracy: 0.8212 - val_loss: 0.3667 - val_accuracy: 0.8967\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5909 - accuracy: 0.8312 - val_loss: 0.3524 - val_accuracy: 0.8991\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5743 - accuracy: 0.8351 - val_loss: 0.3437 - val_accuracy: 0.9022\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5511 - accuracy: 0.8427 - val_loss: 0.3330 - val_accuracy: 0.9043\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5337 - accuracy: 0.8468 - val_loss: 0.3233 - val_accuracy: 0.9047\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5331 - accuracy: 0.8467 - val_loss: 0.3139 - val_accuracy: 0.9070\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5018 - accuracy: 0.8583 - val_loss: 0.3072 - val_accuracy: 0.9083\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4974 - accuracy: 0.8598 - val_loss: 0.2997 - val_accuracy: 0.9104\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4810 - accuracy: 0.8651 - val_loss: 0.2944 - val_accuracy: 0.9123\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4717 - accuracy: 0.8685 - val_loss: 0.2887 - val_accuracy: 0.9141\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4474 - accuracy: 0.8751 - val_loss: 0.2814 - val_accuracy: 0.9171\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4456 - accuracy: 0.8740 - val_loss: 0.2759 - val_accuracy: 0.9180\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4433 - accuracy: 0.8749 - val_loss: 0.2702 - val_accuracy: 0.9200\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4348 - accuracy: 0.8770 - val_loss: 0.2642 - val_accuracy: 0.9218\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4274 - accuracy: 0.8815 - val_loss: 0.2594 - val_accuracy: 0.9230\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4060 - accuracy: 0.8890 - val_loss: 0.2558 - val_accuracy: 0.9237\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4088 - accuracy: 0.8858 - val_loss: 0.2507 - val_accuracy: 0.9252\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3939 - accuracy: 0.8888 - val_loss: 0.2458 - val_accuracy: 0.9279\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3811 - accuracy: 0.8940 - val_loss: 0.2412 - val_accuracy: 0.9294\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3859 - accuracy: 0.8920 - val_loss: 0.2373 - val_accuracy: 0.9298\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3795 - accuracy: 0.8954 - val_loss: 0.2345 - val_accuracy: 0.9315\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3680 - accuracy: 0.8992 - val_loss: 0.2308 - val_accuracy: 0.9332\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3583 - accuracy: 0.8995 - val_loss: 0.2275 - val_accuracy: 0.9339\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3649 - accuracy: 0.8995 - val_loss: 0.2239 - val_accuracy: 0.9346\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3495 - accuracy: 0.9033 - val_loss: 0.2206 - val_accuracy: 0.9359\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3348 - accuracy: 0.9075 - val_loss: 0.2192 - val_accuracy: 0.9364\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3393 - accuracy: 0.9067 - val_loss: 0.2158 - val_accuracy: 0.9371\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3296 - accuracy: 0.9112 - val_loss: 0.2127 - val_accuracy: 0.9387\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3297 - accuracy: 0.9084 - val_loss: 0.2103 - val_accuracy: 0.9380\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3176 - accuracy: 0.9138 - val_loss: 0.2068 - val_accuracy: 0.9388\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3186 - accuracy: 0.9134 - val_loss: 0.2044 - val_accuracy: 0.9398\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3117 - accuracy: 0.9134 - val_loss: 0.2023 - val_accuracy: 0.9416\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3072 - accuracy: 0.9179 - val_loss: 0.1994 - val_accuracy: 0.9413\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3011 - accuracy: 0.9200 - val_loss: 0.1999 - val_accuracy: 0.9417\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2906 - accuracy: 0.9211 - val_loss: 0.1959 - val_accuracy: 0.9424\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2964 - accuracy: 0.9166 - val_loss: 0.1956 - val_accuracy: 0.9425\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.9206 - val_loss: 0.1934 - val_accuracy: 0.9435\n",
      "{'loss': [1.6728157997131348, 1.1250466108322144, 0.931596040725708, 0.8273677825927734, 0.7609162330627441, 0.7132226824760437, 0.6746184825897217, 0.6409403085708618, 0.6197549104690552, 0.5979013442993164, 0.5814087986946106, 0.5627266764640808, 0.551770806312561, 0.5369290113449097, 0.5213026404380798, 0.5151124596595764, 0.5059164762496948, 0.48993176221847534, 0.48226258158683777, 0.4759407043457031, 0.46873778104782104, 0.4599982798099518, 0.4548749327659607, 0.44606757164001465, 0.43660077452659607, 0.4364246129989624, 0.42923152446746826, 0.42143547534942627, 0.4150526523590088, 0.4109973907470703, 0.4086199104785919, 0.4052307605743408, 0.3978520929813385, 0.3943803012371063, 0.384250283241272, 0.3852241635322571, 0.38478541374206543, 0.37436816096305847, 0.3755076825618744, 0.37214580178260803, 0.36619168519973755, 0.3619067072868347, 0.35881534218788147, 0.3549082577228546, 0.3557470440864563, 0.3539377748966217, 0.3423890471458435, 0.3376983106136322, 0.3405897319316864, 0.33435338735580444], 'accuracy': [0.4285208284854889, 0.6376458406448364, 0.7080833315849304, 0.7434583306312561, 0.7652291655540466, 0.7845208048820496, 0.7988541722297668, 0.8087291717529297, 0.8178958296775818, 0.8231874704360962, 0.82833331823349, 0.8364791870117188, 0.840666651725769, 0.8463333249092102, 0.8509374856948853, 0.8526250123977661, 0.8565000295639038, 0.8598333597183228, 0.8646458387374878, 0.8662083148956299, 0.8685208559036255, 0.8721250295639038, 0.8729583621025085, 0.8774166703224182, 0.8791041374206543, 0.8772500157356262, 0.8801458477973938, 0.8828333616256714, 0.8835625052452087, 0.8862291574478149, 0.8876041769981384, 0.8882499933242798, 0.890916645526886, 0.8900833129882812, 0.8936041593551636, 0.8937708139419556, 0.8958125114440918, 0.898687481880188, 0.8982083201408386, 0.8990833163261414, 0.9007083177566528, 0.9018541574478149, 0.901645839214325, 0.9039791822433472, 0.9042916893959045, 0.9042708277702332, 0.9068124890327454, 0.9078750014305115, 0.9079166650772095, 0.9098749756813049], 'val_loss': [0.8570260405540466, 0.6309155821800232, 0.5342880487442017, 0.4810667335987091, 0.4422777593135834, 0.41978785395622253, 0.39800748229026794, 0.3832368552684784, 0.36908194422721863, 0.3587583005428314, 0.3493960499763489, 0.3417980968952179, 0.3345131576061249, 0.32824578881263733, 0.32261231541633606, 0.3214852213859558, 0.3154468536376953, 0.3098171055316925, 0.30688709020614624, 0.3049997389316559, 0.30124610662460327, 0.3000258505344391, 0.29601508378982544, 0.292252779006958, 0.28802359104156494, 0.28717750310897827, 0.284189909696579, 0.2840268909931183, 0.27931416034698486, 0.2793045938014984, 0.2756009101867676, 0.27525413036346436, 0.27093252539634705, 0.27093005180358887, 0.268320769071579, 0.2630384862422943, 0.26487287878990173, 0.2623594105243683, 0.26198047399520874, 0.2590567171573639, 0.25716185569763184, 0.25477227568626404, 0.25331446528434753, 0.2525848150253296, 0.2509217858314514, 0.2505144476890564, 0.2476080358028412, 0.245316281914711, 0.24345065653324127, 0.24236513674259186], 'val_accuracy': [0.7893333435058594, 0.8347499966621399, 0.8518333435058594, 0.8633333444595337, 0.8714166879653931, 0.874833345413208, 0.8820833563804626, 0.8857499957084656, 0.8893333077430725, 0.8923333287239075, 0.8945000171661377, 0.8985833525657654, 0.8996666669845581, 0.9042500257492065, 0.9041666388511658, 0.9054166674613953, 0.9073333144187927, 0.9085833430290222, 0.9098333120346069, 0.9114166498184204, 0.9123333096504211, 0.9129166603088379, 0.9138333201408386, 0.9150000214576721, 0.9159166812896729, 0.9169999957084656, 0.9180833101272583, 0.9184166789054871, 0.9200000166893005, 0.9194166660308838, 0.9210000038146973, 0.9200000166893005, 0.921999990940094, 0.92208331823349, 0.9233333468437195, 0.9247499704360962, 0.9245833158493042, 0.9259999990463257, 0.9267500042915344, 0.9255833625793457, 0.9275833368301392, 0.9282500147819519, 0.9286666512489319, 0.9293333292007446, 0.9300833344459534, 0.9302499890327454, 0.9306666851043701, 0.9327499866485596, 0.9324166774749756, 0.9338333606719971]}\n",
      "{'loss': [2.2849814891815186, 2.0826520919799805, 1.743478536605835, 1.4565825462341309, 1.2488831281661987, 1.092395305633545, 0.9934992790222168, 0.9053071141242981, 0.8343947529792786, 0.792059063911438, 0.7393751740455627, 0.7048856616020203, 0.6659809350967407, 0.6329108476638794, 0.6074504256248474, 0.5841196179389954, 0.5599111318588257, 0.5302839875221252, 0.5105933547019958, 0.4892963767051697, 0.47019457817077637, 0.46143999695777893, 0.44575509428977966, 0.4263555407524109, 0.41230541467666626, 0.39887139201164246, 0.3898971378803253, 0.37469422817230225, 0.36426469683647156, 0.3562195897102356, 0.347413033246994, 0.3375793695449829, 0.32945483922958374, 0.31554898619651794, 0.3079390823841095, 0.3036612272262573, 0.2923087477684021, 0.28042712807655334, 0.27971914410591125, 0.27111202478408813, 0.2630678117275238, 0.26056987047195435, 0.2546614408493042, 0.2432536482810974, 0.23865915834903717, 0.23143760859966278, 0.22980326414108276, 0.22685429453849792, 0.21714438498020172, 0.21619588136672974], 'accuracy': [0.13889583945274353, 0.24537500739097595, 0.37674999237060547, 0.48762500286102295, 0.5637916922569275, 0.6238333582878113, 0.6652291417121887, 0.6991875171661377, 0.7290208339691162, 0.7463541626930237, 0.7630416750907898, 0.7790416479110718, 0.7954791784286499, 0.807854175567627, 0.8176458477973938, 0.8266249895095825, 0.8363541960716248, 0.8424583077430725, 0.8510416746139526, 0.85916668176651, 0.8652708530426025, 0.8686249852180481, 0.8731874823570251, 0.8784375190734863, 0.8823958039283752, 0.8862708210945129, 0.8894791603088379, 0.8947083353996277, 0.8966249823570251, 0.8996666669845581, 0.9039375185966492, 0.9066666960716248, 0.9079375267028809, 0.9114375114440918, 0.914187490940094, 0.9145833253860474, 0.9176041483879089, 0.921833336353302, 0.9225624799728394, 0.9245208501815796, 0.9260208606719971, 0.9283541440963745, 0.9303541779518127, 0.9324166774749756, 0.9344375133514404, 0.9359375238418579, 0.9360208511352539, 0.9365208148956299, 0.9395416378974915, 0.9401458501815796], 'val_loss': [2.165519952774048, 1.6808022260665894, 1.2015780210494995, 0.9140238165855408, 0.7407741546630859, 0.632696270942688, 0.5616132020950317, 0.5076978802680969, 0.46358832716941833, 0.4315050542354584, 0.39727702736854553, 0.3694725036621094, 0.3452576994895935, 0.3270376920700073, 0.30661246180534363, 0.2916201949119568, 0.277060866355896, 0.2694128155708313, 0.2580642104148865, 0.24699902534484863, 0.2410750389099121, 0.23213741183280945, 0.22516943514347076, 0.2202969342470169, 0.21533064544200897, 0.20937936007976532, 0.2056596279144287, 0.20355822145938873, 0.19804659485816956, 0.19831041991710663, 0.19619010388851166, 0.18802288174629211, 0.1881471425294876, 0.18723256886005402, 0.1830320805311203, 0.18552960455417633, 0.18418991565704346, 0.186211958527565, 0.17955079674720764, 0.1770947426557541, 0.1807192862033844, 0.178218275308609, 0.1779266595840454, 0.17790095508098602, 0.17260946333408356, 0.17591311037540436, 0.1784224659204483, 0.1750035434961319, 0.18025192618370056, 0.17803151905536652], 'val_accuracy': [0.4012500047683716, 0.5318333506584167, 0.6545000076293945, 0.7453333139419556, 0.7945833206176758, 0.8177499771118164, 0.8409166932106018, 0.8643333315849304, 0.8759166598320007, 0.8832499980926514, 0.8973333239555359, 0.9020833373069763, 0.9083333611488342, 0.9126666784286499, 0.9175000190734863, 0.9203333258628845, 0.9241666793823242, 0.9279999732971191, 0.9295833110809326, 0.9331666827201843, 0.934333324432373, 0.9362499713897705, 0.9399166703224182, 0.940500020980835, 0.9424999952316284, 0.9436666369438171, 0.9451666474342346, 0.9458333253860474, 0.9473333358764648, 0.9469166398048401, 0.9473333358764648, 0.9507499933242798, 0.9502500295639038, 0.9503333568572998, 0.9520833492279053, 0.9522500038146973, 0.952750027179718, 0.952833354473114, 0.9537500143051147, 0.9543333053588867, 0.9539999961853027, 0.9547500014305115, 0.9559166431427002, 0.9559999704360962, 0.9566666483879089, 0.9571666717529297, 0.956250011920929, 0.9567499756813049, 0.9557499885559082, 0.9571666717529297]}\n",
      "{'loss': [2.153095006942749, 1.5898113250732422, 1.2120003700256348, 0.9983209371566772, 0.8704033493995667, 0.7786045074462891, 0.7147011756896973, 0.6605291366577148, 0.6232655644416809, 0.5871663689613342, 0.5553762316703796, 0.5278351902961731, 0.5050250887870789, 0.49179625511169434, 0.46755558252334595, 0.4462389349937439, 0.4364185929298401, 0.4144990146160126, 0.4033193290233612, 0.39224228262901306, 0.37456631660461426, 0.36815813183784485, 0.356527179479599, 0.3447301983833313, 0.33444076776504517, 0.3298146426677704, 0.31890782713890076, 0.3154902756214142, 0.30149441957473755, 0.29887598752975464, 0.2906850278377533, 0.2815605401992798, 0.2761901915073395, 0.2691812813282013, 0.26348674297332764, 0.2574872374534607, 0.2506605088710785, 0.24398937821388245, 0.24448361992835999, 0.23796497285366058, 0.23468796908855438, 0.2300323098897934, 0.22813059389591217, 0.21932905912399292, 0.21536105871200562, 0.21248620748519897, 0.20786996185779572, 0.20074327290058136, 0.19862177968025208, 0.1939280778169632], 'accuracy': [0.2213958352804184, 0.44439584016799927, 0.5779374837875366, 0.6651666760444641, 0.7172916531562805, 0.7526249885559082, 0.7787291407585144, 0.7986458539962769, 0.812791645526886, 0.828041672706604, 0.8374583125114441, 0.8467291593551636, 0.8543124794960022, 0.8600416779518127, 0.8677291870117188, 0.8750625252723694, 0.8783958554267883, 0.8845208287239075, 0.8885833621025085, 0.8912500143051147, 0.8963750004768372, 0.8998749852180481, 0.9006875157356262, 0.9051874876022339, 0.909333348274231, 0.9084583520889282, 0.9122708439826965, 0.9127916693687439, 0.9175000190734863, 0.918624997138977, 0.9197708368301392, 0.9232916831970215, 0.9237291812896729, 0.9263333082199097, 0.9276250004768372, 0.9285833239555359, 0.9316250085830688, 0.9316458106040955, 0.9333958625793457, 0.9353333115577698, 0.9358958601951599, 0.937666654586792, 0.9378958344459534, 0.9399791955947876, 0.9414166808128357, 0.9408125281333923, 0.9445208311080933, 0.9446041584014893, 0.9463958144187927, 0.9457708597183228], 'val_loss': [1.6749767065048218, 0.9984017014503479, 0.7337123155593872, 0.5783904790878296, 0.49950939416885376, 0.448895663022995, 0.4107847213745117, 0.38113680481910706, 0.35938724875450134, 0.33749592304229736, 0.32350143790245056, 0.30872616171836853, 0.293407678604126, 0.2827704846858978, 0.27191027998924255, 0.2621093690395355, 0.25537970662117004, 0.24734553694725037, 0.2402431219816208, 0.2328079789876938, 0.22713541984558105, 0.22318923473358154, 0.2190542370080948, 0.21232916414737701, 0.2105356901884079, 0.20714692771434784, 0.20268821716308594, 0.20211061835289001, 0.1969590187072754, 0.19403092563152313, 0.19150204956531525, 0.18779516220092773, 0.18578818440437317, 0.18383117020130157, 0.18198756873607635, 0.1802256852388382, 0.17819787561893463, 0.17835648357868195, 0.1765536069869995, 0.17334707081317902, 0.17299214005470276, 0.16861125826835632, 0.16924014687538147, 0.16838319599628448, 0.16716255247592926, 0.16711358726024628, 0.16521424055099487, 0.16534483432769775, 0.16450916230678558, 0.16375650465488434], 'val_accuracy': [0.5402500033378601, 0.7088333368301392, 0.8021666407585144, 0.8443333506584167, 0.8627499938011169, 0.8769999742507935, 0.8881666660308838, 0.8939999938011169, 0.8986666798591614, 0.9049166440963745, 0.9084166884422302, 0.9117500185966492, 0.9148333072662354, 0.9183333516120911, 0.9200833439826965, 0.9229166507720947, 0.925000011920929, 0.9274166822433472, 0.9301666617393494, 0.9325000047683716, 0.9334999918937683, 0.9347500205039978, 0.9366666674613953, 0.9384999871253967, 0.9387500286102295, 0.9412500262260437, 0.9418333172798157, 0.9426666498184204, 0.9434166550636292, 0.9445833563804626, 0.9441666603088379, 0.9452499747276306, 0.9466666579246521, 0.9474999904632568, 0.9465833306312561, 0.9475833177566528, 0.9478333592414856, 0.9484999775886536, 0.9494166374206543, 0.949916660785675, 0.9497500061988831, 0.9514166712760925, 0.9516666531562805, 0.9524166584014893, 0.9524999856948853, 0.9519166946411133, 0.9525833129882812, 0.953000009059906, 0.9524999856948853, 0.9545833468437195]}\n",
      "{'loss': [1.5818843841552734, 0.9980493783950806, 0.8346887230873108, 0.7566401958465576, 0.6960424780845642, 0.65278559923172, 0.6196354627609253, 0.595880389213562, 0.5691279172897339, 0.5547597408294678, 0.5330621004104614, 0.5187239050865173, 0.5052345395088196, 0.4900393784046173, 0.4766840934753418, 0.46195995807647705, 0.4524276852607727, 0.44548654556274414, 0.4330155551433563, 0.42600131034851074, 0.4214459955692291, 0.41144290566444397, 0.4075257182121277, 0.39532995223999023, 0.3904006779193878, 0.38001716136932373, 0.37684690952301025, 0.37341204285621643, 0.3586147129535675, 0.35706815123558044, 0.35370874404907227, 0.3460020422935486, 0.34747350215911865, 0.33738866448402405, 0.3334673345088959, 0.3277124762535095, 0.3263533413410187, 0.3239286243915558, 0.3167448043823242, 0.3123680651187897, 0.30634522438049316, 0.30788829922676086, 0.29682761430740356, 0.2949570417404175, 0.29814016819000244, 0.28650665283203125, 0.286738783121109, 0.28588613867759705, 0.28193700313568115, 0.27967050671577454], 'accuracy': [0.4585833251476288, 0.6693958044052124, 0.7324374914169312, 0.7620624899864197, 0.7845625281333923, 0.7992291450500488, 0.8129166960716248, 0.8227499723434448, 0.8310624957084656, 0.8345000147819519, 0.8424166440963745, 0.8478541374206543, 0.8532708287239075, 0.8554583191871643, 0.8613749742507935, 0.8650208115577698, 0.8677708506584167, 0.8712499737739563, 0.874916672706604, 0.8773750066757202, 0.8785416483879089, 0.8809999823570251, 0.8820624947547913, 0.8872708082199097, 0.8877291679382324, 0.8915416598320007, 0.8922708630561829, 0.8927083611488342, 0.8946874737739563, 0.898312509059906, 0.8991666436195374, 0.901687502861023, 0.9019374847412109, 0.9035833477973938, 0.9054999947547913, 0.9072291851043701, 0.9077708125114441, 0.9078124761581421, 0.9092291593551636, 0.9116874933242798, 0.9125208258628845, 0.9123125076293945, 0.9144583344459534, 0.9159791469573975, 0.9158958196640015, 0.9190208315849304, 0.9193958044052124, 0.9191041588783264, 0.9194791913032532, 0.921833336353302], 'val_loss': [0.6545884609222412, 0.48082786798477173, 0.42012858390808105, 0.3883477747440338, 0.3678133189678192, 0.3535568416118622, 0.3379817605018616, 0.32393592596054077, 0.31599727272987366, 0.3062857985496521, 0.2974063456058502, 0.2941557765007019, 0.28681910037994385, 0.2792585790157318, 0.274384468793869, 0.27111923694610596, 0.26658615469932556, 0.26046812534332275, 0.2579687833786011, 0.25301995873451233, 0.25079894065856934, 0.24668796360492706, 0.24536027014255524, 0.2386285662651062, 0.23794667422771454, 0.23459354043006897, 0.23245379328727722, 0.22901275753974915, 0.22785502672195435, 0.22567415237426758, 0.22393034398555756, 0.220554918050766, 0.2195228636264801, 0.21690058708190918, 0.21311181783676147, 0.21311058104038239, 0.2126757800579071, 0.21133822202682495, 0.20827478170394897, 0.20547574758529663, 0.20161215960979462, 0.20283474028110504, 0.19985955953598022, 0.20065385103225708, 0.19593660533428192, 0.19787022471427917, 0.19522635638713837, 0.19415666162967682, 0.19307562708854675, 0.1922627091407776], 'val_accuracy': [0.8289999961853027, 0.8662499785423279, 0.8784166574478149, 0.8867499828338623, 0.8920833468437195, 0.8955833315849304, 0.8990833163261414, 0.9034166932106018, 0.9051666855812073, 0.9072499871253967, 0.9109166860580444, 0.9124166369438171, 0.9144999980926514, 0.9164999723434448, 0.9183333516120911, 0.9190833568572998, 0.9211666584014893, 0.9212499856948853, 0.9214166402816772, 0.9233333468437195, 0.9229999780654907, 0.9252499938011169, 0.9261666536331177, 0.9279166460037231, 0.9276666641235352, 0.9287499785423279, 0.9294999837875366, 0.9304999709129333, 0.9307500123977661, 0.9319999814033508, 0.9320833086967468, 0.9340000152587891, 0.9353333115577698, 0.9348333477973938, 0.937666654586792, 0.937583327293396, 0.9361666440963745, 0.9357500076293945, 0.937833309173584, 0.9390833377838135, 0.9395833611488342, 0.9394999742507935, 0.9415000081062317, 0.940583348274231, 0.9416666626930237, 0.9421666860580444, 0.9430000185966492, 0.9425833225250244, 0.9431666731834412, 0.9430833458900452]}\n",
      "{'loss': [1.6246494054794312, 0.9532036185264587, 0.8005571365356445, 0.7191370725631714, 0.6713680624961853, 0.6207272410392761, 0.5908334255218506, 0.5698394775390625, 0.5581586360931396, 0.5347172617912292, 0.5176956057548523, 0.5115174055099487, 0.4890980124473572, 0.48241114616394043, 0.4715973436832428, 0.4578888416290283, 0.4461665153503418, 0.4434029161930084, 0.43667086958885193, 0.4262511134147644, 0.42096227407455444, 0.41402745246887207, 0.40682584047317505, 0.39942455291748047, 0.3946872651576996, 0.39177876710891724, 0.3883320391178131, 0.3776283860206604, 0.3741154670715332, 0.3701874911785126, 0.3669278621673584, 0.35776740312576294, 0.35987287759780884, 0.3539421856403351, 0.3506581485271454, 0.3451249301433563, 0.3377703130245209, 0.3365745544433594, 0.33227312564849854, 0.3272179663181305, 0.33023902773857117, 0.32850000262260437, 0.32262495160102844, 0.311947762966156, 0.31514617800712585, 0.31199294328689575, 0.3045346736907959, 0.3032234013080597, 0.3019847273826599, 0.30135148763656616], 'accuracy': [0.5137916803359985, 0.6975625157356262, 0.7465833425521851, 0.7770000100135803, 0.7946666479110718, 0.812125027179718, 0.8237708210945129, 0.8289791941642761, 0.8336666822433472, 0.840624988079071, 0.848520815372467, 0.8513749837875366, 0.8570625185966492, 0.8589791655540466, 0.8634791374206543, 0.8666666746139526, 0.8703749775886536, 0.8708958625793457, 0.8727083206176758, 0.8763750195503235, 0.8791666626930237, 0.8817708492279053, 0.8832083344459534, 0.8844791650772095, 0.8862708210945129, 0.8880208134651184, 0.8911458253860474, 0.8912083506584167, 0.8930000066757202, 0.8932708501815796, 0.895437479019165, 0.8981249928474426, 0.8967708349227905, 0.8988333344459534, 0.8995000123977661, 0.9024583101272583, 0.902916669845581, 0.9044791460037231, 0.9065208435058594, 0.9072291851043701, 0.90625, 0.9080625176429749, 0.9083333611488342, 0.9100000262260437, 0.9102500081062317, 0.9113749861717224, 0.9126458168029785, 0.914229154586792, 0.9144791960716248, 0.9148333072662354], 'val_loss': [0.4620327055454254, 0.40791746973991394, 0.3837692439556122, 0.3604316711425781, 0.34990623593330383, 0.3385908603668213, 0.3282254934310913, 0.3214174211025238, 0.3108570873737335, 0.3089267313480377, 0.3008655905723572, 0.29546883702278137, 0.2918923497200012, 0.28665924072265625, 0.285370409488678, 0.2823333442211151, 0.2756021320819855, 0.27268221974372864, 0.26996126770973206, 0.2660866379737854, 0.2620083689689636, 0.261637419462204, 0.25756970047950745, 0.25639691948890686, 0.2531423568725586, 0.25098100304603577, 0.24933350086212158, 0.24533726274967194, 0.24167436361312866, 0.24128015339374542, 0.23936912417411804, 0.23879677057266235, 0.23606306314468384, 0.23296289145946503, 0.23014524579048157, 0.23124288022518158, 0.2276112288236618, 0.22799040377140045, 0.22828218340873718, 0.22495470941066742, 0.22324873507022858, 0.22002339363098145, 0.2171332985162735, 0.22062063217163086, 0.21720536053180695, 0.21484781801700592, 0.21389196813106537, 0.21167856454849243, 0.20882289111614227, 0.20980827510356903], 'val_accuracy': [0.8622499704360962, 0.8799166679382324, 0.8863333463668823, 0.8945000171661377, 0.8964999914169312, 0.8998333215713501, 0.9012500047683716, 0.9048333168029785, 0.9070833325386047, 0.909416675567627, 0.9114166498184204, 0.9122499823570251, 0.9129999876022339, 0.9141666889190674, 0.9145833253860474, 0.9161666631698608, 0.9182500243186951, 0.918666660785675, 0.9191666841506958, 0.9204166531562805, 0.9210833311080933, 0.9225000143051147, 0.9236666560173035, 0.9240000247955322, 0.9242500066757202, 0.924916684627533, 0.9269166588783264, 0.9278333187103271, 0.9288333058357239, 0.9289166927337646, 0.9294999837875366, 0.9293333292007446, 0.9300833344459534, 0.9313333630561829, 0.9335833191871643, 0.9318333268165588, 0.9334999918937683, 0.9331666827201843, 0.9327499866485596, 0.934416651725769, 0.9347500205039978, 0.934333324432373, 0.9359999895095825, 0.9351666569709778, 0.937333345413208, 0.9369999766349792, 0.9369166493415833, 0.9383333325386047, 0.9397500157356262, 0.9398333430290222]}\n",
      "{'loss': [2.270004987716675, 2.0899343490600586, 1.728729486465454, 1.3197599649429321, 1.0849072933197021, 0.9513030648231506, 0.8546900153160095, 0.7815219163894653, 0.72951340675354, 0.6862708330154419, 0.6517051458358765, 0.6119749546051025, 0.5865236520767212, 0.563143253326416, 0.5392824411392212, 0.5131730437278748, 0.4964245557785034, 0.477794885635376, 0.4651101529598236, 0.4467913508415222, 0.433271199464798, 0.41745543479919434, 0.40616557002067566, 0.3921148180961609, 0.3816736340522766, 0.3742135465145111, 0.3585462272167206, 0.3571854531764984, 0.3388310670852661, 0.33134347200393677, 0.32709965109825134, 0.3222534656524658, 0.3097480833530426, 0.30749502778053284, 0.29761072993278503, 0.29371345043182373, 0.28453850746154785, 0.2800027132034302, 0.2770080864429474, 0.26844483613967896, 0.2629963755607605, 0.26065951585769653, 0.25077465176582336, 0.2534281611442566, 0.24562968313694, 0.2396886646747589, 0.23344333469867706, 0.23497027158737183, 0.22939513623714447, 0.22446230053901672], 'accuracy': [0.1744374930858612, 0.3162499964237213, 0.44056248664855957, 0.5612499713897705, 0.643791675567627, 0.6958541870117188, 0.731124997138977, 0.7566249966621399, 0.7824375033378601, 0.7958958148956299, 0.8091458082199097, 0.8219791650772095, 0.8337500095367432, 0.839020848274231, 0.847041666507721, 0.8544999957084656, 0.8617916703224182, 0.8666874766349792, 0.8708333373069763, 0.8767708539962769, 0.8806874752044678, 0.8856874704360962, 0.8867708444595337, 0.8922083377838135, 0.8955416679382324, 0.8977708220481873, 0.9028124809265137, 0.9034583568572998, 0.9076250195503235, 0.9120000004768372, 0.9115625023841858, 0.9137916564941406, 0.9169374704360962, 0.9180833101272583, 0.9202291369438171, 0.9211458563804626, 0.9224374890327454, 0.9257708191871643, 0.9254791736602783, 0.9286041855812073, 0.9302708506584167, 0.929812490940094, 0.9320625066757202, 0.9327499866485596, 0.9337708353996277, 0.9368125200271606, 0.9372291564941406, 0.9369166493415833, 0.9378958344459534, 0.9398541450500488], 'val_loss': [2.202500104904175, 1.8482569456100464, 1.15699303150177, 0.7959028482437134, 0.6357675790786743, 0.549150824546814, 0.4899565875530243, 0.44576215744018555, 0.4069216251373291, 0.3816748559474945, 0.36212995648384094, 0.34349748492240906, 0.3246147334575653, 0.3099365830421448, 0.299328088760376, 0.2868633270263672, 0.277472585439682, 0.26850801706314087, 0.260760098695755, 0.25406432151794434, 0.2451995462179184, 0.23815928399562836, 0.23176179826259613, 0.22657270729541779, 0.21937690675258636, 0.21469271183013916, 0.2115589827299118, 0.2064795196056366, 0.20337587594985962, 0.19996106624603271, 0.19537806510925293, 0.1923227310180664, 0.19104360044002533, 0.1891096830368042, 0.18494416773319244, 0.1834162026643753, 0.18120022118091583, 0.17835699021816254, 0.17519479990005493, 0.17414166033267975, 0.1725226789712906, 0.16936686635017395, 0.1682617962360382, 0.1673605740070343, 0.16483676433563232, 0.1639934629201889, 0.16103291511535645, 0.16137327253818512, 0.16074715554714203, 0.15926043689250946], 'val_accuracy': [0.38600000739097595, 0.5795833468437195, 0.6981666684150696, 0.7901666760444641, 0.8301666378974915, 0.8500000238418579, 0.8692499995231628, 0.8803333044052124, 0.8869166374206543, 0.8933333158493042, 0.8977500200271606, 0.902916669845581, 0.9068333506584167, 0.9115833044052124, 0.9135000109672546, 0.9164999723434448, 0.9206666946411133, 0.9228333234786987, 0.9257500171661377, 0.9269166588783264, 0.9301666617393494, 0.9324166774749756, 0.934333324432373, 0.9359999895095825, 0.9366666674613953, 0.9384999871253967, 0.9394999742507935, 0.940750002861023, 0.9424999952316284, 0.9425833225250244, 0.9440000057220459, 0.9448333382606506, 0.9463333487510681, 0.9462500214576721, 0.9470000267028809, 0.9479166865348816, 0.9480000138282776, 0.9487500190734863, 0.9495833516120911, 0.9505833387374878, 0.9512500166893005, 0.9514999985694885, 0.9520000219345093, 0.95291668176651, 0.9540833234786987, 0.952833354473114, 0.9541666507720947, 0.9539166688919067, 0.9549999833106995, 0.9546666741371155]}\n",
      "{'loss': [2.27394962310791, 2.164346694946289, 1.7997663021087646, 1.4227927923202515, 1.1922303438186646, 1.0364450216293335, 0.9292000532150269, 0.854610025882721, 0.7887678742408752, 0.7324181199073792, 0.6926706433296204, 0.6581006050109863, 0.6309089064598083, 0.6046549677848816, 0.5815072655677795, 0.5710287094116211, 0.5526196956634521, 0.5356310606002808, 0.5226938724517822, 0.5053351521492004, 0.4917277693748474, 0.4822536110877991, 0.4721398949623108, 0.4563068747520447, 0.4453457295894623, 0.44239336252212524, 0.4321434795856476, 0.4230191111564636, 0.41048792004585266, 0.40148791670799255, 0.3943859040737152, 0.3835487365722656, 0.37870824337005615, 0.3709576725959778, 0.3707636594772339, 0.35908493399620056, 0.35241004824638367, 0.34806180000305176, 0.3385322093963623, 0.3367721438407898, 0.3274156153202057, 0.3276014029979706, 0.3207206130027771, 0.3161427080631256, 0.30797797441482544, 0.307582288980484, 0.3006817102432251, 0.2942913770675659, 0.29737889766693115, 0.28786593675613403], 'accuracy': [0.18950000405311584, 0.32610416412353516, 0.41200000047683716, 0.5162708163261414, 0.5982499718666077, 0.6567291617393494, 0.7003124952316284, 0.7291666865348816, 0.7597291469573975, 0.7774375081062317, 0.7931458353996277, 0.8074791431427002, 0.8162291646003723, 0.8227708339691162, 0.831416666507721, 0.8350833058357239, 0.8424166440963745, 0.8473749756813049, 0.851479172706604, 0.8571249842643738, 0.8600000143051147, 0.8661875128746033, 0.8681041598320007, 0.8727083206176758, 0.8749791383743286, 0.8757916688919067, 0.8779374957084656, 0.882479190826416, 0.8866041898727417, 0.8867083191871643, 0.8911458253860474, 0.8927083611488342, 0.8942499756813049, 0.8974583148956299, 0.89864581823349, 0.9007083177566528, 0.903041660785675, 0.9037291407585144, 0.9066874980926514, 0.9068333506584167, 0.9104166626930237, 0.9094374775886536, 0.9116874933242798, 0.9135000109672546, 0.9143750071525574, 0.9163541793823242, 0.9196875095367432, 0.9190416932106018, 0.9185624718666077, 0.9223333597183228], 'val_loss': [2.2359862327575684, 1.9886263608932495, 1.3658638000488281, 1.004245638847351, 0.7992826104164124, 0.67950040102005, 0.5861221551895142, 0.5236853361129761, 0.47751325368881226, 0.4391348958015442, 0.41509565711021423, 0.39534100890159607, 0.38025569915771484, 0.36673784255981445, 0.3523830473423004, 0.3437034487724304, 0.33295750617980957, 0.32329466938972473, 0.3139035403728485, 0.30719152092933655, 0.29966074228286743, 0.2944338321685791, 0.2887290418148041, 0.28135281801223755, 0.27593567967414856, 0.2701631784439087, 0.26415592432022095, 0.2594388723373413, 0.2557668387889862, 0.2507193088531494, 0.24577538669109344, 0.24119535088539124, 0.2373187094926834, 0.23446740210056305, 0.23079100251197815, 0.2275262027978897, 0.2238912582397461, 0.22058673202991486, 0.21915805339813232, 0.21583962440490723, 0.2126704901456833, 0.2102932184934616, 0.20675061643123627, 0.20435182750225067, 0.20228715240955353, 0.19944611191749573, 0.19985873997211456, 0.19589729607105255, 0.19556376338005066, 0.19338202476501465], 'val_accuracy': [0.46549999713897705, 0.48383334279060364, 0.643833339214325, 0.7477499842643738, 0.8018333315849304, 0.8273333311080933, 0.8500000238418579, 0.8646666407585144, 0.8730000257492065, 0.8801666498184204, 0.8853333592414856, 0.8898333311080933, 0.8924999833106995, 0.8966666460037231, 0.8990833163261414, 0.9022499918937683, 0.9043333530426025, 0.9047499895095825, 0.9070000052452087, 0.9083333611488342, 0.9104166626930237, 0.9123333096504211, 0.9140833616256714, 0.9170833230018616, 0.9179999828338623, 0.9200000166893005, 0.921750009059906, 0.9229999780654907, 0.9237499833106995, 0.9252499938011169, 0.9279166460037231, 0.9294166564941406, 0.9298333525657654, 0.9315000176429749, 0.9331666827201843, 0.9339166879653931, 0.934583306312561, 0.9359166622161865, 0.9364166855812073, 0.9370833039283752, 0.9386666417121887, 0.9380000233650208, 0.9388333559036255, 0.9398333430290222, 0.9415833353996277, 0.9412500262260437, 0.9417499899864197, 0.9424166679382324, 0.9424999952316284, 0.9434999823570251]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation=activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32, activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "noinit_noise_5depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
