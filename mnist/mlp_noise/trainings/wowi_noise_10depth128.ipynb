{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noinit_noise_10depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "d09e0092-dbc5-4fa4-bf35-78ac622f3a07"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 17s 7ms/step - loss: 2.2652 - accuracy: 0.1826 - val_loss: 1.2683 - val_accuracy: 0.6293\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6828 - accuracy: 0.3857 - val_loss: 1.0581 - val_accuracy: 0.6852\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4731 - accuracy: 0.4598 - val_loss: 0.9294 - val_accuracy: 0.7235\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3492 - accuracy: 0.5180 - val_loss: 0.8475 - val_accuracy: 0.7418\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2474 - accuracy: 0.5606 - val_loss: 0.7873 - val_accuracy: 0.7529\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1654 - accuracy: 0.5945 - val_loss: 0.7384 - val_accuracy: 0.7675\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1009 - accuracy: 0.6310 - val_loss: 0.6961 - val_accuracy: 0.7783\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0568 - accuracy: 0.6453 - val_loss: 0.6630 - val_accuracy: 0.7999\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0075 - accuracy: 0.6664 - val_loss: 0.6301 - val_accuracy: 0.8095\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9693 - accuracy: 0.6863 - val_loss: 0.6009 - val_accuracy: 0.8192\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9332 - accuracy: 0.7031 - val_loss: 0.5882 - val_accuracy: 0.8310\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9104 - accuracy: 0.7120 - val_loss: 0.5645 - val_accuracy: 0.8398\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8807 - accuracy: 0.7225 - val_loss: 0.5487 - val_accuracy: 0.8483\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8581 - accuracy: 0.7346 - val_loss: 0.5387 - val_accuracy: 0.8516\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8399 - accuracy: 0.7418 - val_loss: 0.5203 - val_accuracy: 0.8547\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8187 - accuracy: 0.7509 - val_loss: 0.5136 - val_accuracy: 0.8603\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7875 - accuracy: 0.7635 - val_loss: 0.5078 - val_accuracy: 0.8630\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7913 - accuracy: 0.7638 - val_loss: 0.4988 - val_accuracy: 0.8664\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7708 - accuracy: 0.7730 - val_loss: 0.4893 - val_accuracy: 0.8729\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7543 - accuracy: 0.7801 - val_loss: 0.4760 - val_accuracy: 0.8797\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7627 - accuracy: 0.7833 - val_loss: 0.4746 - val_accuracy: 0.8841\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7355 - accuracy: 0.7918 - val_loss: 0.4606 - val_accuracy: 0.8874\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7149 - accuracy: 0.8007 - val_loss: 0.4509 - val_accuracy: 0.8903\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7208 - accuracy: 0.7995 - val_loss: 0.4416 - val_accuracy: 0.8940\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6970 - accuracy: 0.8109 - val_loss: 0.4341 - val_accuracy: 0.8947\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6864 - accuracy: 0.8136 - val_loss: 0.4326 - val_accuracy: 0.8972\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6686 - accuracy: 0.8183 - val_loss: 0.4221 - val_accuracy: 0.8995\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6678 - accuracy: 0.8236 - val_loss: 0.4169 - val_accuracy: 0.9006\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6540 - accuracy: 0.8278 - val_loss: 0.4147 - val_accuracy: 0.9013\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6355 - accuracy: 0.8350 - val_loss: 0.4023 - val_accuracy: 0.9040\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6408 - accuracy: 0.8378 - val_loss: 0.3993 - val_accuracy: 0.9066\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6214 - accuracy: 0.8392 - val_loss: 0.3980 - val_accuracy: 0.9064\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6146 - accuracy: 0.8424 - val_loss: 0.3914 - val_accuracy: 0.9094\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6269 - accuracy: 0.8433 - val_loss: 0.3855 - val_accuracy: 0.9108\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5971 - accuracy: 0.8508 - val_loss: 0.3877 - val_accuracy: 0.9107\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5965 - accuracy: 0.8528 - val_loss: 0.3767 - val_accuracy: 0.9140\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5912 - accuracy: 0.8502 - val_loss: 0.3763 - val_accuracy: 0.9145\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5794 - accuracy: 0.8558 - val_loss: 0.3719 - val_accuracy: 0.9166\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5561 - accuracy: 0.8616 - val_loss: 0.3691 - val_accuracy: 0.9162\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5743 - accuracy: 0.8596 - val_loss: 0.3642 - val_accuracy: 0.9184\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5544 - accuracy: 0.8643 - val_loss: 0.3591 - val_accuracy: 0.9186\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5530 - accuracy: 0.8667 - val_loss: 0.3543 - val_accuracy: 0.9216\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5423 - accuracy: 0.8709 - val_loss: 0.3516 - val_accuracy: 0.9226\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5288 - accuracy: 0.8685 - val_loss: 0.3523 - val_accuracy: 0.9227\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5325 - accuracy: 0.8726 - val_loss: 0.3493 - val_accuracy: 0.9235\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5225 - accuracy: 0.8753 - val_loss: 0.3491 - val_accuracy: 0.9236\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5371 - accuracy: 0.8723 - val_loss: 0.3416 - val_accuracy: 0.9252\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5118 - accuracy: 0.8799 - val_loss: 0.3401 - val_accuracy: 0.9260\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5109 - accuracy: 0.8793 - val_loss: 0.3369 - val_accuracy: 0.9262\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5101 - accuracy: 0.8799 - val_loss: 0.3371 - val_accuracy: 0.9273\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3055 - accuracy: 0.1060 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3015 - accuracy: 0.1213 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2995 - accuracy: 0.1260 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2979 - accuracy: 0.1274 - val_loss: 2.2949 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2920 - accuracy: 0.1363 - val_loss: 2.2670 - val_accuracy: 0.1886\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2713 - accuracy: 0.1625 - val_loss: 2.1834 - val_accuracy: 0.2185\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2157 - accuracy: 0.1822 - val_loss: 2.0846 - val_accuracy: 0.2274\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1581 - accuracy: 0.1963 - val_loss: 2.0173 - val_accuracy: 0.2695\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1098 - accuracy: 0.2039 - val_loss: 1.9611 - val_accuracy: 0.2743\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0541 - accuracy: 0.2099 - val_loss: 1.9097 - val_accuracy: 0.3029\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0042 - accuracy: 0.2380 - val_loss: 1.8393 - val_accuracy: 0.3217\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9517 - accuracy: 0.2544 - val_loss: 1.7599 - val_accuracy: 0.3383\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8902 - accuracy: 0.2907 - val_loss: 1.6840 - val_accuracy: 0.3606\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8423 - accuracy: 0.3100 - val_loss: 1.6075 - val_accuracy: 0.3989\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7903 - accuracy: 0.3356 - val_loss: 1.5708 - val_accuracy: 0.4176\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7299 - accuracy: 0.3589 - val_loss: 1.5337 - val_accuracy: 0.4249\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6893 - accuracy: 0.3711 - val_loss: 1.4930 - val_accuracy: 0.4445\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6534 - accuracy: 0.3895 - val_loss: 1.4619 - val_accuracy: 0.4733\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6127 - accuracy: 0.4054 - val_loss: 1.4261 - val_accuracy: 0.4861\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5800 - accuracy: 0.4148 - val_loss: 1.3938 - val_accuracy: 0.5026\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5652 - accuracy: 0.4194 - val_loss: 1.3689 - val_accuracy: 0.5067\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5274 - accuracy: 0.4335 - val_loss: 1.3433 - val_accuracy: 0.5121\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5118 - accuracy: 0.4442 - val_loss: 1.3195 - val_accuracy: 0.5142\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4670 - accuracy: 0.4615 - val_loss: 1.3205 - val_accuracy: 0.5153\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4366 - accuracy: 0.4792 - val_loss: 1.2978 - val_accuracy: 0.5387\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4085 - accuracy: 0.4915 - val_loss: 1.2543 - val_accuracy: 0.5611\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3843 - accuracy: 0.5028 - val_loss: 1.2409 - val_accuracy: 0.5675\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3540 - accuracy: 0.5083 - val_loss: 1.2039 - val_accuracy: 0.5868\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3260 - accuracy: 0.5175 - val_loss: 1.1812 - val_accuracy: 0.5713\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2919 - accuracy: 0.5306 - val_loss: 1.1549 - val_accuracy: 0.6031\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2598 - accuracy: 0.5437 - val_loss: 1.1237 - val_accuracy: 0.6447\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2332 - accuracy: 0.5436 - val_loss: 1.0943 - val_accuracy: 0.6537\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2108 - accuracy: 0.5514 - val_loss: 1.0643 - val_accuracy: 0.6678\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1764 - accuracy: 0.5585 - val_loss: 1.0368 - val_accuracy: 0.6777\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1538 - accuracy: 0.5652 - val_loss: 1.0075 - val_accuracy: 0.7055\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1526 - accuracy: 0.5703 - val_loss: 0.9865 - val_accuracy: 0.7024\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1132 - accuracy: 0.5794 - val_loss: 0.9629 - val_accuracy: 0.7196\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0928 - accuracy: 0.5821 - val_loss: 0.9479 - val_accuracy: 0.7288\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0738 - accuracy: 0.5888 - val_loss: 0.9471 - val_accuracy: 0.7280\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0605 - accuracy: 0.5942 - val_loss: 0.9509 - val_accuracy: 0.7246\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0430 - accuracy: 0.6008 - val_loss: 0.9273 - val_accuracy: 0.7261\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0190 - accuracy: 0.6036 - val_loss: 0.9312 - val_accuracy: 0.7418\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0061 - accuracy: 0.6082 - val_loss: 0.8786 - val_accuracy: 0.7300\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0068 - accuracy: 0.6070 - val_loss: 0.8931 - val_accuracy: 0.7633\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9860 - accuracy: 0.6147 - val_loss: 0.9012 - val_accuracy: 0.7569\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9753 - accuracy: 0.6223 - val_loss: 0.9614 - val_accuracy: 0.6895\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9751 - accuracy: 0.6192 - val_loss: 0.8982 - val_accuracy: 0.7719\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9557 - accuracy: 0.6287 - val_loss: 0.8873 - val_accuracy: 0.7699\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9463 - accuracy: 0.6338 - val_loss: 0.9016 - val_accuracy: 0.7681\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9383 - accuracy: 0.6347 - val_loss: 0.8686 - val_accuracy: 0.7684\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 7ms/step - loss: 2.3069 - accuracy: 0.1064 - val_loss: 2.2926 - val_accuracy: 0.1138\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2908 - accuracy: 0.1399 - val_loss: 2.2551 - val_accuracy: 0.2103\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2448 - accuracy: 0.1729 - val_loss: 2.0873 - val_accuracy: 0.2088\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1262 - accuracy: 0.2108 - val_loss: 1.9747 - val_accuracy: 0.2184\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0437 - accuracy: 0.2252 - val_loss: 1.8997 - val_accuracy: 0.2320\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9828 - accuracy: 0.2379 - val_loss: 1.8122 - val_accuracy: 0.2570\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9152 - accuracy: 0.2660 - val_loss: 1.6934 - val_accuracy: 0.3523\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8214 - accuracy: 0.3072 - val_loss: 1.5914 - val_accuracy: 0.4302\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7258 - accuracy: 0.3444 - val_loss: 1.4925 - val_accuracy: 0.4643\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6484 - accuracy: 0.3711 - val_loss: 1.3671 - val_accuracy: 0.5094\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5495 - accuracy: 0.4205 - val_loss: 1.2344 - val_accuracy: 0.5870\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4416 - accuracy: 0.4607 - val_loss: 1.1109 - val_accuracy: 0.6661\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3557 - accuracy: 0.4963 - val_loss: 1.0003 - val_accuracy: 0.6862\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2576 - accuracy: 0.5348 - val_loss: 0.9324 - val_accuracy: 0.7049\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1935 - accuracy: 0.5600 - val_loss: 0.8814 - val_accuracy: 0.7215\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1341 - accuracy: 0.5876 - val_loss: 0.8395 - val_accuracy: 0.7413\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0773 - accuracy: 0.6059 - val_loss: 0.8070 - val_accuracy: 0.7453\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0497 - accuracy: 0.6214 - val_loss: 0.7748 - val_accuracy: 0.7541\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0196 - accuracy: 0.6385 - val_loss: 0.7487 - val_accuracy: 0.7744\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9707 - accuracy: 0.6568 - val_loss: 0.7207 - val_accuracy: 0.7742\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9308 - accuracy: 0.6697 - val_loss: 0.6887 - val_accuracy: 0.7984\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9169 - accuracy: 0.6792 - val_loss: 0.6673 - val_accuracy: 0.8074\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8840 - accuracy: 0.6918 - val_loss: 0.6462 - val_accuracy: 0.8163\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8499 - accuracy: 0.7071 - val_loss: 0.6228 - val_accuracy: 0.8307\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8215 - accuracy: 0.7237 - val_loss: 0.5982 - val_accuracy: 0.8448\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8089 - accuracy: 0.7341 - val_loss: 0.5778 - val_accuracy: 0.8544\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7689 - accuracy: 0.7407 - val_loss: 0.5547 - val_accuracy: 0.8612\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7528 - accuracy: 0.7510 - val_loss: 0.5487 - val_accuracy: 0.8690\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7229 - accuracy: 0.7596 - val_loss: 0.5172 - val_accuracy: 0.8720\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7068 - accuracy: 0.7739 - val_loss: 0.5069 - val_accuracy: 0.8799\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.7777 - val_loss: 0.4979 - val_accuracy: 0.8815\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6485 - accuracy: 0.7945 - val_loss: 0.4803 - val_accuracy: 0.8883\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6479 - accuracy: 0.7971 - val_loss: 0.4746 - val_accuracy: 0.8889\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6050 - accuracy: 0.8066 - val_loss: 0.4802 - val_accuracy: 0.8958\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5983 - accuracy: 0.8141 - val_loss: 0.4468 - val_accuracy: 0.8981\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5951 - accuracy: 0.8161 - val_loss: 0.4460 - val_accuracy: 0.9047\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5787 - accuracy: 0.8228 - val_loss: 0.4430 - val_accuracy: 0.9077\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5614 - accuracy: 0.8280 - val_loss: 0.4251 - val_accuracy: 0.9093\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5395 - accuracy: 0.8418 - val_loss: 0.4185 - val_accuracy: 0.9103\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5315 - accuracy: 0.8389 - val_loss: 0.4104 - val_accuracy: 0.9143\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5146 - accuracy: 0.8477 - val_loss: 0.4092 - val_accuracy: 0.9192\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5018 - accuracy: 0.8583 - val_loss: 0.3996 - val_accuracy: 0.9207\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4833 - accuracy: 0.8611 - val_loss: 0.3822 - val_accuracy: 0.9237\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4750 - accuracy: 0.8650 - val_loss: 0.3708 - val_accuracy: 0.9271\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4668 - accuracy: 0.8736 - val_loss: 0.3662 - val_accuracy: 0.9275\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4415 - accuracy: 0.8783 - val_loss: 0.3550 - val_accuracy: 0.9305\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4499 - accuracy: 0.8771 - val_loss: 0.3703 - val_accuracy: 0.9289\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4277 - accuracy: 0.8834 - val_loss: 0.3460 - val_accuracy: 0.9312\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4144 - accuracy: 0.8858 - val_loss: 0.3551 - val_accuracy: 0.9334\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3988 - accuracy: 0.8882 - val_loss: 0.3568 - val_accuracy: 0.9356\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3569 - accuracy: 0.1617 - val_loss: 1.3220 - val_accuracy: 0.6354\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7458 - accuracy: 0.3755 - val_loss: 0.9483 - val_accuracy: 0.7125\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4635 - accuracy: 0.4854 - val_loss: 0.7488 - val_accuracy: 0.7816\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2860 - accuracy: 0.5558 - val_loss: 0.6313 - val_accuracy: 0.8202\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1588 - accuracy: 0.6071 - val_loss: 0.5536 - val_accuracy: 0.8413\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0623 - accuracy: 0.6495 - val_loss: 0.5093 - val_accuracy: 0.8549\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9916 - accuracy: 0.6747 - val_loss: 0.4897 - val_accuracy: 0.8609\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9437 - accuracy: 0.6978 - val_loss: 0.4665 - val_accuracy: 0.8689\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8973 - accuracy: 0.7183 - val_loss: 0.4502 - val_accuracy: 0.8676\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8599 - accuracy: 0.7358 - val_loss: 0.4388 - val_accuracy: 0.8733\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8232 - accuracy: 0.7463 - val_loss: 0.4260 - val_accuracy: 0.8802\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7920 - accuracy: 0.7590 - val_loss: 0.4198 - val_accuracy: 0.8793\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7745 - accuracy: 0.7649 - val_loss: 0.4133 - val_accuracy: 0.8869\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7660 - accuracy: 0.7696 - val_loss: 0.4017 - val_accuracy: 0.8884\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7428 - accuracy: 0.7845 - val_loss: 0.3917 - val_accuracy: 0.8916\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7162 - accuracy: 0.7926 - val_loss: 0.3899 - val_accuracy: 0.8942\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6983 - accuracy: 0.8001 - val_loss: 0.3808 - val_accuracy: 0.8962\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6823 - accuracy: 0.8050 - val_loss: 0.3681 - val_accuracy: 0.8981\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6778 - accuracy: 0.8104 - val_loss: 0.3611 - val_accuracy: 0.9024\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6574 - accuracy: 0.8152 - val_loss: 0.3567 - val_accuracy: 0.9026\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6445 - accuracy: 0.8179 - val_loss: 0.3530 - val_accuracy: 0.9070\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6238 - accuracy: 0.8288 - val_loss: 0.3388 - val_accuracy: 0.9092\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6204 - accuracy: 0.8309 - val_loss: 0.3381 - val_accuracy: 0.9112\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6057 - accuracy: 0.8314 - val_loss: 0.3310 - val_accuracy: 0.9124\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5939 - accuracy: 0.8375 - val_loss: 0.3267 - val_accuracy: 0.9138\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5723 - accuracy: 0.8454 - val_loss: 0.3234 - val_accuracy: 0.9166\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5745 - accuracy: 0.8452 - val_loss: 0.3156 - val_accuracy: 0.9184\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5557 - accuracy: 0.8518 - val_loss: 0.3089 - val_accuracy: 0.9193\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5504 - accuracy: 0.8542 - val_loss: 0.3063 - val_accuracy: 0.9212\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5495 - accuracy: 0.8567 - val_loss: 0.3050 - val_accuracy: 0.9232\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5384 - accuracy: 0.8561 - val_loss: 0.2925 - val_accuracy: 0.9247\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5319 - accuracy: 0.8595 - val_loss: 0.2954 - val_accuracy: 0.9262\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5172 - accuracy: 0.8665 - val_loss: 0.2946 - val_accuracy: 0.9252\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5096 - accuracy: 0.8654 - val_loss: 0.2832 - val_accuracy: 0.9293\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5000 - accuracy: 0.8699 - val_loss: 0.2821 - val_accuracy: 0.9287\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4963 - accuracy: 0.8705 - val_loss: 0.2785 - val_accuracy: 0.9315\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4947 - accuracy: 0.8749 - val_loss: 0.2746 - val_accuracy: 0.9334\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4750 - accuracy: 0.8777 - val_loss: 0.2771 - val_accuracy: 0.9313\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4791 - accuracy: 0.8765 - val_loss: 0.2718 - val_accuracy: 0.9327\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4699 - accuracy: 0.8799 - val_loss: 0.2741 - val_accuracy: 0.9338\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4579 - accuracy: 0.8823 - val_loss: 0.2659 - val_accuracy: 0.9344\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4536 - accuracy: 0.8817 - val_loss: 0.2646 - val_accuracy: 0.9352\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4410 - accuracy: 0.8864 - val_loss: 0.2605 - val_accuracy: 0.9373\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4278 - accuracy: 0.8888 - val_loss: 0.2637 - val_accuracy: 0.9364\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4280 - accuracy: 0.8901 - val_loss: 0.2610 - val_accuracy: 0.9375\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4347 - accuracy: 0.8889 - val_loss: 0.2578 - val_accuracy: 0.9396\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4202 - accuracy: 0.8944 - val_loss: 0.2610 - val_accuracy: 0.9397\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4204 - accuracy: 0.8960 - val_loss: 0.2549 - val_accuracy: 0.9389\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4167 - accuracy: 0.8961 - val_loss: 0.2558 - val_accuracy: 0.9394\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4077 - accuracy: 0.8984 - val_loss: 0.2488 - val_accuracy: 0.9405\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 3.1074 - accuracy: 0.1970 - val_loss: 0.9474 - val_accuracy: 0.7215\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5713 - accuracy: 0.4465 - val_loss: 0.7708 - val_accuracy: 0.7828\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2802 - accuracy: 0.5523 - val_loss: 0.6898 - val_accuracy: 0.7983\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1612 - accuracy: 0.6023 - val_loss: 0.6316 - val_accuracy: 0.8052\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0615 - accuracy: 0.6405 - val_loss: 0.5848 - val_accuracy: 0.8198\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9972 - accuracy: 0.6728 - val_loss: 0.5492 - val_accuracy: 0.8371\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9536 - accuracy: 0.6988 - val_loss: 0.5178 - val_accuracy: 0.8503\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9168 - accuracy: 0.7090 - val_loss: 0.5014 - val_accuracy: 0.8526\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8643 - accuracy: 0.7300 - val_loss: 0.4845 - val_accuracy: 0.8649\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8427 - accuracy: 0.7468 - val_loss: 0.4645 - val_accuracy: 0.8782\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8272 - accuracy: 0.7501 - val_loss: 0.4506 - val_accuracy: 0.8826\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7990 - accuracy: 0.7640 - val_loss: 0.4308 - val_accuracy: 0.8880\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7667 - accuracy: 0.7786 - val_loss: 0.4217 - val_accuracy: 0.8893\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7513 - accuracy: 0.7828 - val_loss: 0.4052 - val_accuracy: 0.8948\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7402 - accuracy: 0.7939 - val_loss: 0.3958 - val_accuracy: 0.8975\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7115 - accuracy: 0.8020 - val_loss: 0.3857 - val_accuracy: 0.9004\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6856 - accuracy: 0.8129 - val_loss: 0.3881 - val_accuracy: 0.9038\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6758 - accuracy: 0.8142 - val_loss: 0.3750 - val_accuracy: 0.9052\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6681 - accuracy: 0.8198 - val_loss: 0.3672 - val_accuracy: 0.9068\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6517 - accuracy: 0.8231 - val_loss: 0.3589 - val_accuracy: 0.9091\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6383 - accuracy: 0.8306 - val_loss: 0.3533 - val_accuracy: 0.9112\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6260 - accuracy: 0.8344 - val_loss: 0.3507 - val_accuracy: 0.9124\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6040 - accuracy: 0.8412 - val_loss: 0.3455 - val_accuracy: 0.9148\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5988 - accuracy: 0.8442 - val_loss: 0.3362 - val_accuracy: 0.9155\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5905 - accuracy: 0.8483 - val_loss: 0.3336 - val_accuracy: 0.9178\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5753 - accuracy: 0.8540 - val_loss: 0.3284 - val_accuracy: 0.9177\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5680 - accuracy: 0.8584 - val_loss: 0.3243 - val_accuracy: 0.9193\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5702 - accuracy: 0.8555 - val_loss: 0.3212 - val_accuracy: 0.9205\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.8564 - val_loss: 0.3187 - val_accuracy: 0.9214\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5445 - accuracy: 0.8641 - val_loss: 0.3170 - val_accuracy: 0.9237\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5450 - accuracy: 0.8619 - val_loss: 0.3126 - val_accuracy: 0.9234\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5256 - accuracy: 0.8676 - val_loss: 0.3092 - val_accuracy: 0.9237\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5113 - accuracy: 0.8699 - val_loss: 0.3109 - val_accuracy: 0.9247\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4980 - accuracy: 0.8755 - val_loss: 0.3061 - val_accuracy: 0.9258\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5020 - accuracy: 0.8770 - val_loss: 0.3008 - val_accuracy: 0.9275\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4958 - accuracy: 0.8781 - val_loss: 0.2997 - val_accuracy: 0.9287\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5003 - accuracy: 0.8748 - val_loss: 0.2955 - val_accuracy: 0.9310\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4774 - accuracy: 0.8824 - val_loss: 0.2948 - val_accuracy: 0.9302\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4722 - accuracy: 0.8835 - val_loss: 0.2885 - val_accuracy: 0.9321\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4738 - accuracy: 0.8837 - val_loss: 0.2846 - val_accuracy: 0.9333\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4789 - accuracy: 0.8814 - val_loss: 0.2827 - val_accuracy: 0.9341\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4492 - accuracy: 0.8887 - val_loss: 0.2845 - val_accuracy: 0.9347\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4555 - accuracy: 0.8899 - val_loss: 0.2765 - val_accuracy: 0.9349\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4452 - accuracy: 0.8920 - val_loss: 0.2761 - val_accuracy: 0.9361\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4388 - accuracy: 0.8924 - val_loss: 0.2754 - val_accuracy: 0.9361\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4395 - accuracy: 0.8942 - val_loss: 0.2730 - val_accuracy: 0.9362\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4293 - accuracy: 0.8967 - val_loss: 0.2686 - val_accuracy: 0.9392\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4206 - accuracy: 0.8981 - val_loss: 0.2684 - val_accuracy: 0.9388\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4206 - accuracy: 0.8968 - val_loss: 0.2662 - val_accuracy: 0.9389\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4177 - accuracy: 0.8978 - val_loss: 0.2678 - val_accuracy: 0.9386\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 8ms/step - loss: 2.3022 - accuracy: 0.1164 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3014 - accuracy: 0.1132 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1136 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1160 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1153 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1159 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1138 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3002 - accuracy: 0.1120 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1132 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2999 - accuracy: 0.1145 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2992 - accuracy: 0.1158 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2996 - accuracy: 0.1133 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2994 - accuracy: 0.1140 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2987 - accuracy: 0.1138 - val_loss: 2.2998 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2984 - accuracy: 0.1135 - val_loss: 2.2994 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2978 - accuracy: 0.1160 - val_loss: 2.2989 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2980 - accuracy: 0.1125 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2975 - accuracy: 0.1120 - val_loss: 2.2973 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2964 - accuracy: 0.1126 - val_loss: 2.2959 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2943 - accuracy: 0.1195 - val_loss: 2.2933 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2918 - accuracy: 0.1217 - val_loss: 2.2872 - val_accuracy: 0.1097\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2826 - accuracy: 0.1381 - val_loss: 2.2537 - val_accuracy: 0.1733\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2484 - accuracy: 0.1597 - val_loss: 2.1553 - val_accuracy: 0.1914\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.1843 - accuracy: 0.2131 - val_loss: 2.0390 - val_accuracy: 0.3131\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.1015 - accuracy: 0.2221 - val_loss: 1.9087 - val_accuracy: 0.2968\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.0125 - accuracy: 0.2441 - val_loss: 1.7870 - val_accuracy: 0.3448\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.9299 - accuracy: 0.2622 - val_loss: 1.6803 - val_accuracy: 0.4217\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.8501 - accuracy: 0.2847 - val_loss: 1.5903 - val_accuracy: 0.4526\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.7698 - accuracy: 0.3103 - val_loss: 1.4887 - val_accuracy: 0.4733\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.6835 - accuracy: 0.3384 - val_loss: 1.3843 - val_accuracy: 0.5194\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.6037 - accuracy: 0.3760 - val_loss: 1.2974 - val_accuracy: 0.5530\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5394 - accuracy: 0.4029 - val_loss: 1.2334 - val_accuracy: 0.5773\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.4775 - accuracy: 0.4371 - val_loss: 1.1748 - val_accuracy: 0.5935\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.4295 - accuracy: 0.4573 - val_loss: 1.1176 - val_accuracy: 0.6209\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.3885 - accuracy: 0.4757 - val_loss: 1.0556 - val_accuracy: 0.6459\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.3321 - accuracy: 0.4974 - val_loss: 0.9940 - val_accuracy: 0.6687\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2964 - accuracy: 0.5190 - val_loss: 0.9456 - val_accuracy: 0.6875\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2436 - accuracy: 0.5356 - val_loss: 0.9028 - val_accuracy: 0.7192\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2141 - accuracy: 0.5486 - val_loss: 0.8536 - val_accuracy: 0.7266\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1709 - accuracy: 0.5689 - val_loss: 0.8122 - val_accuracy: 0.7482\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.1531 - accuracy: 0.5831 - val_loss: 0.7748 - val_accuracy: 0.7692\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0999 - accuracy: 0.6021 - val_loss: 0.7484 - val_accuracy: 0.7782\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0751 - accuracy: 0.6181 - val_loss: 0.7170 - val_accuracy: 0.7912\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0463 - accuracy: 0.6245 - val_loss: 0.6871 - val_accuracy: 0.7936\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0295 - accuracy: 0.6344 - val_loss: 0.6753 - val_accuracy: 0.8104\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9870 - accuracy: 0.6493 - val_loss: 0.6481 - val_accuracy: 0.8173\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9645 - accuracy: 0.6568 - val_loss: 0.6329 - val_accuracy: 0.8213\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9467 - accuracy: 0.6651 - val_loss: 0.6129 - val_accuracy: 0.8249\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9216 - accuracy: 0.6746 - val_loss: 0.6004 - val_accuracy: 0.8341\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9075 - accuracy: 0.6860 - val_loss: 0.5826 - val_accuracy: 0.8399\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 7ms/step - loss: 2.3023 - accuracy: 0.1159 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1119 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1126 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1145 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1149 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1128 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1150 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1148 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2997 - accuracy: 0.1151 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2998 - accuracy: 0.1139 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1123 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2995 - accuracy: 0.1138 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1109 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2992 - accuracy: 0.1158 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2992 - accuracy: 0.1128 - val_loss: 2.2999 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2994 - accuracy: 0.1104 - val_loss: 2.2996 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2982 - accuracy: 0.1157 - val_loss: 2.2992 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2981 - accuracy: 0.1147 - val_loss: 2.2988 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2974 - accuracy: 0.1156 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2970 - accuracy: 0.1151 - val_loss: 2.2976 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2969 - accuracy: 0.1121 - val_loss: 2.2967 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2956 - accuracy: 0.1143 - val_loss: 2.2954 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2941 - accuracy: 0.1154 - val_loss: 2.2935 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2921 - accuracy: 0.1201 - val_loss: 2.2902 - val_accuracy: 0.1061\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2877 - accuracy: 0.1313 - val_loss: 2.2830 - val_accuracy: 0.1408\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2788 - accuracy: 0.1621 - val_loss: 2.2579 - val_accuracy: 0.1942\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2419 - accuracy: 0.2073 - val_loss: 2.1251 - val_accuracy: 0.2383\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1385 - accuracy: 0.2073 - val_loss: 2.0028 - val_accuracy: 0.2362\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0660 - accuracy: 0.2251 - val_loss: 1.9211 - val_accuracy: 0.2960\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9980 - accuracy: 0.2526 - val_loss: 1.8363 - val_accuracy: 0.3197\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9278 - accuracy: 0.2810 - val_loss: 1.7516 - val_accuracy: 0.3350\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8658 - accuracy: 0.2972 - val_loss: 1.6836 - val_accuracy: 0.3580\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8051 - accuracy: 0.3095 - val_loss: 1.6301 - val_accuracy: 0.3727\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7592 - accuracy: 0.3217 - val_loss: 1.5784 - val_accuracy: 0.3798\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7012 - accuracy: 0.3356 - val_loss: 1.5270 - val_accuracy: 0.3994\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6587 - accuracy: 0.3508 - val_loss: 1.4828 - val_accuracy: 0.4128\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6198 - accuracy: 0.3663 - val_loss: 1.4425 - val_accuracy: 0.4314\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5692 - accuracy: 0.3874 - val_loss: 1.3975 - val_accuracy: 0.4493\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5353 - accuracy: 0.3979 - val_loss: 1.3549 - val_accuracy: 0.4682\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.4889 - accuracy: 0.4175 - val_loss: 1.3017 - val_accuracy: 0.5182\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4474 - accuracy: 0.4369 - val_loss: 1.2411 - val_accuracy: 0.5738\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.4134 - accuracy: 0.4647 - val_loss: 1.1900 - val_accuracy: 0.6119\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3672 - accuracy: 0.4867 - val_loss: 1.1357 - val_accuracy: 0.6507\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3368 - accuracy: 0.5024 - val_loss: 1.0966 - val_accuracy: 0.6652\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2845 - accuracy: 0.5230 - val_loss: 1.0640 - val_accuracy: 0.6695\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2777 - accuracy: 0.5282 - val_loss: 1.0333 - val_accuracy: 0.6924\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2364 - accuracy: 0.5488 - val_loss: 1.0025 - val_accuracy: 0.7011\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2096 - accuracy: 0.5545 - val_loss: 0.9756 - val_accuracy: 0.7117\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.1897 - accuracy: 0.5682 - val_loss: 0.9513 - val_accuracy: 0.7193\n",
            "{'loss': [2.0490963459014893, 1.6186683177947998, 1.436441421508789, 1.3166568279266357, 1.225070595741272, 1.1521588563919067, 1.0927984714508057, 1.0453273057937622, 0.9959884285926819, 0.9630861282348633, 0.927085280418396, 0.9036442637443542, 0.875747561454773, 0.8523174524307251, 0.8323935270309448, 0.820560872554779, 0.7960605621337891, 0.7855631709098816, 0.7744267582893372, 0.7553819417953491, 0.7519124150276184, 0.7320374250411987, 0.7184545993804932, 0.7107847332954407, 0.6965499520301819, 0.6841320991516113, 0.6722576022148132, 0.6631233096122742, 0.6563191413879395, 0.6389067769050598, 0.6378926038742065, 0.6255287528038025, 0.6169711351394653, 0.6107377409934998, 0.6031532287597656, 0.5912885665893555, 0.5856526494026184, 0.5823462009429932, 0.5675177574157715, 0.5603562593460083, 0.5556482076644897, 0.5507349967956543, 0.5479044318199158, 0.5287978053092957, 0.5297316908836365, 0.5244582295417786, 0.5324480533599854, 0.5136765837669373, 0.5140382051467896, 0.5107317566871643], 'accuracy': [0.2539583444595337, 0.40720832347869873, 0.47716665267944336, 0.5313541889190674, 0.5707916617393494, 0.6043124794960022, 0.6320000290870667, 0.6518541574478149, 0.6742916703224182, 0.6894375085830688, 0.7037500143051147, 0.714187502861023, 0.7254166603088379, 0.7361458539962769, 0.7458750009536743, 0.7532291412353516, 0.7617499828338623, 0.7672083377838135, 0.7743124961853027, 0.7802291512489319, 0.7862916588783264, 0.7929999828338623, 0.8008750081062317, 0.8034999966621399, 0.8106250166893005, 0.8155624866485596, 0.8201249837875366, 0.8240416646003723, 0.828416645526886, 0.8341249823570251, 0.8377500176429749, 0.8400208353996277, 0.8411874771118164, 0.8463541865348816, 0.8496249914169312, 0.8546666502952576, 0.8530416488647461, 0.854812502861023, 0.8608333468437195, 0.8628333210945129, 0.8654791712760925, 0.8671249747276306, 0.8696458339691162, 0.8716041445732117, 0.871958315372467, 0.8743749856948853, 0.8729166388511658, 0.8788124918937683, 0.877958357334137, 0.8793125152587891], 'val_loss': [1.268291711807251, 1.0581380128860474, 0.9294335842132568, 0.847524881362915, 0.7873243093490601, 0.7384074926376343, 0.6961148381233215, 0.6629942059516907, 0.6301091909408569, 0.600909948348999, 0.5881821513175964, 0.5645473599433899, 0.5487207770347595, 0.5386650562286377, 0.5203112959861755, 0.5136138796806335, 0.5077965259552002, 0.4988040328025818, 0.4892926812171936, 0.47596442699432373, 0.47455012798309326, 0.46064993739128113, 0.4508950114250183, 0.4416457414627075, 0.434104859828949, 0.4325854778289795, 0.4220711290836334, 0.4168732166290283, 0.4147293269634247, 0.4023297131061554, 0.39932242035865784, 0.3979724943637848, 0.3914470076560974, 0.38554874062538147, 0.3876588046550751, 0.3766538202762604, 0.37625131011009216, 0.3719252049922943, 0.3691260516643524, 0.3642219603061676, 0.3590987026691437, 0.354279488325119, 0.35156843066215515, 0.3522915542125702, 0.34925010800361633, 0.3491455018520355, 0.34160131216049194, 0.3401453197002411, 0.336929053068161, 0.3371466100215912], 'val_accuracy': [0.6293333172798157, 0.6852499842643738, 0.7235000133514404, 0.7418333292007446, 0.752916693687439, 0.7674999833106995, 0.778333306312561, 0.799916684627533, 0.809499979019165, 0.8191666603088379, 0.8309999704360962, 0.8398333191871643, 0.8483333587646484, 0.8515833616256714, 0.8546666502952576, 0.8603333234786987, 0.8629999756813049, 0.8664166927337646, 0.8729166388511658, 0.8796666860580444, 0.8840833306312561, 0.887416660785675, 0.890250027179718, 0.8939999938011169, 0.8947499990463257, 0.8971666693687439, 0.8995000123977661, 0.9005833268165588, 0.9013333320617676, 0.9039999842643738, 0.906583309173584, 0.906416654586792, 0.909416675567627, 0.9108333587646484, 0.9106666445732117, 0.9139999747276306, 0.9144999980926514, 0.9165833592414856, 0.9161666631698608, 0.9184166789054871, 0.918583333492279, 0.921583354473114, 0.9225833415985107, 0.9226666688919067, 0.9235000014305115, 0.9235833287239075, 0.9252499938011169, 0.9259999990463257, 0.9262499809265137, 0.9273333549499512]}\n",
            "{'loss': [2.3036768436431885, 2.3011088371276855, 2.2994000911712646, 2.296980381011963, 2.2889513969421387, 2.259122848510742, 2.2012875080108643, 2.146014928817749, 2.096317768096924, 2.0408596992492676, 1.9899742603302002, 1.9340790510177612, 1.8776499032974243, 1.8236277103424072, 1.7722071409225464, 1.721550464630127, 1.684095025062561, 1.6456618309020996, 1.6086763143539429, 1.5776519775390625, 1.5516557693481445, 1.5251435041427612, 1.49922513961792, 1.4699817895889282, 1.4362766742706299, 1.4010626077651978, 1.3748844861984253, 1.338999629020691, 1.3157774209976196, 1.282883644104004, 1.257347822189331, 1.2293680906295776, 1.2019226551055908, 1.1726988554000854, 1.1486197710037231, 1.1361408233642578, 1.1115020513534546, 1.0871397256851196, 1.0745251178741455, 1.060333013534546, 1.037293791770935, 1.0230921506881714, 1.0193630456924438, 1.008266806602478, 0.9890533685684204, 0.975110650062561, 0.9671390652656555, 0.9598785638809204, 0.9418057203292847, 0.9385411739349365], 'accuracy': [0.11112499982118607, 0.12177083641290665, 0.1264166682958603, 0.12962499260902405, 0.14370833337306976, 0.16868749260902405, 0.1848125010728836, 0.1990624964237213, 0.20808333158493042, 0.21649999916553497, 0.2409166693687439, 0.2646041810512543, 0.29512500762939453, 0.3187083303928375, 0.3423125147819519, 0.36110416054725647, 0.3738958239555359, 0.39277082681655884, 0.40695834159851074, 0.41725000739097595, 0.4269374907016754, 0.4361666738986969, 0.44856250286102295, 0.46552082896232605, 0.4791249930858612, 0.4937708377838135, 0.5034583210945129, 0.5160624980926514, 0.5247291922569275, 0.5352708101272583, 0.5417083501815796, 0.5450624823570251, 0.5536458492279053, 0.5608749985694885, 0.5662708282470703, 0.5760833621025085, 0.5794374942779541, 0.5839166641235352, 0.5883541703224182, 0.5925208330154419, 0.5998333096504211, 0.6037708520889282, 0.6049791574478149, 0.6076250076293945, 0.6162916421890259, 0.6192291378974915, 0.6240416765213013, 0.6283541917800903, 0.6348124742507935, 0.637458324432373], 'val_loss': [2.3014976978302, 2.301126718521118, 2.3004093170166016, 2.2949001789093018, 2.2670154571533203, 2.1833579540252686, 2.084571361541748, 2.017280101776123, 1.9610658884048462, 1.909713864326477, 1.8393168449401855, 1.7599339485168457, 1.6840403079986572, 1.6074504852294922, 1.5707693099975586, 1.5337353944778442, 1.4929906129837036, 1.4618792533874512, 1.426056146621704, 1.3938050270080566, 1.3688724040985107, 1.3433260917663574, 1.3195445537567139, 1.3205146789550781, 1.2977865934371948, 1.2543138265609741, 1.2408738136291504, 1.2038527727127075, 1.181203842163086, 1.1548534631729126, 1.1236915588378906, 1.0942586660385132, 1.0642725229263306, 1.0368175506591797, 1.0074715614318848, 0.9865123629570007, 0.9629316329956055, 0.9479014277458191, 0.9471473097801208, 0.9509174227714539, 0.9272801280021667, 0.931247889995575, 0.8786057829856873, 0.8930505514144897, 0.9011560082435608, 0.9613586664199829, 0.8982406258583069, 0.8873324394226074, 0.9016406536102295, 0.8686267733573914], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.18858332931995392, 0.21850000321865082, 0.22741666436195374, 0.2694999873638153, 0.27433332800865173, 0.30291667580604553, 0.3217499852180481, 0.3382500112056732, 0.3605833351612091, 0.39891666173934937, 0.4175833463668823, 0.42491665482521057, 0.44449999928474426, 0.47333332896232605, 0.48608332872390747, 0.5025833249092102, 0.5067499876022339, 0.5120833516120911, 0.5141666531562805, 0.515250027179718, 0.5387499928474426, 0.5610833168029785, 0.5674999952316284, 0.5868333578109741, 0.5712500214576721, 0.6030833125114441, 0.6446666717529297, 0.6536666750907898, 0.6677500009536743, 0.6776666641235352, 0.7055000066757202, 0.7024166584014893, 0.7195833325386047, 0.7288333177566528, 0.7279999852180481, 0.7245833277702332, 0.7260833382606506, 0.7417500019073486, 0.7300000190734863, 0.7633333206176758, 0.7569166421890259, 0.6894999742507935, 0.7719166874885559, 0.7699166536331177, 0.7680833339691162, 0.7684166431427002]}\n",
            "{'loss': [2.3019814491271973, 2.285795211791992, 2.217618703842163, 2.101600408554077, 2.0270721912384033, 1.9651284217834473, 1.8885709047317505, 1.7967746257781982, 1.706697702407837, 1.6215227842330933, 1.5233219861984253, 1.419134497642517, 1.327173113822937, 1.2399086952209473, 1.173747181892395, 1.1238638162612915, 1.0754191875457764, 1.0330355167388916, 1.0047283172607422, 0.9679870009422302, 0.9272006750106812, 0.9069774746894836, 0.8722443580627441, 0.8476999402046204, 0.8123850226402283, 0.8045503497123718, 0.7702978253364563, 0.7455556392669678, 0.7238098382949829, 0.7011758089065552, 0.6793133616447449, 0.6592873334884644, 0.6465389132499695, 0.6208083033561707, 0.6052163243293762, 0.5898139476776123, 0.575293779373169, 0.5617425441741943, 0.5417771935462952, 0.5302547812461853, 0.5133798718452454, 0.5026017427444458, 0.48613420128822327, 0.47893697023391724, 0.46329355239868164, 0.44546806812286377, 0.4441802203655243, 0.42621269822120667, 0.4165976941585541, 0.4010592997074127], 'accuracy': [0.11510416865348816, 0.14479166269302368, 0.18464583158493042, 0.2136249989271164, 0.22614583373069763, 0.24443750083446503, 0.2748749852180481, 0.3149791657924652, 0.35368749499320984, 0.38725000619888306, 0.43060415983200073, 0.47333332896232605, 0.5104583501815796, 0.5425208210945129, 0.5687083601951599, 0.5888124704360962, 0.6086458563804626, 0.6277916431427002, 0.6418125033378601, 0.6598749756813049, 0.6735000014305115, 0.6847708225250244, 0.6965416669845581, 0.710895836353302, 0.7264999747276306, 0.7350416779518127, 0.7434583306312561, 0.7544999718666077, 0.7611874938011169, 0.7755208611488342, 0.7796249985694885, 0.7916250228881836, 0.7973541617393494, 0.8042916655540466, 0.8113124966621399, 0.8171250224113464, 0.8241249918937683, 0.8292499780654907, 0.839187502861023, 0.8418750166893005, 0.8496458530426025, 0.8559166789054871, 0.8626041412353516, 0.8664583563804626, 0.8745208382606506, 0.8768333196640015, 0.8790000081062317, 0.8835625052452087, 0.8872500061988831, 0.8896250128746033], 'val_loss': [2.2926344871520996, 2.255089282989502, 2.0872864723205566, 1.9746575355529785, 1.899749517440796, 1.812247395515442, 1.6934012174606323, 1.5913567543029785, 1.4924966096878052, 1.3670501708984375, 1.234408974647522, 1.1108630895614624, 1.0002646446228027, 0.9324158430099487, 0.8813841938972473, 0.8394601345062256, 0.8069596886634827, 0.7747734189033508, 0.7487038373947144, 0.7206822037696838, 0.6886690258979797, 0.6672681570053101, 0.6462455987930298, 0.6227642297744751, 0.5982311367988586, 0.5777888894081116, 0.5546965599060059, 0.5486589074134827, 0.5172430276870728, 0.5069368481636047, 0.49787554144859314, 0.4803156852722168, 0.47460347414016724, 0.48015841841697693, 0.4467860162258148, 0.44598737359046936, 0.44297102093696594, 0.42509618401527405, 0.4184689521789551, 0.41044023633003235, 0.40918758511543274, 0.399554967880249, 0.3822370171546936, 0.3708268702030182, 0.3661983907222748, 0.3549506366252899, 0.3702510893344879, 0.3460047245025635, 0.35505831241607666, 0.3567684292793274], 'val_accuracy': [0.11383333057165146, 0.21033333241939545, 0.20883333683013916, 0.21841666102409363, 0.23199999332427979, 0.25699999928474426, 0.35225000977516174, 0.43024998903274536, 0.46433332562446594, 0.5094166398048401, 0.5870000123977661, 0.6660833358764648, 0.6861666440963745, 0.7049166560173035, 0.7214999794960022, 0.7413333058357239, 0.7453333139419556, 0.7540833353996277, 0.7744166851043701, 0.7741666436195374, 0.7984166741371155, 0.8074166774749756, 0.8163333535194397, 0.8306666612625122, 0.8448333144187927, 0.8544166684150696, 0.8612499833106995, 0.8690000176429749, 0.871999979019165, 0.8799166679382324, 0.8815000057220459, 0.8883333206176758, 0.8889166712760925, 0.8958333134651184, 0.8980833292007446, 0.9047499895095825, 0.9076666831970215, 0.909333348274231, 0.9103333353996277, 0.9143333435058594, 0.9191666841506958, 0.9206666946411133, 0.9237499833106995, 0.9270833134651184, 0.9275000095367432, 0.9304999709129333, 0.9289166927337646, 0.9312499761581421, 0.9334166646003723, 0.9355833530426025]}\n",
            "{'loss': [2.1487679481506348, 1.6664748191833496, 1.4203143119812012, 1.255109190940857, 1.1369762420654297, 1.0456956624984741, 0.9862513542175293, 0.9295514225959778, 0.8872965574264526, 0.8494037389755249, 0.8197360634803772, 0.791975736618042, 0.7783826589584351, 0.7598827481269836, 0.7357839345932007, 0.7143262624740601, 0.6961421966552734, 0.6854328513145447, 0.6777424812316895, 0.6547430753707886, 0.6447925567626953, 0.6263747811317444, 0.6161954998970032, 0.6016192436218262, 0.5915126800537109, 0.5749563574790955, 0.5667440295219421, 0.5578049421310425, 0.5477681159973145, 0.5435195565223694, 0.5374415516853333, 0.5232639908790588, 0.5136309266090393, 0.5065067410469055, 0.4962972104549408, 0.4927482008934021, 0.4860958755016327, 0.477043092250824, 0.47402727603912354, 0.46772390604019165, 0.4634532332420349, 0.44629448652267456, 0.44015127420425415, 0.43693065643310547, 0.43143120408058167, 0.43032294511795044, 0.4202902019023895, 0.4196769893169403, 0.41110944747924805, 0.4125463366508484], 'accuracy': [0.2241666615009308, 0.40708333253860474, 0.5006458163261414, 0.5649791955947876, 0.6167291402816772, 0.6539999842643738, 0.6780416369438171, 0.703125, 0.7215625047683716, 0.7364791631698608, 0.7494375109672546, 0.7603750228881836, 0.765541672706604, 0.7756666541099548, 0.7846249938011169, 0.7925833463668823, 0.8006666898727417, 0.8057083487510681, 0.8110208511352539, 0.8164583444595337, 0.8196666836738586, 0.827833354473114, 0.8326249718666077, 0.8346458077430725, 0.838937520980835, 0.8447083234786987, 0.8477916717529297, 0.8508541584014893, 0.8543333411216736, 0.8569999933242798, 0.856416642665863, 0.8619583249092102, 0.866895854473114, 0.8677291870117188, 0.8700833320617676, 0.8717291951179504, 0.875041663646698, 0.8784375190734863, 0.8775833249092102, 0.8798333406448364, 0.8810208439826965, 0.8846874833106995, 0.885854184627533, 0.8875625133514404, 0.8884999752044678, 0.8901875019073486, 0.8936458230018616, 0.8947291374206543, 0.8976458311080933, 0.8973125219345093], 'val_loss': [1.3220148086547852, 0.9482636451721191, 0.7487817406654358, 0.6313340663909912, 0.553581714630127, 0.5093057751655579, 0.4896816313266754, 0.4665086269378662, 0.4501595199108124, 0.43878138065338135, 0.425994336605072, 0.4197738766670227, 0.41329509019851685, 0.4017072021961212, 0.3916734755039215, 0.38985970616340637, 0.3807970881462097, 0.3680972456932068, 0.3610534965991974, 0.3566657602787018, 0.3530307710170746, 0.33878132700920105, 0.3381204307079315, 0.33100369572639465, 0.326739102602005, 0.32337817549705505, 0.3155635893344879, 0.3089044690132141, 0.3062644302845001, 0.30497321486473083, 0.29246872663497925, 0.2953825294971466, 0.29457104206085205, 0.283237487077713, 0.28211989998817444, 0.2784809470176697, 0.2746259272098541, 0.2770790755748749, 0.27180197834968567, 0.2740669548511505, 0.2659442126750946, 0.26457273960113525, 0.26053550839424133, 0.26372742652893066, 0.2609686255455017, 0.2577768862247467, 0.26096558570861816, 0.25493207573890686, 0.25576964020729065, 0.24877624213695526], 'val_accuracy': [0.6354166865348816, 0.7124999761581421, 0.781583309173584, 0.8202499747276306, 0.8412500023841858, 0.8549166917800903, 0.8609166741371155, 0.8689166903495789, 0.8675833344459534, 0.8732500076293945, 0.8802499771118164, 0.8793333172798157, 0.8869166374206543, 0.8884166479110718, 0.8915833234786987, 0.8942499756813049, 0.8961666822433472, 0.8980833292007446, 0.9024166464805603, 0.9025833606719971, 0.9070000052452087, 0.909166693687439, 0.9111666679382324, 0.9124166369438171, 0.9138333201408386, 0.9165833592414856, 0.9184166789054871, 0.9193333387374878, 0.9211666584014893, 0.9231666922569275, 0.9247499704360962, 0.9261666536331177, 0.9252499938011169, 0.9292500019073486, 0.9287499785423279, 0.9315000176429749, 0.9334166646003723, 0.9313333630561829, 0.9327499866485596, 0.9338333606719971, 0.934416651725769, 0.9352499842643738, 0.937333345413208, 0.9364166855812073, 0.9375, 0.9395833611488342, 0.9396666884422302, 0.9389166831970215, 0.9394166469573975, 0.940500020980835]}\n",
            "{'loss': [2.4094133377075195, 1.478427529335022, 1.2439396381378174, 1.1253409385681152, 1.050246238708496, 0.9870364665985107, 0.9453576803207397, 0.9041246771812439, 0.8683221936225891, 0.8391122221946716, 0.813286542892456, 0.7914695739746094, 0.7640939354896545, 0.7532308101654053, 0.723911464214325, 0.7091086506843567, 0.6854729056358337, 0.6814368367195129, 0.6639605164527893, 0.649965226650238, 0.6429939866065979, 0.6194848418235779, 0.6039471626281738, 0.6043609380722046, 0.5933709144592285, 0.5768001079559326, 0.5730718374252319, 0.5684899687767029, 0.5579257607460022, 0.546930193901062, 0.5444308519363403, 0.5225108861923218, 0.5184715390205383, 0.5026078820228577, 0.5064328908920288, 0.49641403555870056, 0.4934910535812378, 0.47837987542152405, 0.47316861152648926, 0.47474193572998047, 0.47015947103500366, 0.45653706789016724, 0.4562712013721466, 0.44432738423347473, 0.44124242663383484, 0.4410364031791687, 0.43142545223236084, 0.4227728545665741, 0.42199409008026123, 0.41544637084007263], 'accuracy': [0.27527081966400146, 0.47858333587646484, 0.5657291412353516, 0.6138333082199097, 0.648395836353302, 0.6772708296775818, 0.7010833621025085, 0.7144791483879089, 0.731249988079071, 0.746874988079071, 0.7574999928474426, 0.765458345413208, 0.7788125276565552, 0.7852708101272583, 0.7953541874885559, 0.805020809173584, 0.8134791851043701, 0.8133749961853027, 0.8219375014305115, 0.8255416750907898, 0.831375002861023, 0.8373333215713501, 0.8422291874885559, 0.8442083597183228, 0.8475624918937683, 0.8526041507720947, 0.8571041822433472, 0.8553958535194397, 0.8586249947547913, 0.8636041879653931, 0.8638749718666077, 0.8673333525657654, 0.870229184627533, 0.8741875290870667, 0.875083327293396, 0.8774583339691162, 0.8775208592414856, 0.8820624947547913, 0.882437527179718, 0.8826666474342346, 0.8840625286102295, 0.887583315372467, 0.8892499804496765, 0.890916645526886, 0.8920208215713501, 0.8926458358764648, 0.8956458568572998, 0.8979374766349792, 0.8977083563804626, 0.8989583253860474], 'val_loss': [0.9473572373390198, 0.7707682847976685, 0.6897536516189575, 0.631624162197113, 0.5848317742347717, 0.5491591691970825, 0.5178227424621582, 0.501446008682251, 0.4845411777496338, 0.464476078748703, 0.45056766271591187, 0.4308432936668396, 0.4216814637184143, 0.405178427696228, 0.3958226442337036, 0.3856929838657379, 0.3881014287471771, 0.3750249147415161, 0.3671922981739044, 0.3589321970939636, 0.35325267910957336, 0.3507232367992401, 0.34554120898246765, 0.3362022936344147, 0.33356162905693054, 0.32835498452186584, 0.32429033517837524, 0.3211654722690582, 0.31870993971824646, 0.3170434832572937, 0.31255844235420227, 0.309182733297348, 0.310852974653244, 0.30610543489456177, 0.30080828070640564, 0.29968759417533875, 0.2954908311367035, 0.29477208852767944, 0.28853341937065125, 0.2846309244632721, 0.2826807200908661, 0.2845056653022766, 0.2764533460140228, 0.27614501118659973, 0.2753657102584839, 0.27300989627838135, 0.26860255002975464, 0.2684345841407776, 0.26616808772087097, 0.26783686876296997], 'val_accuracy': [0.7214999794960022, 0.7827500104904175, 0.7983333468437195, 0.8051666617393494, 0.8198333382606506, 0.8370833396911621, 0.8503333330154419, 0.8525833487510681, 0.8649166822433472, 0.878166675567627, 0.8825833201408386, 0.8880000114440918, 0.8893333077430725, 0.8948333263397217, 0.8974999785423279, 0.9004166722297668, 0.9038333296775818, 0.9051666855812073, 0.9068333506584167, 0.9090833067893982, 0.9111666679382324, 0.9124166369438171, 0.9148333072662354, 0.9154999852180481, 0.9178333282470703, 0.9176666736602783, 0.9192500114440918, 0.9204999804496765, 0.9214166402816772, 0.9237499833106995, 0.9234166741371155, 0.9237499833106995, 0.9246666431427002, 0.9257500171661377, 0.9275000095367432, 0.9287499785423279, 0.9309999942779541, 0.9301666617393494, 0.9320833086967468, 0.9333333373069763, 0.9340833425521851, 0.9346666932106018, 0.9349166750907898, 0.9360833168029785, 0.9360833168029785, 0.9361666440963745, 0.9391666650772095, 0.9388333559036255, 0.9389166831970215, 0.9385833144187927]}\n",
            "{'loss': [2.301964044570923, 2.3012795448303223, 2.300891876220703, 2.3006839752197266, 2.3005948066711426, 2.300379514694214, 2.3003551959991455, 2.300105571746826, 2.299976348876953, 2.2998459339141846, 2.299739122390747, 2.299450397491455, 2.299197196960449, 2.298954963684082, 2.298574209213257, 2.2980947494506836, 2.297593832015991, 2.2968358993530273, 2.2957804203033447, 2.2939414978027344, 2.290287494659424, 2.2768938541412354, 2.2347612380981445, 2.1612701416015625, 2.0818731784820557, 1.99168860912323, 1.9090116024017334, 1.832438349723816, 1.747972011566162, 1.6628624200820923, 1.590126633644104, 1.5260716676712036, 1.4710137844085693, 1.4191230535507202, 1.3739829063415527, 1.3245800733566284, 1.287353754043579, 1.241282343864441, 1.207827091217041, 1.1623190641403198, 1.126842737197876, 1.1004095077514648, 1.068617820739746, 1.037186622619629, 1.0213154554367065, 0.9882706999778748, 0.9659311771392822, 0.9422847628593445, 0.9154358506202698, 0.900222897529602], 'accuracy': [0.11533333361148834, 0.11400000005960464, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11397916823625565, 0.11397916823625565, 0.11410416662693024, 0.11427083611488342, 0.11489583551883698, 0.11685416847467422, 0.12416666746139526, 0.14174999296665192, 0.16906249523162842, 0.21902082860469818, 0.226500004529953, 0.24891667068004608, 0.2684375047683716, 0.28939583897590637, 0.3161666691303253, 0.3490625023841858, 0.3830833435058594, 0.41447916626930237, 0.43954166769981384, 0.4596875011920929, 0.4830833375453949, 0.5016041398048401, 0.5210208296775818, 0.5380833148956299, 0.5536041855812073, 0.5721874833106995, 0.5884583592414856, 0.601395845413208, 0.617270827293396, 0.6270208358764648, 0.6362291574478149, 0.6513333320617676, 0.6582291722297668, 0.6679166555404663, 0.6774374842643738, 0.6874374747276306], 'val_loss': [2.301898717880249, 2.301712989807129, 2.3016011714935303, 2.3015408515930176, 2.3014395236968994, 2.3013205528259277, 2.3012168407440186, 2.301095962524414, 2.300924777984619, 2.300767660140991, 2.3005788326263428, 2.300379514694214, 2.300107479095459, 2.2997798919677734, 2.2993836402893066, 2.298889398574829, 2.2982327938079834, 2.2973389625549316, 2.29593825340271, 2.293341636657715, 2.287160873413086, 2.253659725189209, 2.1553351879119873, 2.03903865814209, 1.9086792469024658, 1.7869917154312134, 1.6803045272827148, 1.5902968645095825, 1.4886959791183472, 1.3843061923980713, 1.2974166870117188, 1.2333638668060303, 1.1748294830322266, 1.1176224946975708, 1.0556193590164185, 0.9940344095230103, 0.945620596408844, 0.9028324484825134, 0.8536149263381958, 0.8122323155403137, 0.7747823596000671, 0.7484146952629089, 0.7170042395591736, 0.6871272921562195, 0.675303041934967, 0.6480821371078491, 0.6329393982887268, 0.6129410266876221, 0.6003676056861877, 0.5826110243797302], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10966666787862778, 0.1732500046491623, 0.1914166659116745, 0.31308332085609436, 0.296833336353302, 0.3448333442211151, 0.4216666519641876, 0.45258334279060364, 0.47325000166893005, 0.5194166898727417, 0.5529999732971191, 0.5772500038146973, 0.593500018119812, 0.6209166646003723, 0.6459166407585144, 0.668666660785675, 0.6875, 0.7191666960716248, 0.7265833616256714, 0.7481666803359985, 0.7691666483879089, 0.778166651725769, 0.7911666631698608, 0.793583333492279, 0.8104166388511658, 0.8173333406448364, 0.8213333487510681, 0.824916660785675, 0.8340833187103271, 0.8399166464805603]}\n",
            "{'loss': [2.301987886428833, 2.301352024078369, 2.3010337352752686, 2.300813674926758, 2.3005638122558594, 2.300501823425293, 2.30039644241333, 2.300245761871338, 2.3002493381500244, 2.300093412399292, 2.299893379211426, 2.299753189086914, 2.2996087074279785, 2.299443006515503, 2.2992019653320312, 2.2990190982818604, 2.298771858215332, 2.2984254360198975, 2.2979562282562256, 2.2975387573242188, 2.297043561935425, 2.296196937561035, 2.295322895050049, 2.293583393096924, 2.291290044784546, 2.2866079807281494, 2.274054527282715, 2.218860387802124, 2.1193227767944336, 2.0461843013763428, 1.9809468984603882, 1.9128450155258179, 1.8521794080734253, 1.7931946516036987, 1.740085482597351, 1.6871646642684937, 1.6443564891815186, 1.6042571067810059, 1.5613017082214355, 1.52247154712677, 1.4796174764633179, 1.4442259073257446, 1.3984407186508179, 1.3610540628433228, 1.324476957321167, 1.2932052612304688, 1.2608063220977783, 1.2319289445877075, 1.2099223136901855, 1.188439130783081], 'accuracy': [0.11483333259820938, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11400000005960464, 0.11397916823625565, 0.11410416662693024, 0.11429166793823242, 0.1145208328962326, 0.11612500250339508, 0.12183333188295364, 0.13497917354106903, 0.17366667091846466, 0.20741666853427887, 0.210916668176651, 0.23520833253860474, 0.2631458342075348, 0.2849791646003723, 0.29785415530204773, 0.31304165720939636, 0.3226250112056732, 0.3399166762828827, 0.3538333475589752, 0.36752083897590637, 0.3882916569709778, 0.4034374952316284, 0.42393749952316284, 0.4423125088214874, 0.4728333353996277, 0.49270832538604736, 0.507479190826416, 0.5245416760444641, 0.5340833067893982, 0.5455208420753479, 0.5559999942779541, 0.5692499876022339], 'val_loss': [2.302046775817871, 2.3018510341644287, 2.3017475605010986, 2.3016903400421143, 2.3015918731689453, 2.3015196323394775, 2.301427125930786, 2.301316976547241, 2.301158905029297, 2.301034688949585, 2.3008744716644287, 2.3007235527038574, 2.300562858581543, 2.300368070602417, 2.300123691558838, 2.299908399581909, 2.2996294498443604, 2.2992026805877686, 2.2987887859344482, 2.298224925994873, 2.2975544929504395, 2.2967143058776855, 2.2954397201538086, 2.2934510707855225, 2.290179967880249, 2.2830169200897217, 2.257852554321289, 2.1251168251037598, 2.002770185470581, 1.9210731983184814, 1.836293339729309, 1.7516056299209595, 1.6836174726486206, 1.6301403045654297, 1.5784084796905518, 1.526959776878357, 1.4828180074691772, 1.4424619674682617, 1.3974872827529907, 1.354862093925476, 1.3017281293869019, 1.2411012649536133, 1.1900033950805664, 1.1356968879699707, 1.0966134071350098, 1.0639501810073853, 1.0332649946212769, 1.0025091171264648, 0.9756472706794739, 0.9512616395950317], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10608333349227905, 0.14083333313465118, 0.1941666603088379, 0.2382500022649765, 0.23616667091846466, 0.29600000381469727, 0.31966665387153625, 0.33500000834465027, 0.3580000102519989, 0.3726666569709778, 0.3798333406448364, 0.39941665530204773, 0.4128333330154419, 0.43141666054725647, 0.4492500126361847, 0.46816667914390564, 0.5182499885559082, 0.5737500190734863, 0.6119166612625122, 0.6506666541099548, 0.6651666760444641, 0.6694999933242798, 0.6924166679382324, 0.7010833621025085, 0.7116666436195374, 0.7192500233650208]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}