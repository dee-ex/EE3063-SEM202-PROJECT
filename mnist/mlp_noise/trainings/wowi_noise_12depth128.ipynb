{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noinit_noise_12depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "e294b8c5-71b2-48b1-f448-6ca4c166d8bd"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 15s 6ms/step - loss: 2.3720 - accuracy: 0.1257 - val_loss: 1.7924 - val_accuracy: 0.2951\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0488 - accuracy: 0.2278 - val_loss: 1.5556 - val_accuracy: 0.4119\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8584 - accuracy: 0.2863 - val_loss: 1.4294 - val_accuracy: 0.5082\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7360 - accuracy: 0.3320 - val_loss: 1.2932 - val_accuracy: 0.5598\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6175 - accuracy: 0.3841 - val_loss: 1.1722 - val_accuracy: 0.5932\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5168 - accuracy: 0.4265 - val_loss: 1.0969 - val_accuracy: 0.5933\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4533 - accuracy: 0.4537 - val_loss: 1.0564 - val_accuracy: 0.6034\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3913 - accuracy: 0.4732 - val_loss: 1.0160 - val_accuracy: 0.6080\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3370 - accuracy: 0.4881 - val_loss: 0.9953 - val_accuracy: 0.6181\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3025 - accuracy: 0.5043 - val_loss: 0.9772 - val_accuracy: 0.6371\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2666 - accuracy: 0.5179 - val_loss: 0.9644 - val_accuracy: 0.6299\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2470 - accuracy: 0.5316 - val_loss: 0.9516 - val_accuracy: 0.6514\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2276 - accuracy: 0.5359 - val_loss: 0.9504 - val_accuracy: 0.6482\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2049 - accuracy: 0.5463 - val_loss: 0.9312 - val_accuracy: 0.6499\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1878 - accuracy: 0.5533 - val_loss: 0.9266 - val_accuracy: 0.6463\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1827 - accuracy: 0.5611 - val_loss: 0.9114 - val_accuracy: 0.6494\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1571 - accuracy: 0.5734 - val_loss: 0.9122 - val_accuracy: 0.6488\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1357 - accuracy: 0.5771 - val_loss: 0.9055 - val_accuracy: 0.6652\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1321 - accuracy: 0.5835 - val_loss: 0.8805 - val_accuracy: 0.6812\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1244 - accuracy: 0.5927 - val_loss: 0.8577 - val_accuracy: 0.7041\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0961 - accuracy: 0.6043 - val_loss: 0.8380 - val_accuracy: 0.7177\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0816 - accuracy: 0.6156 - val_loss: 0.8157 - val_accuracy: 0.7283\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0525 - accuracy: 0.6226 - val_loss: 0.7940 - val_accuracy: 0.7337\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0473 - accuracy: 0.6292 - val_loss: 0.7750 - val_accuracy: 0.7615\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0392 - accuracy: 0.6381 - val_loss: 0.7597 - val_accuracy: 0.7636\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0133 - accuracy: 0.6471 - val_loss: 0.7429 - val_accuracy: 0.7657\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0034 - accuracy: 0.6526 - val_loss: 0.7475 - val_accuracy: 0.7638\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9881 - accuracy: 0.6590 - val_loss: 0.7174 - val_accuracy: 0.7540\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9733 - accuracy: 0.6704 - val_loss: 0.7093 - val_accuracy: 0.7636\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9569 - accuracy: 0.6783 - val_loss: 0.6914 - val_accuracy: 0.7775\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9449 - accuracy: 0.6843 - val_loss: 0.6722 - val_accuracy: 0.8205\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9312 - accuracy: 0.6930 - val_loss: 0.6495 - val_accuracy: 0.8130\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9250 - accuracy: 0.7007 - val_loss: 0.6254 - val_accuracy: 0.8224\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9031 - accuracy: 0.7132 - val_loss: 0.6114 - val_accuracy: 0.8493\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8830 - accuracy: 0.7233 - val_loss: 0.5988 - val_accuracy: 0.8424\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8687 - accuracy: 0.7338 - val_loss: 0.5834 - val_accuracy: 0.8484\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8469 - accuracy: 0.7377 - val_loss: 0.5816 - val_accuracy: 0.8572\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8388 - accuracy: 0.7451 - val_loss: 0.5653 - val_accuracy: 0.8286\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8445 - accuracy: 0.7435 - val_loss: 0.5630 - val_accuracy: 0.8322\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8179 - accuracy: 0.7524 - val_loss: 0.5529 - val_accuracy: 0.8335\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8121 - accuracy: 0.7593 - val_loss: 0.5614 - val_accuracy: 0.8352\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8121 - accuracy: 0.7540 - val_loss: 0.5446 - val_accuracy: 0.8347\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8040 - accuracy: 0.7549 - val_loss: 0.5414 - val_accuracy: 0.8368\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7940 - accuracy: 0.7647 - val_loss: 0.5394 - val_accuracy: 0.8367\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7793 - accuracy: 0.7692 - val_loss: 0.5437 - val_accuracy: 0.8367\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7879 - accuracy: 0.7680 - val_loss: 0.5313 - val_accuracy: 0.8380\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7677 - accuracy: 0.7721 - val_loss: 0.5303 - val_accuracy: 0.8389\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7604 - accuracy: 0.7730 - val_loss: 0.5296 - val_accuracy: 0.8411\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7551 - accuracy: 0.7739 - val_loss: 0.5208 - val_accuracy: 0.8424\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7513 - accuracy: 0.7725 - val_loss: 0.5172 - val_accuracy: 0.8408\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3061 - accuracy: 0.1127 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3011 - accuracy: 0.1197 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3006 - accuracy: 0.1173 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2997 - accuracy: 0.1173 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2979 - accuracy: 0.1174 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2955 - accuracy: 0.1193 - val_loss: 2.2999 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2917 - accuracy: 0.1157 - val_loss: 2.2887 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2769 - accuracy: 0.1124 - val_loss: 2.2526 - val_accuracy: 0.1229\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2485 - accuracy: 0.1221 - val_loss: 2.1939 - val_accuracy: 0.2079\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2103 - accuracy: 0.1568 - val_loss: 2.1179 - val_accuracy: 0.2076\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1680 - accuracy: 0.1779 - val_loss: 2.0621 - val_accuracy: 0.2263\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1121 - accuracy: 0.1873 - val_loss: 2.0132 - val_accuracy: 0.2269\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0660 - accuracy: 0.1972 - val_loss: 1.9687 - val_accuracy: 0.2172\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0171 - accuracy: 0.2064 - val_loss: 1.9266 - val_accuracy: 0.2626\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9747 - accuracy: 0.2247 - val_loss: 1.8917 - val_accuracy: 0.2498\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9319 - accuracy: 0.2332 - val_loss: 1.8488 - val_accuracy: 0.2751\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9024 - accuracy: 0.2371 - val_loss: 1.8432 - val_accuracy: 0.2823\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8680 - accuracy: 0.2503 - val_loss: 1.7981 - val_accuracy: 0.2782\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8368 - accuracy: 0.2539 - val_loss: 1.7669 - val_accuracy: 0.2777\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8087 - accuracy: 0.2584 - val_loss: 1.7371 - val_accuracy: 0.2891\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7831 - accuracy: 0.2627 - val_loss: 1.7259 - val_accuracy: 0.2878\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7614 - accuracy: 0.2700 - val_loss: 1.6958 - val_accuracy: 0.2758\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7442 - accuracy: 0.2733 - val_loss: 1.6855 - val_accuracy: 0.2952\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7281 - accuracy: 0.2736 - val_loss: 1.6670 - val_accuracy: 0.2989\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7140 - accuracy: 0.2788 - val_loss: 1.6689 - val_accuracy: 0.2864\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6993 - accuracy: 0.2822 - val_loss: 1.6347 - val_accuracy: 0.3101\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6897 - accuracy: 0.2817 - val_loss: 1.6324 - val_accuracy: 0.3133\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6622 - accuracy: 0.2899 - val_loss: 1.6291 - val_accuracy: 0.3080\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6545 - accuracy: 0.2919 - val_loss: 1.6033 - val_accuracy: 0.3192\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6474 - accuracy: 0.2874 - val_loss: 1.5762 - val_accuracy: 0.3273\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6351 - accuracy: 0.2854 - val_loss: 1.5745 - val_accuracy: 0.3038\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6279 - accuracy: 0.2899 - val_loss: 1.5914 - val_accuracy: 0.3161\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6145 - accuracy: 0.2923 - val_loss: 1.5568 - val_accuracy: 0.3269\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6089 - accuracy: 0.2898 - val_loss: 1.6053 - val_accuracy: 0.3058\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5895 - accuracy: 0.2979 - val_loss: 1.5665 - val_accuracy: 0.2819\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5923 - accuracy: 0.2921 - val_loss: 1.5665 - val_accuracy: 0.3153\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5893 - accuracy: 0.2952 - val_loss: 1.5509 - val_accuracy: 0.3183\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5678 - accuracy: 0.3029 - val_loss: 1.5357 - val_accuracy: 0.3133\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5582 - accuracy: 0.3064 - val_loss: 1.5183 - val_accuracy: 0.3365\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5434 - accuracy: 0.3194 - val_loss: 1.5141 - val_accuracy: 0.3504\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5211 - accuracy: 0.3139 - val_loss: 1.5066 - val_accuracy: 0.3753\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5234 - accuracy: 0.3237 - val_loss: 1.4983 - val_accuracy: 0.3360\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5069 - accuracy: 0.3252 - val_loss: 1.4843 - val_accuracy: 0.3738\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4952 - accuracy: 0.3322 - val_loss: 1.5429 - val_accuracy: 0.3162\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4911 - accuracy: 0.3350 - val_loss: 1.4863 - val_accuracy: 0.3413\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4795 - accuracy: 0.3402 - val_loss: 1.4876 - val_accuracy: 0.3627\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4622 - accuracy: 0.3503 - val_loss: 1.4522 - val_accuracy: 0.3738\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4564 - accuracy: 0.3552 - val_loss: 1.4937 - val_accuracy: 0.3482\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4620 - accuracy: 0.3526 - val_loss: 1.4682 - val_accuracy: 0.3590\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4452 - accuracy: 0.3585 - val_loss: 1.4992 - val_accuracy: 0.3190\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 8ms/step - loss: 2.3092 - accuracy: 0.1030 - val_loss: 2.3019 - val_accuracy: 0.1058\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1135 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2992 - accuracy: 0.1173 - val_loss: 2.2995 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2961 - accuracy: 0.1211 - val_loss: 2.2849 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2859 - accuracy: 0.1288 - val_loss: 2.2410 - val_accuracy: 0.2098\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2426 - accuracy: 0.1545 - val_loss: 2.1213 - val_accuracy: 0.2050\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1708 - accuracy: 0.1678 - val_loss: 2.0163 - val_accuracy: 0.1996\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0950 - accuracy: 0.1775 - val_loss: 1.9426 - val_accuracy: 0.2062\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0471 - accuracy: 0.1837 - val_loss: 1.8961 - val_accuracy: 0.2208\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0120 - accuracy: 0.1859 - val_loss: 1.8629 - val_accuracy: 0.2952\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9653 - accuracy: 0.1994 - val_loss: 1.8437 - val_accuracy: 0.2761\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9431 - accuracy: 0.2033 - val_loss: 1.8231 - val_accuracy: 0.2939\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9171 - accuracy: 0.2113 - val_loss: 1.7940 - val_accuracy: 0.2848\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8910 - accuracy: 0.2233 - val_loss: 1.7553 - val_accuracy: 0.3107\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8429 - accuracy: 0.2468 - val_loss: 1.6661 - val_accuracy: 0.3377\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7830 - accuracy: 0.2784 - val_loss: 1.5915 - val_accuracy: 0.3602\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7406 - accuracy: 0.3032 - val_loss: 1.5602 - val_accuracy: 0.3857\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6904 - accuracy: 0.3226 - val_loss: 1.5242 - val_accuracy: 0.3772\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6548 - accuracy: 0.3324 - val_loss: 1.5090 - val_accuracy: 0.3904\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6086 - accuracy: 0.3488 - val_loss: 1.4583 - val_accuracy: 0.4296\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5744 - accuracy: 0.3615 - val_loss: 1.4112 - val_accuracy: 0.4674\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5458 - accuracy: 0.3777 - val_loss: 1.3770 - val_accuracy: 0.4874\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5021 - accuracy: 0.3905 - val_loss: 1.3288 - val_accuracy: 0.4938\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4743 - accuracy: 0.4043 - val_loss: 1.2996 - val_accuracy: 0.5257\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4426 - accuracy: 0.4140 - val_loss: 1.2679 - val_accuracy: 0.5171\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4038 - accuracy: 0.4302 - val_loss: 1.2432 - val_accuracy: 0.5080\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3810 - accuracy: 0.4351 - val_loss: 1.2234 - val_accuracy: 0.5095\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3571 - accuracy: 0.4420 - val_loss: 1.1973 - val_accuracy: 0.5115\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3351 - accuracy: 0.4516 - val_loss: 1.1869 - val_accuracy: 0.5062\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3126 - accuracy: 0.4624 - val_loss: 1.1758 - val_accuracy: 0.5318\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2910 - accuracy: 0.4664 - val_loss: 1.1575 - val_accuracy: 0.5343\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2730 - accuracy: 0.4772 - val_loss: 1.1636 - val_accuracy: 0.5320\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2469 - accuracy: 0.4881 - val_loss: 1.1412 - val_accuracy: 0.5389\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2270 - accuracy: 0.4932 - val_loss: 1.1488 - val_accuracy: 0.5283\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2193 - accuracy: 0.5045 - val_loss: 1.1210 - val_accuracy: 0.5463\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2028 - accuracy: 0.5098 - val_loss: 1.0949 - val_accuracy: 0.5543\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1753 - accuracy: 0.5201 - val_loss: 1.0727 - val_accuracy: 0.5862\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1749 - accuracy: 0.5248 - val_loss: 1.0638 - val_accuracy: 0.5796\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1346 - accuracy: 0.5422 - val_loss: 1.0575 - val_accuracy: 0.6008\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1173 - accuracy: 0.5508 - val_loss: 1.0254 - val_accuracy: 0.6454\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1094 - accuracy: 0.5557 - val_loss: 1.0165 - val_accuracy: 0.6415\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0804 - accuracy: 0.5652 - val_loss: 1.0129 - val_accuracy: 0.6431\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0697 - accuracy: 0.5779 - val_loss: 0.9775 - val_accuracy: 0.6641\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0431 - accuracy: 0.5892 - val_loss: 0.9413 - val_accuracy: 0.6777\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0260 - accuracy: 0.5948 - val_loss: 0.9167 - val_accuracy: 0.7039\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0037 - accuracy: 0.6144 - val_loss: 0.9049 - val_accuracy: 0.6978\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9926 - accuracy: 0.6150 - val_loss: 0.8977 - val_accuracy: 0.7115\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9747 - accuracy: 0.6204 - val_loss: 1.0597 - val_accuracy: 0.6424\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9824 - accuracy: 0.6211 - val_loss: 0.8338 - val_accuracy: 0.7398\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9224 - accuracy: 0.6398 - val_loss: 0.8262 - val_accuracy: 0.7343\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.4123 - accuracy: 0.1367 - val_loss: 1.5178 - val_accuracy: 0.5601\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9322 - accuracy: 0.2911 - val_loss: 1.1986 - val_accuracy: 0.6092\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6856 - accuracy: 0.3761 - val_loss: 1.0582 - val_accuracy: 0.6360\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5316 - accuracy: 0.4364 - val_loss: 0.9684 - val_accuracy: 0.6751\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4346 - accuracy: 0.4713 - val_loss: 0.8954 - val_accuracy: 0.7238\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3648 - accuracy: 0.5022 - val_loss: 0.8238 - val_accuracy: 0.7440\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2903 - accuracy: 0.5378 - val_loss: 0.7723 - val_accuracy: 0.7612\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2406 - accuracy: 0.5585 - val_loss: 0.7370 - val_accuracy: 0.7736\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1975 - accuracy: 0.5728 - val_loss: 0.7096 - val_accuracy: 0.7768\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1509 - accuracy: 0.5848 - val_loss: 0.6914 - val_accuracy: 0.7845\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1134 - accuracy: 0.6034 - val_loss: 0.6806 - val_accuracy: 0.7701\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0778 - accuracy: 0.6201 - val_loss: 0.6668 - val_accuracy: 0.7727\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0498 - accuracy: 0.6268 - val_loss: 0.6597 - val_accuracy: 0.7818\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0310 - accuracy: 0.6325 - val_loss: 0.6460 - val_accuracy: 0.7886\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9949 - accuracy: 0.6507 - val_loss: 0.6293 - val_accuracy: 0.7874\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9752 - accuracy: 0.6552 - val_loss: 0.6290 - val_accuracy: 0.7783\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9629 - accuracy: 0.6639 - val_loss: 0.6113 - val_accuracy: 0.7767\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9414 - accuracy: 0.6702 - val_loss: 0.6025 - val_accuracy: 0.7829\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9428 - accuracy: 0.6681 - val_loss: 0.5935 - val_accuracy: 0.8176\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9139 - accuracy: 0.6779 - val_loss: 0.5830 - val_accuracy: 0.7847\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8886 - accuracy: 0.6919 - val_loss: 0.5740 - val_accuracy: 0.8017\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8893 - accuracy: 0.6881 - val_loss: 0.5673 - val_accuracy: 0.8044\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8765 - accuracy: 0.6986 - val_loss: 0.5612 - val_accuracy: 0.7873\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8467 - accuracy: 0.7033 - val_loss: 0.5595 - val_accuracy: 0.8008\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8398 - accuracy: 0.7050 - val_loss: 0.5553 - val_accuracy: 0.8092\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8324 - accuracy: 0.7105 - val_loss: 0.5523 - val_accuracy: 0.8135\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8178 - accuracy: 0.7188 - val_loss: 0.5453 - val_accuracy: 0.8021\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8122 - accuracy: 0.7188 - val_loss: 0.5399 - val_accuracy: 0.8155\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8009 - accuracy: 0.7221 - val_loss: 0.5385 - val_accuracy: 0.8055\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7962 - accuracy: 0.7220 - val_loss: 0.5319 - val_accuracy: 0.7993\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7723 - accuracy: 0.7309 - val_loss: 0.5263 - val_accuracy: 0.8005\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7806 - accuracy: 0.7299 - val_loss: 0.5247 - val_accuracy: 0.8108\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7629 - accuracy: 0.7321 - val_loss: 0.5202 - val_accuracy: 0.8172\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7557 - accuracy: 0.7304 - val_loss: 0.5246 - val_accuracy: 0.8202\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7434 - accuracy: 0.7394 - val_loss: 0.5167 - val_accuracy: 0.8090\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7535 - accuracy: 0.7362 - val_loss: 0.5174 - val_accuracy: 0.8144\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7354 - accuracy: 0.7421 - val_loss: 0.5183 - val_accuracy: 0.8173\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7358 - accuracy: 0.7427 - val_loss: 0.5163 - val_accuracy: 0.8239\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7172 - accuracy: 0.7472 - val_loss: 0.5063 - val_accuracy: 0.8293\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7182 - accuracy: 0.7474 - val_loss: 0.5029 - val_accuracy: 0.8073\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7152 - accuracy: 0.7469 - val_loss: 0.5009 - val_accuracy: 0.8421\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6977 - accuracy: 0.7590 - val_loss: 0.4941 - val_accuracy: 0.8440\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6815 - accuracy: 0.7611 - val_loss: 0.4956 - val_accuracy: 0.8422\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6909 - accuracy: 0.7558 - val_loss: 0.4914 - val_accuracy: 0.8377\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6822 - accuracy: 0.7635 - val_loss: 0.4910 - val_accuracy: 0.8344\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6745 - accuracy: 0.7657 - val_loss: 0.4803 - val_accuracy: 0.8426\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6847 - accuracy: 0.7649 - val_loss: 0.4748 - val_accuracy: 0.8619\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6660 - accuracy: 0.7689 - val_loss: 0.4733 - val_accuracy: 0.8643\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6531 - accuracy: 0.7735 - val_loss: 0.4681 - val_accuracy: 0.8737\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6641 - accuracy: 0.7755 - val_loss: 0.4640 - val_accuracy: 0.8658\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 3.3113 - accuracy: 0.1182 - val_loss: 1.7500 - val_accuracy: 0.2968\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0793 - accuracy: 0.2062 - val_loss: 1.5754 - val_accuracy: 0.4673\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8301 - accuracy: 0.2882 - val_loss: 1.2769 - val_accuracy: 0.5262\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6007 - accuracy: 0.3724 - val_loss: 1.1430 - val_accuracy: 0.5303\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4708 - accuracy: 0.4193 - val_loss: 1.1119 - val_accuracy: 0.5250\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3946 - accuracy: 0.4445 - val_loss: 1.0838 - val_accuracy: 0.5324\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3497 - accuracy: 0.4607 - val_loss: 1.0705 - val_accuracy: 0.5664\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3305 - accuracy: 0.4631 - val_loss: 1.0532 - val_accuracy: 0.5783\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2957 - accuracy: 0.4832 - val_loss: 1.0437 - val_accuracy: 0.5867\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2667 - accuracy: 0.4871 - val_loss: 1.0307 - val_accuracy: 0.5933\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2531 - accuracy: 0.5017 - val_loss: 1.0189 - val_accuracy: 0.5967\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2274 - accuracy: 0.5108 - val_loss: 1.0058 - val_accuracy: 0.6153\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2279 - accuracy: 0.5101 - val_loss: 0.9834 - val_accuracy: 0.6192\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2056 - accuracy: 0.5183 - val_loss: 0.9578 - val_accuracy: 0.6227\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1863 - accuracy: 0.5358 - val_loss: 0.9430 - val_accuracy: 0.6267\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1572 - accuracy: 0.5414 - val_loss: 0.9300 - val_accuracy: 0.6334\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1501 - accuracy: 0.5513 - val_loss: 0.9245 - val_accuracy: 0.6337\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1290 - accuracy: 0.5552 - val_loss: 0.9018 - val_accuracy: 0.6394\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1265 - accuracy: 0.5670 - val_loss: 0.8926 - val_accuracy: 0.6869\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1083 - accuracy: 0.5751 - val_loss: 0.8835 - val_accuracy: 0.6878\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0866 - accuracy: 0.5833 - val_loss: 0.8619 - val_accuracy: 0.6866\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0835 - accuracy: 0.5876 - val_loss: 0.8356 - val_accuracy: 0.7139\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0569 - accuracy: 0.6020 - val_loss: 0.8066 - val_accuracy: 0.7267\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0336 - accuracy: 0.6220 - val_loss: 0.7267 - val_accuracy: 0.7662\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0187 - accuracy: 0.6405 - val_loss: 0.6847 - val_accuracy: 0.7629\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9797 - accuracy: 0.6564 - val_loss: 0.6633 - val_accuracy: 0.7630\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9625 - accuracy: 0.6635 - val_loss: 0.6524 - val_accuracy: 0.7663\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9298 - accuracy: 0.6791 - val_loss: 0.6442 - val_accuracy: 0.7732\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9221 - accuracy: 0.6847 - val_loss: 0.6337 - val_accuracy: 0.7755\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9010 - accuracy: 0.6880 - val_loss: 0.6240 - val_accuracy: 0.7754\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8839 - accuracy: 0.6956 - val_loss: 0.6134 - val_accuracy: 0.7799\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8900 - accuracy: 0.6969 - val_loss: 0.6093 - val_accuracy: 0.7793\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8653 - accuracy: 0.7048 - val_loss: 0.6032 - val_accuracy: 0.7821\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8594 - accuracy: 0.7066 - val_loss: 0.5951 - val_accuracy: 0.7847\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8578 - accuracy: 0.7117 - val_loss: 0.5871 - val_accuracy: 0.7903\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8516 - accuracy: 0.7121 - val_loss: 0.5837 - val_accuracy: 0.7962\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8345 - accuracy: 0.7164 - val_loss: 0.5762 - val_accuracy: 0.7926\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8191 - accuracy: 0.7190 - val_loss: 0.5612 - val_accuracy: 0.8051\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8141 - accuracy: 0.7236 - val_loss: 0.5734 - val_accuracy: 0.8084\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7915 - accuracy: 0.7366 - val_loss: 0.5444 - val_accuracy: 0.8075\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8069 - accuracy: 0.7277 - val_loss: 0.5452 - val_accuracy: 0.8127\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7802 - accuracy: 0.7404 - val_loss: 0.5348 - val_accuracy: 0.8163\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7766 - accuracy: 0.7405 - val_loss: 0.5360 - val_accuracy: 0.8117\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7641 - accuracy: 0.7464 - val_loss: 0.5276 - val_accuracy: 0.8179\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7613 - accuracy: 0.7476 - val_loss: 0.5264 - val_accuracy: 0.8191\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7438 - accuracy: 0.7527 - val_loss: 0.5151 - val_accuracy: 0.8242\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7554 - accuracy: 0.7496 - val_loss: 0.5178 - val_accuracy: 0.8227\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7307 - accuracy: 0.7586 - val_loss: 0.5141 - val_accuracy: 0.8239\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7241 - accuracy: 0.7600 - val_loss: 0.4995 - val_accuracy: 0.8257\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7197 - accuracy: 0.7624 - val_loss: 0.5075 - val_accuracy: 0.8253\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 9ms/step - loss: 2.3022 - accuracy: 0.1155 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3015 - accuracy: 0.1128 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1144 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1122 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1152 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1147 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1150 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1141 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1127 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1123 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1151 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1117 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1126 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1127 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1152 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1146 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1165 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1116 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1123 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3002 - accuracy: 0.1173 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1150 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1152 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1137 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1138 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1146 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1152 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1143 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1151 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1143 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1131 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1114 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1152 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1132 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1146 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1133 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1134 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1126 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1145 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1150 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1154 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1145 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2998 - accuracy: 0.1156 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1137 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3002 - accuracy: 0.1133 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.3023 - accuracy: 0.1158 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1141 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1144 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1164 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1145 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1148 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1150 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1153 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1117 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1141 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1141 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1162 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1127 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1135 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1162 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1123 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1144 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1147 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1158 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1135 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1137 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1134 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1120 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1117 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1126 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1153 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1125 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1141 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1157 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1143 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1109 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1138 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1151 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1147 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1134 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1163 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1125 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "{'loss': [2.28065824508667, 1.9938714504241943, 1.824742078781128, 1.7078373432159424, 1.593531847000122, 1.4954580068588257, 1.4328429698944092, 1.370607852935791, 1.3321763277053833, 1.299397587776184, 1.265773057937622, 1.2428700923919678, 1.2287445068359375, 1.2060374021530151, 1.182878851890564, 1.1768569946289062, 1.1561075448989868, 1.1438524723052979, 1.1307777166366577, 1.1194764375686646, 1.0955928564071655, 1.075027346611023, 1.0596750974655151, 1.0446771383285522, 1.028662085533142, 1.0123611688613892, 0.99812912940979, 0.9831750392913818, 0.9727339148521423, 0.9615801572799683, 0.9442076683044434, 0.9322763681411743, 0.9175615906715393, 0.9007789492607117, 0.8791226148605347, 0.8677866458892822, 0.8472263216972351, 0.8408024907112122, 0.8356655836105347, 0.8154441714286804, 0.8136879801750183, 0.8084772825241089, 0.7976433634757996, 0.7902108430862427, 0.7842563390731812, 0.769446611404419, 0.7683832049369812, 0.7527675628662109, 0.7443061470985413, 0.7494036555290222], 'accuracy': [0.15412500500679016, 0.2459791600704193, 0.3008541762828827, 0.3477083444595337, 0.3955624997615814, 0.4358333349227905, 0.4570416808128357, 0.47960415482521057, 0.49293750524520874, 0.5071250200271606, 0.520354151725769, 0.5322083234786987, 0.5351874828338623, 0.5450416803359985, 0.5569375157356262, 0.5635625123977661, 0.5742291808128357, 0.5786250233650208, 0.5858749747276306, 0.5953333377838135, 0.6074166893959045, 0.6164166927337646, 0.6239791512489319, 0.6309166550636292, 0.640874981880188, 0.6460624933242798, 0.6546875238418579, 0.6606458425521851, 0.6696458458900452, 0.6773541569709778, 0.6865624785423279, 0.6964374780654907, 0.7046874761581421, 0.7149583101272583, 0.7244583368301392, 0.7324374914169312, 0.737541675567627, 0.7432291507720947, 0.745395839214325, 0.7513541579246521, 0.7573750019073486, 0.7575833201408386, 0.7590000033378601, 0.7649999856948853, 0.7669166922569275, 0.7715208530426025, 0.7705625295639038, 0.7755416631698608, 0.7777291536331177, 0.7734583616256714], 'val_loss': [1.792413592338562, 1.555574893951416, 1.4293873310089111, 1.293186902999878, 1.172229290008545, 1.0968750715255737, 1.0564464330673218, 1.0159958600997925, 0.9953462481498718, 0.9772066473960876, 0.9643723964691162, 0.9515846967697144, 0.9503716826438904, 0.9312362670898438, 0.9265608787536621, 0.9113553166389465, 0.9122435450553894, 0.9055235981941223, 0.8804917931556702, 0.8577097058296204, 0.8379703164100647, 0.8157466650009155, 0.7939725518226624, 0.7750357389450073, 0.7597124576568604, 0.7429494857788086, 0.747504472732544, 0.7174147367477417, 0.7093460559844971, 0.6914318799972534, 0.672161877155304, 0.649472713470459, 0.625377893447876, 0.6113969683647156, 0.5988147258758545, 0.5833753943443298, 0.5815971493721008, 0.56529301404953, 0.5629749298095703, 0.5529343485832214, 0.5614386796951294, 0.5445587038993835, 0.541428804397583, 0.539424479007721, 0.5437007546424866, 0.5312922596931458, 0.5303170084953308, 0.5295506715774536, 0.5207927823066711, 0.5172109603881836], 'val_accuracy': [0.29508334398269653, 0.41191667318344116, 0.5082499980926514, 0.5597500205039978, 0.5932499766349792, 0.5933333039283752, 0.6034166812896729, 0.6079999804496765, 0.6180833578109741, 0.6370833516120911, 0.6299166679382324, 0.6514166593551636, 0.6482499837875366, 0.6499166488647461, 0.6462500095367432, 0.6494166851043701, 0.6488333344459534, 0.6651666760444641, 0.6812499761581421, 0.7040833234786987, 0.7176666855812073, 0.7283333539962769, 0.7336666584014893, 0.7615000009536743, 0.7635833621025085, 0.765749990940094, 0.7637500166893005, 0.7540000081062317, 0.7635833621025085, 0.7774999737739563, 0.8205000162124634, 0.8130000233650208, 0.8224166631698608, 0.8493333458900452, 0.8424166440963745, 0.8484166860580444, 0.8572499752044678, 0.8285833597183228, 0.8322499990463257, 0.8335000276565552, 0.8351666927337646, 0.8346666693687439, 0.8368333578109741, 0.8366666436195374, 0.8366666436195374, 0.8379999995231628, 0.8389166593551636, 0.8410833477973938, 0.8424166440963745, 0.840833306312561]}\n",
            "{'loss': [2.303778886795044, 2.3010239601135254, 2.3003790378570557, 2.299578905105591, 2.2975385189056396, 2.2946369647979736, 2.288800001144409, 2.272104263305664, 2.239741563796997, 2.1993443965911865, 2.153592824935913, 2.1033506393432617, 2.052938461303711, 2.0065178871154785, 1.9664503335952759, 1.925690770149231, 1.8951691389083862, 1.8643834590911865, 1.830866813659668, 1.8063522577285767, 1.7780513763427734, 1.7607651948928833, 1.7425525188446045, 1.724124789237976, 1.7144261598587036, 1.6961591243743896, 1.6822595596313477, 1.667268991470337, 1.6544547080993652, 1.6464684009552002, 1.6379122734069824, 1.623157024383545, 1.6186740398406982, 1.6083263158798218, 1.591363787651062, 1.5858880281448364, 1.5836131572723389, 1.5656721591949463, 1.5530822277069092, 1.5404441356658936, 1.5265403985977173, 1.5187890529632568, 1.5051074028015137, 1.4971603155136108, 1.4844346046447754, 1.4761357307434082, 1.4644074440002441, 1.4630320072174072, 1.4559556245803833, 1.4432964324951172], 'accuracy': [0.11743749678134918, 0.11937499791383743, 0.117208331823349, 0.11733333021402359, 0.11706250160932541, 0.11814583092927933, 0.11560416966676712, 0.11293750256299973, 0.12845833599567413, 0.1666249930858612, 0.18131250143051147, 0.1901041716337204, 0.20012499392032623, 0.20995832979679108, 0.22762499749660492, 0.23512500524520874, 0.23906250298023224, 0.24833333492279053, 0.2526666522026062, 0.2617083191871643, 0.265749990940094, 0.27139583230018616, 0.2720000147819519, 0.27308332920074463, 0.28060415387153625, 0.28200000524520874, 0.2828333377838135, 0.28816667199134827, 0.2875416576862335, 0.28806251287460327, 0.2861250042915344, 0.29083332419395447, 0.2930625081062317, 0.28949999809265137, 0.296812504529953, 0.2944583296775818, 0.296854168176651, 0.3060833215713501, 0.30679166316986084, 0.31564584374427795, 0.31439584493637085, 0.3239583373069763, 0.32887500524520874, 0.33260416984558105, 0.3375833332538605, 0.34316667914390564, 0.35093748569488525, 0.35208332538604736, 0.35491666197776794, 0.3582916557788849], 'val_loss': [2.302213191986084, 2.302182674407959, 2.3022067546844482, 2.3022170066833496, 2.3023898601531982, 2.299926519393921, 2.288654088973999, 2.25256085395813, 2.193895101547241, 2.1178932189941406, 2.0620880126953125, 2.013190984725952, 1.9687491655349731, 1.9265590906143188, 1.8917348384857178, 1.848810076713562, 1.8432492017745972, 1.7981091737747192, 1.7668899297714233, 1.7370575666427612, 1.7258888483047485, 1.6958011388778687, 1.6855320930480957, 1.6669827699661255, 1.6689043045043945, 1.6347322463989258, 1.6324312686920166, 1.6290584802627563, 1.6032532453536987, 1.576168417930603, 1.574474573135376, 1.5914479494094849, 1.5567822456359863, 1.6053037643432617, 1.566493272781372, 1.5664619207382202, 1.5508975982666016, 1.5357285737991333, 1.5182504653930664, 1.514131784439087, 1.506626009941101, 1.4983339309692383, 1.4843260049819946, 1.5429472923278809, 1.4863297939300537, 1.4876166582107544, 1.452174186706543, 1.4936987161636353, 1.4681588411331177, 1.4991672039031982], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.12291666865348816, 0.20791666209697723, 0.20758333802223206, 0.22633333504199982, 0.22691667079925537, 0.21716666221618652, 0.26258334517478943, 0.24975000321865082, 0.2750833332538605, 0.2823333442211151, 0.27816668152809143, 0.2777499854564667, 0.289083331823349, 0.2877500057220459, 0.2757500112056732, 0.29516667127609253, 0.29891666769981384, 0.2864166796207428, 0.3100833296775818, 0.31333333253860474, 0.30799999833106995, 0.3192499876022339, 0.32725000381469727, 0.30375000834465027, 0.3160833418369293, 0.3269166648387909, 0.3058333396911621, 0.28191667795181274, 0.3153333365917206, 0.31833332777023315, 0.31333333253860474, 0.33649998903274536, 0.3504166603088379, 0.3752500116825104, 0.335999995470047, 0.3738333284854889, 0.3161666691303253, 0.3413333296775818, 0.36274999380111694, 0.3737500011920929, 0.34816667437553406, 0.35899999737739563, 0.3190000057220459]}\n",
            "{'loss': [2.3055617809295654, 2.3009464740753174, 2.2988669872283936, 2.2937257289886475, 2.2791361808776855, 2.2250852584838867, 2.1508798599243164, 2.0823724269866943, 2.036679744720459, 1.9968249797821045, 1.959715485572815, 1.9396666288375854, 1.911746859550476, 1.8794890642166138, 1.8311258554458618, 1.7765755653381348, 1.724368691444397, 1.6782379150390625, 1.6462842226028442, 1.6042602062225342, 1.5702893733978271, 1.5359623432159424, 1.492869257926941, 1.4638550281524658, 1.435015320777893, 1.4064624309539795, 1.3760567903518677, 1.3507065773010254, 1.3317930698394775, 1.3147116899490356, 1.2924652099609375, 1.270046353340149, 1.2510915994644165, 1.2335317134857178, 1.2120527029037476, 1.2010514736175537, 1.1733710765838623, 1.1613037586212158, 1.1355702877044678, 1.116074800491333, 1.1000715494155884, 1.0780233144760132, 1.064757227897644, 1.0514676570892334, 1.02452552318573, 1.0061007738113403, 0.9953038096427917, 0.9727471470832825, 0.9532387852668762, 0.9243007898330688], 'accuracy': [0.1067708358168602, 0.11652083694934845, 0.11762499809265137, 0.12197916954755783, 0.13349999487400055, 0.1602499932050705, 0.17100000381469727, 0.1795624941587448, 0.187479168176651, 0.19029167294502258, 0.19760416448116302, 0.20491667091846466, 0.2135416716337204, 0.2291249930858612, 0.25558334589004517, 0.2849999964237213, 0.3076666593551636, 0.32633334398269653, 0.33506250381469727, 0.3529583215713501, 0.367000013589859, 0.38360416889190674, 0.3941666781902313, 0.4075208306312561, 0.4177291691303253, 0.42906248569488525, 0.4359374940395355, 0.44614583253860474, 0.4533541798591614, 0.46306249499320984, 0.4699791669845581, 0.476395845413208, 0.48627084493637085, 0.4948541522026062, 0.5051458477973938, 0.5118541717529297, 0.5213333368301392, 0.5280625224113464, 0.5441250205039978, 0.5538958311080933, 0.5611041784286499, 0.5683749914169312, 0.5803541541099548, 0.5874583125114441, 0.5948749780654907, 0.613979160785675, 0.6149583458900452, 0.6221874952316284, 0.6302916407585144, 0.6428958177566528], 'val_loss': [2.3019378185272217, 2.301466226577759, 2.299506187438965, 2.2849020957946777, 2.2409584522247314, 2.1213269233703613, 2.0163211822509766, 1.9425530433654785, 1.8960556983947754, 1.8628572225570679, 1.8437260389328003, 1.8231250047683716, 1.7940171957015991, 1.7553424835205078, 1.6661207675933838, 1.591474175453186, 1.5602145195007324, 1.524244785308838, 1.509045124053955, 1.4583063125610352, 1.4111528396606445, 1.3770194053649902, 1.3287901878356934, 1.299587368965149, 1.2678606510162354, 1.2431693077087402, 1.2233611345291138, 1.1972582340240479, 1.1868774890899658, 1.1758075952529907, 1.1574547290802002, 1.1636483669281006, 1.1411973237991333, 1.1487630605697632, 1.120965600013733, 1.094886302947998, 1.0726566314697266, 1.0637991428375244, 1.0574755668640137, 1.025398850440979, 1.0165332555770874, 1.0128800868988037, 0.9775463938713074, 0.9412777423858643, 0.9167229533195496, 0.9048755168914795, 0.8976756930351257, 1.0596771240234375, 0.8338177800178528, 0.8262473344802856], 'val_accuracy': [0.10575000196695328, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.20983333885669708, 0.20499999821186066, 0.19958333671092987, 0.20624999701976776, 0.22075000405311584, 0.29516667127609253, 0.2760833203792572, 0.2939166724681854, 0.2847500145435333, 0.31066668033599854, 0.33766666054725647, 0.36016666889190674, 0.3857499957084656, 0.37716665863990784, 0.3904166519641876, 0.429583340883255, 0.4674166738986969, 0.48741665482521057, 0.4937500059604645, 0.5256666541099548, 0.5170833468437195, 0.5080000162124634, 0.5095000267028809, 0.5115000009536743, 0.5061666369438171, 0.5317500233650208, 0.534250020980835, 0.5320000052452087, 0.5389166474342346, 0.528333306312561, 0.5463333129882812, 0.5542500019073486, 0.5861666798591614, 0.5795833468437195, 0.6008333563804626, 0.6454166769981384, 0.6414999961853027, 0.6430833339691162, 0.6640833616256714, 0.6777499914169312, 0.7039166688919067, 0.6978333592414856, 0.7114999890327454, 0.6424166560173035, 0.7397500276565552, 0.734333336353302]}\n",
            "{'loss': [2.272859573364258, 1.8640270233154297, 1.6430119276046753, 1.513608694076538, 1.4165757894515991, 1.348170280456543, 1.2763234376907349, 1.2194842100143433, 1.181132435798645, 1.1400089263916016, 1.1059949398040771, 1.0701894760131836, 1.0486878156661987, 1.0178252458572388, 0.9885953068733215, 0.9736005663871765, 0.9551318287849426, 0.9366470575332642, 0.9295651316642761, 0.9045287370681763, 0.8936043381690979, 0.8832967877388, 0.8700196146965027, 0.8506671786308289, 0.8380527496337891, 0.8309598565101624, 0.8123128414154053, 0.8057467341423035, 0.7979283332824707, 0.7928510904312134, 0.7798416614532471, 0.7785727381706238, 0.7653856873512268, 0.7576638460159302, 0.7545072436332703, 0.7416976094245911, 0.7320654988288879, 0.7284942865371704, 0.7220665812492371, 0.7207662463188171, 0.7133426070213318, 0.701913595199585, 0.6938643455505371, 0.6873491406440735, 0.6835888624191284, 0.6746124029159546, 0.6816601157188416, 0.6682789325714111, 0.6628017425537109, 0.659392237663269], 'accuracy': [0.1730833351612091, 0.3178125023841858, 0.39097917079925537, 0.44214582443237305, 0.4803958237171173, 0.5101875066757202, 0.5420833230018616, 0.5633124709129333, 0.5798125267028809, 0.5918541550636292, 0.604770839214325, 0.6184375286102295, 0.6267083287239075, 0.6357083320617676, 0.6503333449363708, 0.656583309173584, 0.66385418176651, 0.6701666712760925, 0.6717291474342346, 0.6805416941642761, 0.6902916431427002, 0.6925416588783264, 0.6991666555404663, 0.7039583325386047, 0.7091041803359985, 0.710770845413208, 0.7187708616256714, 0.7186041474342346, 0.7226458191871643, 0.7218124866485596, 0.7288958430290222, 0.7304791808128357, 0.7323333621025085, 0.7319583296775818, 0.7375624775886536, 0.7401041388511658, 0.7428541779518127, 0.7438541650772095, 0.7458750009536743, 0.7492291927337646, 0.7501458525657654, 0.7566041946411133, 0.7578333616256714, 0.757937490940094, 0.7608749866485596, 0.7647500038146973, 0.7652083039283752, 0.7691041827201843, 0.773729145526886, 0.7749999761581421], 'val_loss': [1.5178195238113403, 1.198628544807434, 1.0581729412078857, 0.9684199094772339, 0.8953928351402283, 0.823778510093689, 0.7722731828689575, 0.7369743585586548, 0.709600031375885, 0.6914258599281311, 0.6805737018585205, 0.666756808757782, 0.6596951484680176, 0.6459920406341553, 0.629298746585846, 0.6289820671081543, 0.6113001108169556, 0.6024828553199768, 0.5934964418411255, 0.5830289125442505, 0.5740265846252441, 0.5673137903213501, 0.5611752271652222, 0.5595071911811829, 0.5553427338600159, 0.5523217916488647, 0.5452677011489868, 0.5398595929145813, 0.5385027527809143, 0.5319050550460815, 0.5263309478759766, 0.5246695280075073, 0.5201953649520874, 0.5245956182479858, 0.5167417526245117, 0.5174456238746643, 0.5182645916938782, 0.5163406133651733, 0.5062740445137024, 0.5029152631759644, 0.500929594039917, 0.4941276013851166, 0.4955517053604126, 0.4913690984249115, 0.49101126194000244, 0.4803296625614166, 0.47477641701698303, 0.4733107089996338, 0.4681423604488373, 0.4640331566333771], 'val_accuracy': [0.5600833296775818, 0.60916668176651, 0.6359999775886536, 0.675083339214325, 0.7238333225250244, 0.7440000176429749, 0.7611666917800903, 0.7735833525657654, 0.7767500281333923, 0.784500002861023, 0.7700833082199097, 0.7726666927337646, 0.7817500233650208, 0.7885833382606506, 0.7874166369438171, 0.778333306312561, 0.7766666412353516, 0.7829166650772095, 0.8175833225250244, 0.7847499847412109, 0.8016666769981384, 0.8044166564941406, 0.7873333096504211, 0.8008333444595337, 0.809166669845581, 0.8134999871253967, 0.8020833134651184, 0.815500020980835, 0.8054999709129333, 0.7993333339691162, 0.8004999756813049, 0.8107500076293945, 0.8171666860580444, 0.8201666474342346, 0.8090000152587891, 0.8144166469573975, 0.8172500133514404, 0.8239166736602783, 0.8293333053588867, 0.8073333501815796, 0.8420833349227905, 0.843999981880188, 0.8422499895095825, 0.8376666903495789, 0.8344166874885559, 0.8425833582878113, 0.8619166612625122, 0.8642500042915344, 0.8737499713897705, 0.8657500147819519]}\n",
            "{'loss': [2.7626216411590576, 2.0066308975219727, 1.7644580602645874, 1.5568017959594727, 1.4502612352371216, 1.382673978805542, 1.3420929908752441, 1.3130089044570923, 1.289101004600525, 1.263313889503479, 1.250854730606079, 1.2293072938919067, 1.2138874530792236, 1.1960214376449585, 1.17819344997406, 1.1599571704864502, 1.1399376392364502, 1.1248615980148315, 1.1184428930282593, 1.1053261756896973, 1.086702823638916, 1.083385944366455, 1.0581779479980469, 1.0310667753219604, 1.0071351528167725, 0.9746363162994385, 0.9527269601821899, 0.9352998733520508, 0.9199945330619812, 0.9001190066337585, 0.8927004337310791, 0.8869991898536682, 0.8640856146812439, 0.8587974309921265, 0.8557633757591248, 0.8363075256347656, 0.8292372822761536, 0.816489577293396, 0.8126826286315918, 0.79766446352005, 0.7884721755981445, 0.7828593850135803, 0.7755350470542908, 0.7666634321212769, 0.7607330083847046, 0.7447803020477295, 0.7390165328979492, 0.7309331297874451, 0.7266700267791748, 0.723497211933136], 'accuracy': [0.14091666042804718, 0.22204166650772095, 0.31304165720939636, 0.3865833282470703, 0.42645832896232605, 0.4495416581630707, 0.46274998784065247, 0.4714166522026062, 0.4841666519641876, 0.4884375035762787, 0.5004791617393494, 0.5087708234786987, 0.5163541436195374, 0.5229791402816772, 0.5375833511352539, 0.5434166789054871, 0.5561666488647461, 0.5582500100135803, 0.5689374804496765, 0.5758958458900452, 0.5832916498184204, 0.5923541784286499, 0.6081249713897705, 0.6236249804496765, 0.6439791917800903, 0.6563958525657654, 0.667187511920929, 0.6783333420753479, 0.6832916736602783, 0.6886875033378601, 0.6934999823570251, 0.6976458430290222, 0.7059583067893982, 0.7070624828338623, 0.710687518119812, 0.7164999842643738, 0.7180208563804626, 0.7226250171661377, 0.7248958349227905, 0.7361249923706055, 0.737541675567627, 0.7381874918937683, 0.7399166822433472, 0.7431458234786987, 0.750291645526886, 0.7535833120346069, 0.7544375061988831, 0.7601249814033508, 0.7619791626930237, 0.760812520980835], 'val_loss': [1.7499563694000244, 1.5753690004348755, 1.2768956422805786, 1.1429986953735352, 1.1118543148040771, 1.0837584733963013, 1.0705406665802002, 1.053236722946167, 1.0436608791351318, 1.030660629272461, 1.01887845993042, 1.0058444738388062, 0.9834413528442383, 0.9577601552009583, 0.9430058598518372, 0.9300298690795898, 0.9244694709777832, 0.9017674326896667, 0.8926337361335754, 0.8834525346755981, 0.8618800640106201, 0.8355973362922668, 0.8065564036369324, 0.726687490940094, 0.6846746206283569, 0.6633154153823853, 0.6524358987808228, 0.6442040801048279, 0.6337376832962036, 0.6240220069885254, 0.613379180431366, 0.6092687249183655, 0.6032008528709412, 0.5951082706451416, 0.5871207118034363, 0.5837250351905823, 0.5762499570846558, 0.5611739754676819, 0.5733962059020996, 0.5444411039352417, 0.5451773405075073, 0.534828245639801, 0.5360334515571594, 0.527563214302063, 0.5264493823051453, 0.5151418447494507, 0.5177527070045471, 0.5141240358352661, 0.499492347240448, 0.5075135231018066], 'val_accuracy': [0.296833336353302, 0.4673333466053009, 0.5261666774749756, 0.5302500128746033, 0.5249999761581421, 0.5324166417121887, 0.5664166808128357, 0.57833331823349, 0.5866666436195374, 0.5933333039283752, 0.596666693687439, 0.6153333187103271, 0.6192499995231628, 0.6226666569709778, 0.6267499923706055, 0.6334166526794434, 0.6336666941642761, 0.6394166946411133, 0.6869166493415833, 0.687833309173584, 0.6865833401679993, 0.7139166593551636, 0.7266666889190674, 0.7661666870117188, 0.7629166841506958, 0.7630000114440918, 0.7663333415985107, 0.7732499837875366, 0.7754999995231628, 0.7754166722297668, 0.7799166440963745, 0.7792500257492065, 0.7820833325386047, 0.7847499847412109, 0.7903333306312561, 0.7962499856948853, 0.7925833463668823, 0.8050833344459534, 0.8084166646003723, 0.8075000047683716, 0.812749981880188, 0.8163333535194397, 0.8116666674613953, 0.8179166913032532, 0.8190833330154419, 0.8241666555404663, 0.8227499723434448, 0.8239166736602783, 0.8256666660308838, 0.8253333568572998]}\n",
            "{'loss': [2.301994562149048, 2.3014047145843506, 2.3011887073516846, 2.301058053970337, 2.301039218902588, 2.3010528087615967, 2.3009581565856934, 2.300983190536499, 2.300952911376953, 2.300997018814087, 2.300971746444702, 2.3009302616119385, 2.3008573055267334, 2.300872802734375, 2.3008861541748047, 2.3008460998535156, 2.3008854389190674, 2.3008501529693604, 2.3008737564086914, 2.3008272647857666, 2.3008041381835938, 2.300798177719116, 2.3008084297180176, 2.300750732421875, 2.3007614612579346, 2.3007466793060303, 2.3007538318634033, 2.300739049911499, 2.300727367401123, 2.3007006645202637, 2.3007068634033203, 2.300642728805542, 2.3006930351257324, 2.3006432056427, 2.300602674484253, 2.300572156906128, 2.30055832862854, 2.3005595207214355, 2.300530433654785, 2.3005316257476807, 2.300478458404541, 2.300450563430786, 2.3004491329193115, 2.3003997802734375, 2.300398826599121, 2.3003337383270264, 2.3003056049346924, 2.3002586364746094, 2.3002448081970215, 2.300179958343506], 'accuracy': [0.11391666531562805, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3019776344299316, 2.3018975257873535, 2.301913261413574, 2.301945209503174, 2.3019230365753174, 2.3019216060638428, 2.301943302154541, 2.30195689201355, 2.301950216293335, 2.3019514083862305, 2.3019304275512695, 2.3019301891326904, 2.301950454711914, 2.301936388015747, 2.301936626434326, 2.301952600479126, 2.3019204139709473, 2.3019490242004395, 2.3018929958343506, 2.301892042160034, 2.3018898963928223, 2.301877498626709, 2.301840305328369, 2.3018112182617188, 2.301814079284668, 2.3018059730529785, 2.301806688308716, 2.301784038543701, 2.3017735481262207, 2.301727771759033, 2.3017125129699707, 2.3016974925994873, 2.3017001152038574, 2.301689863204956, 2.3016738891601562, 2.3016397953033447, 2.3016130924224854, 2.301572322845459, 2.3015835285186768, 2.3015575408935547, 2.3015224933624268, 2.301502227783203, 2.3014791011810303, 2.3014519214630127, 2.3014369010925293, 2.3013734817504883, 2.3013532161712646, 2.301304340362549, 2.301265239715576, 2.3012325763702393], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
            "{'loss': [2.302048444747925, 2.301377296447754, 2.301178216934204, 2.301116943359375, 2.301048994064331, 2.3010663986206055, 2.3010785579681396, 2.3010261058807373, 2.3010549545288086, 2.301035165786743, 2.3009867668151855, 2.300976276397705, 2.3009257316589355, 2.3009371757507324, 2.3009297847747803, 2.3009133338928223, 2.3009395599365234, 2.300956964492798, 2.300924062728882, 2.300912857055664, 2.3009092807769775, 2.300884485244751, 2.300884962081909, 2.3008975982666016, 2.300879955291748, 2.300869941711426, 2.300856113433838, 2.300865650177002, 2.3008384704589844, 2.3007936477661133, 2.300793170928955, 2.3008131980895996, 2.3008100986480713, 2.300786018371582, 2.3007442951202393, 2.300769090652466, 2.3007657527923584, 2.30075740814209, 2.300734519958496, 2.3007328510284424, 2.300729274749756, 2.3007476329803467, 2.300684690475464, 2.3006656169891357, 2.3006556034088135, 2.3006250858306885, 2.3006041049957275, 2.3005993366241455, 2.3005788326263428, 2.3005850315093994], 'accuracy': [0.11445832997560501, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.301985740661621, 2.301880359649658, 2.3019156455993652, 2.3019299507141113, 2.302004814147949, 2.302016496658325, 2.3020308017730713, 2.302035093307495, 2.302030086517334, 2.3020212650299072, 2.3020365238189697, 2.3020379543304443, 2.3020098209381104, 2.302032470703125, 2.302030324935913, 2.3020379543304443, 2.3020286560058594, 2.3020269870758057, 2.302046775817871, 2.3020026683807373, 2.3019819259643555, 2.3019535541534424, 2.301978349685669, 2.3019425868988037, 2.301952362060547, 2.301936149597168, 2.3019354343414307, 2.301892042160034, 2.301913022994995, 2.301909923553467, 2.301903247833252, 2.301912546157837, 2.3018970489501953, 2.3019192218780518, 2.3019065856933594, 2.3018908500671387, 2.3018558025360107, 2.3018462657928467, 2.3018381595611572, 2.3018059730529785, 2.301787853240967, 2.3017823696136475, 2.3017704486846924, 2.3017570972442627, 2.301743268966675, 2.3017334938049316, 2.301746368408203, 2.3016860485076904, 2.3016915321350098, 2.3016576766967773], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}