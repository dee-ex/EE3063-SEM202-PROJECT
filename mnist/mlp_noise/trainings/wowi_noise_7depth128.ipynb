{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noinit_noise_7depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "264312ea-68be-437d-b90c-dde0a6eeb5eb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 14s 5ms/step - loss: 2.1580 - accuracy: 0.2258 - val_loss: 1.2220 - val_accuracy: 0.6682\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5653 - accuracy: 0.4571 - val_loss: 0.9436 - val_accuracy: 0.7747\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3470 - accuracy: 0.5432 - val_loss: 0.7783 - val_accuracy: 0.8147\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1970 - accuracy: 0.5965 - val_loss: 0.6686 - val_accuracy: 0.8369\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0996 - accuracy: 0.6361 - val_loss: 0.5936 - val_accuracy: 0.8489\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0126 - accuracy: 0.6735 - val_loss: 0.5464 - val_accuracy: 0.8558\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9491 - accuracy: 0.6995 - val_loss: 0.5114 - val_accuracy: 0.8641\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9116 - accuracy: 0.7109 - val_loss: 0.4816 - val_accuracy: 0.8679\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8723 - accuracy: 0.7281 - val_loss: 0.4628 - val_accuracy: 0.8740\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8280 - accuracy: 0.7463 - val_loss: 0.4423 - val_accuracy: 0.8783\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8160 - accuracy: 0.7503 - val_loss: 0.4275 - val_accuracy: 0.8821\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7950 - accuracy: 0.7652 - val_loss: 0.4218 - val_accuracy: 0.8838\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7616 - accuracy: 0.7747 - val_loss: 0.4083 - val_accuracy: 0.8879\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7372 - accuracy: 0.7818 - val_loss: 0.4008 - val_accuracy: 0.8899\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7231 - accuracy: 0.7904 - val_loss: 0.3949 - val_accuracy: 0.8925\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7144 - accuracy: 0.7969 - val_loss: 0.3850 - val_accuracy: 0.8942\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6949 - accuracy: 0.8032 - val_loss: 0.3789 - val_accuracy: 0.8972\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6910 - accuracy: 0.8042 - val_loss: 0.3779 - val_accuracy: 0.8990\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6687 - accuracy: 0.8116 - val_loss: 0.3682 - val_accuracy: 0.9007\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6524 - accuracy: 0.8183 - val_loss: 0.3650 - val_accuracy: 0.9027\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6499 - accuracy: 0.8217 - val_loss: 0.3627 - val_accuracy: 0.9025\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6357 - accuracy: 0.8237 - val_loss: 0.3580 - val_accuracy: 0.9049\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6237 - accuracy: 0.8298 - val_loss: 0.3508 - val_accuracy: 0.9068\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6180 - accuracy: 0.8324 - val_loss: 0.3462 - val_accuracy: 0.9089\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6048 - accuracy: 0.8380 - val_loss: 0.3427 - val_accuracy: 0.9103\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6073 - accuracy: 0.8376 - val_loss: 0.3408 - val_accuracy: 0.9118\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5954 - accuracy: 0.8386 - val_loss: 0.3393 - val_accuracy: 0.9113\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.8450 - val_loss: 0.3389 - val_accuracy: 0.9133\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5722 - accuracy: 0.8472 - val_loss: 0.3333 - val_accuracy: 0.9133\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5769 - accuracy: 0.8477 - val_loss: 0.3345 - val_accuracy: 0.9138\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5640 - accuracy: 0.8521 - val_loss: 0.3281 - val_accuracy: 0.9163\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5514 - accuracy: 0.8566 - val_loss: 0.3277 - val_accuracy: 0.9190\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5479 - accuracy: 0.8594 - val_loss: 0.3202 - val_accuracy: 0.9200\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5403 - accuracy: 0.8604 - val_loss: 0.3227 - val_accuracy: 0.9196\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5342 - accuracy: 0.8620 - val_loss: 0.3137 - val_accuracy: 0.9222\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5283 - accuracy: 0.8621 - val_loss: 0.3113 - val_accuracy: 0.9222\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5282 - accuracy: 0.8632 - val_loss: 0.3109 - val_accuracy: 0.9227\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.8680 - val_loss: 0.3063 - val_accuracy: 0.9244\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5174 - accuracy: 0.8662 - val_loss: 0.3070 - val_accuracy: 0.9247\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.8706 - val_loss: 0.3084 - val_accuracy: 0.9252\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5141 - accuracy: 0.8678 - val_loss: 0.2965 - val_accuracy: 0.9277\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5068 - accuracy: 0.8704 - val_loss: 0.3004 - val_accuracy: 0.9269\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4936 - accuracy: 0.8730 - val_loss: 0.2947 - val_accuracy: 0.9285\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.8759 - val_loss: 0.2966 - val_accuracy: 0.9280\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.8784 - val_loss: 0.2952 - val_accuracy: 0.9271\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4776 - accuracy: 0.8811 - val_loss: 0.2909 - val_accuracy: 0.9299\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4777 - accuracy: 0.8801 - val_loss: 0.2881 - val_accuracy: 0.9308\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4668 - accuracy: 0.8804 - val_loss: 0.2875 - val_accuracy: 0.9307\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4656 - accuracy: 0.8814 - val_loss: 0.2860 - val_accuracy: 0.9317\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4602 - accuracy: 0.8825 - val_loss: 0.2870 - val_accuracy: 0.9327\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.3093 - accuracy: 0.1043 - val_loss: 2.2974 - val_accuracy: 0.1100\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2955 - accuracy: 0.1303 - val_loss: 2.2621 - val_accuracy: 0.1928\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2691 - accuracy: 0.1607 - val_loss: 2.1453 - val_accuracy: 0.1982\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1910 - accuracy: 0.1841 - val_loss: 1.9647 - val_accuracy: 0.2669\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.0932 - accuracy: 0.2052 - val_loss: 1.7770 - val_accuracy: 0.4117\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9678 - accuracy: 0.2357 - val_loss: 1.5855 - val_accuracy: 0.4737\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.8629 - accuracy: 0.2663 - val_loss: 1.4387 - val_accuracy: 0.4930\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.7503 - accuracy: 0.3093 - val_loss: 1.2855 - val_accuracy: 0.4952\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.6567 - accuracy: 0.3430 - val_loss: 1.1931 - val_accuracy: 0.5149\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5769 - accuracy: 0.3677 - val_loss: 1.1290 - val_accuracy: 0.5206\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5187 - accuracy: 0.3779 - val_loss: 1.0858 - val_accuracy: 0.5345\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4698 - accuracy: 0.4020 - val_loss: 1.0511 - val_accuracy: 0.5444\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4262 - accuracy: 0.4123 - val_loss: 1.0221 - val_accuracy: 0.5559\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3963 - accuracy: 0.4202 - val_loss: 0.9957 - val_accuracy: 0.5669\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3592 - accuracy: 0.4338 - val_loss: 0.9667 - val_accuracy: 0.5904\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3301 - accuracy: 0.4462 - val_loss: 0.9361 - val_accuracy: 0.6028\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2990 - accuracy: 0.4674 - val_loss: 0.9102 - val_accuracy: 0.6322\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2679 - accuracy: 0.4804 - val_loss: 0.8751 - val_accuracy: 0.6561\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2382 - accuracy: 0.4954 - val_loss: 0.8498 - val_accuracy: 0.6899\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2083 - accuracy: 0.5159 - val_loss: 0.8199 - val_accuracy: 0.7265\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1862 - accuracy: 0.5261 - val_loss: 0.7861 - val_accuracy: 0.7430\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1496 - accuracy: 0.5496 - val_loss: 0.7537 - val_accuracy: 0.7679\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1320 - accuracy: 0.5633 - val_loss: 0.7275 - val_accuracy: 0.7722\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0931 - accuracy: 0.5801 - val_loss: 0.7087 - val_accuracy: 0.8048\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0734 - accuracy: 0.5921 - val_loss: 0.6776 - val_accuracy: 0.8116\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0534 - accuracy: 0.6053 - val_loss: 0.6532 - val_accuracy: 0.8299\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0363 - accuracy: 0.6190 - val_loss: 0.6353 - val_accuracy: 0.8284\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0066 - accuracy: 0.6334 - val_loss: 0.6125 - val_accuracy: 0.8419\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0059 - accuracy: 0.6372 - val_loss: 0.5958 - val_accuracy: 0.8493\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9738 - accuracy: 0.6521 - val_loss: 0.5773 - val_accuracy: 0.8583\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9492 - accuracy: 0.6606 - val_loss: 0.5588 - val_accuracy: 0.8559\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9271 - accuracy: 0.6748 - val_loss: 0.5433 - val_accuracy: 0.8597\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9153 - accuracy: 0.6765 - val_loss: 0.5339 - val_accuracy: 0.8477\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8875 - accuracy: 0.6899 - val_loss: 0.5205 - val_accuracy: 0.8571\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8823 - accuracy: 0.6936 - val_loss: 0.5068 - val_accuracy: 0.8607\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8565 - accuracy: 0.6998 - val_loss: 0.5027 - val_accuracy: 0.8712\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8262 - accuracy: 0.7093 - val_loss: 0.4901 - val_accuracy: 0.8815\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8163 - accuracy: 0.7156 - val_loss: 0.4774 - val_accuracy: 0.8727\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8032 - accuracy: 0.7188 - val_loss: 0.4657 - val_accuracy: 0.8792\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7814 - accuracy: 0.7272 - val_loss: 0.4571 - val_accuracy: 0.8681\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7648 - accuracy: 0.7333 - val_loss: 0.4535 - val_accuracy: 0.8925\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7598 - accuracy: 0.7371 - val_loss: 0.4422 - val_accuracy: 0.8804\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7369 - accuracy: 0.7471 - val_loss: 0.4438 - val_accuracy: 0.8915\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7316 - accuracy: 0.7503 - val_loss: 0.4301 - val_accuracy: 0.8908\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7150 - accuracy: 0.7569 - val_loss: 0.4297 - val_accuracy: 0.8957\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7072 - accuracy: 0.7542 - val_loss: 0.4327 - val_accuracy: 0.8807\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6888 - accuracy: 0.7609 - val_loss: 0.4258 - val_accuracy: 0.9074\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6789 - accuracy: 0.7660 - val_loss: 0.4318 - val_accuracy: 0.9068\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6758 - accuracy: 0.7708 - val_loss: 0.4352 - val_accuracy: 0.9105\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6539 - accuracy: 0.7744 - val_loss: 0.4213 - val_accuracy: 0.9069\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3086 - accuracy: 0.1114 - val_loss: 2.2476 - val_accuracy: 0.3588\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2346 - accuracy: 0.1766 - val_loss: 1.9566 - val_accuracy: 0.4045\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.0125 - accuracy: 0.2712 - val_loss: 1.5585 - val_accuracy: 0.4848\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.7759 - accuracy: 0.3547 - val_loss: 1.2883 - val_accuracy: 0.6102\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5730 - accuracy: 0.4306 - val_loss: 1.0365 - val_accuracy: 0.7322\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3980 - accuracy: 0.5034 - val_loss: 0.8329 - val_accuracy: 0.7772\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2308 - accuracy: 0.5749 - val_loss: 0.6950 - val_accuracy: 0.8148\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1172 - accuracy: 0.6219 - val_loss: 0.6130 - val_accuracy: 0.8329\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0178 - accuracy: 0.6623 - val_loss: 0.5412 - val_accuracy: 0.8557\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9608 - accuracy: 0.6873 - val_loss: 0.4917 - val_accuracy: 0.8718\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8853 - accuracy: 0.7169 - val_loss: 0.4608 - val_accuracy: 0.8792\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8277 - accuracy: 0.7372 - val_loss: 0.4260 - val_accuracy: 0.8852\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7936 - accuracy: 0.7569 - val_loss: 0.3973 - val_accuracy: 0.8957\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7479 - accuracy: 0.7675 - val_loss: 0.3746 - val_accuracy: 0.9014\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7213 - accuracy: 0.7799 - val_loss: 0.3554 - val_accuracy: 0.9051\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.7969 - val_loss: 0.3378 - val_accuracy: 0.9093\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6632 - accuracy: 0.8035 - val_loss: 0.3236 - val_accuracy: 0.9106\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6300 - accuracy: 0.8168 - val_loss: 0.3061 - val_accuracy: 0.9161\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5981 - accuracy: 0.8252 - val_loss: 0.2960 - val_accuracy: 0.9183\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5904 - accuracy: 0.8306 - val_loss: 0.2836 - val_accuracy: 0.9209\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5585 - accuracy: 0.8396 - val_loss: 0.2767 - val_accuracy: 0.9232\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5497 - accuracy: 0.8455 - val_loss: 0.2710 - val_accuracy: 0.9233\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5413 - accuracy: 0.8450 - val_loss: 0.2614 - val_accuracy: 0.9268\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5051 - accuracy: 0.8552 - val_loss: 0.2545 - val_accuracy: 0.9291\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4915 - accuracy: 0.8625 - val_loss: 0.2498 - val_accuracy: 0.9306\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4751 - accuracy: 0.8635 - val_loss: 0.2439 - val_accuracy: 0.9352\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4788 - accuracy: 0.8650 - val_loss: 0.2393 - val_accuracy: 0.9343\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4483 - accuracy: 0.8752 - val_loss: 0.2354 - val_accuracy: 0.9354\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4363 - accuracy: 0.8754 - val_loss: 0.2310 - val_accuracy: 0.9361\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.8782 - val_loss: 0.2291 - val_accuracy: 0.9373\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4271 - accuracy: 0.8822 - val_loss: 0.2252 - val_accuracy: 0.9393\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4163 - accuracy: 0.8847 - val_loss: 0.2207 - val_accuracy: 0.9402\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4033 - accuracy: 0.8876 - val_loss: 0.2183 - val_accuracy: 0.9413\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8915 - val_loss: 0.2128 - val_accuracy: 0.9423\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3832 - accuracy: 0.8915 - val_loss: 0.2160 - val_accuracy: 0.9438\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3688 - accuracy: 0.8937 - val_loss: 0.2129 - val_accuracy: 0.9434\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3670 - accuracy: 0.8994 - val_loss: 0.2075 - val_accuracy: 0.9444\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3519 - accuracy: 0.9017 - val_loss: 0.2061 - val_accuracy: 0.9450\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.9023 - val_loss: 0.2069 - val_accuracy: 0.9450\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3384 - accuracy: 0.9047 - val_loss: 0.2039 - val_accuracy: 0.9470\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.9071 - val_loss: 0.2006 - val_accuracy: 0.9482\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3227 - accuracy: 0.9115 - val_loss: 0.2019 - val_accuracy: 0.9478\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3229 - accuracy: 0.9058 - val_loss: 0.2010 - val_accuracy: 0.9490\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3127 - accuracy: 0.9145 - val_loss: 0.2013 - val_accuracy: 0.9506\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3095 - accuracy: 0.9143 - val_loss: 0.1982 - val_accuracy: 0.9498\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2977 - accuracy: 0.9167 - val_loss: 0.1986 - val_accuracy: 0.9519\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2909 - accuracy: 0.9213 - val_loss: 0.2015 - val_accuracy: 0.9504\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2985 - accuracy: 0.9178 - val_loss: 0.1980 - val_accuracy: 0.9502\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2904 - accuracy: 0.9211 - val_loss: 0.1989 - val_accuracy: 0.9525\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2728 - accuracy: 0.9244 - val_loss: 0.1968 - val_accuracy: 0.9520\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.1569 - accuracy: 0.2362 - val_loss: 0.9927 - val_accuracy: 0.7639\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4515 - accuracy: 0.4989 - val_loss: 0.6935 - val_accuracy: 0.8194\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1977 - accuracy: 0.5980 - val_loss: 0.5485 - val_accuracy: 0.8480\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0772 - accuracy: 0.6447 - val_loss: 0.4870 - val_accuracy: 0.8598\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9817 - accuracy: 0.6804 - val_loss: 0.4479 - val_accuracy: 0.8723\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9199 - accuracy: 0.7030 - val_loss: 0.4259 - val_accuracy: 0.8755\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8632 - accuracy: 0.7263 - val_loss: 0.4038 - val_accuracy: 0.8828\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8363 - accuracy: 0.7404 - val_loss: 0.3870 - val_accuracy: 0.8874\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7921 - accuracy: 0.7575 - val_loss: 0.3711 - val_accuracy: 0.8918\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7686 - accuracy: 0.7636 - val_loss: 0.3578 - val_accuracy: 0.8958\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7336 - accuracy: 0.7776 - val_loss: 0.3458 - val_accuracy: 0.9001\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7191 - accuracy: 0.7822 - val_loss: 0.3363 - val_accuracy: 0.9022\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6986 - accuracy: 0.7943 - val_loss: 0.3273 - val_accuracy: 0.9062\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6803 - accuracy: 0.8018 - val_loss: 0.3155 - val_accuracy: 0.9079\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.8063 - val_loss: 0.3105 - val_accuracy: 0.9083\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6371 - accuracy: 0.8148 - val_loss: 0.2991 - val_accuracy: 0.9118\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6189 - accuracy: 0.8234 - val_loss: 0.2939 - val_accuracy: 0.9125\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5972 - accuracy: 0.8275 - val_loss: 0.2862 - val_accuracy: 0.9154\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5944 - accuracy: 0.8313 - val_loss: 0.2816 - val_accuracy: 0.9164\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5758 - accuracy: 0.8391 - val_loss: 0.2748 - val_accuracy: 0.9197\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5814 - accuracy: 0.8390 - val_loss: 0.2719 - val_accuracy: 0.9194\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5688 - accuracy: 0.8411 - val_loss: 0.2686 - val_accuracy: 0.9224\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5448 - accuracy: 0.8512 - val_loss: 0.2627 - val_accuracy: 0.9233\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5330 - accuracy: 0.8508 - val_loss: 0.2581 - val_accuracy: 0.9243\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5255 - accuracy: 0.8550 - val_loss: 0.2549 - val_accuracy: 0.9243\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5281 - accuracy: 0.8569 - val_loss: 0.2518 - val_accuracy: 0.9274\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5014 - accuracy: 0.8630 - val_loss: 0.2444 - val_accuracy: 0.9280\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5089 - accuracy: 0.8627 - val_loss: 0.2463 - val_accuracy: 0.9282\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5001 - accuracy: 0.8622 - val_loss: 0.2429 - val_accuracy: 0.9303\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4860 - accuracy: 0.8689 - val_loss: 0.2378 - val_accuracy: 0.9314\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4806 - accuracy: 0.8704 - val_loss: 0.2352 - val_accuracy: 0.9339\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4627 - accuracy: 0.8777 - val_loss: 0.2345 - val_accuracy: 0.9328\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4606 - accuracy: 0.8739 - val_loss: 0.2322 - val_accuracy: 0.9340\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.8795 - val_loss: 0.2299 - val_accuracy: 0.9342\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4402 - accuracy: 0.8819 - val_loss: 0.2290 - val_accuracy: 0.9357\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.8778 - val_loss: 0.2269 - val_accuracy: 0.9359\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4270 - accuracy: 0.8850 - val_loss: 0.2201 - val_accuracy: 0.9383\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4159 - accuracy: 0.8894 - val_loss: 0.2207 - val_accuracy: 0.9379\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4177 - accuracy: 0.8894 - val_loss: 0.2175 - val_accuracy: 0.9398\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4136 - accuracy: 0.8922 - val_loss: 0.2209 - val_accuracy: 0.9387\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4051 - accuracy: 0.8912 - val_loss: 0.2207 - val_accuracy: 0.9385\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4007 - accuracy: 0.8935 - val_loss: 0.2138 - val_accuracy: 0.9400\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4125 - accuracy: 0.8928 - val_loss: 0.2135 - val_accuracy: 0.9410\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3937 - accuracy: 0.8977 - val_loss: 0.2135 - val_accuracy: 0.9420\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3951 - accuracy: 0.8973 - val_loss: 0.2119 - val_accuracy: 0.9420\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3924 - accuracy: 0.8961 - val_loss: 0.2100 - val_accuracy: 0.9430\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3744 - accuracy: 0.8998 - val_loss: 0.2135 - val_accuracy: 0.9412\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3729 - accuracy: 0.9037 - val_loss: 0.2072 - val_accuracy: 0.9443\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3620 - accuracy: 0.9051 - val_loss: 0.2067 - val_accuracy: 0.9442\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3746 - accuracy: 0.9018 - val_loss: 0.2114 - val_accuracy: 0.9432\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 2.6292 - accuracy: 0.2676 - val_loss: 0.6950 - val_accuracy: 0.7943\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3384 - accuracy: 0.5410 - val_loss: 0.5515 - val_accuracy: 0.8419\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0972 - accuracy: 0.6296 - val_loss: 0.4801 - val_accuracy: 0.8663\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9719 - accuracy: 0.6754 - val_loss: 0.4423 - val_accuracy: 0.8713\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9073 - accuracy: 0.7131 - val_loss: 0.4085 - val_accuracy: 0.8832\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8421 - accuracy: 0.7335 - val_loss: 0.3844 - val_accuracy: 0.8882\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7939 - accuracy: 0.7549 - val_loss: 0.3731 - val_accuracy: 0.8923\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7712 - accuracy: 0.7656 - val_loss: 0.3588 - val_accuracy: 0.8962\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7524 - accuracy: 0.7752 - val_loss: 0.3449 - val_accuracy: 0.8984\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7152 - accuracy: 0.7881 - val_loss: 0.3361 - val_accuracy: 0.9026\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6905 - accuracy: 0.8004 - val_loss: 0.3282 - val_accuracy: 0.9062\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6783 - accuracy: 0.8054 - val_loss: 0.3201 - val_accuracy: 0.9083\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6680 - accuracy: 0.8102 - val_loss: 0.3116 - val_accuracy: 0.9102\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6389 - accuracy: 0.8176 - val_loss: 0.3074 - val_accuracy: 0.9127\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6293 - accuracy: 0.8200 - val_loss: 0.3049 - val_accuracy: 0.9137\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5976 - accuracy: 0.8330 - val_loss: 0.2963 - val_accuracy: 0.9172\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5951 - accuracy: 0.8306 - val_loss: 0.2956 - val_accuracy: 0.9166\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5917 - accuracy: 0.8382 - val_loss: 0.2856 - val_accuracy: 0.9199\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5734 - accuracy: 0.8388 - val_loss: 0.2849 - val_accuracy: 0.9207\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5610 - accuracy: 0.8451 - val_loss: 0.2783 - val_accuracy: 0.9211\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5388 - accuracy: 0.8515 - val_loss: 0.2780 - val_accuracy: 0.9227\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5358 - accuracy: 0.8526 - val_loss: 0.2742 - val_accuracy: 0.9237\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5373 - accuracy: 0.8536 - val_loss: 0.2684 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5328 - accuracy: 0.8545 - val_loss: 0.2694 - val_accuracy: 0.9250\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5120 - accuracy: 0.8649 - val_loss: 0.2646 - val_accuracy: 0.9262\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5095 - accuracy: 0.8615 - val_loss: 0.2630 - val_accuracy: 0.9268\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4992 - accuracy: 0.8656 - val_loss: 0.2605 - val_accuracy: 0.9274\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4831 - accuracy: 0.8698 - val_loss: 0.2540 - val_accuracy: 0.9287\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4859 - accuracy: 0.8699 - val_loss: 0.2515 - val_accuracy: 0.9286\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4807 - accuracy: 0.8708 - val_loss: 0.2546 - val_accuracy: 0.9287\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4642 - accuracy: 0.8739 - val_loss: 0.2483 - val_accuracy: 0.9298\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.8799 - val_loss: 0.2473 - val_accuracy: 0.9313\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4508 - accuracy: 0.8831 - val_loss: 0.2441 - val_accuracy: 0.9313\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4549 - accuracy: 0.8801 - val_loss: 0.2413 - val_accuracy: 0.9332\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4333 - accuracy: 0.8832 - val_loss: 0.2407 - val_accuracy: 0.9337\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4323 - accuracy: 0.8860 - val_loss: 0.2376 - val_accuracy: 0.9342\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4352 - accuracy: 0.8843 - val_loss: 0.2359 - val_accuracy: 0.9345\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4219 - accuracy: 0.8888 - val_loss: 0.2361 - val_accuracy: 0.9356\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4276 - accuracy: 0.8869 - val_loss: 0.2344 - val_accuracy: 0.9359\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4056 - accuracy: 0.8894 - val_loss: 0.2337 - val_accuracy: 0.9352\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4028 - accuracy: 0.8912 - val_loss: 0.2290 - val_accuracy: 0.9362\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3984 - accuracy: 0.8921 - val_loss: 0.2281 - val_accuracy: 0.9367\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4153 - accuracy: 0.8903 - val_loss: 0.2303 - val_accuracy: 0.9373\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4011 - accuracy: 0.8946 - val_loss: 0.2284 - val_accuracy: 0.9377\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3859 - accuracy: 0.8988 - val_loss: 0.2248 - val_accuracy: 0.9383\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3918 - accuracy: 0.8992 - val_loss: 0.2244 - val_accuracy: 0.9385\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3808 - accuracy: 0.9007 - val_loss: 0.2225 - val_accuracy: 0.9400\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3768 - accuracy: 0.9006 - val_loss: 0.2225 - val_accuracy: 0.9382\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3744 - accuracy: 0.9010 - val_loss: 0.2240 - val_accuracy: 0.9391\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3693 - accuracy: 0.9023 - val_loss: 0.2193 - val_accuracy: 0.9418\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3002 - accuracy: 0.1201 - val_loss: 2.2930 - val_accuracy: 0.1535\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2898 - accuracy: 0.1706 - val_loss: 2.2755 - val_accuracy: 0.2582\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2635 - accuracy: 0.2133 - val_loss: 2.1537 - val_accuracy: 0.2969\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1593 - accuracy: 0.2560 - val_loss: 1.9511 - val_accuracy: 0.3648\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0040 - accuracy: 0.3212 - val_loss: 1.7114 - val_accuracy: 0.4125\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8398 - accuracy: 0.3660 - val_loss: 1.5364 - val_accuracy: 0.4846\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7125 - accuracy: 0.4077 - val_loss: 1.3772 - val_accuracy: 0.5733\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5902 - accuracy: 0.4534 - val_loss: 1.2302 - val_accuracy: 0.6631\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4752 - accuracy: 0.4966 - val_loss: 1.0878 - val_accuracy: 0.7212\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3690 - accuracy: 0.5341 - val_loss: 0.9657 - val_accuracy: 0.7542\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2732 - accuracy: 0.5728 - val_loss: 0.8705 - val_accuracy: 0.7779\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1997 - accuracy: 0.5989 - val_loss: 0.7967 - val_accuracy: 0.7944\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1434 - accuracy: 0.6210 - val_loss: 0.7349 - val_accuracy: 0.8187\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1010 - accuracy: 0.6429 - val_loss: 0.6845 - val_accuracy: 0.8332\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0460 - accuracy: 0.6664 - val_loss: 0.6431 - val_accuracy: 0.8412\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0115 - accuracy: 0.6769 - val_loss: 0.5979 - val_accuracy: 0.8543\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9773 - accuracy: 0.6951 - val_loss: 0.5761 - val_accuracy: 0.8587\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9365 - accuracy: 0.7040 - val_loss: 0.5459 - val_accuracy: 0.8662\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9084 - accuracy: 0.7190 - val_loss: 0.5176 - val_accuracy: 0.8701\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8774 - accuracy: 0.7293 - val_loss: 0.4988 - val_accuracy: 0.8762\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8634 - accuracy: 0.7328 - val_loss: 0.4793 - val_accuracy: 0.8832\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8335 - accuracy: 0.7444 - val_loss: 0.4599 - val_accuracy: 0.8863\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8129 - accuracy: 0.7480 - val_loss: 0.4436 - val_accuracy: 0.8900\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7797 - accuracy: 0.7618 - val_loss: 0.4288 - val_accuracy: 0.8958\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7684 - accuracy: 0.7628 - val_loss: 0.4168 - val_accuracy: 0.8990\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7661 - accuracy: 0.7673 - val_loss: 0.4063 - val_accuracy: 0.9003\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7336 - accuracy: 0.7757 - val_loss: 0.3887 - val_accuracy: 0.9054\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7151 - accuracy: 0.7850 - val_loss: 0.3790 - val_accuracy: 0.9080\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7127 - accuracy: 0.7839 - val_loss: 0.3703 - val_accuracy: 0.9093\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.7925 - val_loss: 0.3571 - val_accuracy: 0.9132\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6746 - accuracy: 0.7985 - val_loss: 0.3454 - val_accuracy: 0.9141\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6727 - accuracy: 0.7987 - val_loss: 0.3403 - val_accuracy: 0.9165\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6617 - accuracy: 0.8043 - val_loss: 0.3306 - val_accuracy: 0.9177\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6420 - accuracy: 0.8040 - val_loss: 0.3238 - val_accuracy: 0.9211\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6287 - accuracy: 0.8107 - val_loss: 0.3159 - val_accuracy: 0.9236\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6103 - accuracy: 0.8163 - val_loss: 0.3078 - val_accuracy: 0.9249\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5982 - accuracy: 0.8220 - val_loss: 0.2996 - val_accuracy: 0.9270\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5958 - accuracy: 0.8218 - val_loss: 0.2933 - val_accuracy: 0.9278\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5816 - accuracy: 0.8283 - val_loss: 0.2877 - val_accuracy: 0.9282\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5828 - accuracy: 0.8278 - val_loss: 0.2833 - val_accuracy: 0.9304\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5691 - accuracy: 0.8349 - val_loss: 0.2802 - val_accuracy: 0.9333\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5467 - accuracy: 0.8388 - val_loss: 0.2713 - val_accuracy: 0.9320\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5395 - accuracy: 0.8422 - val_loss: 0.2706 - val_accuracy: 0.9330\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5367 - accuracy: 0.8408 - val_loss: 0.2639 - val_accuracy: 0.9348\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5301 - accuracy: 0.8430 - val_loss: 0.2617 - val_accuracy: 0.9353\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5147 - accuracy: 0.8498 - val_loss: 0.2599 - val_accuracy: 0.9358\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5088 - accuracy: 0.8495 - val_loss: 0.2519 - val_accuracy: 0.9378\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4907 - accuracy: 0.8567 - val_loss: 0.2499 - val_accuracy: 0.9373\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4907 - accuracy: 0.8544 - val_loss: 0.2508 - val_accuracy: 0.9402\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4747 - accuracy: 0.8623 - val_loss: 0.2439 - val_accuracy: 0.9407\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 2.3014 - accuracy: 0.1138 - val_loss: 2.2973 - val_accuracy: 0.1168\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2964 - accuracy: 0.1434 - val_loss: 2.2920 - val_accuracy: 0.1240\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2906 - accuracy: 0.1508 - val_loss: 2.2839 - val_accuracy: 0.1772\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2816 - accuracy: 0.1782 - val_loss: 2.2671 - val_accuracy: 0.2086\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2590 - accuracy: 0.2112 - val_loss: 2.1917 - val_accuracy: 0.2272\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.1767 - accuracy: 0.2286 - val_loss: 2.0360 - val_accuracy: 0.2676\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.0737 - accuracy: 0.2428 - val_loss: 1.8967 - val_accuracy: 0.3371\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9625 - accuracy: 0.2736 - val_loss: 1.7087 - val_accuracy: 0.3985\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8244 - accuracy: 0.3219 - val_loss: 1.5498 - val_accuracy: 0.5008\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.7108 - accuracy: 0.3718 - val_loss: 1.4101 - val_accuracy: 0.5706\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5899 - accuracy: 0.4307 - val_loss: 1.2401 - val_accuracy: 0.6453\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4740 - accuracy: 0.4827 - val_loss: 1.0922 - val_accuracy: 0.7036\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3672 - accuracy: 0.5266 - val_loss: 0.9619 - val_accuracy: 0.7531\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2786 - accuracy: 0.5665 - val_loss: 0.8695 - val_accuracy: 0.7818\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2100 - accuracy: 0.5922 - val_loss: 0.8092 - val_accuracy: 0.7963\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1468 - accuracy: 0.6161 - val_loss: 0.7433 - val_accuracy: 0.8089\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0931 - accuracy: 0.6352 - val_loss: 0.6960 - val_accuracy: 0.8207\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0458 - accuracy: 0.6596 - val_loss: 0.6460 - val_accuracy: 0.8344\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0082 - accuracy: 0.6687 - val_loss: 0.6138 - val_accuracy: 0.8441\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9710 - accuracy: 0.6897 - val_loss: 0.5775 - val_accuracy: 0.8513\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9399 - accuracy: 0.7026 - val_loss: 0.5535 - val_accuracy: 0.8569\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9184 - accuracy: 0.7121 - val_loss: 0.5270 - val_accuracy: 0.8602\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8934 - accuracy: 0.7188 - val_loss: 0.5080 - val_accuracy: 0.8666\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8687 - accuracy: 0.7313 - val_loss: 0.4931 - val_accuracy: 0.8690\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8492 - accuracy: 0.7366 - val_loss: 0.4770 - val_accuracy: 0.8742\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8197 - accuracy: 0.7427 - val_loss: 0.4648 - val_accuracy: 0.8766\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8019 - accuracy: 0.7497 - val_loss: 0.4510 - val_accuracy: 0.8828\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7843 - accuracy: 0.7617 - val_loss: 0.4347 - val_accuracy: 0.8853\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7775 - accuracy: 0.7614 - val_loss: 0.4252 - val_accuracy: 0.8863\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7478 - accuracy: 0.7688 - val_loss: 0.4155 - val_accuracy: 0.8905\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7510 - accuracy: 0.7741 - val_loss: 0.4042 - val_accuracy: 0.8936\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7422 - accuracy: 0.7757 - val_loss: 0.3961 - val_accuracy: 0.8961\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7276 - accuracy: 0.7787 - val_loss: 0.3863 - val_accuracy: 0.8982\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7088 - accuracy: 0.7852 - val_loss: 0.3793 - val_accuracy: 0.9022\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.7909 - val_loss: 0.3706 - val_accuracy: 0.9039\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6795 - accuracy: 0.7953 - val_loss: 0.3639 - val_accuracy: 0.9063\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6761 - accuracy: 0.7972 - val_loss: 0.3580 - val_accuracy: 0.9090\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6710 - accuracy: 0.7997 - val_loss: 0.3494 - val_accuracy: 0.9103\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6572 - accuracy: 0.8028 - val_loss: 0.3438 - val_accuracy: 0.9120\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6493 - accuracy: 0.8067 - val_loss: 0.3393 - val_accuracy: 0.9128\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6308 - accuracy: 0.8095 - val_loss: 0.3322 - val_accuracy: 0.9142\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6333 - accuracy: 0.8135 - val_loss: 0.3257 - val_accuracy: 0.9158\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6084 - accuracy: 0.8199 - val_loss: 0.3200 - val_accuracy: 0.9172\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6043 - accuracy: 0.8208 - val_loss: 0.3151 - val_accuracy: 0.9195\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5870 - accuracy: 0.8273 - val_loss: 0.3121 - val_accuracy: 0.9187\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5869 - accuracy: 0.8277 - val_loss: 0.3049 - val_accuracy: 0.9218\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5828 - accuracy: 0.8262 - val_loss: 0.3010 - val_accuracy: 0.9230\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5689 - accuracy: 0.8359 - val_loss: 0.2987 - val_accuracy: 0.9239\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5597 - accuracy: 0.8361 - val_loss: 0.2948 - val_accuracy: 0.9225\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5704 - accuracy: 0.8352 - val_loss: 0.2930 - val_accuracy: 0.9255\n",
            "{'loss': [1.93510103225708, 1.5024217367172241, 1.3063887357711792, 1.1690926551818848, 1.0727602243423462, 0.9993179440498352, 0.9411200284957886, 0.9053431749343872, 0.862804114818573, 0.8306085467338562, 0.8031669855117798, 0.7856155633926392, 0.7624044418334961, 0.735852837562561, 0.727887749671936, 0.7040997743606567, 0.6968080997467041, 0.6812192797660828, 0.6696529984474182, 0.6559476852416992, 0.647413432598114, 0.633974552154541, 0.6223906874656677, 0.6112446188926697, 0.6108840107917786, 0.5984898805618286, 0.5914885401725769, 0.5824031233787537, 0.5743644833564758, 0.5705186128616333, 0.5602754950523376, 0.5545857548713684, 0.5481847524642944, 0.544015645980835, 0.5349820256233215, 0.5287197828292847, 0.5241619348526001, 0.5205627679824829, 0.518680989742279, 0.5117768049240112, 0.5072585940361023, 0.5001178979873657, 0.49403315782546997, 0.48744291067123413, 0.4849358797073364, 0.4781516492366791, 0.47642168402671814, 0.46770572662353516, 0.4708665907382965, 0.4566483497619629], 'accuracy': [0.31166666746139526, 0.47983333468437195, 0.5569375157356262, 0.6083958148956299, 0.648312509059906, 0.6776875257492065, 0.7018541693687439, 0.7158750295639038, 0.7313125133514404, 0.7460416555404663, 0.754770815372467, 0.765541672706604, 0.7741666436195374, 0.7825000286102295, 0.7904999852180481, 0.7989791631698608, 0.8017500042915344, 0.8080624938011169, 0.8117916584014893, 0.8193125128746033, 0.823604166507721, 0.8247708082199097, 0.8305000066757202, 0.8336458206176758, 0.836062490940094, 0.8411041498184204, 0.8408541679382324, 0.8446875214576721, 0.8478541374206543, 0.8497291803359985, 0.8522083163261414, 0.8552708625793457, 0.8591041564941406, 0.8597291707992554, 0.8619166612625122, 0.8648541569709778, 0.8645416498184204, 0.8662499785423279, 0.8659791946411133, 0.8702083230018616, 0.8696874976158142, 0.8734791874885559, 0.8731041550636292, 0.874875009059906, 0.8783958554267883, 0.8795833587646484, 0.8808958530426025, 0.8807500004768372, 0.8811249732971191, 0.8839791417121887], 'val_loss': [1.2220098972320557, 0.9436109066009521, 0.7782843708992004, 0.6686171293258667, 0.5935639142990112, 0.5463607907295227, 0.5113509297370911, 0.48160502314567566, 0.4627716839313507, 0.44225621223449707, 0.4275089204311371, 0.4217713475227356, 0.4083017110824585, 0.4008258879184723, 0.39493685960769653, 0.38496243953704834, 0.3788745105266571, 0.3779210150241852, 0.36817941069602966, 0.3649933934211731, 0.3627077341079712, 0.35804057121276855, 0.35078081488609314, 0.3462156057357788, 0.34274983406066895, 0.3407760560512543, 0.33930036425590515, 0.33894574642181396, 0.33332493901252747, 0.3345266580581665, 0.3281233012676239, 0.3277120888233185, 0.320158988237381, 0.3227342665195465, 0.3136705458164215, 0.31131356954574585, 0.3108523488044739, 0.3063317835330963, 0.30702584981918335, 0.30841097235679626, 0.2964734435081482, 0.30044102668762207, 0.29465270042419434, 0.29656124114990234, 0.2951597571372986, 0.29092249274253845, 0.28806519508361816, 0.2874852120876312, 0.28599658608436584, 0.2869596481323242], 'val_accuracy': [0.6681666374206543, 0.7746666669845581, 0.8146666884422302, 0.8369166851043701, 0.8489166498184204, 0.8558333516120911, 0.8640833497047424, 0.8679166436195374, 0.8740000128746033, 0.878250002861023, 0.8820833563804626, 0.8838333487510681, 0.8879166841506958, 0.8899166584014893, 0.8924999833106995, 0.8942499756813049, 0.8972499966621399, 0.8989999890327454, 0.9007499814033508, 0.9026666879653931, 0.9024999737739563, 0.9049166440963745, 0.9067500233650208, 0.9089166522026062, 0.9103333353996277, 0.9117500185966492, 0.9113333225250244, 0.9132500290870667, 0.9133333563804626, 0.9138333201408386, 0.9163333177566528, 0.9190000295639038, 0.9200000166893005, 0.9195833206176758, 0.922166645526886, 0.922249972820282, 0.9227499961853027, 0.9244166612625122, 0.9247499704360962, 0.9252499938011169, 0.9277499914169312, 0.9269166588783264, 0.9284999966621399, 0.9279999732971191, 0.9270833134651184, 0.9299166798591614, 0.9308333396911621, 0.9306666851043701, 0.9316666722297668, 0.9326666593551636]}\n",
            "{'loss': [2.3045897483825684, 2.292029619216919, 2.25441837310791, 2.1659348011016846, 2.0626332759857178, 1.9395235776901245, 1.8344993591308594, 1.7301177978515625, 1.6378626823425293, 1.5583882331848145, 1.5051881074905396, 1.462032437324524, 1.419921875, 1.387102723121643, 1.3514119386672974, 1.3190529346466064, 1.2948870658874512, 1.2654122114181519, 1.2379579544067383, 1.2058067321777344, 1.1787184476852417, 1.1482388973236084, 1.1251959800720215, 1.096105694770813, 1.072529911994934, 1.0511573553085327, 1.0278663635253906, 1.0009857416152954, 0.9970295429229736, 0.9657976627349854, 0.9448781609535217, 0.9257694482803345, 0.9050447344779968, 0.8886377215385437, 0.8737629652023315, 0.8485931158065796, 0.826150119304657, 0.8174813389778137, 0.8037818074226379, 0.784113347530365, 0.7636336088180542, 0.7628400921821594, 0.73533034324646, 0.7259082794189453, 0.7125476598739624, 0.7036362290382385, 0.6896387338638306, 0.6848890781402588, 0.6673905253410339, 0.658098578453064], 'accuracy': [0.11077083647251129, 0.1352708339691162, 0.16704165935516357, 0.1873749941587448, 0.2110833376646042, 0.2446041703224182, 0.27814581990242004, 0.31845831871032715, 0.351645827293396, 0.3699791729450226, 0.38345834612846375, 0.3999791741371155, 0.41208332777023315, 0.42258334159851074, 0.4348333477973938, 0.4507708251476288, 0.47185418009757996, 0.4855625033378601, 0.4984166622161865, 0.5174791812896729, 0.5324166417121887, 0.5503958463668823, 0.5660208463668823, 0.5832708477973938, 0.5926458239555359, 0.609333336353302, 0.6222500205039978, 0.636145830154419, 0.6414791941642761, 0.6546249985694885, 0.663937509059906, 0.6744999885559082, 0.6813958287239075, 0.6903125047683716, 0.6969791650772095, 0.7018125057220459, 0.710770845413208, 0.7166875004768372, 0.7205208539962769, 0.7272083163261414, 0.7357083559036255, 0.7383958101272583, 0.7463750243186951, 0.750083327293396, 0.754604160785675, 0.7568749785423279, 0.7612708210945129, 0.765500009059906, 0.773187518119812, 0.7760416865348816], 'val_loss': [2.2974321842193604, 2.2621445655822754, 2.1452744007110596, 1.9646730422973633, 1.776981234550476, 1.5854629278182983, 1.4387013912200928, 1.2855169773101807, 1.193140983581543, 1.1289576292037964, 1.0857858657836914, 1.0511295795440674, 1.0221338272094727, 0.9957482218742371, 0.9667407274246216, 0.9361284375190735, 0.9101635813713074, 0.8751351833343506, 0.8498339653015137, 0.8198535442352295, 0.7861114144325256, 0.753709077835083, 0.7274855971336365, 0.7086819410324097, 0.6775657534599304, 0.6531649827957153, 0.6352854371070862, 0.6124959588050842, 0.5957598686218262, 0.5772778391838074, 0.5587918162345886, 0.54332435131073, 0.5339457392692566, 0.5204965472221375, 0.5068174004554749, 0.5026867389678955, 0.4901450276374817, 0.4774436950683594, 0.4657141864299774, 0.45706653594970703, 0.4535415768623352, 0.44219985604286194, 0.4437616765499115, 0.43008100986480713, 0.4296647012233734, 0.4326951205730438, 0.4258333444595337, 0.43182477355003357, 0.4351581335067749, 0.4212895631790161], 'val_accuracy': [0.10999999940395355, 0.1928333342075348, 0.19824999570846558, 0.2669166624546051, 0.4117499887943268, 0.4736666679382324, 0.49300000071525574, 0.4951666593551636, 0.5149166584014893, 0.5205833315849304, 0.534500002861023, 0.5444166660308838, 0.5559166669845581, 0.5669166445732117, 0.590416669845581, 0.6028333306312561, 0.6321666836738586, 0.656083345413208, 0.6899166703224182, 0.7264999747276306, 0.7429999709129333, 0.7679166793823242, 0.7722499966621399, 0.8047500252723694, 0.8115833401679993, 0.8299166560173035, 0.828416645526886, 0.8419166803359985, 0.8493333458900452, 0.8583333492279053, 0.8559166789054871, 0.859666645526886, 0.8476666808128357, 0.8570833206176758, 0.8606666922569275, 0.8712499737739563, 0.8815000057220459, 0.8726666569709778, 0.8791666626930237, 0.8680833578109741, 0.8924999833106995, 0.8804166913032532, 0.8914999961853027, 0.89083331823349, 0.8956666588783264, 0.8806666731834412, 0.9074166417121887, 0.9068333506584167, 0.9104999899864197, 0.9069166779518127]}\n",
            "{'loss': [2.293879508972168, 2.1951215267181396, 1.947283387184143, 1.7238088846206665, 1.5280359983444214, 1.3510695695877075, 1.205117106437683, 1.0925281047821045, 0.9946448802947998, 0.9330970644950867, 0.8735171556472778, 0.8190532326698303, 0.7852810025215149, 0.7413213849067688, 0.709284245967865, 0.6802881956100464, 0.6562684178352356, 0.6234128475189209, 0.6053175330162048, 0.5856297016143799, 0.5637944936752319, 0.5398620367050171, 0.5288537740707397, 0.5099719762802124, 0.49616673588752747, 0.4764239490032196, 0.4745849668979645, 0.4560173451900482, 0.4410596787929535, 0.42935433983802795, 0.422203928232193, 0.4116668701171875, 0.4005158245563507, 0.39210328459739685, 0.3784002959728241, 0.3677434027194977, 0.36603838205337524, 0.36008158326148987, 0.35084307193756104, 0.3410128355026245, 0.3335432708263397, 0.32410359382629395, 0.32106244564056396, 0.31735777854919434, 0.31142935156822205, 0.3034645915031433, 0.2948472797870636, 0.29323703050613403, 0.2904251217842102, 0.27640897035598755], 'accuracy': [0.12564583122730255, 0.1978541612625122, 0.2945833206176758, 0.3753125071525574, 0.45093750953674316, 0.5235416889190674, 0.5851666927337646, 0.632687509059906, 0.6702708601951599, 0.6964791417121887, 0.7220208048820496, 0.7429791688919067, 0.7588124871253967, 0.7728541493415833, 0.7856875061988831, 0.7978125214576721, 0.8053541779518127, 0.8175416588783264, 0.8256041407585144, 0.8306249976158142, 0.8386041522026062, 0.8457083106040955, 0.8490833044052124, 0.8547499775886536, 0.8593124747276306, 0.8644999861717224, 0.866895854473114, 0.8728958368301392, 0.8756458163261414, 0.8804374933242798, 0.8832291960716248, 0.8855208158493042, 0.8884999752044678, 0.8905624747276306, 0.8937708139419556, 0.8975625038146973, 0.9001250267028809, 0.8999583125114441, 0.9032291769981384, 0.9041458368301392, 0.9070000052452087, 0.910895824432373, 0.9105833172798157, 0.9126250147819519, 0.9133750200271606, 0.9146458506584167, 0.9195208549499512, 0.9174583554267883, 0.9203125238418579, 0.9233750104904175], 'val_loss': [2.2476439476013184, 1.9565927982330322, 1.5584561824798584, 1.2883241176605225, 1.0365383625030518, 0.832872748374939, 0.6950042247772217, 0.6129850745201111, 0.5412328243255615, 0.49170243740081787, 0.4608091115951538, 0.4259573221206665, 0.3973087668418884, 0.3746166229248047, 0.35538631677627563, 0.33775201439857483, 0.3236417770385742, 0.3061094284057617, 0.29599931836128235, 0.28356480598449707, 0.27668970823287964, 0.27103909850120544, 0.26140519976615906, 0.2545303404331207, 0.2497541755437851, 0.243922159075737, 0.2392500340938568, 0.23535603284835815, 0.23097111284732819, 0.22909647226333618, 0.22523978352546692, 0.2206730991601944, 0.2183082550764084, 0.21280664205551147, 0.2159890979528427, 0.21288137137889862, 0.20745554566383362, 0.20609287917613983, 0.2068677544593811, 0.20392905175685883, 0.20063474774360657, 0.20186053216457367, 0.20104406774044037, 0.20134267210960388, 0.1982298344373703, 0.19855263829231262, 0.20153018832206726, 0.1980312019586563, 0.19892160594463348, 0.1967739313840866], 'val_accuracy': [0.35883334279060364, 0.40450000762939453, 0.48483332991600037, 0.6102499961853027, 0.7322499752044678, 0.7771666646003723, 0.8147500157356262, 0.8329166769981384, 0.8556666374206543, 0.871833324432373, 0.8792499899864197, 0.8852499723434448, 0.8956666588783264, 0.9014166593551636, 0.9050833582878113, 0.909250020980835, 0.9105833172798157, 0.9160833358764648, 0.9182500243186951, 0.9209166765213013, 0.9231666922569275, 0.9233333468437195, 0.9267500042915344, 0.9290833473205566, 0.9305833578109741, 0.9352499842643738, 0.934333324432373, 0.9354166388511658, 0.9360833168029785, 0.937250018119812, 0.9393333196640015, 0.9401666522026062, 0.9412500262260437, 0.9422500133514404, 0.9437500238418579, 0.9434166550636292, 0.9444166421890259, 0.9449999928474426, 0.9449999928474426, 0.9470000267028809, 0.9481666684150696, 0.9478333592414856, 0.9490000009536743, 0.9505833387374878, 0.949833333492279, 0.9519166946411133, 0.9504166841506958, 0.950166642665863, 0.9524999856948853, 0.9520000219345093]}\n",
            "{'loss': [1.8907325267791748, 1.3821799755096436, 1.1650853157043457, 1.0413888692855835, 0.9594953656196594, 0.902682363986969, 0.8536430597305298, 0.8235058784484863, 0.7829431295394897, 0.765403151512146, 0.7235432267189026, 0.7131989002227783, 0.6979078650474548, 0.6793477535247803, 0.6588029265403748, 0.6395291090011597, 0.6229696273803711, 0.6118399500846863, 0.5950244069099426, 0.5835880041122437, 0.5698896646499634, 0.5560559630393982, 0.544670581817627, 0.5309668183326721, 0.5225532054901123, 0.5214251279830933, 0.504463255405426, 0.4984351694583893, 0.49311140179634094, 0.4861322343349457, 0.475023478269577, 0.46710145473480225, 0.46280738711357117, 0.44337406754493713, 0.4426606297492981, 0.44204792380332947, 0.43260347843170166, 0.4238707721233368, 0.42438170313835144, 0.41906657814979553, 0.40591204166412354, 0.40380600094795227, 0.403818279504776, 0.39549654722213745, 0.39021143317222595, 0.38807621598243713, 0.37811633944511414, 0.38033682107925415, 0.369648277759552, 0.37249624729156494], 'accuracy': [0.3310416638851166, 0.5261458158493042, 0.609541654586792, 0.6569583415985107, 0.6892708539962769, 0.7100833058357239, 0.7309791445732117, 0.7431458234786987, 0.7582291960716248, 0.765958309173584, 0.7795624732971191, 0.7866458296775818, 0.7948750257492065, 0.8014166951179504, 0.8074374794960022, 0.8153125047683716, 0.8228541612625122, 0.8248541951179504, 0.8333333134651184, 0.8369583487510681, 0.8429375290870667, 0.84395831823349, 0.8498541712760925, 0.854604184627533, 0.856249988079071, 0.8578333258628845, 0.8629375100135803, 0.8651666641235352, 0.8661041855812073, 0.8702083230018616, 0.8722291588783264, 0.8753541707992554, 0.8737916946411133, 0.8810833096504211, 0.8812083601951599, 0.8804791569709778, 0.8843125104904175, 0.8869583606719971, 0.8880624771118164, 0.8894791603088379, 0.8913958072662354, 0.8936458230018616, 0.8945208191871643, 0.8970416784286499, 0.8972708582878113, 0.8990416526794434, 0.9000416398048401, 0.9004791378974915, 0.9030208587646484, 0.9021250009536743], 'val_loss': [0.992688775062561, 0.6934647560119629, 0.5485222339630127, 0.48700717091560364, 0.44786205887794495, 0.42590847611427307, 0.4038446843624115, 0.38703653216362, 0.37109890580177307, 0.3578058183193207, 0.34584832191467285, 0.3363015651702881, 0.32725661993026733, 0.31547197699546814, 0.3104625940322876, 0.29909756779670715, 0.2938552796840668, 0.28624847531318665, 0.28156524896621704, 0.2747807204723358, 0.2718869149684906, 0.26861196756362915, 0.2627171277999878, 0.2580958306789398, 0.25485748052597046, 0.251765638589859, 0.24439792335033417, 0.24632181227207184, 0.24287565052509308, 0.23781335353851318, 0.23524267971515656, 0.23453934490680695, 0.2321867197751999, 0.22992505133152008, 0.22904212772846222, 0.22685836255550385, 0.22011759877204895, 0.22072835266590118, 0.2174595594406128, 0.22086769342422485, 0.2207202911376953, 0.21381951868534088, 0.21347105503082275, 0.21347518265247345, 0.21185441315174103, 0.21004618704319, 0.21352125704288483, 0.2071574479341507, 0.206731379032135, 0.21140460669994354], 'val_accuracy': [0.7639166712760925, 0.8194166421890259, 0.8479999899864197, 0.8598333597183228, 0.8722500205039978, 0.8755000233650208, 0.8828333616256714, 0.887416660785675, 0.8918333053588867, 0.8958333134651184, 0.9000833630561829, 0.9021666646003723, 0.906166672706604, 0.9079166650772095, 0.9083333611488342, 0.9117500185966492, 0.9125000238418579, 0.9154166579246521, 0.9164166450500488, 0.9196666479110718, 0.9194166660308838, 0.9224166870117188, 0.9232500195503235, 0.9243333339691162, 0.9242500066757202, 0.9274166822433472, 0.9279999732971191, 0.9281666874885559, 0.9303333163261414, 0.9314166903495789, 0.9339166879653931, 0.9328333139419556, 0.9340000152587891, 0.934166669845581, 0.9356666803359985, 0.9359166622161865, 0.9383333325386047, 0.9379166960716248, 0.9397500157356262, 0.9386666417121887, 0.9384999871253967, 0.9399999976158142, 0.9409999847412109, 0.9419999718666077, 0.9419999718666077, 0.9430000185966492, 0.9411666393280029, 0.9443333148956299, 0.9442499876022339, 0.9431666731834412]}\n",
            "{'loss': [2.0308640003204346, 1.2592915296554565, 1.06893789768219, 0.9608731865882874, 0.8842625617980957, 0.838248610496521, 0.7958284616470337, 0.7656782269477844, 0.7363579273223877, 0.7099704742431641, 0.6911752820014954, 0.6758530139923096, 0.6596391201019287, 0.640860915184021, 0.6251067519187927, 0.6011786460876465, 0.590904176235199, 0.5879720449447632, 0.5723976492881775, 0.5616657733917236, 0.5423124432563782, 0.5451834201812744, 0.5278626084327698, 0.5276615023612976, 0.5183759927749634, 0.5000598430633545, 0.49538469314575195, 0.4888753592967987, 0.481783002614975, 0.47325316071510315, 0.4727245271205902, 0.45773664116859436, 0.45692670345306396, 0.45459040999412537, 0.4355970025062561, 0.43606945872306824, 0.43232670426368713, 0.425220787525177, 0.42315539717674255, 0.41343486309051514, 0.4092249870300293, 0.406254380941391, 0.4033527076244354, 0.3952467143535614, 0.3888460397720337, 0.3890649080276489, 0.38482901453971863, 0.37876883149147034, 0.37379035353660583, 0.37474870681762695], 'accuracy': [0.3719791769981384, 0.5665416717529297, 0.6392291784286499, 0.6851666569709778, 0.7215416431427002, 0.7390833497047424, 0.7570624947547913, 0.7700416445732117, 0.7819791436195374, 0.7902500033378601, 0.8002291917800903, 0.8058333396911621, 0.812375009059906, 0.8186249732971191, 0.823354184627533, 0.8307291865348816, 0.8332916498184204, 0.8393541574478149, 0.8407291769981384, 0.8445624709129333, 0.8508541584014893, 0.8505833148956299, 0.8554583191871643, 0.8557291626930237, 0.8630833625793457, 0.8658958077430725, 0.8666250109672546, 0.8691041469573975, 0.8711041808128357, 0.872083306312561, 0.8731874823570251, 0.8776458501815796, 0.879687488079071, 0.8792499899864197, 0.8838541507720947, 0.8838958144187927, 0.8847916722297668, 0.8878750205039978, 0.8883958458900452, 0.8899375200271606, 0.8901666402816772, 0.8924791812896729, 0.8938124775886536, 0.8956041932106018, 0.8977916836738586, 0.8990416526794434, 0.8995416760444641, 0.9003958106040955, 0.8999583125114441, 0.9016666412353516], 'val_loss': [0.6949627995491028, 0.5515403747558594, 0.48013970255851746, 0.442289799451828, 0.4085274338722229, 0.3843575716018677, 0.37314721941947937, 0.35881295800209045, 0.3449443280696869, 0.3360691964626312, 0.32815709710121155, 0.3201397955417633, 0.31161558628082275, 0.30739161372184753, 0.30494898557662964, 0.2962973713874817, 0.2956341803073883, 0.28563258051872253, 0.28491300344467163, 0.2783290445804596, 0.27795645594596863, 0.2742428183555603, 0.2683826982975006, 0.2694111168384552, 0.26459813117980957, 0.2629794180393219, 0.2604965269565582, 0.25395673513412476, 0.25153782963752747, 0.2546072006225586, 0.2483218014240265, 0.24728654325008392, 0.2440759539604187, 0.24132296442985535, 0.24072210490703583, 0.2376185655593872, 0.23593410849571228, 0.23606549203395844, 0.23439203202724457, 0.23373262584209442, 0.22900895774364471, 0.2280941605567932, 0.23034889996051788, 0.22840428352355957, 0.22482945024967194, 0.22442962229251862, 0.22251439094543457, 0.2224789261817932, 0.22402651607990265, 0.21927551925182343], 'val_accuracy': [0.7943333387374878, 0.8419166803359985, 0.8663333058357239, 0.8713333606719971, 0.8832499980926514, 0.8882499933242798, 0.8923333287239075, 0.8961666822433472, 0.8984166383743286, 0.9025833606719971, 0.90625, 0.9083333611488342, 0.9101666808128357, 0.9126666784286499, 0.9136666655540466, 0.9172499775886536, 0.9165833592414856, 0.9199166893959045, 0.9206666946411133, 0.9210833311080933, 0.9227499961853027, 0.9236666560173035, 0.925000011920929, 0.925000011920929, 0.9262499809265137, 0.9267500042915344, 0.9274166822433472, 0.9286666512489319, 0.9285833239555359, 0.9286666512489319, 0.9298333525657654, 0.9313333630561829, 0.9313333630561829, 0.9331666827201843, 0.9336666464805603, 0.934166669845581, 0.934499979019165, 0.9355833530426025, 0.9359166622161865, 0.9351666569709778, 0.9362499713897705, 0.9367499947547913, 0.937250018119812, 0.937666654586792, 0.9383333325386047, 0.9384999871253967, 0.9399999976158142, 0.9381666779518127, 0.9390833377838135, 0.9418333172798157]}\n",
            "{'loss': [2.2977519035339355, 2.2861130237579346, 2.242744207382202, 2.1234307289123535, 1.9597493410110474, 1.8065999746322632, 1.672796368598938, 1.5592881441116333, 1.4487773180007935, 1.3481028079986572, 1.2599263191223145, 1.1872410774230957, 1.1271216869354248, 1.0884982347488403, 1.0369359254837036, 0.9940717220306396, 0.9689361453056335, 0.9353806376457214, 0.8997038006782532, 0.8732821345329285, 0.8547855019569397, 0.8265855312347412, 0.8083235621452332, 0.7801525592803955, 0.7726026177406311, 0.7624744176864624, 0.7327114939689636, 0.7240359783172607, 0.7095015645027161, 0.6860024333000183, 0.6755505800247192, 0.6618315577507019, 0.6537967324256897, 0.633070170879364, 0.6263219118118286, 0.6065601110458374, 0.5986541509628296, 0.5925859808921814, 0.5798212885856628, 0.5735239386558533, 0.5594375729560852, 0.5431649684906006, 0.5429450869560242, 0.5345401167869568, 0.5224932432174683, 0.5124179720878601, 0.5071614980697632, 0.49329283833503723, 0.48819324374198914, 0.47694361209869385], 'accuracy': [0.1381666660308838, 0.18189583718776703, 0.22366666793823242, 0.2711041569709778, 0.3321458399295807, 0.375, 0.42008334398269653, 0.46654167771339417, 0.5068541765213013, 0.5431874990463257, 0.5794791579246521, 0.6049374938011169, 0.6289374828338623, 0.6470624804496765, 0.6673333048820496, 0.682687520980835, 0.69552081823349, 0.7083958387374878, 0.7208958268165588, 0.7304999828338623, 0.7365833520889282, 0.7456458210945129, 0.7511666417121887, 0.7624375224113464, 0.7638958096504211, 0.7700416445732117, 0.778249979019165, 0.7835000157356262, 0.7864166498184204, 0.7940416932106018, 0.7984583377838135, 0.8034791946411133, 0.8059791922569275, 0.8085416555404663, 0.8134583234786987, 0.8185625076293945, 0.8232499957084656, 0.8230833411216736, 0.8278541564941406, 0.8291666507720947, 0.8339791893959045, 0.8414166569709778, 0.8422083258628845, 0.8430833220481873, 0.8461458086967468, 0.8513333201408386, 0.8507708311080933, 0.8570625185966492, 0.8552291393280029, 0.8606666922569275], 'val_loss': [2.292973518371582, 2.27554988861084, 2.1536672115325928, 1.9510650634765625, 1.7114015817642212, 1.5363779067993164, 1.3771981000900269, 1.2301552295684814, 1.0877891778945923, 0.9657256603240967, 0.870548665523529, 0.7966744899749756, 0.7348619699478149, 0.6844689846038818, 0.643050491809845, 0.5979355573654175, 0.576093852519989, 0.5458940267562866, 0.5176296234130859, 0.4988114535808563, 0.47931209206581116, 0.4598722755908966, 0.44359883666038513, 0.4287979304790497, 0.4167795479297638, 0.4062844216823578, 0.3886605501174927, 0.37903913855552673, 0.370332270860672, 0.35712069272994995, 0.34544870257377625, 0.34029293060302734, 0.33056381344795227, 0.3238336145877838, 0.31585851311683655, 0.3078354597091675, 0.2996045649051666, 0.2933436334133148, 0.2877013087272644, 0.2832626402378082, 0.2801925539970398, 0.2713007926940918, 0.2705950438976288, 0.2639126479625702, 0.2617073953151703, 0.25994062423706055, 0.2519412934780121, 0.2498892992734909, 0.2508218288421631, 0.24385371804237366], 'val_accuracy': [0.1535000056028366, 0.25824999809265137, 0.296916663646698, 0.3648333251476288, 0.4124999940395355, 0.4845833480358124, 0.5733333230018616, 0.6630833148956299, 0.7212499976158142, 0.7541666626930237, 0.777916669845581, 0.7944166660308838, 0.8186666369438171, 0.8331666588783264, 0.8411666750907898, 0.8542500138282776, 0.8586666584014893, 0.8662499785423279, 0.8700833320617676, 0.8761666417121887, 0.8832499980926514, 0.8863333463668823, 0.8899999856948853, 0.8958333134651184, 0.8989999890327454, 0.9002500176429749, 0.9054166674613953, 0.9079999923706055, 0.909333348274231, 0.9131666421890259, 0.9140833616256714, 0.9164999723434448, 0.9176666736602783, 0.9210833311080933, 0.9235833287239075, 0.924916684627533, 0.9269999861717224, 0.9278333187103271, 0.9281666874885559, 0.9304166436195374, 0.9333333373069763, 0.9319999814033508, 0.9330000281333923, 0.9347500205039978, 0.9353333115577698, 0.9357500076293945, 0.937833309173584, 0.937333345413208, 0.9401666522026062, 0.940666675567627]}\n",
            "{'loss': [2.300045967102051, 2.294806480407715, 2.288423776626587, 2.2773542404174805, 2.2450077533721924, 2.1481847763061523, 2.0436654090881348, 1.9277799129486084, 1.7938416004180908, 1.6841059923171997, 1.5687936544418335, 1.4487214088439941, 1.3411661386489868, 1.2632715702056885, 1.2008863687515259, 1.1324979066848755, 1.0914466381072998, 1.0385923385620117, 1.0053274631500244, 0.9673978686332703, 0.9388605356216431, 0.9045335054397583, 0.8897588849067688, 0.8633257746696472, 0.8422791361808777, 0.8238736391067505, 0.806324303150177, 0.7848744988441467, 0.7736032605171204, 0.758975088596344, 0.7458326816558838, 0.7312347292900085, 0.7225052714347839, 0.7073368430137634, 0.6921162009239197, 0.6858893036842346, 0.6748067140579224, 0.6594992280006409, 0.6480025053024292, 0.64408278465271, 0.6307817101478577, 0.623792827129364, 0.6144270300865173, 0.6046866774559021, 0.5943393707275391, 0.5881442427635193, 0.5865744948387146, 0.5730586051940918, 0.5598156452178955, 0.5604350566864014], 'accuracy': [0.12981249392032623, 0.14618749916553497, 0.15727083384990692, 0.19060416519641876, 0.21814583241939545, 0.23202084004878998, 0.2535208463668823, 0.28456249833106995, 0.33268749713897705, 0.3828125, 0.4402916729450226, 0.49410417675971985, 0.5377500057220459, 0.5713541507720947, 0.5952083468437195, 0.6230833530426025, 0.6382499933242798, 0.6621875166893005, 0.6736875176429749, 0.6921250224113464, 0.7030208110809326, 0.7170208096504211, 0.7201874852180481, 0.7320833206176758, 0.7401041388511658, 0.7446041703224182, 0.7506666779518127, 0.7592083215713501, 0.7628124952316284, 0.7652083039283752, 0.7735000252723694, 0.778166651725769, 0.7820000052452087, 0.7864166498184204, 0.7905416488647461, 0.7932708263397217, 0.7985625267028809, 0.8021666407585144, 0.8044583201408386, 0.8067291378974915, 0.8113541603088379, 0.8159999847412109, 0.820187509059906, 0.820020854473114, 0.824916660785675, 0.8295208215713501, 0.8272083401679993, 0.8333125114440918, 0.8379583358764648, 0.8366666436195374], 'val_loss': [2.297309398651123, 2.2919647693634033, 2.2839338779449463, 2.267073154449463, 2.191706895828247, 2.0360028743743896, 1.8966624736785889, 1.7086844444274902, 1.5497816801071167, 1.4101063013076782, 1.2400718927383423, 1.0921566486358643, 0.9618948698043823, 0.8695204854011536, 0.8092188239097595, 0.74334716796875, 0.6960265040397644, 0.6459733843803406, 0.613795816898346, 0.5775043368339539, 0.5535265207290649, 0.5269879102706909, 0.5079779624938965, 0.4931151568889618, 0.47700801491737366, 0.46480005979537964, 0.4509529769420624, 0.4346950948238373, 0.42523372173309326, 0.4154881536960602, 0.40416714549064636, 0.3961434066295624, 0.3862529993057251, 0.3793118894100189, 0.3705548942089081, 0.36393022537231445, 0.3580036163330078, 0.3494386672973633, 0.3437579870223999, 0.3393445611000061, 0.3321746289730072, 0.32571274042129517, 0.3199988305568695, 0.315053254365921, 0.31206077337265015, 0.3049161434173584, 0.3009835481643677, 0.29870325326919556, 0.2948157787322998, 0.2929970324039459], 'val_accuracy': [0.11675000190734863, 0.12399999797344208, 0.1771666705608368, 0.20858334004878998, 0.22716666758060455, 0.26758334040641785, 0.3370833396911621, 0.398499995470047, 0.5008333325386047, 0.5705833435058594, 0.6453333497047424, 0.7035833597183228, 0.753083348274231, 0.7818333506584167, 0.7963333129882812, 0.8089166879653931, 0.8206666707992554, 0.8344166874885559, 0.844083309173584, 0.8513333201408386, 0.8569166660308838, 0.8601666688919067, 0.8665833473205566, 0.8690000176429749, 0.8742499947547913, 0.8765833377838135, 0.8828333616256714, 0.8853333592414856, 0.8863333463668823, 0.890500009059906, 0.893583357334137, 0.8960833549499512, 0.8981666564941406, 0.9021666646003723, 0.9039166569709778, 0.906333327293396, 0.9089999794960022, 0.9103333353996277, 0.9120000004768372, 0.9127500057220459, 0.9141666889190674, 0.9158333539962769, 0.9171666502952576, 0.9194999933242798, 0.918749988079071, 0.921750009059906, 0.9229999780654907, 0.9239166378974915, 0.9225000143051147, 0.9254999756813049]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}