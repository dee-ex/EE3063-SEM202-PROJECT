{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noinit_noise_11depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "f70205dd-ce53-4059-87c4-940b7193b55d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 15s 6ms/step - loss: 2.3665 - accuracy: 0.1496 - val_loss: 1.4967 - val_accuracy: 0.5893\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8723 - accuracy: 0.3313 - val_loss: 1.2431 - val_accuracy: 0.6194\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6259 - accuracy: 0.4155 - val_loss: 1.1268 - val_accuracy: 0.6463\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5075 - accuracy: 0.4566 - val_loss: 1.0569 - val_accuracy: 0.6593\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4101 - accuracy: 0.4951 - val_loss: 1.0057 - val_accuracy: 0.6726\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3477 - accuracy: 0.5211 - val_loss: 0.9639 - val_accuracy: 0.6841\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3056 - accuracy: 0.5403 - val_loss: 0.9330 - val_accuracy: 0.6971\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2602 - accuracy: 0.5584 - val_loss: 0.8989 - val_accuracy: 0.7085\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2226 - accuracy: 0.5800 - val_loss: 0.8679 - val_accuracy: 0.7300\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1900 - accuracy: 0.5963 - val_loss: 0.8355 - val_accuracy: 0.7394\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1652 - accuracy: 0.6096 - val_loss: 0.7987 - val_accuracy: 0.7607\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1254 - accuracy: 0.6225 - val_loss: 0.7645 - val_accuracy: 0.7762\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0955 - accuracy: 0.6382 - val_loss: 0.7374 - val_accuracy: 0.7881\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0574 - accuracy: 0.6571 - val_loss: 0.7106 - val_accuracy: 0.7940\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0497 - accuracy: 0.6636 - val_loss: 0.6898 - val_accuracy: 0.8020\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0169 - accuracy: 0.6794 - val_loss: 0.6704 - val_accuracy: 0.8080\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0082 - accuracy: 0.6869 - val_loss: 0.6527 - val_accuracy: 0.8118\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9802 - accuracy: 0.6936 - val_loss: 0.6353 - val_accuracy: 0.8145\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9515 - accuracy: 0.7083 - val_loss: 0.6185 - val_accuracy: 0.8198\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9420 - accuracy: 0.7109 - val_loss: 0.6136 - val_accuracy: 0.8246\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9201 - accuracy: 0.7134 - val_loss: 0.5958 - val_accuracy: 0.8241\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9006 - accuracy: 0.7261 - val_loss: 0.5814 - val_accuracy: 0.8375\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8898 - accuracy: 0.7330 - val_loss: 0.5680 - val_accuracy: 0.8431\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8699 - accuracy: 0.7395 - val_loss: 0.5604 - val_accuracy: 0.8451\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8549 - accuracy: 0.7476 - val_loss: 0.5403 - val_accuracy: 0.8572\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8377 - accuracy: 0.7532 - val_loss: 0.5373 - val_accuracy: 0.8636\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8186 - accuracy: 0.7604 - val_loss: 0.5206 - val_accuracy: 0.8652\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8209 - accuracy: 0.7644 - val_loss: 0.5112 - val_accuracy: 0.8748\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7932 - accuracy: 0.7726 - val_loss: 0.4975 - val_accuracy: 0.8821\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7942 - accuracy: 0.7807 - val_loss: 0.4935 - val_accuracy: 0.8838\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7591 - accuracy: 0.7868 - val_loss: 0.4791 - val_accuracy: 0.8905\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7657 - accuracy: 0.7904 - val_loss: 0.4732 - val_accuracy: 0.8924\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7523 - accuracy: 0.7970 - val_loss: 0.4604 - val_accuracy: 0.8957\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7146 - accuracy: 0.8080 - val_loss: 0.4550 - val_accuracy: 0.8977\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7166 - accuracy: 0.8121 - val_loss: 0.4450 - val_accuracy: 0.9001\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7040 - accuracy: 0.8152 - val_loss: 0.4387 - val_accuracy: 0.9007\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6976 - accuracy: 0.8204 - val_loss: 0.4280 - val_accuracy: 0.9045\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6833 - accuracy: 0.8251 - val_loss: 0.4223 - val_accuracy: 0.9047\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6813 - accuracy: 0.8282 - val_loss: 0.4231 - val_accuracy: 0.9070\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6600 - accuracy: 0.8345 - val_loss: 0.4167 - val_accuracy: 0.9080\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6562 - accuracy: 0.8378 - val_loss: 0.4084 - val_accuracy: 0.9103\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6458 - accuracy: 0.8397 - val_loss: 0.4135 - val_accuracy: 0.9093\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6456 - accuracy: 0.8411 - val_loss: 0.4068 - val_accuracy: 0.9119\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6199 - accuracy: 0.8526 - val_loss: 0.4033 - val_accuracy: 0.9135\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6275 - accuracy: 0.8459 - val_loss: 0.4014 - val_accuracy: 0.9147\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6111 - accuracy: 0.8523 - val_loss: 0.3921 - val_accuracy: 0.9158\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6119 - accuracy: 0.8543 - val_loss: 0.3884 - val_accuracy: 0.9162\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6060 - accuracy: 0.8554 - val_loss: 0.3914 - val_accuracy: 0.9162\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5929 - accuracy: 0.8589 - val_loss: 0.3937 - val_accuracy: 0.9168\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5792 - accuracy: 0.8647 - val_loss: 0.3831 - val_accuracy: 0.9193\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3048 - accuracy: 0.1042 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3020 - accuracy: 0.1212 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3003 - accuracy: 0.1199 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2986 - accuracy: 0.1232 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2955 - accuracy: 0.1264 - val_loss: 2.2961 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2883 - accuracy: 0.1321 - val_loss: 2.2723 - val_accuracy: 0.1723\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2673 - accuracy: 0.1391 - val_loss: 2.2012 - val_accuracy: 0.1936\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2190 - accuracy: 0.1520 - val_loss: 2.1185 - val_accuracy: 0.1998\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1729 - accuracy: 0.1622 - val_loss: 2.0686 - val_accuracy: 0.2126\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1272 - accuracy: 0.1773 - val_loss: 2.0134 - val_accuracy: 0.2222\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0853 - accuracy: 0.1855 - val_loss: 1.9819 - val_accuracy: 0.2308\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0415 - accuracy: 0.2014 - val_loss: 1.9466 - val_accuracy: 0.2380\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0002 - accuracy: 0.2154 - val_loss: 1.9159 - val_accuracy: 0.2435\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9688 - accuracy: 0.2322 - val_loss: 1.8773 - val_accuracy: 0.2681\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9480 - accuracy: 0.2399 - val_loss: 1.8717 - val_accuracy: 0.2841\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9192 - accuracy: 0.2502 - val_loss: 1.8591 - val_accuracy: 0.2940\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8828 - accuracy: 0.2573 - val_loss: 1.8080 - val_accuracy: 0.3087\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8595 - accuracy: 0.2640 - val_loss: 1.8068 - val_accuracy: 0.2948\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8446 - accuracy: 0.2643 - val_loss: 1.7492 - val_accuracy: 0.3223\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8143 - accuracy: 0.2757 - val_loss: 1.7405 - val_accuracy: 0.3200\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7934 - accuracy: 0.2790 - val_loss: 1.7529 - val_accuracy: 0.3226\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7784 - accuracy: 0.2814 - val_loss: 1.7019 - val_accuracy: 0.3183\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7646 - accuracy: 0.2858 - val_loss: 1.7063 - val_accuracy: 0.3372\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7418 - accuracy: 0.2887 - val_loss: 1.6744 - val_accuracy: 0.3406\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7228 - accuracy: 0.2959 - val_loss: 1.6619 - val_accuracy: 0.3490\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6996 - accuracy: 0.2969 - val_loss: 1.6574 - val_accuracy: 0.3422\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6852 - accuracy: 0.3053 - val_loss: 1.6568 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6699 - accuracy: 0.3109 - val_loss: 1.6431 - val_accuracy: 0.3357\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6592 - accuracy: 0.3132 - val_loss: 1.6072 - val_accuracy: 0.3568\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6437 - accuracy: 0.3180 - val_loss: 1.5974 - val_accuracy: 0.3384\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6285 - accuracy: 0.3197 - val_loss: 1.6025 - val_accuracy: 0.3606\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6316 - accuracy: 0.3247 - val_loss: 1.5724 - val_accuracy: 0.3662\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6139 - accuracy: 0.3279 - val_loss: 1.5777 - val_accuracy: 0.3684\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6042 - accuracy: 0.3295 - val_loss: 1.5793 - val_accuracy: 0.3742\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5966 - accuracy: 0.3302 - val_loss: 1.5430 - val_accuracy: 0.3674\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5848 - accuracy: 0.3401 - val_loss: 1.5324 - val_accuracy: 0.3748\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5635 - accuracy: 0.3378 - val_loss: 1.5235 - val_accuracy: 0.3796\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5555 - accuracy: 0.3411 - val_loss: 1.5217 - val_accuracy: 0.3764\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5430 - accuracy: 0.3442 - val_loss: 1.5099 - val_accuracy: 0.3789\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5362 - accuracy: 0.3448 - val_loss: 1.4993 - val_accuracy: 0.3817\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5305 - accuracy: 0.3497 - val_loss: 1.4951 - val_accuracy: 0.3589\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5401 - accuracy: 0.3472 - val_loss: 1.4926 - val_accuracy: 0.3728\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5158 - accuracy: 0.3532 - val_loss: 1.4765 - val_accuracy: 0.3688\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5019 - accuracy: 0.3560 - val_loss: 1.4854 - val_accuracy: 0.3742\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5254 - accuracy: 0.3517 - val_loss: 1.4634 - val_accuracy: 0.3792\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4837 - accuracy: 0.3590 - val_loss: 1.4704 - val_accuracy: 0.3834\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4879 - accuracy: 0.3591 - val_loss: 1.4413 - val_accuracy: 0.3937\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4668 - accuracy: 0.3623 - val_loss: 1.4517 - val_accuracy: 0.3859\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4675 - accuracy: 0.3652 - val_loss: 1.4400 - val_accuracy: 0.3882\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4475 - accuracy: 0.3704 - val_loss: 1.4334 - val_accuracy: 0.3836\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 7ms/step - loss: 2.3091 - accuracy: 0.0997 - val_loss: 2.3015 - val_accuracy: 0.1062\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3017 - accuracy: 0.1197 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2991 - accuracy: 0.1243 - val_loss: 2.2972 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2943 - accuracy: 0.1262 - val_loss: 2.2765 - val_accuracy: 0.1481\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2715 - accuracy: 0.1509 - val_loss: 2.1642 - val_accuracy: 0.2282\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1896 - accuracy: 0.1902 - val_loss: 2.0163 - val_accuracy: 0.2514\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0902 - accuracy: 0.2166 - val_loss: 1.8449 - val_accuracy: 0.2967\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9721 - accuracy: 0.2436 - val_loss: 1.6442 - val_accuracy: 0.3386\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8372 - accuracy: 0.2847 - val_loss: 1.4986 - val_accuracy: 0.3730\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7130 - accuracy: 0.3251 - val_loss: 1.4078 - val_accuracy: 0.4249\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6138 - accuracy: 0.3663 - val_loss: 1.3377 - val_accuracy: 0.4812\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5500 - accuracy: 0.3920 - val_loss: 1.2861 - val_accuracy: 0.5091\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4752 - accuracy: 0.4151 - val_loss: 1.2418 - val_accuracy: 0.5610\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4358 - accuracy: 0.4349 - val_loss: 1.2020 - val_accuracy: 0.5742\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3835 - accuracy: 0.4547 - val_loss: 1.1725 - val_accuracy: 0.5874\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3669 - accuracy: 0.4571 - val_loss: 1.1432 - val_accuracy: 0.5779\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3250 - accuracy: 0.4722 - val_loss: 1.1235 - val_accuracy: 0.5891\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2895 - accuracy: 0.4819 - val_loss: 1.0983 - val_accuracy: 0.6037\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2781 - accuracy: 0.4910 - val_loss: 1.0737 - val_accuracy: 0.6211\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2325 - accuracy: 0.5124 - val_loss: 1.0606 - val_accuracy: 0.6028\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2213 - accuracy: 0.5141 - val_loss: 1.0364 - val_accuracy: 0.6308\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1874 - accuracy: 0.5284 - val_loss: 1.0187 - val_accuracy: 0.6352\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1856 - accuracy: 0.5389 - val_loss: 1.0045 - val_accuracy: 0.6518\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1461 - accuracy: 0.5492 - val_loss: 0.9839 - val_accuracy: 0.6632\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1452 - accuracy: 0.5609 - val_loss: 0.9631 - val_accuracy: 0.6745\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0990 - accuracy: 0.5776 - val_loss: 0.9387 - val_accuracy: 0.6848\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0717 - accuracy: 0.5892 - val_loss: 0.9206 - val_accuracy: 0.7019\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0581 - accuracy: 0.6011 - val_loss: 0.8940 - val_accuracy: 0.7083\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0442 - accuracy: 0.6038 - val_loss: 0.8688 - val_accuracy: 0.7317\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0191 - accuracy: 0.6150 - val_loss: 0.8386 - val_accuracy: 0.7423\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9833 - accuracy: 0.6386 - val_loss: 0.8111 - val_accuracy: 0.7422\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9600 - accuracy: 0.6503 - val_loss: 0.7883 - val_accuracy: 0.7580\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9295 - accuracy: 0.6629 - val_loss: 0.7533 - val_accuracy: 0.7626\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9056 - accuracy: 0.6760 - val_loss: 0.7260 - val_accuracy: 0.7865\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8809 - accuracy: 0.7006 - val_loss: 0.7013 - val_accuracy: 0.8300\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8433 - accuracy: 0.7244 - val_loss: 0.6596 - val_accuracy: 0.8523\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8057 - accuracy: 0.7340 - val_loss: 0.6536 - val_accuracy: 0.8673\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7969 - accuracy: 0.7468 - val_loss: 0.6386 - val_accuracy: 0.8662\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7581 - accuracy: 0.7594 - val_loss: 0.6281 - val_accuracy: 0.8633\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7496 - accuracy: 0.7649 - val_loss: 0.6052 - val_accuracy: 0.8742\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7267 - accuracy: 0.7741 - val_loss: 0.6127 - val_accuracy: 0.8720\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7085 - accuracy: 0.7810 - val_loss: 0.6058 - val_accuracy: 0.8823\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6990 - accuracy: 0.7902 - val_loss: 0.5771 - val_accuracy: 0.8808\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6730 - accuracy: 0.7975 - val_loss: 0.5915 - val_accuracy: 0.8783\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6564 - accuracy: 0.7992 - val_loss: 0.5622 - val_accuracy: 0.8834\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6438 - accuracy: 0.8079 - val_loss: 0.5539 - val_accuracy: 0.8895\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6340 - accuracy: 0.8114 - val_loss: 0.5686 - val_accuracy: 0.8935\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6146 - accuracy: 0.8182 - val_loss: 0.5715 - val_accuracy: 0.8675\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6021 - accuracy: 0.8212 - val_loss: 0.5604 - val_accuracy: 0.8876\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5774 - accuracy: 0.8304 - val_loss: 0.5403 - val_accuracy: 0.8971\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.4179 - accuracy: 0.1434 - val_loss: 1.4924 - val_accuracy: 0.5890\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8958 - accuracy: 0.3188 - val_loss: 1.0713 - val_accuracy: 0.6866\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6083 - accuracy: 0.4344 - val_loss: 0.8056 - val_accuracy: 0.7389\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3743 - accuracy: 0.5233 - val_loss: 0.6733 - val_accuracy: 0.7912\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2246 - accuracy: 0.5736 - val_loss: 0.6029 - val_accuracy: 0.8149\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1290 - accuracy: 0.6153 - val_loss: 0.5688 - val_accuracy: 0.8299\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0466 - accuracy: 0.6510 - val_loss: 0.5347 - val_accuracy: 0.8258\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0032 - accuracy: 0.6699 - val_loss: 0.5151 - val_accuracy: 0.8462\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9642 - accuracy: 0.6859 - val_loss: 0.4985 - val_accuracy: 0.8403\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9389 - accuracy: 0.6966 - val_loss: 0.4896 - val_accuracy: 0.8403\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8960 - accuracy: 0.7162 - val_loss: 0.4716 - val_accuracy: 0.8481\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8746 - accuracy: 0.7214 - val_loss: 0.4675 - val_accuracy: 0.8516\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8554 - accuracy: 0.7287 - val_loss: 0.4584 - val_accuracy: 0.8568\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8277 - accuracy: 0.7405 - val_loss: 0.4464 - val_accuracy: 0.8583\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8132 - accuracy: 0.7468 - val_loss: 0.4390 - val_accuracy: 0.8512\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8040 - accuracy: 0.7539 - val_loss: 0.4297 - val_accuracy: 0.8637\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7666 - accuracy: 0.7617 - val_loss: 0.4290 - val_accuracy: 0.8593\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7498 - accuracy: 0.7711 - val_loss: 0.4139 - val_accuracy: 0.8704\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7480 - accuracy: 0.7697 - val_loss: 0.4115 - val_accuracy: 0.8868\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7291 - accuracy: 0.7791 - val_loss: 0.4036 - val_accuracy: 0.8863\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7180 - accuracy: 0.7866 - val_loss: 0.3954 - val_accuracy: 0.8938\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7108 - accuracy: 0.7905 - val_loss: 0.3875 - val_accuracy: 0.8857\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.7964 - val_loss: 0.3749 - val_accuracy: 0.8962\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6812 - accuracy: 0.8008 - val_loss: 0.3749 - val_accuracy: 0.9051\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6791 - accuracy: 0.8030 - val_loss: 0.3597 - val_accuracy: 0.9076\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6533 - accuracy: 0.8109 - val_loss: 0.3538 - val_accuracy: 0.9094\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6405 - accuracy: 0.8184 - val_loss: 0.3478 - val_accuracy: 0.9102\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6381 - accuracy: 0.8234 - val_loss: 0.3384 - val_accuracy: 0.9158\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6198 - accuracy: 0.8239 - val_loss: 0.3331 - val_accuracy: 0.9176\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6115 - accuracy: 0.8327 - val_loss: 0.3256 - val_accuracy: 0.9185\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6012 - accuracy: 0.8342 - val_loss: 0.3181 - val_accuracy: 0.9219\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6039 - accuracy: 0.8341 - val_loss: 0.3056 - val_accuracy: 0.9237\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5848 - accuracy: 0.8389 - val_loss: 0.3053 - val_accuracy: 0.9252\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5797 - accuracy: 0.8436 - val_loss: 0.3002 - val_accuracy: 0.9257\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5682 - accuracy: 0.8467 - val_loss: 0.2990 - val_accuracy: 0.9247\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5582 - accuracy: 0.8476 - val_loss: 0.2928 - val_accuracy: 0.9253\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5390 - accuracy: 0.8562 - val_loss: 0.2894 - val_accuracy: 0.9300\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5476 - accuracy: 0.8553 - val_loss: 0.2828 - val_accuracy: 0.9301\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5269 - accuracy: 0.8607 - val_loss: 0.2779 - val_accuracy: 0.9321\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5216 - accuracy: 0.8622 - val_loss: 0.2752 - val_accuracy: 0.9310\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5153 - accuracy: 0.8651 - val_loss: 0.2802 - val_accuracy: 0.9311\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5123 - accuracy: 0.8680 - val_loss: 0.2665 - val_accuracy: 0.9340\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5114 - accuracy: 0.8676 - val_loss: 0.2690 - val_accuracy: 0.9343\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4940 - accuracy: 0.8733 - val_loss: 0.2677 - val_accuracy: 0.9337\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4992 - accuracy: 0.8745 - val_loss: 0.2610 - val_accuracy: 0.9364\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4820 - accuracy: 0.8783 - val_loss: 0.2680 - val_accuracy: 0.9358\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4828 - accuracy: 0.8767 - val_loss: 0.2627 - val_accuracy: 0.9370\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4705 - accuracy: 0.8830 - val_loss: 0.2523 - val_accuracy: 0.9402\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4688 - accuracy: 0.8843 - val_loss: 0.2572 - val_accuracy: 0.9403\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4577 - accuracy: 0.8848 - val_loss: 0.2564 - val_accuracy: 0.9395\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 3.2080 - accuracy: 0.1516 - val_loss: 1.2561 - val_accuracy: 0.6002\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7999 - accuracy: 0.3523 - val_loss: 1.0647 - val_accuracy: 0.6201\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4906 - accuracy: 0.4492 - val_loss: 0.9551 - val_accuracy: 0.6688\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3404 - accuracy: 0.5058 - val_loss: 0.8723 - val_accuracy: 0.6818\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2375 - accuracy: 0.5501 - val_loss: 0.7782 - val_accuracy: 0.7236\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1743 - accuracy: 0.5798 - val_loss: 0.7275 - val_accuracy: 0.7338\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1117 - accuracy: 0.6075 - val_loss: 0.7072 - val_accuracy: 0.7368\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0700 - accuracy: 0.6262 - val_loss: 0.6946 - val_accuracy: 0.7302\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0427 - accuracy: 0.6382 - val_loss: 0.6743 - val_accuracy: 0.7513\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0020 - accuracy: 0.6511 - val_loss: 0.6535 - val_accuracy: 0.7707\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9771 - accuracy: 0.6577 - val_loss: 0.6337 - val_accuracy: 0.7784\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9525 - accuracy: 0.6653 - val_loss: 0.6235 - val_accuracy: 0.7817\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9383 - accuracy: 0.6766 - val_loss: 0.6116 - val_accuracy: 0.7856\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9105 - accuracy: 0.6827 - val_loss: 0.5909 - val_accuracy: 0.7955\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8883 - accuracy: 0.6968 - val_loss: 0.5845 - val_accuracy: 0.7979\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8749 - accuracy: 0.7019 - val_loss: 0.5658 - val_accuracy: 0.8037\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8634 - accuracy: 0.7114 - val_loss: 0.5534 - val_accuracy: 0.8079\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8403 - accuracy: 0.7181 - val_loss: 0.5417 - val_accuracy: 0.8114\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8289 - accuracy: 0.7235 - val_loss: 0.5353 - val_accuracy: 0.8198\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8082 - accuracy: 0.7286 - val_loss: 0.5261 - val_accuracy: 0.8135\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7977 - accuracy: 0.7351 - val_loss: 0.5221 - val_accuracy: 0.8103\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7858 - accuracy: 0.7430 - val_loss: 0.5121 - val_accuracy: 0.8138\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7695 - accuracy: 0.7458 - val_loss: 0.5011 - val_accuracy: 0.8168\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7689 - accuracy: 0.7487 - val_loss: 0.4953 - val_accuracy: 0.8352\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7553 - accuracy: 0.7580 - val_loss: 0.4937 - val_accuracy: 0.8217\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7407 - accuracy: 0.7592 - val_loss: 0.4898 - val_accuracy: 0.8242\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7350 - accuracy: 0.7614 - val_loss: 0.4827 - val_accuracy: 0.8259\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7145 - accuracy: 0.7677 - val_loss: 0.4774 - val_accuracy: 0.8239\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7119 - accuracy: 0.7732 - val_loss: 0.4621 - val_accuracy: 0.8284\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6903 - accuracy: 0.7706 - val_loss: 0.4682 - val_accuracy: 0.8288\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.7782 - val_loss: 0.4610 - val_accuracy: 0.8274\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6810 - accuracy: 0.7781 - val_loss: 0.4544 - val_accuracy: 0.8319\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6781 - accuracy: 0.7822 - val_loss: 0.4436 - val_accuracy: 0.8338\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6593 - accuracy: 0.7805 - val_loss: 0.4394 - val_accuracy: 0.8357\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6478 - accuracy: 0.7898 - val_loss: 0.4429 - val_accuracy: 0.8356\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6407 - accuracy: 0.7895 - val_loss: 0.4403 - val_accuracy: 0.8353\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6299 - accuracy: 0.7932 - val_loss: 0.4355 - val_accuracy: 0.8393\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6287 - accuracy: 0.7949 - val_loss: 0.4349 - val_accuracy: 0.8365\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6171 - accuracy: 0.7972 - val_loss: 0.4363 - val_accuracy: 0.8378\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6047 - accuracy: 0.8036 - val_loss: 0.4235 - val_accuracy: 0.8399\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5947 - accuracy: 0.8021 - val_loss: 0.4247 - val_accuracy: 0.8409\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6073 - accuracy: 0.8010 - val_loss: 0.4266 - val_accuracy: 0.8395\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5871 - accuracy: 0.8050 - val_loss: 0.4232 - val_accuracy: 0.8429\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5923 - accuracy: 0.8044 - val_loss: 0.4203 - val_accuracy: 0.8421\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5772 - accuracy: 0.8110 - val_loss: 0.4181 - val_accuracy: 0.8427\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5861 - accuracy: 0.8075 - val_loss: 0.4141 - val_accuracy: 0.8457\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5796 - accuracy: 0.8096 - val_loss: 0.4169 - val_accuracy: 0.8416\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5651 - accuracy: 0.8147 - val_loss: 0.4135 - val_accuracy: 0.8457\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5676 - accuracy: 0.8124 - val_loss: 0.4128 - val_accuracy: 0.8462\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5619 - accuracy: 0.8117 - val_loss: 0.4120 - val_accuracy: 0.8470\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 8ms/step - loss: 2.3023 - accuracy: 0.1141 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1138 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3014 - accuracy: 0.1119 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1140 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1159 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3015 - accuracy: 0.1107 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1157 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1128 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1140 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1125 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1142 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1134 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1143 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1115 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1155 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1160 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1144 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2996 - accuracy: 0.1162 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1119 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1104 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3002 - accuracy: 0.1146 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3000 - accuracy: 0.1138 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2997 - accuracy: 0.1153 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1129 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2999 - accuracy: 0.1123 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2996 - accuracy: 0.1132 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2999 - accuracy: 0.1121 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2989 - accuracy: 0.1156 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2993 - accuracy: 0.1131 - val_loss: 2.2998 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2985 - accuracy: 0.1118 - val_loss: 2.2994 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2979 - accuracy: 0.1148 - val_loss: 2.2988 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2972 - accuracy: 0.1153 - val_loss: 2.2975 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2952 - accuracy: 0.1237 - val_loss: 2.2929 - val_accuracy: 0.1307\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2797 - accuracy: 0.1577 - val_loss: 2.1813 - val_accuracy: 0.1965\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2049 - accuracy: 0.1868 - val_loss: 2.1074 - val_accuracy: 0.1950\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.1389 - accuracy: 0.1974 - val_loss: 2.0732 - val_accuracy: 0.1964\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.1104 - accuracy: 0.1934 - val_loss: 2.0541 - val_accuracy: 0.1997\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.0891 - accuracy: 0.1990 - val_loss: 2.0388 - val_accuracy: 0.2026\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.0669 - accuracy: 0.2065 - val_loss: 2.0216 - val_accuracy: 0.2116\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.0418 - accuracy: 0.2198 - val_loss: 1.9782 - val_accuracy: 0.2364\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.9996 - accuracy: 0.2466 - val_loss: 1.8839 - val_accuracy: 0.3004\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.9502 - accuracy: 0.2705 - val_loss: 1.7937 - val_accuracy: 0.3413\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.8724 - accuracy: 0.3012 - val_loss: 1.7440 - val_accuracy: 0.3557\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.8291 - accuracy: 0.3164 - val_loss: 1.6935 - val_accuracy: 0.4070\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.7817 - accuracy: 0.3365 - val_loss: 1.6446 - val_accuracy: 0.4344\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7400 - accuracy: 0.3524 - val_loss: 1.5890 - val_accuracy: 0.4480\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.6789 - accuracy: 0.3680 - val_loss: 1.5252 - val_accuracy: 0.4611\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.3023 - accuracy: 0.1148 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1138 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1128 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1164 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1141 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1131 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1159 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1151 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1134 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1119 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1133 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1157 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1120 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1162 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1102 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1135 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1153 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1136 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1105 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1127 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1156 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1128 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1127 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1111 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1135 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1131 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1143 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1119 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1143 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1152 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1144 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1155 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1141 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1123 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1136 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1147 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1134 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2996 - accuracy: 0.1150 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1150 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1131 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1145 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
            "{'loss': [2.2061874866485596, 1.7982970476150513, 1.5925712585449219, 1.4809596538543701, 1.3919847011566162, 1.3355634212493896, 1.2891860008239746, 1.2512359619140625, 1.2154426574707031, 1.1809988021850586, 1.1500225067138672, 1.1239194869995117, 1.0957061052322388, 1.0572165250778198, 1.0459612607955933, 1.0165482759475708, 0.9971522092819214, 0.9780125617980957, 0.9546946883201599, 0.9331749081611633, 0.9180442690849304, 0.901951014995575, 0.8827862739562988, 0.8646066188812256, 0.8547248244285583, 0.8432861566543579, 0.8189325332641602, 0.8183032870292664, 0.794309675693512, 0.783424973487854, 0.7602868676185608, 0.7630560994148254, 0.7414519786834717, 0.7229795455932617, 0.7109679579734802, 0.7056776285171509, 0.6979233622550964, 0.6823300719261169, 0.6749774813652039, 0.6618999242782593, 0.6566954255104065, 0.6404795050621033, 0.631964921951294, 0.6262491345405579, 0.6224515438079834, 0.6117507815361023, 0.6010504961013794, 0.5996399521827698, 0.5840452909469604, 0.5824539661407471], 'accuracy': [0.2018958330154419, 0.35631251335144043, 0.42781248688697815, 0.4659166634082794, 0.5013750195503235, 0.5253541469573975, 0.5442708134651184, 0.5631250143051147, 0.5822499990463257, 0.5972499847412109, 0.6162083148956299, 0.6274791955947876, 0.6420624852180481, 0.6600000262260437, 0.6651874780654907, 0.6790624856948853, 0.6880208253860474, 0.6959999799728394, 0.7067291736602783, 0.7146458625793457, 0.7147708535194397, 0.7256249785423279, 0.7338125109672546, 0.7403125166893005, 0.7458541393280029, 0.7533958554267883, 0.762541651725769, 0.7659375071525574, 0.773729145526886, 0.781000018119812, 0.7881249785423279, 0.792145848274231, 0.7988541722297668, 0.8062499761581421, 0.812333345413208, 0.8153333067893982, 0.8194791674613953, 0.8246250152587891, 0.8301041722297668, 0.8342499732971191, 0.8383125066757202, 0.8412083387374878, 0.8436874747276306, 0.8491458296775818, 0.8481458425521851, 0.8536458611488342, 0.8567291498184204, 0.8572499752044678, 0.8623541593551636, 0.8629166483879089], 'val_loss': [1.4966914653778076, 1.2431429624557495, 1.1268380880355835, 1.0568647384643555, 1.005708932876587, 0.9639188051223755, 0.933012843132019, 0.8988877534866333, 0.8678644895553589, 0.8355489373207092, 0.7987434267997742, 0.7644714117050171, 0.7373823523521423, 0.7106371521949768, 0.6897599101066589, 0.6703581213951111, 0.6527096629142761, 0.6352581977844238, 0.6184889078140259, 0.6135959029197693, 0.5958259701728821, 0.581371545791626, 0.5680040121078491, 0.5603947639465332, 0.5402523279190063, 0.5372775197029114, 0.5205767154693604, 0.5111587643623352, 0.49753063917160034, 0.4934990108013153, 0.4791220724582672, 0.4732080399990082, 0.4603530764579773, 0.4549950063228607, 0.4450157582759857, 0.43874040246009827, 0.4279962182044983, 0.42227575182914734, 0.4230714440345764, 0.41673988103866577, 0.40841159224510193, 0.41353023052215576, 0.40680932998657227, 0.40327584743499756, 0.40144023299217224, 0.39210161566734314, 0.3883835971355438, 0.3913598954677582, 0.39367395639419556, 0.3831108808517456], 'val_accuracy': [0.5893333554267883, 0.6194166541099548, 0.6462500095367432, 0.659333348274231, 0.6725833415985107, 0.6840833425521851, 0.6970833539962769, 0.7085000276565552, 0.7300000190734863, 0.7394166588783264, 0.7606666684150696, 0.7761666774749756, 0.7880833148956299, 0.7940000295639038, 0.8019999861717224, 0.8080000281333923, 0.8118333220481873, 0.8144999742507935, 0.8198333382606506, 0.8245833516120911, 0.8240833282470703, 0.8374999761581421, 0.8430833220481873, 0.8450833559036255, 0.8572499752044678, 0.8635833263397217, 0.8651666641235352, 0.874750018119812, 0.8820833563804626, 0.8838333487510681, 0.890500009059906, 0.8924166560173035, 0.8956666588783264, 0.8976666927337646, 0.9000833630561829, 0.9007499814033508, 0.9045000076293945, 0.9047499895095825, 0.9070000052452087, 0.9079999923706055, 0.9103333353996277, 0.909250020980835, 0.9119166731834412, 0.9135000109672546, 0.9147499799728394, 0.9157500267028809, 0.9161666631698608, 0.9162499904632568, 0.9168333411216736, 0.9192500114440918]}\n",
            "{'loss': [2.303776741027832, 2.301405668258667, 2.299636125564575, 2.298098564147949, 2.294618606567383, 2.284423828125, 2.2572691440582275, 2.2061386108398438, 2.162912607192993, 2.1169097423553467, 2.0738277435302734, 2.0331342220306396, 1.9969627857208252, 1.9636037349700928, 1.9378986358642578, 1.9141751527786255, 1.8778406381607056, 1.8561383485794067, 1.838695764541626, 1.8132579326629639, 1.7961030006408691, 1.771544098854065, 1.754745602607727, 1.7352396249771118, 1.7217226028442383, 1.6989308595657349, 1.6848232746124268, 1.6717873811721802, 1.65785551071167, 1.644818902015686, 1.629713535308838, 1.625452995300293, 1.6091187000274658, 1.6001790761947632, 1.597343921661377, 1.5800526142120361, 1.5637080669403076, 1.554041862487793, 1.5463523864746094, 1.5410454273223877, 1.5277647972106934, 1.5335843563079834, 1.5120418071746826, 1.5041695833206177, 1.5076825618743896, 1.4872548580169678, 1.4856692552566528, 1.4607722759246826, 1.4668587446212769, 1.4449301958084106], 'accuracy': [0.10966666787862778, 0.1224583312869072, 0.1223749965429306, 0.12304166704416275, 0.12843750417232513, 0.13335417211055756, 0.14172916114330292, 0.15575000643730164, 0.1666458398103714, 0.17766666412353516, 0.18983332812786102, 0.20510417222976685, 0.2188750058412552, 0.23543749749660492, 0.24187499284744263, 0.24804165959358215, 0.2580208480358124, 0.26527082920074463, 0.26906248927116394, 0.2757083475589752, 0.27916666865348816, 0.28325000405311584, 0.2906875014305115, 0.2916666567325592, 0.29747915267944336, 0.3008958399295807, 0.3059583306312561, 0.3114583194255829, 0.31335416436195374, 0.31706249713897705, 0.32116666436195374, 0.32366666197776794, 0.3268750011920929, 0.3294583261013031, 0.3309583365917206, 0.33816665410995483, 0.33920833468437195, 0.3427291810512543, 0.3434999883174896, 0.34416666626930237, 0.35056251287460327, 0.35097917914390564, 0.35212498903274536, 0.35495832562446594, 0.3527083396911621, 0.359562486410141, 0.35837501287460327, 0.3643541634082794, 0.3659166693687439, 0.36893749237060547], 'val_loss': [2.3022100925445557, 2.3020873069763184, 2.302100658416748, 2.301939010620117, 2.2960705757141113, 2.2722504138946533, 2.2012078762054443, 2.1185340881347656, 2.0685975551605225, 2.013360023498535, 1.9818787574768066, 1.9466009140014648, 1.9158940315246582, 1.8772664070129395, 1.8717409372329712, 1.85907781124115, 1.8079819679260254, 1.806810736656189, 1.749218463897705, 1.740457534790039, 1.7529059648513794, 1.7018654346466064, 1.7063084840774536, 1.6744468212127686, 1.6619402170181274, 1.6573705673217773, 1.6567615270614624, 1.6431108713150024, 1.607197642326355, 1.597373366355896, 1.6024609804153442, 1.5724375247955322, 1.57770574092865, 1.5792856216430664, 1.542980432510376, 1.5324082374572754, 1.5235377550125122, 1.521661400794983, 1.509906530380249, 1.4993460178375244, 1.4951183795928955, 1.4926226139068604, 1.4765286445617676, 1.4854004383087158, 1.4633780717849731, 1.4704198837280273, 1.4412717819213867, 1.4517438411712646, 1.4399908781051636, 1.4333642721176147], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.17225000262260437, 0.19358333945274353, 0.19983333349227905, 0.21258333325386047, 0.22216667234897614, 0.23083333671092987, 0.23800000548362732, 0.2434999942779541, 0.2680833339691162, 0.2840833365917206, 0.2939999997615814, 0.3086666762828827, 0.29483333230018616, 0.32225000858306885, 0.3199999928474426, 0.3225833475589752, 0.31833332777023315, 0.3372499942779541, 0.34058332443237305, 0.3490000069141388, 0.3421666622161865, 0.3399166762828827, 0.3356666564941406, 0.3567500114440918, 0.3384166657924652, 0.3605833351612091, 0.3661666810512543, 0.3684166669845581, 0.37424999475479126, 0.3674166798591614, 0.374833345413208, 0.37958332896232605, 0.3764166533946991, 0.3789166808128357, 0.3817499876022339, 0.35891667008399963, 0.37275001406669617, 0.3687500059604645, 0.37416666746139526, 0.3792499899864197, 0.38341665267944336, 0.39366665482521057, 0.38591668009757996, 0.3882499933242798, 0.38358333706855774]}\n",
            "{'loss': [2.3069510459899902, 2.3010802268981934, 2.298065423965454, 2.291323661804199, 2.255887985229492, 2.166825294494629, 2.0696511268615723, 1.938034176826477, 1.805351734161377, 1.687813639640808, 1.5945338010787964, 1.5299726724624634, 1.4743032455444336, 1.4248411655426025, 1.3860571384429932, 1.3470580577850342, 1.321763038635254, 1.2882633209228516, 1.2657389640808105, 1.2388219833374023, 1.2148531675338745, 1.1929219961166382, 1.173231601715088, 1.146390438079834, 1.1343451738357544, 1.1035507917404175, 1.0753509998321533, 1.0601210594177246, 1.033236026763916, 1.0066875219345093, 0.97841876745224, 0.9517884254455566, 0.9253373742103577, 0.8946230411529541, 0.8629243969917297, 0.8403640389442444, 0.804651141166687, 0.7941041588783264, 0.7626636028289795, 0.7451177835464478, 0.7245126366615295, 0.7029454112052917, 0.6885644793510437, 0.6854161620140076, 0.66164231300354, 0.6490313410758972, 0.6268269419670105, 0.6122857928276062, 0.6011350154876709, 0.587111234664917], 'accuracy': [0.10318750143051147, 0.11952083557844162, 0.12341666966676712, 0.12991666793823242, 0.16310416162014008, 0.19568750262260437, 0.21929167211055756, 0.25562500953674316, 0.29758334159851074, 0.3347083330154419, 0.375041663646698, 0.3996874988079071, 0.42112499475479126, 0.437541663646698, 0.4504583477973938, 0.46318748593330383, 0.4741874933242798, 0.4857083261013031, 0.4973541796207428, 0.5101875066757202, 0.5180416703224182, 0.5270416736602783, 0.5410416722297668, 0.5534166693687439, 0.5644791722297668, 0.5766041874885559, 0.590624988079071, 0.6015625, 0.6107708215713501, 0.6240208148956299, 0.6398125290870667, 0.6517916917800903, 0.6691041588783264, 0.6845625042915344, 0.7069166898727417, 0.7237708568572998, 0.7378749847412109, 0.7485833168029785, 0.7590625286102295, 0.7679791450500488, 0.7762500047683716, 0.7828541398048401, 0.7926874756813049, 0.7962916493415833, 0.8004375100135803, 0.8069375157356262, 0.8132291436195374, 0.8198333382606506, 0.8243541717529297, 0.8298125267028809], 'val_loss': [2.301537036895752, 2.300607681274414, 2.297245979309082, 2.2765049934387207, 2.164191961288452, 2.0162715911865234, 1.8449363708496094, 1.644160509109497, 1.4986484050750732, 1.4077982902526855, 1.3376716375350952, 1.2860515117645264, 1.241795539855957, 1.202000617980957, 1.1725436449050903, 1.143235445022583, 1.1234886646270752, 1.098299264907837, 1.0736867189407349, 1.060612440109253, 1.036415696144104, 1.018717885017395, 1.0044777393341064, 0.9839361310005188, 0.9630581736564636, 0.938694179058075, 0.920554518699646, 0.8940211534500122, 0.8688098192214966, 0.8385613560676575, 0.8110779523849487, 0.7882817983627319, 0.7532545328140259, 0.7259519100189209, 0.7013438940048218, 0.6596261858940125, 0.6536204218864441, 0.6385670304298401, 0.6281260848045349, 0.6051831841468811, 0.6127090454101562, 0.6058189868927002, 0.577065646648407, 0.5914912819862366, 0.562200665473938, 0.553891658782959, 0.5685879588127136, 0.5714874863624573, 0.5603926181793213, 0.5402888059616089], 'val_accuracy': [0.10616666823625565, 0.10599999874830246, 0.10599999874830246, 0.14808332920074463, 0.22824999690055847, 0.2514166533946991, 0.2966666519641876, 0.3385833203792572, 0.37299999594688416, 0.42491665482521057, 0.48116666078567505, 0.5090833306312561, 0.5609999895095825, 0.5741666555404663, 0.5874166488647461, 0.57791668176651, 0.5890833139419556, 0.6037499904632568, 0.6210833191871643, 0.6027500033378601, 0.6307500004768372, 0.6351666450500488, 0.6517500281333923, 0.6631666421890259, 0.6744999885559082, 0.6848333477973938, 0.7019166946411133, 0.7083333134651184, 0.7316666841506958, 0.7423333525657654, 0.7421666383743286, 0.7580000162124634, 0.762583315372467, 0.7864999771118164, 0.8299999833106995, 0.8523333072662354, 0.8673333525657654, 0.8661666512489319, 0.8633333444595337, 0.8742499947547913, 0.871999979019165, 0.8822500109672546, 0.8807500004768372, 0.878250002861023, 0.8834166526794434, 0.8895000219345093, 0.8934999704360962, 0.8675000071525574, 0.887583315372467, 0.8970833420753479]}\n",
            "{'loss': [2.2552859783172607, 1.8223835229873657, 1.541797399520874, 1.334810495376587, 1.1932764053344727, 1.1105788946151733, 1.0433411598205566, 0.9910091757774353, 0.9524720311164856, 0.9232547283172607, 0.8879533410072327, 0.8705759048461914, 0.8437439799308777, 0.8248444199562073, 0.8093600869178772, 0.7911125421524048, 0.772696852684021, 0.7567726969718933, 0.7449819445610046, 0.7270241975784302, 0.7164708375930786, 0.7131111025810242, 0.6911494731903076, 0.6805238723754883, 0.670510470867157, 0.6517221927642822, 0.6458293199539185, 0.636389434337616, 0.6244903206825256, 0.6152104735374451, 0.6026929616928101, 0.6037477850914001, 0.5800713896751404, 0.5787904262542725, 0.5680655241012573, 0.5526006817817688, 0.5447595715522766, 0.54360431432724, 0.5335150361061096, 0.5235695242881775, 0.5166729688644409, 0.5142327547073364, 0.5058826804161072, 0.49286961555480957, 0.4919719099998474, 0.4805273115634918, 0.47986575961112976, 0.47252002358436584, 0.4700320363044739, 0.455309122800827], 'accuracy': [0.19200000166893005, 0.3476041555404663, 0.4585624933242798, 0.5363749861717224, 0.5872499942779541, 0.6230833530426025, 0.6523125171661377, 0.6732916831970215, 0.6901458501815796, 0.7010833621025085, 0.718791663646698, 0.7224583625793457, 0.73416668176651, 0.7402291893959045, 0.7473958134651184, 0.7566666603088379, 0.7606666684150696, 0.770520806312561, 0.7734375, 0.7807083129882812, 0.7851250171661377, 0.788770854473114, 0.7970625162124634, 0.8026666641235352, 0.8053958415985107, 0.8126875162124634, 0.8164374828338623, 0.8214374780654907, 0.8241249918937683, 0.8310624957084656, 0.8347291946411133, 0.8354583382606506, 0.840749979019165, 0.8440625071525574, 0.8480208516120911, 0.8525416851043701, 0.854854166507721, 0.8555833101272583, 0.8620416522026062, 0.8617291450500488, 0.866854190826416, 0.8675000071525574, 0.8709999918937683, 0.8743125200271606, 0.8756250143051147, 0.8780208230018616, 0.8777916431427002, 0.8808125257492065, 0.8819166421890259, 0.8855208158493042], 'val_loss': [1.4924451112747192, 1.071329951286316, 0.805566668510437, 0.6733048558235168, 0.6028836965560913, 0.5687859058380127, 0.5346943140029907, 0.5151020288467407, 0.49847444891929626, 0.4895997643470764, 0.4716399312019348, 0.4674791991710663, 0.45843395590782166, 0.44642719626426697, 0.43895161151885986, 0.42969316244125366, 0.42902055382728577, 0.4139174520969391, 0.41151419281959534, 0.40361160039901733, 0.39542892575263977, 0.38751620054244995, 0.3749282956123352, 0.3748665750026703, 0.3596571087837219, 0.35375750064849854, 0.3478114902973175, 0.3384438157081604, 0.33309438824653625, 0.32562196254730225, 0.3181450068950653, 0.30556514859199524, 0.3053337335586548, 0.30019161105155945, 0.29902830719947815, 0.29281920194625854, 0.2894057333469391, 0.2828373908996582, 0.2779029607772827, 0.2751733064651489, 0.2801748812198639, 0.26652219891548157, 0.26902294158935547, 0.26766493916511536, 0.2609969973564148, 0.2679567039012909, 0.2627100944519043, 0.25232669711112976, 0.257223516702652, 0.2563599646091461], 'val_accuracy': [0.5889999866485596, 0.6865833401679993, 0.7389166951179504, 0.7911666631698608, 0.8149166703224182, 0.8299166560173035, 0.8258333206176758, 0.8462499976158142, 0.8402500152587891, 0.8402500152587891, 0.8480833172798157, 0.8515833616256714, 0.8568333387374878, 0.8582500219345093, 0.8511666655540466, 0.8637499809265137, 0.859333336353302, 0.8704166412353516, 0.8868333101272583, 0.8862500190734863, 0.893750011920929, 0.8856666684150696, 0.8961666822433472, 0.9050833582878113, 0.9075833559036255, 0.909416675567627, 0.9101666808128357, 0.9158333539962769, 0.9175833463668823, 0.9185000061988831, 0.921916663646698, 0.9236666560173035, 0.925166666507721, 0.9256666898727417, 0.9247499704360962, 0.9253333210945129, 0.9300000071525574, 0.9300833344459534, 0.9320833086967468, 0.9309999942779541, 0.9310833215713501, 0.9340000152587891, 0.934333324432373, 0.9336666464805603, 0.9364166855812073, 0.9358333349227905, 0.9369999766349792, 0.9402499794960022, 0.9403333067893982, 0.9394999742507935]}\n",
            "{'loss': [2.6195108890533447, 1.6969736814498901, 1.4447872638702393, 1.3185149431228638, 1.2283998727798462, 1.1627277135849, 1.103940486907959, 1.06194269657135, 1.0270551443099976, 1.0007179975509644, 0.9761236906051636, 0.9486920833587646, 0.9307659268379211, 0.9047510623931885, 0.8943732380867004, 0.8721286058425903, 0.8589372634887695, 0.8377523422241211, 0.8338339924812317, 0.8119021654129028, 0.798490047454834, 0.7889010310173035, 0.7723796367645264, 0.7623589038848877, 0.7479963898658752, 0.738569974899292, 0.7221096158027649, 0.7148767113685608, 0.7098322510719299, 0.6889303922653198, 0.684986412525177, 0.6768528819084167, 0.6750682592391968, 0.6615564227104187, 0.6483284831047058, 0.646184504032135, 0.6312221884727478, 0.6276007890701294, 0.6162711381912231, 0.6123348474502563, 0.6083390116691589, 0.603819727897644, 0.5996337532997131, 0.5931826829910278, 0.5804339051246643, 0.5801972150802612, 0.5754504203796387, 0.5599353313446045, 0.561937689781189, 0.5570202469825745], 'accuracy': [0.20235416293144226, 0.3816874921321869, 0.46693751215934753, 0.5145000219345093, 0.5540833473205566, 0.5849791765213013, 0.6103958487510681, 0.628125011920929, 0.6423749923706055, 0.6498333215713501, 0.659250020980835, 0.6681041717529297, 0.6777916550636292, 0.6911666393280029, 0.6955416798591614, 0.7048333287239075, 0.7113749980926514, 0.7203541398048401, 0.7240625023841858, 0.7291250228881836, 0.7385833263397217, 0.7430833578109741, 0.746916651725769, 0.7517499923706055, 0.7573958039283752, 0.7611666917800903, 0.7643125057220459, 0.7697499990463257, 0.770354151725769, 0.7739791870117188, 0.778208315372467, 0.7788749933242798, 0.7825624942779541, 0.7841249704360962, 0.7901666760444641, 0.7893333435058594, 0.7943541407585144, 0.7947708368301392, 0.797041654586792, 0.7990208268165588, 0.801437497138977, 0.8010625243186951, 0.8022916913032532, 0.8061249852180481, 0.807937502861023, 0.8083541393280029, 0.8100833296775818, 0.8145833611488342, 0.8144999742507935, 0.8133541941642761], 'val_loss': [1.2561140060424805, 1.0647011995315552, 0.9551384449005127, 0.8722789883613586, 0.7781891822814941, 0.7274919152259827, 0.7072208523750305, 0.6946207880973816, 0.6743460893630981, 0.6535005569458008, 0.6336830854415894, 0.623491108417511, 0.6116158366203308, 0.5908918380737305, 0.5844931602478027, 0.5657713413238525, 0.5534364581108093, 0.5416849255561829, 0.5353201627731323, 0.5260623097419739, 0.5221053957939148, 0.5120737552642822, 0.50107342004776, 0.4952828288078308, 0.49371686577796936, 0.48981934785842896, 0.48271045088768005, 0.4774465262889862, 0.4620821475982666, 0.4681588411331177, 0.46096932888031006, 0.4544280171394348, 0.44355687499046326, 0.4393896460533142, 0.4429447054862976, 0.44026562571525574, 0.4354751408100128, 0.43486443161964417, 0.43633702397346497, 0.42347246408462524, 0.4246773421764374, 0.42658573389053345, 0.4232317805290222, 0.4202759563922882, 0.4181324541568756, 0.41412922739982605, 0.4169272184371948, 0.413493275642395, 0.4128267467021942, 0.4120182693004608], 'val_accuracy': [0.6001666784286499, 0.6200833320617676, 0.668833315372467, 0.6818333268165588, 0.7235833406448364, 0.7338333129882812, 0.7367500066757202, 0.7301666736602783, 0.7513333559036255, 0.7707499861717224, 0.7784166932106018, 0.7816666960716248, 0.7855833172798157, 0.7954999804496765, 0.7979166507720947, 0.8037499785423279, 0.8079166412353516, 0.8114166855812073, 0.8198333382606506, 0.8134999871253967, 0.8103333115577698, 0.8138333559036255, 0.8168333172798157, 0.8351666927337646, 0.8216666579246521, 0.8242499828338623, 0.8259166479110718, 0.8239166736602783, 0.828416645526886, 0.8288333415985107, 0.8274166584014893, 0.8319166898727417, 0.8338333368301392, 0.8357499837875366, 0.8355833292007446, 0.8352500200271606, 0.8393333554267883, 0.8364999890327454, 0.8377500176429749, 0.8399166464805603, 0.8409166932106018, 0.8395000100135803, 0.8429166674613953, 0.8420833349227905, 0.8426666855812073, 0.8457499742507935, 0.8415833115577698, 0.8456666469573975, 0.8462499976158142, 0.847000002861023]}\n",
            "{'loss': [2.3019700050354004, 2.301281452178955, 2.301074266433716, 2.3009021282196045, 2.3009727001190186, 2.3008930683135986, 2.3008124828338623, 2.3008182048797607, 2.300795793533325, 2.3007020950317383, 2.3006513118743896, 2.300645351409912, 2.3006701469421387, 2.3005661964416504, 2.3005595207214355, 2.300506591796875, 2.3004050254821777, 2.300382375717163, 2.3004233837127686, 2.300245523452759, 2.3002073764801025, 2.300161838531494, 2.3001301288604736, 2.3000659942626953, 2.3000173568725586, 2.299893617630005, 2.299752712249756, 2.2996532917022705, 2.299564838409424, 2.2993087768554688, 2.299159526824951, 2.298976182937622, 2.2984507083892822, 2.2979609966278076, 2.297030210494995, 2.2944583892822266, 2.2621397972106934, 2.1854441165924072, 2.1327741146087646, 2.102673292160034, 2.082223653793335, 2.0641205310821533, 2.038482189178467, 1.9900355339050293, 1.9249534606933594, 1.8660120964050293, 1.816865086555481, 1.767530918121338, 1.727975606918335, 1.6744598150253296], 'accuracy': [0.1158749982714653, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11397916823625565, 0.11395833641290665, 0.11402083188295364, 0.11397916823625565, 0.11429166793823242, 0.11502083390951157, 0.11687500029802322, 0.1263333261013031, 0.16856250166893005, 0.1875, 0.19306249916553497, 0.19491666555404663, 0.20341666042804718, 0.21031250059604645, 0.22574999928474426, 0.2525416612625122, 0.28187501430511475, 0.30368751287460327, 0.32064583897590637, 0.3420833349227905, 0.35333332419395447, 0.3686458468437195], 'val_loss': [2.301893472671509, 2.30179500579834, 2.301790714263916, 2.3018136024475098, 2.301807165145874, 2.301807165145874, 2.301788091659546, 2.301778554916382, 2.301765203475952, 2.3017730712890625, 2.301743507385254, 2.301693916320801, 2.301647901535034, 2.3015999794006348, 2.301586151123047, 2.3015148639678955, 2.301500082015991, 2.3014442920684814, 2.3013861179351807, 2.3013672828674316, 2.3012914657592773, 2.3012547492980957, 2.3011693954467773, 2.3010518550872803, 2.300954818725586, 2.3008501529693604, 2.300776243209839, 2.300666093826294, 2.3004844188690186, 2.3003127574920654, 2.300069570541382, 2.299809455871582, 2.2993950843811035, 2.2987935543060303, 2.2975423336029053, 2.2928993701934814, 2.1813130378723145, 2.1073801517486572, 2.0732109546661377, 2.0541117191314697, 2.0387520790100098, 2.0215723514556885, 1.9782272577285767, 1.8839497566223145, 1.7936687469482422, 1.7440022230148315, 1.6934685707092285, 1.6445668935775757, 1.589030146598816, 1.5252280235290527], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.13066667318344116, 0.1965000033378601, 0.19499999284744263, 0.19641666114330292, 0.19966666400432587, 0.20258332788944244, 0.21158333122730255, 0.23641666769981384, 0.3004166781902313, 0.3412500023841858, 0.3557499945163727, 0.40700000524520874, 0.43441668152809143, 0.4480000138282776, 0.461083322763443]}\n",
            "{'loss': [2.3020174503326416, 2.3013808727264404, 2.301131010055542, 2.3010404109954834, 2.301053285598755, 2.3009984493255615, 2.3010241985321045, 2.3010241985321045, 2.3009088039398193, 2.3009979724884033, 2.3009352684020996, 2.3009190559387207, 2.300894260406494, 2.3008012771606445, 2.300872564315796, 2.3008463382720947, 2.3008553981781006, 2.3008055686950684, 2.300762891769409, 2.3007588386535645, 2.3007779121398926, 2.300774574279785, 2.3007426261901855, 2.3007395267486572, 2.3006746768951416, 2.3006486892700195, 2.300661087036133, 2.300645589828491, 2.300654172897339, 2.3005757331848145, 2.3005309104919434, 2.3005480766296387, 2.300523281097412, 2.3005311489105225, 2.300492763519287, 2.300482988357544, 2.300410270690918, 2.3003897666931152, 2.300398826599121, 2.3003249168395996, 2.300304412841797, 2.3002896308898926, 2.300276756286621, 2.3002383708953857, 2.3001506328582764, 2.300091505050659, 2.3001010417938232, 2.299990177154541, 2.299926519393921, 2.29988431930542], 'accuracy': [0.11402083188295364, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.301920175552368, 2.3018476963043213, 2.301875591278076, 2.3019113540649414, 2.301953077316284, 2.3019795417785645, 2.3019602298736572, 2.30196213722229, 2.301964282989502, 2.301940679550171, 2.301952838897705, 2.301926374435425, 2.301924467086792, 2.3019206523895264, 2.3019301891326904, 2.301908254623413, 2.3018782138824463, 2.301875591278076, 2.3018693923950195, 2.301845073699951, 2.3018243312835693, 2.3018152713775635, 2.3018012046813965, 2.3017499446868896, 2.3017170429229736, 2.3017189502716064, 2.301720380783081, 2.301680564880371, 2.3016836643218994, 2.3016693592071533, 2.3016278743743896, 2.30163311958313, 2.3016247749328613, 2.3015758991241455, 2.3015658855438232, 2.3015267848968506, 2.301513671875, 2.3014461994171143, 2.301438093185425, 2.301379442214966, 2.3013556003570557, 2.3013381958007812, 2.3013052940368652, 2.3012635707855225, 2.3011996746063232, 2.301166296005249, 2.301121711730957, 2.301063299179077, 2.3009681701660156, 2.3008856773376465], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}