{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "2edbc5e7-1d61-420c-f4e4-ec3d2f4a39a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 17s 5ms/step - loss: 1.6270 - accuracy: 0.4548 - val_loss: 0.5760 - val_accuracy: 0.8493\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7103 - accuracy: 0.7840 - val_loss: 0.4491 - val_accuracy: 0.8733\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5758 - accuracy: 0.8275 - val_loss: 0.4027 - val_accuracy: 0.8808\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5226 - accuracy: 0.8408 - val_loss: 0.3766 - val_accuracy: 0.8878\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.8513 - val_loss: 0.3613 - val_accuracy: 0.8915\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4652 - accuracy: 0.8602 - val_loss: 0.3502 - val_accuracy: 0.8950\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4416 - accuracy: 0.8672 - val_loss: 0.3411 - val_accuracy: 0.8990\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.8675 - val_loss: 0.3341 - val_accuracy: 0.9009\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8707 - val_loss: 0.3284 - val_accuracy: 0.9032\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - accuracy: 0.8751 - val_loss: 0.3247 - val_accuracy: 0.9032\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.8778 - val_loss: 0.3201 - val_accuracy: 0.9056\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - accuracy: 0.8782 - val_loss: 0.3167 - val_accuracy: 0.9057\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3927 - accuracy: 0.8814 - val_loss: 0.3133 - val_accuracy: 0.9073\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3851 - accuracy: 0.8845 - val_loss: 0.3114 - val_accuracy: 0.9069\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3828 - accuracy: 0.8831 - val_loss: 0.3083 - val_accuracy: 0.9093\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3792 - accuracy: 0.8858 - val_loss: 0.3062 - val_accuracy: 0.9099\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8845 - val_loss: 0.3045 - val_accuracy: 0.9099\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8890 - val_loss: 0.3010 - val_accuracy: 0.9122\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3624 - accuracy: 0.8899 - val_loss: 0.3009 - val_accuracy: 0.9115\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.8935 - val_loss: 0.2978 - val_accuracy: 0.9128\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3585 - accuracy: 0.8907 - val_loss: 0.2956 - val_accuracy: 0.9128\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3535 - accuracy: 0.8937 - val_loss: 0.2943 - val_accuracy: 0.9141\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3492 - accuracy: 0.8936 - val_loss: 0.2927 - val_accuracy: 0.9146\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8951 - val_loss: 0.2905 - val_accuracy: 0.9151\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3488 - accuracy: 0.8967 - val_loss: 0.2894 - val_accuracy: 0.9154\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8981 - val_loss: 0.2875 - val_accuracy: 0.9163\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.8971 - val_loss: 0.2858 - val_accuracy: 0.9161\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.9020 - val_loss: 0.2843 - val_accuracy: 0.9168\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.9001 - val_loss: 0.2835 - val_accuracy: 0.9163\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.9030 - val_loss: 0.2822 - val_accuracy: 0.9162\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3254 - accuracy: 0.9008 - val_loss: 0.2807 - val_accuracy: 0.9168\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.9028 - val_loss: 0.2807 - val_accuracy: 0.9177\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3130 - accuracy: 0.9043 - val_loss: 0.2785 - val_accuracy: 0.9188\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.9065 - val_loss: 0.2775 - val_accuracy: 0.9197\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3199 - accuracy: 0.9033 - val_loss: 0.2764 - val_accuracy: 0.9188\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3107 - accuracy: 0.9048 - val_loss: 0.2750 - val_accuracy: 0.9199\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3108 - accuracy: 0.9053 - val_loss: 0.2737 - val_accuracy: 0.9193\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3145 - accuracy: 0.9046 - val_loss: 0.2736 - val_accuracy: 0.9197\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3091 - accuracy: 0.9049 - val_loss: 0.2712 - val_accuracy: 0.9204\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2998 - accuracy: 0.9064 - val_loss: 0.2708 - val_accuracy: 0.9206\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3052 - accuracy: 0.9058 - val_loss: 0.2696 - val_accuracy: 0.9215\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3036 - accuracy: 0.9084 - val_loss: 0.2675 - val_accuracy: 0.9224\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3062 - accuracy: 0.9066 - val_loss: 0.2664 - val_accuracy: 0.9231\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.9086 - val_loss: 0.2657 - val_accuracy: 0.9233\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2966 - accuracy: 0.9103 - val_loss: 0.2638 - val_accuracy: 0.9237\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.9086 - val_loss: 0.2633 - val_accuracy: 0.9234\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2907 - accuracy: 0.9111 - val_loss: 0.2623 - val_accuracy: 0.9237\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.9103 - val_loss: 0.2607 - val_accuracy: 0.9244\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2899 - accuracy: 0.9126 - val_loss: 0.2604 - val_accuracy: 0.9239\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2882 - accuracy: 0.9123 - val_loss: 0.2589 - val_accuracy: 0.9247\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 4ms/step - loss: 1.9784 - accuracy: 0.3006 - val_loss: 0.8216 - val_accuracy: 0.8150\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9915 - accuracy: 0.6801 - val_loss: 0.5385 - val_accuracy: 0.8620\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7618 - accuracy: 0.7584 - val_loss: 0.4422 - val_accuracy: 0.8808\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6485 - accuracy: 0.8007 - val_loss: 0.3927 - val_accuracy: 0.8903\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5802 - accuracy: 0.8218 - val_loss: 0.3630 - val_accuracy: 0.8952\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5286 - accuracy: 0.8383 - val_loss: 0.3393 - val_accuracy: 0.9017\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4916 - accuracy: 0.8495 - val_loss: 0.3240 - val_accuracy: 0.9053\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4687 - accuracy: 0.8598 - val_loss: 0.3104 - val_accuracy: 0.9082\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.8656 - val_loss: 0.2961 - val_accuracy: 0.9129\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4176 - accuracy: 0.8755 - val_loss: 0.2860 - val_accuracy: 0.9153\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4060 - accuracy: 0.8798 - val_loss: 0.2779 - val_accuracy: 0.9168\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3917 - accuracy: 0.8825 - val_loss: 0.2674 - val_accuracy: 0.9206\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8871 - val_loss: 0.2616 - val_accuracy: 0.9209\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3701 - accuracy: 0.8908 - val_loss: 0.2536 - val_accuracy: 0.9244\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3518 - accuracy: 0.8973 - val_loss: 0.2477 - val_accuracy: 0.9258\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3451 - accuracy: 0.8970 - val_loss: 0.2416 - val_accuracy: 0.9271\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3322 - accuracy: 0.9021 - val_loss: 0.2358 - val_accuracy: 0.9299\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.9056 - val_loss: 0.2309 - val_accuracy: 0.9313\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3220 - accuracy: 0.9050 - val_loss: 0.2259 - val_accuracy: 0.9323\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2993 - accuracy: 0.9114 - val_loss: 0.2216 - val_accuracy: 0.9341\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2997 - accuracy: 0.9112 - val_loss: 0.2174 - val_accuracy: 0.9355\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2982 - accuracy: 0.9115 - val_loss: 0.2131 - val_accuracy: 0.9367\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2913 - accuracy: 0.9134 - val_loss: 0.2093 - val_accuracy: 0.9380\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2692 - accuracy: 0.9206 - val_loss: 0.2058 - val_accuracy: 0.9388\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2704 - accuracy: 0.9181 - val_loss: 0.2027 - val_accuracy: 0.9402\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.9211 - val_loss: 0.1999 - val_accuracy: 0.9404\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2567 - accuracy: 0.9228 - val_loss: 0.1959 - val_accuracy: 0.9402\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2572 - accuracy: 0.9228 - val_loss: 0.1936 - val_accuracy: 0.9411\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.9243 - val_loss: 0.1903 - val_accuracy: 0.9421\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2418 - accuracy: 0.9283 - val_loss: 0.1873 - val_accuracy: 0.9432\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2404 - accuracy: 0.9293 - val_loss: 0.1856 - val_accuracy: 0.9431\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2311 - accuracy: 0.9320 - val_loss: 0.1831 - val_accuracy: 0.9441\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2299 - accuracy: 0.9314 - val_loss: 0.1811 - val_accuracy: 0.9451\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2258 - accuracy: 0.9327 - val_loss: 0.1788 - val_accuracy: 0.9451\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2250 - accuracy: 0.9317 - val_loss: 0.1770 - val_accuracy: 0.9454\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2178 - accuracy: 0.9345 - val_loss: 0.1736 - val_accuracy: 0.9476\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.9375 - val_loss: 0.1725 - val_accuracy: 0.9478\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9371 - val_loss: 0.1714 - val_accuracy: 0.9482\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9396 - val_loss: 0.1685 - val_accuracy: 0.9491\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2069 - accuracy: 0.9390 - val_loss: 0.1682 - val_accuracy: 0.9494\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1997 - accuracy: 0.9391 - val_loss: 0.1650 - val_accuracy: 0.9503\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1975 - accuracy: 0.9414 - val_loss: 0.1644 - val_accuracy: 0.9507\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1914 - accuracy: 0.9430 - val_loss: 0.1625 - val_accuracy: 0.9508\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1878 - accuracy: 0.9437 - val_loss: 0.1609 - val_accuracy: 0.9514\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1865 - accuracy: 0.9438 - val_loss: 0.1601 - val_accuracy: 0.9519\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1753 - accuracy: 0.9480 - val_loss: 0.1589 - val_accuracy: 0.9523\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1762 - accuracy: 0.9477 - val_loss: 0.1563 - val_accuracy: 0.9527\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1757 - accuracy: 0.9463 - val_loss: 0.1554 - val_accuracy: 0.9528\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1727 - accuracy: 0.9471 - val_loss: 0.1543 - val_accuracy: 0.9534\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1707 - accuracy: 0.9489 - val_loss: 0.1531 - val_accuracy: 0.9535\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8489 - accuracy: 0.3698 - val_loss: 0.7452 - val_accuracy: 0.8257\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8849 - accuracy: 0.7230 - val_loss: 0.5056 - val_accuracy: 0.8677\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6793 - accuracy: 0.7883 - val_loss: 0.4295 - val_accuracy: 0.8839\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5927 - accuracy: 0.8197 - val_loss: 0.3889 - val_accuracy: 0.8917\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.8401 - val_loss: 0.3638 - val_accuracy: 0.8972\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5033 - accuracy: 0.8481 - val_loss: 0.3447 - val_accuracy: 0.9011\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4736 - accuracy: 0.8591 - val_loss: 0.3317 - val_accuracy: 0.9041\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4459 - accuracy: 0.8670 - val_loss: 0.3194 - val_accuracy: 0.9068\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4282 - accuracy: 0.8728 - val_loss: 0.3099 - val_accuracy: 0.9086\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4192 - accuracy: 0.8752 - val_loss: 0.3015 - val_accuracy: 0.9125\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4028 - accuracy: 0.8802 - val_loss: 0.2940 - val_accuracy: 0.9143\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3950 - accuracy: 0.8842 - val_loss: 0.2864 - val_accuracy: 0.9164\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3803 - accuracy: 0.8861 - val_loss: 0.2805 - val_accuracy: 0.9170\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8898 - val_loss: 0.2746 - val_accuracy: 0.9188\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3646 - accuracy: 0.8900 - val_loss: 0.2683 - val_accuracy: 0.9212\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3467 - accuracy: 0.8984 - val_loss: 0.2633 - val_accuracy: 0.9222\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8971 - val_loss: 0.2591 - val_accuracy: 0.9245\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8992 - val_loss: 0.2536 - val_accuracy: 0.9257\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.9025 - val_loss: 0.2509 - val_accuracy: 0.9268\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.9039 - val_loss: 0.2457 - val_accuracy: 0.9286\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3086 - accuracy: 0.9072 - val_loss: 0.2418 - val_accuracy: 0.9294\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3037 - accuracy: 0.9091 - val_loss: 0.2380 - val_accuracy: 0.9304\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3022 - accuracy: 0.9090 - val_loss: 0.2348 - val_accuracy: 0.9312\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2930 - accuracy: 0.9109 - val_loss: 0.2315 - val_accuracy: 0.9327\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2876 - accuracy: 0.9126 - val_loss: 0.2278 - val_accuracy: 0.9335\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2809 - accuracy: 0.9164 - val_loss: 0.2256 - val_accuracy: 0.9343\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.9141 - val_loss: 0.2227 - val_accuracy: 0.9346\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2804 - accuracy: 0.9141 - val_loss: 0.2200 - val_accuracy: 0.9357\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2716 - accuracy: 0.9168 - val_loss: 0.2165 - val_accuracy: 0.9363\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2720 - accuracy: 0.9187 - val_loss: 0.2144 - val_accuracy: 0.9366\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2607 - accuracy: 0.9221 - val_loss: 0.2115 - val_accuracy: 0.9372\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.9240 - val_loss: 0.2097 - val_accuracy: 0.9383\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2513 - accuracy: 0.9239 - val_loss: 0.2074 - val_accuracy: 0.9388\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2500 - accuracy: 0.9261 - val_loss: 0.2049 - val_accuracy: 0.9407\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2432 - accuracy: 0.9257 - val_loss: 0.2028 - val_accuracy: 0.9402\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2398 - accuracy: 0.9281 - val_loss: 0.2005 - val_accuracy: 0.9407\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2428 - accuracy: 0.9262 - val_loss: 0.1983 - val_accuracy: 0.9416\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2382 - accuracy: 0.9299 - val_loss: 0.1964 - val_accuracy: 0.9418\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2308 - accuracy: 0.9328 - val_loss: 0.1951 - val_accuracy: 0.9423\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2267 - accuracy: 0.9315 - val_loss: 0.1930 - val_accuracy: 0.9425\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2264 - accuracy: 0.9298 - val_loss: 0.1912 - val_accuracy: 0.9435\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2225 - accuracy: 0.9311 - val_loss: 0.1889 - val_accuracy: 0.9439\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2179 - accuracy: 0.9340 - val_loss: 0.1874 - val_accuracy: 0.9433\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2141 - accuracy: 0.9362 - val_loss: 0.1858 - val_accuracy: 0.9446\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9369 - val_loss: 0.1843 - val_accuracy: 0.9445\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9353 - val_loss: 0.1826 - val_accuracy: 0.9450\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2033 - accuracy: 0.9381 - val_loss: 0.1810 - val_accuracy: 0.9452\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9353 - val_loss: 0.1807 - val_accuracy: 0.9452\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2082 - accuracy: 0.9388 - val_loss: 0.1784 - val_accuracy: 0.9466\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9415 - val_loss: 0.1770 - val_accuracy: 0.9467\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5450 - accuracy: 0.4839 - val_loss: 0.5443 - val_accuracy: 0.8553\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6886 - accuracy: 0.7830 - val_loss: 0.4320 - val_accuracy: 0.8780\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5748 - accuracy: 0.8245 - val_loss: 0.3912 - val_accuracy: 0.8863\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5129 - accuracy: 0.8414 - val_loss: 0.3687 - val_accuracy: 0.8928\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4935 - accuracy: 0.8519 - val_loss: 0.3553 - val_accuracy: 0.8957\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4635 - accuracy: 0.8600 - val_loss: 0.3453 - val_accuracy: 0.8989\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.8662 - val_loss: 0.3373 - val_accuracy: 0.9014\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4238 - accuracy: 0.8718 - val_loss: 0.3288 - val_accuracy: 0.9032\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4172 - accuracy: 0.8733 - val_loss: 0.3238 - val_accuracy: 0.9051\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4150 - accuracy: 0.8756 - val_loss: 0.3180 - val_accuracy: 0.9060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4111 - accuracy: 0.8766 - val_loss: 0.3124 - val_accuracy: 0.9083\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3894 - accuracy: 0.8821 - val_loss: 0.3096 - val_accuracy: 0.9082\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3898 - accuracy: 0.8807 - val_loss: 0.3061 - val_accuracy: 0.9096\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3823 - accuracy: 0.8819 - val_loss: 0.3017 - val_accuracy: 0.9112\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3719 - accuracy: 0.8860 - val_loss: 0.2991 - val_accuracy: 0.9114\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3687 - accuracy: 0.8903 - val_loss: 0.2955 - val_accuracy: 0.9126\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3600 - accuracy: 0.8916 - val_loss: 0.2937 - val_accuracy: 0.9136\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8942 - val_loss: 0.2891 - val_accuracy: 0.9153\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3573 - accuracy: 0.8925 - val_loss: 0.2867 - val_accuracy: 0.9159\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.8965 - val_loss: 0.2831 - val_accuracy: 0.9185\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3459 - accuracy: 0.8939 - val_loss: 0.2815 - val_accuracy: 0.9179\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8939 - val_loss: 0.2791 - val_accuracy: 0.9194\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3354 - accuracy: 0.8987 - val_loss: 0.2763 - val_accuracy: 0.9193\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3354 - accuracy: 0.8983 - val_loss: 0.2738 - val_accuracy: 0.9205\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.9046 - val_loss: 0.2720 - val_accuracy: 0.9213\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3213 - accuracy: 0.9034 - val_loss: 0.2697 - val_accuracy: 0.9217\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3188 - accuracy: 0.9025 - val_loss: 0.2673 - val_accuracy: 0.9230\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.9040 - val_loss: 0.2661 - val_accuracy: 0.9237\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.9006 - val_loss: 0.2626 - val_accuracy: 0.9243\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3128 - accuracy: 0.9048 - val_loss: 0.2616 - val_accuracy: 0.9241\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.9025 - val_loss: 0.2582 - val_accuracy: 0.9249\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3102 - accuracy: 0.9032 - val_loss: 0.2566 - val_accuracy: 0.9273\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3121 - accuracy: 0.9041 - val_loss: 0.2539 - val_accuracy: 0.9265\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.9091 - val_loss: 0.2517 - val_accuracy: 0.9268\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2929 - accuracy: 0.9101 - val_loss: 0.2496 - val_accuracy: 0.9279\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2943 - accuracy: 0.9105 - val_loss: 0.2485 - val_accuracy: 0.9284\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2836 - accuracy: 0.9127 - val_loss: 0.2464 - val_accuracy: 0.9292\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.9108 - val_loss: 0.2443 - val_accuracy: 0.9290\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.9113 - val_loss: 0.2421 - val_accuracy: 0.9302\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2824 - accuracy: 0.9130 - val_loss: 0.2412 - val_accuracy: 0.9298\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.9118 - val_loss: 0.2401 - val_accuracy: 0.9300\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2736 - accuracy: 0.9180 - val_loss: 0.2379 - val_accuracy: 0.9306\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2748 - accuracy: 0.9147 - val_loss: 0.2359 - val_accuracy: 0.9317\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2777 - accuracy: 0.9159 - val_loss: 0.2341 - val_accuracy: 0.9319\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9152 - val_loss: 0.2319 - val_accuracy: 0.9323\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.9175 - val_loss: 0.2304 - val_accuracy: 0.9327\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2679 - accuracy: 0.9175 - val_loss: 0.2298 - val_accuracy: 0.9328\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2591 - accuracy: 0.9196 - val_loss: 0.2275 - val_accuracy: 0.9333\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.9192 - val_loss: 0.2260 - val_accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2594 - accuracy: 0.9232 - val_loss: 0.2252 - val_accuracy: 0.9332\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4774 - accuracy: 0.5235 - val_loss: 0.4361 - val_accuracy: 0.8717\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6313 - accuracy: 0.7979 - val_loss: 0.3854 - val_accuracy: 0.8865\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5505 - accuracy: 0.8282 - val_loss: 0.3646 - val_accuracy: 0.8919\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5056 - accuracy: 0.8437 - val_loss: 0.3484 - val_accuracy: 0.8980\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4773 - accuracy: 0.8549 - val_loss: 0.3416 - val_accuracy: 0.9010\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4561 - accuracy: 0.8617 - val_loss: 0.3355 - val_accuracy: 0.9024\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8638 - val_loss: 0.3299 - val_accuracy: 0.9043\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4397 - accuracy: 0.8690 - val_loss: 0.3264 - val_accuracy: 0.9055\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4237 - accuracy: 0.8708 - val_loss: 0.3250 - val_accuracy: 0.9053\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4147 - accuracy: 0.8754 - val_loss: 0.3208 - val_accuracy: 0.9063\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4028 - accuracy: 0.8772 - val_loss: 0.3181 - val_accuracy: 0.9077\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - accuracy: 0.8772 - val_loss: 0.3164 - val_accuracy: 0.9089\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3925 - accuracy: 0.8795 - val_loss: 0.3140 - val_accuracy: 0.9094\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3870 - accuracy: 0.8832 - val_loss: 0.3122 - val_accuracy: 0.9097\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3829 - accuracy: 0.8837 - val_loss: 0.3101 - val_accuracy: 0.9095\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3830 - accuracy: 0.8863 - val_loss: 0.3095 - val_accuracy: 0.9108\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3781 - accuracy: 0.8872 - val_loss: 0.3092 - val_accuracy: 0.9097\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3696 - accuracy: 0.8892 - val_loss: 0.3056 - val_accuracy: 0.9111\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3707 - accuracy: 0.8875 - val_loss: 0.3048 - val_accuracy: 0.9122\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3663 - accuracy: 0.8896 - val_loss: 0.3026 - val_accuracy: 0.9128\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3638 - accuracy: 0.8903 - val_loss: 0.3011 - val_accuracy: 0.9131\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3568 - accuracy: 0.8933 - val_loss: 0.3002 - val_accuracy: 0.9137\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3522 - accuracy: 0.8929 - val_loss: 0.2988 - val_accuracy: 0.9140\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3527 - accuracy: 0.8933 - val_loss: 0.2979 - val_accuracy: 0.9137\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3507 - accuracy: 0.8947 - val_loss: 0.2972 - val_accuracy: 0.9137\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3461 - accuracy: 0.8943 - val_loss: 0.2956 - val_accuracy: 0.9153\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3421 - accuracy: 0.8987 - val_loss: 0.2940 - val_accuracy: 0.9156\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8973 - val_loss: 0.2929 - val_accuracy: 0.9153\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3355 - accuracy: 0.8998 - val_loss: 0.2912 - val_accuracy: 0.9162\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3440 - accuracy: 0.8938 - val_loss: 0.2901 - val_accuracy: 0.9159\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8985 - val_loss: 0.2888 - val_accuracy: 0.9167\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3357 - accuracy: 0.8997 - val_loss: 0.2869 - val_accuracy: 0.9179\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3237 - accuracy: 0.9031 - val_loss: 0.2870 - val_accuracy: 0.9173\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3240 - accuracy: 0.9029 - val_loss: 0.2847 - val_accuracy: 0.9179\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3227 - accuracy: 0.9020 - val_loss: 0.2836 - val_accuracy: 0.9185\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.9016 - val_loss: 0.2817 - val_accuracy: 0.9191\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.9027 - val_loss: 0.2816 - val_accuracy: 0.9197\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3221 - accuracy: 0.9017 - val_loss: 0.2804 - val_accuracy: 0.9190\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3168 - accuracy: 0.9044 - val_loss: 0.2800 - val_accuracy: 0.9194\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3102 - accuracy: 0.9061 - val_loss: 0.2779 - val_accuracy: 0.9195\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3264 - accuracy: 0.9013 - val_loss: 0.2767 - val_accuracy: 0.9203\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3052 - accuracy: 0.9044 - val_loss: 0.2755 - val_accuracy: 0.9215\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3078 - accuracy: 0.9064 - val_loss: 0.2737 - val_accuracy: 0.9207\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3099 - accuracy: 0.9068 - val_loss: 0.2725 - val_accuracy: 0.9221\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3037 - accuracy: 0.9077 - val_loss: 0.2723 - val_accuracy: 0.9203\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2945 - accuracy: 0.9092 - val_loss: 0.2697 - val_accuracy: 0.9230\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2995 - accuracy: 0.9097 - val_loss: 0.2694 - val_accuracy: 0.9217\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2979 - accuracy: 0.9069 - val_loss: 0.2677 - val_accuracy: 0.9227\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3014 - accuracy: 0.9083 - val_loss: 0.2667 - val_accuracy: 0.9233\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2990 - accuracy: 0.9078 - val_loss: 0.2665 - val_accuracy: 0.9235\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.0140 - accuracy: 0.3150 - val_loss: 0.9161 - val_accuracy: 0.8121\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9920 - accuracy: 0.7019 - val_loss: 0.5592 - val_accuracy: 0.8603\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7165 - accuracy: 0.7813 - val_loss: 0.4614 - val_accuracy: 0.8777\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6224 - accuracy: 0.8131 - val_loss: 0.4126 - val_accuracy: 0.8862\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5587 - accuracy: 0.8328 - val_loss: 0.3827 - val_accuracy: 0.8927\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5154 - accuracy: 0.8458 - val_loss: 0.3617 - val_accuracy: 0.8981\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4882 - accuracy: 0.8535 - val_loss: 0.3445 - val_accuracy: 0.9035\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4694 - accuracy: 0.8584 - val_loss: 0.3303 - val_accuracy: 0.9062\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4380 - accuracy: 0.8701 - val_loss: 0.3192 - val_accuracy: 0.9087\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4240 - accuracy: 0.8733 - val_loss: 0.3083 - val_accuracy: 0.9114\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4094 - accuracy: 0.8807 - val_loss: 0.2992 - val_accuracy: 0.9137\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3926 - accuracy: 0.8826 - val_loss: 0.2913 - val_accuracy: 0.9157\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3811 - accuracy: 0.8868 - val_loss: 0.2837 - val_accuracy: 0.9178\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3706 - accuracy: 0.8907 - val_loss: 0.2762 - val_accuracy: 0.9195\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3658 - accuracy: 0.8912 - val_loss: 0.2689 - val_accuracy: 0.9231\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3465 - accuracy: 0.8972 - val_loss: 0.2626 - val_accuracy: 0.9246\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.8993 - val_loss: 0.2573 - val_accuracy: 0.9256\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.9024 - val_loss: 0.2518 - val_accuracy: 0.9259\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.9032 - val_loss: 0.2462 - val_accuracy: 0.9283\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3154 - accuracy: 0.9061 - val_loss: 0.2413 - val_accuracy: 0.9293\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3030 - accuracy: 0.9096 - val_loss: 0.2366 - val_accuracy: 0.9316\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2975 - accuracy: 0.9118 - val_loss: 0.2314 - val_accuracy: 0.9328\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2922 - accuracy: 0.9121 - val_loss: 0.2283 - val_accuracy: 0.9330\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2850 - accuracy: 0.9163 - val_loss: 0.2238 - val_accuracy: 0.9352\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.9146 - val_loss: 0.2205 - val_accuracy: 0.9350\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2790 - accuracy: 0.9166 - val_loss: 0.2169 - val_accuracy: 0.9367\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.9198 - val_loss: 0.2132 - val_accuracy: 0.9377\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2675 - accuracy: 0.9227 - val_loss: 0.2102 - val_accuracy: 0.9377\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2607 - accuracy: 0.9233 - val_loss: 0.2074 - val_accuracy: 0.9385\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2550 - accuracy: 0.9255 - val_loss: 0.2038 - val_accuracy: 0.9392\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2510 - accuracy: 0.9264 - val_loss: 0.2003 - val_accuracy: 0.9408\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2414 - accuracy: 0.9290 - val_loss: 0.1985 - val_accuracy: 0.9411\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2400 - accuracy: 0.9278 - val_loss: 0.1955 - val_accuracy: 0.9423\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2433 - accuracy: 0.9271 - val_loss: 0.1929 - val_accuracy: 0.9417\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2313 - accuracy: 0.9302 - val_loss: 0.1911 - val_accuracy: 0.9423\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2311 - accuracy: 0.9319 - val_loss: 0.1878 - val_accuracy: 0.9436\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2252 - accuracy: 0.9317 - val_loss: 0.1859 - val_accuracy: 0.9441\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2229 - accuracy: 0.9332 - val_loss: 0.1831 - val_accuracy: 0.9457\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2187 - accuracy: 0.9345 - val_loss: 0.1817 - val_accuracy: 0.9452\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9357 - val_loss: 0.1793 - val_accuracy: 0.9464\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9363 - val_loss: 0.1770 - val_accuracy: 0.9467\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2087 - accuracy: 0.9370 - val_loss: 0.1756 - val_accuracy: 0.9468\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2052 - accuracy: 0.9388 - val_loss: 0.1735 - val_accuracy: 0.9472\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1981 - accuracy: 0.9407 - val_loss: 0.1724 - val_accuracy: 0.9474\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2050 - accuracy: 0.9396 - val_loss: 0.1707 - val_accuracy: 0.9480\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1952 - accuracy: 0.9407 - val_loss: 0.1686 - val_accuracy: 0.9487\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1944 - accuracy: 0.9411 - val_loss: 0.1670 - val_accuracy: 0.9497\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1848 - accuracy: 0.9460 - val_loss: 0.1658 - val_accuracy: 0.9499\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1911 - accuracy: 0.9419 - val_loss: 0.1646 - val_accuracy: 0.9502\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1893 - accuracy: 0.9437 - val_loss: 0.1635 - val_accuracy: 0.9503\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.0533 - accuracy: 0.3076 - val_loss: 1.0905 - val_accuracy: 0.7854\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0818 - accuracy: 0.6834 - val_loss: 0.6374 - val_accuracy: 0.8478\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7806 - accuracy: 0.7606 - val_loss: 0.5101 - val_accuracy: 0.8662\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6642 - accuracy: 0.7968 - val_loss: 0.4493 - val_accuracy: 0.8802\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5954 - accuracy: 0.8207 - val_loss: 0.4160 - val_accuracy: 0.8867\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5521 - accuracy: 0.8310 - val_loss: 0.3918 - val_accuracy: 0.8913\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5196 - accuracy: 0.8442 - val_loss: 0.3744 - val_accuracy: 0.8950\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.8516 - val_loss: 0.3626 - val_accuracy: 0.8981\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4726 - accuracy: 0.8586 - val_loss: 0.3500 - val_accuracy: 0.9012\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4580 - accuracy: 0.8652 - val_loss: 0.3409 - val_accuracy: 0.9032\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4348 - accuracy: 0.8721 - val_loss: 0.3323 - val_accuracy: 0.9050\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4242 - accuracy: 0.8729 - val_loss: 0.3245 - val_accuracy: 0.9078\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4186 - accuracy: 0.8734 - val_loss: 0.3179 - val_accuracy: 0.9082\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4115 - accuracy: 0.8772 - val_loss: 0.3115 - val_accuracy: 0.9102\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3935 - accuracy: 0.8813 - val_loss: 0.3059 - val_accuracy: 0.9107\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3930 - accuracy: 0.8844 - val_loss: 0.3003 - val_accuracy: 0.9122\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3857 - accuracy: 0.8863 - val_loss: 0.2944 - val_accuracy: 0.9130\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8900 - val_loss: 0.2901 - val_accuracy: 0.9146\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3672 - accuracy: 0.8884 - val_loss: 0.2848 - val_accuracy: 0.9158\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3601 - accuracy: 0.8927 - val_loss: 0.2814 - val_accuracy: 0.9164\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3551 - accuracy: 0.8928 - val_loss: 0.2758 - val_accuracy: 0.9187\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3505 - accuracy: 0.8955 - val_loss: 0.2728 - val_accuracy: 0.9187\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3385 - accuracy: 0.8997 - val_loss: 0.2682 - val_accuracy: 0.9202\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.8981 - val_loss: 0.2647 - val_accuracy: 0.9212\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3269 - accuracy: 0.9039 - val_loss: 0.2609 - val_accuracy: 0.9226\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3222 - accuracy: 0.9031 - val_loss: 0.2572 - val_accuracy: 0.9243\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3243 - accuracy: 0.9033 - val_loss: 0.2532 - val_accuracy: 0.9259\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3230 - accuracy: 0.9042 - val_loss: 0.2498 - val_accuracy: 0.9266\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3146 - accuracy: 0.9045 - val_loss: 0.2475 - val_accuracy: 0.9271\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2981 - accuracy: 0.9112 - val_loss: 0.2436 - val_accuracy: 0.9289\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2968 - accuracy: 0.9083 - val_loss: 0.2400 - val_accuracy: 0.9298\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2968 - accuracy: 0.9094 - val_loss: 0.2372 - val_accuracy: 0.9304\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2878 - accuracy: 0.9131 - val_loss: 0.2344 - val_accuracy: 0.9317\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.9145 - val_loss: 0.2317 - val_accuracy: 0.9324\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2873 - accuracy: 0.9143 - val_loss: 0.2293 - val_accuracy: 0.9325\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2738 - accuracy: 0.9175 - val_loss: 0.2261 - val_accuracy: 0.9333\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2722 - accuracy: 0.9163 - val_loss: 0.2238 - val_accuracy: 0.9344\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2733 - accuracy: 0.9190 - val_loss: 0.2211 - val_accuracy: 0.9351\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2702 - accuracy: 0.9196 - val_loss: 0.2187 - val_accuracy: 0.9359\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2664 - accuracy: 0.9192 - val_loss: 0.2168 - val_accuracy: 0.9366\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2614 - accuracy: 0.9198 - val_loss: 0.2140 - val_accuracy: 0.9376\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2617 - accuracy: 0.9204 - val_loss: 0.2125 - val_accuracy: 0.9377\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2510 - accuracy: 0.9235 - val_loss: 0.2104 - val_accuracy: 0.9386\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2544 - accuracy: 0.9224 - val_loss: 0.2078 - val_accuracy: 0.9389\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2463 - accuracy: 0.9256 - val_loss: 0.2057 - val_accuracy: 0.9402\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2473 - accuracy: 0.9243 - val_loss: 0.2036 - val_accuracy: 0.9402\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2435 - accuracy: 0.9256 - val_loss: 0.2023 - val_accuracy: 0.9401\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2371 - accuracy: 0.9285 - val_loss: 0.1999 - val_accuracy: 0.9411\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2376 - accuracy: 0.9275 - val_loss: 0.1983 - val_accuracy: 0.9414\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2314 - accuracy: 0.9296 - val_loss: 0.1962 - val_accuracy: 0.9419\n",
      "{'loss': [1.1897891759872437, 0.6609874963760376, 0.5613510608673096, 0.5104910135269165, 0.48037800192832947, 0.46160897612571716, 0.4461436867713928, 0.4306809604167938, 0.4231646656990051, 0.4123142957687378, 0.4041286110877991, 0.3978569805622101, 0.3912390172481537, 0.3880823254585266, 0.38291940093040466, 0.37802547216415405, 0.3747873902320862, 0.3715331554412842, 0.36485812067985535, 0.3618714213371277, 0.35372260212898254, 0.3505834937095642, 0.3489868938922882, 0.3460577130317688, 0.3411753475666046, 0.3376522362232208, 0.3357907235622406, 0.3372727632522583, 0.33346256613731384, 0.3290809690952301, 0.32637137174606323, 0.326071172952652, 0.32111823558807373, 0.3212299942970276, 0.3158206045627594, 0.31045639514923096, 0.31381872296333313, 0.31271469593048096, 0.3119770586490631, 0.3067117929458618, 0.3056682050228119, 0.30192089080810547, 0.3027160167694092, 0.3005683422088623, 0.2982693612575531, 0.297990620136261, 0.29309630393981934, 0.2945502698421478, 0.29088839888572693, 0.2859116494655609], 'accuracy': [0.6204166412353516, 0.7992500066757202, 0.8314999938011169, 0.8462708592414856, 0.8544999957084656, 0.8598750233650208, 0.8647291660308838, 0.8692708611488342, 0.8713958263397217, 0.874750018119812, 0.879770815372467, 0.8787500262260437, 0.8823124766349792, 0.8843749761581421, 0.8845208287239075, 0.885895848274231, 0.8860833048820496, 0.8881250023841858, 0.8901249766349792, 0.890791654586792, 0.8940208554267883, 0.8953750133514404, 0.8943958282470703, 0.8966875076293945, 0.8970416784286499, 0.8977291584014893, 0.8989375233650208, 0.8990208506584167, 0.8992083072662354, 0.9012500047683716, 0.9016249775886536, 0.9011458158493042, 0.9022708535194397, 0.9040208458900452, 0.9051041603088379, 0.9053958058357239, 0.9049166440963745, 0.9052083492279053, 0.9038333296775818, 0.906291663646698, 0.9067500233650208, 0.9069583415985107, 0.9068124890327454, 0.9087916612625122, 0.9100833535194397, 0.9105208516120911, 0.910979151725769, 0.9097083210945129, 0.9126041531562805, 0.9118958115577698], 'val_loss': [0.5760352611541748, 0.4491250813007355, 0.40274834632873535, 0.37658190727233887, 0.3613150119781494, 0.3502242863178253, 0.3411305844783783, 0.3341025710105896, 0.32836613059043884, 0.32465431094169617, 0.320096492767334, 0.31672781705856323, 0.3133292496204376, 0.3114408552646637, 0.3083357512950897, 0.3061940371990204, 0.3044680058956146, 0.3010397255420685, 0.3008975684642792, 0.29784953594207764, 0.2956160604953766, 0.2942972481250763, 0.292728990316391, 0.2905478775501251, 0.28938648104667664, 0.28748518228530884, 0.28578680753707886, 0.28428390622138977, 0.28345438838005066, 0.2821950912475586, 0.28065231442451477, 0.2807272672653198, 0.2785385251045227, 0.27751532196998596, 0.276356041431427, 0.2749806046485901, 0.2737177610397339, 0.2736411392688751, 0.2712441086769104, 0.2707560360431671, 0.2696472108364105, 0.2674533426761627, 0.26635393500328064, 0.26568299531936646, 0.26381054520606995, 0.26327717304229736, 0.26229095458984375, 0.2606848478317261, 0.26042893528938293, 0.2589143216609955], 'val_accuracy': [0.8492500185966492, 0.8733333349227905, 0.8808333277702332, 0.8877500295639038, 0.8914999961853027, 0.8949999809265137, 0.8989999890327454, 0.9009166955947876, 0.903166651725769, 0.903249979019165, 0.9055833220481873, 0.9056666493415833, 0.9073333144187927, 0.9069166779518127, 0.909250020980835, 0.9099166393280029, 0.9099166393280029, 0.9121666550636292, 0.9114999771118164, 0.9128333330154419, 0.9127500057220459, 0.9140833616256714, 0.9145833253860474, 0.9150833487510681, 0.9154166579246521, 0.9163333177566528, 0.9160833358764648, 0.9168333411216736, 0.9163333177566528, 0.9162499904632568, 0.9167500138282776, 0.9176666736602783, 0.918833315372467, 0.9197499752044678, 0.918833315372467, 0.9199166893959045, 0.9193333387374878, 0.9196666479110718, 0.9204166531562805, 0.9205833077430725, 0.921500027179718, 0.9224166870117188, 0.9230833053588867, 0.9233333468437195, 0.9237499833106995, 0.9234166741371155, 0.9237499833106995, 0.9244166612625122, 0.9239166378974915, 0.9247499704360962]}\n",
      "{'loss': [1.6214028596878052, 0.9144358038902283, 0.7201553583145142, 0.6231478452682495, 0.5655328631401062, 0.5133376717567444, 0.4890347123146057, 0.4670766592025757, 0.4381180703639984, 0.4162469506263733, 0.4022475481033325, 0.3885331153869629, 0.3752034902572632, 0.36241140961647034, 0.3483564853668213, 0.33901461958885193, 0.3308263421058655, 0.32420337200164795, 0.31346797943115234, 0.30361807346343994, 0.2977263927459717, 0.2891151010990143, 0.28606942296028137, 0.2771851718425751, 0.2695199251174927, 0.26401853561401367, 0.2596115171909332, 0.2540411651134491, 0.24831469357013702, 0.2444530427455902, 0.23797953128814697, 0.2315402626991272, 0.22907492518424988, 0.22523649036884308, 0.21925164759159088, 0.21546418964862823, 0.21347540616989136, 0.20958732068538666, 0.20394626259803772, 0.20172226428985596, 0.19739538431167603, 0.19423407316207886, 0.1899983286857605, 0.18608495593070984, 0.18542897701263428, 0.1826646327972412, 0.17764689028263092, 0.17808103561401367, 0.1730574071407318, 0.1701788306236267], 'accuracy': [0.45402082800865173, 0.7076249718666077, 0.7721458077430725, 0.8084375262260437, 0.8261666893959045, 0.8430208563804626, 0.8510416746139526, 0.8588958382606506, 0.8662083148956299, 0.874666690826416, 0.8808958530426025, 0.8838958144187927, 0.8870000243186951, 0.8920208215713501, 0.8970000147819519, 0.898812472820282, 0.9017083048820496, 0.9037708044052124, 0.9069374799728394, 0.9097916483879089, 0.9126874804496765, 0.9142916798591614, 0.9142500162124634, 0.9180625081062317, 0.9197291731834412, 0.921583354473114, 0.9227291941642761, 0.9243333339691162, 0.9256250262260437, 0.9275624752044678, 0.9296249747276306, 0.9316874742507935, 0.9318958520889282, 0.932687520980835, 0.9340208172798157, 0.9348750114440918, 0.9366041421890259, 0.9369791746139526, 0.9391666650772095, 0.940541684627533, 0.9408749938011169, 0.942395806312561, 0.9438124895095825, 0.9433749914169312, 0.9446458220481873, 0.9452916383743286, 0.9473749995231628, 0.9458125233650208, 0.9476249814033508, 0.9492083191871643], 'val_loss': [0.8216471076011658, 0.5384602546691895, 0.44223231077194214, 0.3926856219768524, 0.3630247116088867, 0.33931973576545715, 0.32404646277427673, 0.31040990352630615, 0.29606667160987854, 0.28604814410209656, 0.27788546681404114, 0.2674196660518646, 0.26157042384147644, 0.25356703996658325, 0.24774764478206635, 0.24162070453166962, 0.2357872575521469, 0.23086264729499817, 0.22586850821971893, 0.22157904505729675, 0.21737052500247955, 0.21311832964420319, 0.20931392908096313, 0.20583738386631012, 0.20266322791576385, 0.19986672699451447, 0.19586266577243805, 0.19364383816719055, 0.19034269452095032, 0.18734468519687653, 0.185629740357399, 0.18313905596733093, 0.18114760518074036, 0.17884638905525208, 0.1770097315311432, 0.17364372313022614, 0.17248763144016266, 0.17143899202346802, 0.16849099099636078, 0.1682160347700119, 0.16495868563652039, 0.1643814742565155, 0.16251994669437408, 0.1609068363904953, 0.16005352139472961, 0.15893664956092834, 0.15634457767009735, 0.15544171631336212, 0.15426002442836761, 0.1530962884426117], 'val_accuracy': [0.8149999976158142, 0.8619999885559082, 0.8807500004768372, 0.890250027179718, 0.8951666951179504, 0.9016666412353516, 0.9052500128746033, 0.9082499742507935, 0.9129166603088379, 0.9152500033378601, 0.9168333411216736, 0.9205833077430725, 0.9209166765213013, 0.9244166612625122, 0.9257500171661377, 0.9270833134651184, 0.9299166798591614, 0.9313333630561829, 0.9323333501815796, 0.9340833425521851, 0.9355000257492065, 0.9367499947547913, 0.9380000233650208, 0.9388333559036255, 0.9402499794960022, 0.940416693687439, 0.9401666522026062, 0.9410833120346069, 0.9420833587646484, 0.9431666731834412, 0.9430833458900452, 0.9440833330154419, 0.9450833201408386, 0.9450833201408386, 0.9454166889190674, 0.9475833177566528, 0.9478333592414856, 0.9481666684150696, 0.9490833282470703, 0.9494166374206543, 0.9503333568572998, 0.9506666660308838, 0.9508333206176758, 0.9514166712760925, 0.9519166946411133, 0.9522500038146973, 0.9526666402816772, 0.952750027179718, 0.953416645526886, 0.953499972820282]}\n",
      "{'loss': [1.4762523174285889, 0.8160801529884338, 0.6527209877967834, 0.5743589401245117, 0.5256994366645813, 0.4880055785179138, 0.46707120537757874, 0.4429004192352295, 0.42753154039382935, 0.4145679175853729, 0.3984520137310028, 0.3887658715248108, 0.37867406010627747, 0.36580342054367065, 0.3577805161476135, 0.3476621210575104, 0.34084993600845337, 0.3323001265525818, 0.3284618854522705, 0.31989166140556335, 0.31183406710624695, 0.30615872144699097, 0.29953327775001526, 0.2974954843521118, 0.28833329677581787, 0.2854233682155609, 0.27975332736968994, 0.273423433303833, 0.2697642147541046, 0.26641204953193665, 0.2626229524612427, 0.256227046251297, 0.2533368170261383, 0.2513328790664673, 0.24509195983409882, 0.24085335433483124, 0.2391674816608429, 0.23168298602104187, 0.23284615576267242, 0.22377842664718628, 0.2247873693704605, 0.22272735834121704, 0.21803900599479675, 0.21598872542381287, 0.2121286243200302, 0.20905761420726776, 0.20816679298877716, 0.2077583372592926, 0.20335355401039124, 0.19912005960941315], 'accuracy': [0.5254999995231628, 0.7454166412353516, 0.796541690826416, 0.8245208263397217, 0.8414999842643738, 0.8525416851043701, 0.8605833053588867, 0.8670416474342346, 0.8722291588783264, 0.8759375214576721, 0.8809999823570251, 0.8846250176429749, 0.8865000009536743, 0.8903124928474426, 0.8923333287239075, 0.8966041803359985, 0.8967083096504211, 0.9006041884422302, 0.9027083516120911, 0.9044166803359985, 0.9069374799728394, 0.9076666831970215, 0.9103958606719971, 0.9095625281333923, 0.9120416641235352, 0.9152916669845581, 0.9156041741371155, 0.9168958067893982, 0.9178541898727417, 0.9197083115577698, 0.9212291836738586, 0.9237708449363708, 0.9240000247955322, 0.9247499704360962, 0.9256666898727417, 0.9270625114440918, 0.9275416731834412, 0.9301041960716248, 0.9301249980926514, 0.9320208430290222, 0.9302291870117188, 0.9314374923706055, 0.9330416917800903, 0.9351875185966492, 0.9360416531562805, 0.9361875057220459, 0.9377291798591614, 0.9369375109672546, 0.9384375214576721, 0.9397291541099548], 'val_loss': [0.7452194690704346, 0.5055570602416992, 0.429452121257782, 0.38889506459236145, 0.36381983757019043, 0.3447217345237732, 0.33168646693229675, 0.31942757964134216, 0.30991822481155396, 0.3014943301677704, 0.2940385639667511, 0.286434143781662, 0.2805277109146118, 0.2745678424835205, 0.268296480178833, 0.26334890723228455, 0.2591022849082947, 0.2536453306674957, 0.2508523762226105, 0.24567675590515137, 0.2417636662721634, 0.23803532123565674, 0.2347652167081833, 0.23150528967380524, 0.22781260311603546, 0.2255517989397049, 0.22272057831287384, 0.21997863054275513, 0.21645794808864594, 0.21435970067977905, 0.21153733134269714, 0.20967212319374084, 0.20739708840847015, 0.20488031208515167, 0.20283891260623932, 0.20049609243869781, 0.19829894602298737, 0.19643272459506989, 0.19514353573322296, 0.1930450052022934, 0.19118815660476685, 0.18887528777122498, 0.1873931884765625, 0.18581563234329224, 0.18434064090251923, 0.18256732821464539, 0.18102134764194489, 0.180715411901474, 0.17836512625217438, 0.17700450122356415], 'val_accuracy': [0.8257499933242798, 0.8677499890327454, 0.8839166760444641, 0.8917499780654907, 0.8972499966621399, 0.9010833501815796, 0.9040833115577698, 0.9068333506584167, 0.9085833430290222, 0.9125000238418579, 0.9143333435058594, 0.9164166450500488, 0.9169999957084656, 0.918833315372467, 0.9211666584014893, 0.922166645526886, 0.9244999885559082, 0.9256666898727417, 0.9268333315849304, 0.9285833239555359, 0.9294166564941406, 0.9304166436195374, 0.9311666488647461, 0.9326666593551636, 0.9334999918937683, 0.934333324432373, 0.934583306312561, 0.9356666803359985, 0.9363333582878113, 0.9365833401679993, 0.937166690826416, 0.9383333325386047, 0.9388333559036255, 0.940666675567627, 0.9401666522026062, 0.940666675567627, 0.9415833353996277, 0.9418333172798157, 0.9423333406448364, 0.9424999952316284, 0.9434999823570251, 0.9439166784286499, 0.9433333277702332, 0.9445833563804626, 0.9445000290870667, 0.9449999928474426, 0.9452499747276306, 0.9452499747276306, 0.9465833306312561, 0.9467499852180481]}\n",
      "{'loss': [1.127264380455017, 0.6463750600814819, 0.5567253232002258, 0.5058661103248596, 0.48312509059906006, 0.46250244975090027, 0.44516244530677795, 0.42935997247695923, 0.42042601108551025, 0.4129614233970642, 0.4037576913833618, 0.3931863605976105, 0.3872329592704773, 0.38159677386283875, 0.3743572533130646, 0.36791470646858215, 0.3654595613479614, 0.35758110880851746, 0.35582756996154785, 0.3488106429576874, 0.3442915976047516, 0.3444095551967621, 0.33519870042800903, 0.33712926506996155, 0.32988402247428894, 0.3258667588233948, 0.3215528726577759, 0.31626299023628235, 0.3181476294994354, 0.31299889087677, 0.3093029260635376, 0.30597493052482605, 0.3017469644546509, 0.2990301251411438, 0.29750528931617737, 0.2900935709476471, 0.28820353746414185, 0.29097190499305725, 0.28946977853775024, 0.283539354801178, 0.28213614225387573, 0.2762572169303894, 0.27767428755760193, 0.27521389722824097, 0.2723706066608429, 0.2674311101436615, 0.26608583331108093, 0.2610315680503845, 0.25943857431411743, 0.2611809968948364], 'accuracy': [0.6380833387374878, 0.7975833415985107, 0.8295833468437195, 0.8449166417121887, 0.8539791703224182, 0.8606458306312561, 0.8653749823570251, 0.8698750138282776, 0.8726875185966492, 0.8766458630561829, 0.8787083625793457, 0.8808125257492065, 0.8828125, 0.8828125, 0.886020839214325, 0.8885625004768372, 0.8897083401679993, 0.8925416469573975, 0.8931249976158142, 0.8940416574478149, 0.895229160785675, 0.8950416445732117, 0.898687481880188, 0.8978333473205566, 0.9017083048820496, 0.9019374847412109, 0.9019791483879089, 0.9041458368301392, 0.9008749723434448, 0.9055208563804626, 0.9064791798591614, 0.9055833220481873, 0.9079999923706055, 0.9083750247955322, 0.909375011920929, 0.9122083187103271, 0.9118124842643738, 0.9123333096504211, 0.9118333458900452, 0.9131458401679993, 0.9124166369438171, 0.9167500138282776, 0.9147916436195374, 0.9169166684150696, 0.9159583449363708, 0.9176666736602783, 0.9179166555404663, 0.918874979019165, 0.9202916622161865, 0.9208750128746033], 'val_loss': [0.5443012118339539, 0.43196743726730347, 0.391203373670578, 0.3686898648738861, 0.35528719425201416, 0.34534817934036255, 0.3373447358608246, 0.32879751920700073, 0.3237569034099579, 0.31797826290130615, 0.31236568093299866, 0.30959421396255493, 0.3060951828956604, 0.30170169472694397, 0.29911500215530396, 0.29547855257987976, 0.29366204142570496, 0.28906676173210144, 0.2867455780506134, 0.28309014439582825, 0.28150442242622375, 0.2791338562965393, 0.2762634754180908, 0.2737963795661926, 0.2719658315181732, 0.26973527669906616, 0.2672552168369293, 0.26609933376312256, 0.26259148120880127, 0.26157501339912415, 0.25820067524909973, 0.2565845251083374, 0.25392234325408936, 0.25171828269958496, 0.24955648183822632, 0.24852553009986877, 0.2464217096567154, 0.2442549169063568, 0.24209624528884888, 0.24117836356163025, 0.24013040959835052, 0.23786014318466187, 0.23594476282596588, 0.23405756056308746, 0.2318662703037262, 0.23042713105678558, 0.22983701527118683, 0.22751879692077637, 0.22599458694458008, 0.22517499327659607], 'val_accuracy': [0.8553333282470703, 0.878000020980835, 0.8863333463668823, 0.8927500247955322, 0.8956666588783264, 0.8989166617393494, 0.9014166593551636, 0.903166651725769, 0.9050833582878113, 0.906000018119812, 0.9083333611488342, 0.9082499742507935, 0.909583330154419, 0.9111666679382324, 0.9114166498184204, 0.9125833511352539, 0.9135833382606506, 0.9152500033378601, 0.9159166812896729, 0.9185000061988831, 0.9179166555404663, 0.9194166660308838, 0.9192500114440918, 0.9204999804496765, 0.9213333129882812, 0.92166668176651, 0.9229999780654907, 0.9236666560173035, 0.9243333339691162, 0.9240833520889282, 0.924916684627533, 0.9272500276565552, 0.9265000224113464, 0.9267500042915344, 0.9279166460037231, 0.9284166693687439, 0.9291666746139526, 0.9290000200271606, 0.9301666617393494, 0.9298333525657654, 0.9300000071525574, 0.9305833578109741, 0.9317499995231628, 0.9319166541099548, 0.9322500228881836, 0.9327499866485596, 0.9328333139419556, 0.9333333373069763, 0.9333333373069763, 0.9331666827201843]}\n",
      "{'loss': [1.0144166946411133, 0.6075479388237, 0.5385389924049377, 0.5019773244857788, 0.47919315099716187, 0.4566708505153656, 0.4470581114292145, 0.433402955532074, 0.42221584916114807, 0.41340401768684387, 0.4079051613807678, 0.40134260058403015, 0.3957436978816986, 0.3890881836414337, 0.3827764391899109, 0.3816855549812317, 0.3766116201877594, 0.3710969090461731, 0.36955562233924866, 0.36457088589668274, 0.35596418380737305, 0.3554554581642151, 0.35081928968429565, 0.3499161899089813, 0.35099637508392334, 0.34308281540870667, 0.34216275811195374, 0.34203702211380005, 0.3383139967918396, 0.33643069863319397, 0.3333359658718109, 0.3317222595214844, 0.32775723934173584, 0.3248922526836395, 0.3216157555580139, 0.32018494606018066, 0.318820059299469, 0.3180449604988098, 0.31543123722076416, 0.3119415044784546, 0.31406205892562866, 0.30808454751968384, 0.3104892671108246, 0.30407872796058655, 0.3033658266067505, 0.300540566444397, 0.29926156997680664, 0.2973955571651459, 0.2959774136543274, 0.2951081395149231], 'accuracy': [0.667395830154419, 0.8080833554267883, 0.8325833082199097, 0.8466249704360962, 0.8541874885559082, 0.8615000247955322, 0.8651250004768372, 0.8692291378974915, 0.8717708587646484, 0.87520831823349, 0.8768541812896729, 0.878000020980835, 0.8799583315849304, 0.8832083344459534, 0.8851041793823242, 0.8859999775886536, 0.8865416646003723, 0.8889166712760925, 0.8882499933242798, 0.8896458148956299, 0.8934375047683716, 0.8916458487510681, 0.8947291374206543, 0.8941458463668823, 0.8944374918937683, 0.8962083458900452, 0.8976666927337646, 0.8973958492279053, 0.898312509059906, 0.8969374895095825, 0.9001041650772095, 0.8998333215713501, 0.9012916684150696, 0.901479184627533, 0.9020416736602783, 0.9023541808128357, 0.9033958315849304, 0.9023541808128357, 0.9040416479110718, 0.9050416946411133, 0.9050833582878113, 0.9058541655540466, 0.9052916765213013, 0.9072083234786987, 0.9074166417121887, 0.9066458344459534, 0.9091249704360962, 0.9084791541099548, 0.9102500081062317, 0.909291684627533], 'val_loss': [0.43614616990089417, 0.38540858030319214, 0.36461278796195984, 0.348431795835495, 0.34155526757240295, 0.33550816774368286, 0.32993564009666443, 0.32642295956611633, 0.3250010311603546, 0.3208191990852356, 0.318112850189209, 0.3163794279098511, 0.3140343725681305, 0.3122127950191498, 0.3101193606853485, 0.30952131748199463, 0.3091663718223572, 0.30555257201194763, 0.30479174852371216, 0.3025642931461334, 0.30106285214424133, 0.30018532276153564, 0.29882359504699707, 0.29785436391830444, 0.2972447872161865, 0.2955951988697052, 0.29397451877593994, 0.29292193055152893, 0.2912154495716095, 0.2901483476161957, 0.2887667715549469, 0.2869073152542114, 0.286984384059906, 0.28470906615257263, 0.28363892436027527, 0.2817343473434448, 0.28160250186920166, 0.2803697884082794, 0.280006468296051, 0.277861088514328, 0.27669665217399597, 0.27548113465309143, 0.2737193703651428, 0.2724927067756653, 0.2723366618156433, 0.26968610286712646, 0.26942795515060425, 0.267733633518219, 0.2667413353919983, 0.2664763629436493], 'val_accuracy': [0.871749997138977, 0.8865000009536743, 0.8919166922569275, 0.8980000019073486, 0.9010000228881836, 0.9024166464805603, 0.9043333530426025, 0.9054999947547913, 0.9053333401679993, 0.906333327293396, 0.9076666831970215, 0.9089166522026062, 0.909416675567627, 0.9096666574478149, 0.909500002861023, 0.9108333587646484, 0.9096666574478149, 0.9110833406448364, 0.9122499823570251, 0.9128333330154419, 0.9130833148956299, 0.9136666655540466, 0.9139999747276306, 0.9137499928474426, 0.9137499928474426, 0.9152500033378601, 0.9155833125114441, 0.9152500033378601, 0.9161666631698608, 0.9159166812896729, 0.9166666865348816, 0.9179166555404663, 0.9173333048820496, 0.9179166555404663, 0.9185000061988831, 0.9190833568572998, 0.9196666479110718, 0.9190000295639038, 0.9194166660308838, 0.9194999933242798, 0.9203333258628845, 0.921500027179718, 0.9206666946411133, 0.92208331823349, 0.9203333258628845, 0.9229999780654907, 0.92166668176651, 0.9227499961853027, 0.9232500195503235, 0.9235000014305115]}\n",
      "{'loss': [1.6852679252624512, 0.8988563418388367, 0.6936627626419067, 0.603365957736969, 0.5523239970207214, 0.5111846923828125, 0.4805447459220886, 0.45958247780799866, 0.4393289387226105, 0.42064550518989563, 0.40548816323280334, 0.39157259464263916, 0.3791735768318176, 0.36905497312545776, 0.35970738530158997, 0.3470801115036011, 0.3400949239730835, 0.3288349211215973, 0.3222651481628418, 0.3131966292858124, 0.30608680844306946, 0.30079132318496704, 0.2950513958930969, 0.2897335886955261, 0.2818335294723511, 0.2805308699607849, 0.27170655131340027, 0.2661251127719879, 0.2605063021183014, 0.254515141248703, 0.2530367970466614, 0.24889807403087616, 0.2416049838066101, 0.239329531788826, 0.23427492380142212, 0.22966203093528748, 0.2262139618396759, 0.22380678355693817, 0.21714937686920166, 0.2142280638217926, 0.211507186293602, 0.2089776247739792, 0.20461668074131012, 0.20055195689201355, 0.19846667349338531, 0.19485096633434296, 0.1950821727514267, 0.18931151926517487, 0.18949656188488007, 0.18652459979057312], 'accuracy': [0.47462499141693115, 0.7269583344459534, 0.7874166369438171, 0.8187916874885559, 0.8344374895095825, 0.8481875061988831, 0.8572499752044678, 0.8622291684150696, 0.8686041831970215, 0.875124990940094, 0.8811666369438171, 0.8841458559036255, 0.8867083191871643, 0.8902083039283752, 0.8934791684150696, 0.8978958129882812, 0.8989583253860474, 0.9021875262260437, 0.9039166569709778, 0.9071458578109741, 0.9096666574478149, 0.911104142665863, 0.910895824432373, 0.914395809173584, 0.9156666398048401, 0.9163958430290222, 0.9197708368301392, 0.9216874837875366, 0.9229999780654907, 0.9253958463668823, 0.9258541464805603, 0.926604151725769, 0.9280624985694885, 0.9288750290870667, 0.9291666746139526, 0.9326249957084656, 0.932937502861023, 0.9338541626930237, 0.934416651725769, 0.9365416765213013, 0.9374374747276306, 0.9374791383743286, 0.9391458630561829, 0.9402708411216736, 0.9399791955947876, 0.9409166574478149, 0.942145824432373, 0.9434375166893005, 0.9419583082199097, 0.9448541402816772], 'val_loss': [0.9161022901535034, 0.5592029690742493, 0.46140339970588684, 0.4126017391681671, 0.3827480375766754, 0.36166906356811523, 0.3444977104663849, 0.3302716016769409, 0.3191797435283661, 0.30826258659362793, 0.29923415184020996, 0.29132071137428284, 0.2837243378162384, 0.27616992592811584, 0.2689366936683655, 0.26256808638572693, 0.2573356330394745, 0.25178006291389465, 0.2461702823638916, 0.2412557750940323, 0.23660488426685333, 0.23143625259399414, 0.22831793129444122, 0.22380845248699188, 0.2205418348312378, 0.21688079833984375, 0.21324485540390015, 0.21016187965869904, 0.2074204683303833, 0.20376358926296234, 0.20032232999801636, 0.19848008453845978, 0.1954677551984787, 0.19290322065353394, 0.19107508659362793, 0.18777714669704437, 0.18593479692935944, 0.1830625683069229, 0.1816604882478714, 0.1793326586484909, 0.17699600756168365, 0.17564059793949127, 0.17352373898029327, 0.17238138616085052, 0.17068475484848022, 0.16858036816120148, 0.16701531410217285, 0.16584597527980804, 0.1646013855934143, 0.16348597407341003], 'val_accuracy': [0.8120833039283752, 0.8603333234786987, 0.8777499794960022, 0.8861666917800903, 0.8926666378974915, 0.8980833292007446, 0.9035000205039978, 0.906166672706604, 0.9087499976158142, 0.9114166498184204, 0.9137499928474426, 0.9156666398048401, 0.9177500009536743, 0.9194999933242798, 0.9230833053588867, 0.9245833158493042, 0.9255833625793457, 0.9259166717529297, 0.9283333420753479, 0.9293333292007446, 0.9315833449363708, 0.9328333139419556, 0.9330000281333923, 0.9351666569709778, 0.9350000023841858, 0.9366666674613953, 0.937749981880188, 0.937666654586792, 0.9384999871253967, 0.9392499923706055, 0.940833330154419, 0.9410833120346069, 0.9423333406448364, 0.9417499899864197, 0.9422500133514404, 0.9435833096504211, 0.9440833330154419, 0.9456666707992554, 0.9451666474342346, 0.9464166760444641, 0.9467499852180481, 0.9468333125114441, 0.9471666812896729, 0.9474166631698608, 0.9480000138282776, 0.9486666917800903, 0.9496666789054871, 0.949916660785675, 0.950166642665863, 0.9502500295639038]}\n",
      "{'loss': [1.762470006942749, 0.980993390083313, 0.7420035004615784, 0.6370551586151123, 0.579910397529602, 0.5353341102600098, 0.5108144283294678, 0.487611323595047, 0.4694671928882599, 0.4495847523212433, 0.43790701031684875, 0.4268125891685486, 0.41723597049713135, 0.40647685527801514, 0.3951401710510254, 0.38833147287368774, 0.38151073455810547, 0.37292781472206116, 0.36634695529937744, 0.3607889711856842, 0.35243913531303406, 0.3447249233722687, 0.33837324380874634, 0.33277174830436707, 0.32665812969207764, 0.3221082091331482, 0.3199780583381653, 0.31665119528770447, 0.3095347285270691, 0.3030887246131897, 0.2969125509262085, 0.2950893044471741, 0.29056480526924133, 0.28810423612594604, 0.28322774171829224, 0.2786017954349518, 0.2738426625728607, 0.2742817997932434, 0.26792123913764954, 0.2653246819972992, 0.26100048422813416, 0.25681227445602417, 0.25342249870300293, 0.24875184893608093, 0.2500803470611572, 0.24404361844062805, 0.2420429289340973, 0.2399846613407135, 0.23673714697360992, 0.23199506103992462], 'accuracy': [0.4622499942779541, 0.7069791555404663, 0.77322918176651, 0.8051458597183228, 0.8254583477973938, 0.8376458287239075, 0.8469374775886536, 0.8540833592414856, 0.8599166870117188, 0.8655833601951599, 0.8700000047683716, 0.8715000152587891, 0.875083327293396, 0.878208339214325, 0.8805208206176758, 0.8847083449363708, 0.8869166374206543, 0.8891875147819519, 0.890708327293396, 0.8926458358764648, 0.8942083120346069, 0.8966666460037231, 0.8982916474342346, 0.9005416631698608, 0.9020833373069763, 0.9036666750907898, 0.9046875238418579, 0.9050833582878113, 0.9065625071525574, 0.9095208048820496, 0.9100833535194397, 0.910937488079071, 0.9123125076293945, 0.9130833148956299, 0.9145833253860474, 0.9158750176429749, 0.9159166812896729, 0.9186458587646484, 0.918874979019165, 0.9193333387374878, 0.9204999804496765, 0.9212708473205566, 0.9229583144187927, 0.9245625138282776, 0.9238333106040955, 0.9254999756813049, 0.926354169845581, 0.9279375076293945, 0.9282291531562805, 0.9295416474342346], 'val_loss': [1.090486764907837, 0.6373660564422607, 0.5100558400154114, 0.4493367075920105, 0.41604989767074585, 0.39177942276000977, 0.37438833713531494, 0.36256149411201477, 0.34999507665634155, 0.34093189239501953, 0.33233800530433655, 0.32450008392333984, 0.31788378953933716, 0.31146639585494995, 0.3058668076992035, 0.30027633905410767, 0.2944415211677551, 0.2901094853878021, 0.28481411933898926, 0.281398743391037, 0.2757958769798279, 0.2727966606616974, 0.2681540548801422, 0.26467177271842957, 0.2609155774116516, 0.2571609616279602, 0.2531784772872925, 0.24984173476696014, 0.24749688804149628, 0.24360504746437073, 0.2399662286043167, 0.23723341524600983, 0.2344038486480713, 0.2317199558019638, 0.22931595146656036, 0.22610469162464142, 0.2237522453069687, 0.2211066037416458, 0.21873562037944794, 0.21678848564624786, 0.21399833261966705, 0.21247179806232452, 0.21043330430984497, 0.2078324556350708, 0.2056942731142044, 0.20362819731235504, 0.2022988647222519, 0.19986458122730255, 0.19825492799282074, 0.1962084174156189], 'val_accuracy': [0.7854166626930237, 0.8478333353996277, 0.8661666512489319, 0.8801666498184204, 0.8867499828338623, 0.8913333415985107, 0.8949999809265137, 0.8980833292007446, 0.9011666774749756, 0.903249979019165, 0.9049999713897705, 0.9078333377838135, 0.9081666469573975, 0.9101666808128357, 0.9106666445732117, 0.9122499823570251, 0.9129999876022339, 0.9145833253860474, 0.9158333539962769, 0.9164166450500488, 0.918666660785675, 0.918749988079071, 0.9202499985694885, 0.9211666584014893, 0.9225833415985107, 0.9242500066757202, 0.9259166717529297, 0.9265833497047424, 0.9270833134651184, 0.9289166927337646, 0.9297500252723694, 0.9304166436195374, 0.9316666722297668, 0.9324166774749756, 0.9325000047683716, 0.9333333373069763, 0.934416651725769, 0.9350833296775818, 0.9359166622161865, 0.9365833401679993, 0.937583327293396, 0.937749981880188, 0.9385833144187927, 0.9389166831970215, 0.9401666522026062, 0.9402499794960022, 0.9400833249092102, 0.9410833120346069, 0.9414166808128357, 0.9419166445732117]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "noinit_noise_2depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
