{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noinit_noise_3depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "71d76724-1eae-4ead-c0b9-ca5e3bfbe587"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 14s 5ms/step - loss: 1.5747 - accuracy: 0.4713 - val_loss: 0.5267 - val_accuracy: 0.8572\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7029 - accuracy: 0.7814 - val_loss: 0.4174 - val_accuracy: 0.8802\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5816 - accuracy: 0.8186 - val_loss: 0.3798 - val_accuracy: 0.8873\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5107 - accuracy: 0.8436 - val_loss: 0.3581 - val_accuracy: 0.8949\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.8485 - val_loss: 0.3468 - val_accuracy: 0.8977\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4763 - accuracy: 0.8507 - val_loss: 0.3368 - val_accuracy: 0.9009\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8655 - val_loss: 0.3302 - val_accuracy: 0.9025\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4367 - accuracy: 0.8671 - val_loss: 0.3240 - val_accuracy: 0.9050\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4278 - accuracy: 0.8701 - val_loss: 0.3181 - val_accuracy: 0.9068\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4077 - accuracy: 0.8753 - val_loss: 0.3145 - val_accuracy: 0.9076\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4080 - accuracy: 0.8761 - val_loss: 0.3104 - val_accuracy: 0.9096\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8805 - val_loss: 0.3069 - val_accuracy: 0.9102\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4003 - accuracy: 0.8790 - val_loss: 0.3033 - val_accuracy: 0.9107\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3817 - accuracy: 0.8845 - val_loss: 0.3012 - val_accuracy: 0.9116\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8833 - val_loss: 0.2972 - val_accuracy: 0.9129\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3770 - accuracy: 0.8859 - val_loss: 0.2953 - val_accuracy: 0.9128\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3715 - accuracy: 0.8870 - val_loss: 0.2936 - val_accuracy: 0.9139\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3656 - accuracy: 0.8904 - val_loss: 0.2905 - val_accuracy: 0.9150\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3576 - accuracy: 0.8938 - val_loss: 0.2866 - val_accuracy: 0.9158\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3582 - accuracy: 0.8914 - val_loss: 0.2846 - val_accuracy: 0.9171\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8958 - val_loss: 0.2839 - val_accuracy: 0.9160\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8965 - val_loss: 0.2800 - val_accuracy: 0.9177\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3427 - accuracy: 0.8955 - val_loss: 0.2786 - val_accuracy: 0.9178\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8970 - val_loss: 0.2762 - val_accuracy: 0.9194\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3287 - accuracy: 0.9010 - val_loss: 0.2735 - val_accuracy: 0.9193\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8980 - val_loss: 0.2715 - val_accuracy: 0.9203\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.9025 - val_loss: 0.2702 - val_accuracy: 0.9215\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3216 - accuracy: 0.9031 - val_loss: 0.2674 - val_accuracy: 0.9210\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.9053 - val_loss: 0.2654 - val_accuracy: 0.9220\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.9005 - val_loss: 0.2639 - val_accuracy: 0.9221\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3135 - accuracy: 0.9046 - val_loss: 0.2621 - val_accuracy: 0.9233\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.9081 - val_loss: 0.2604 - val_accuracy: 0.9234\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.9091 - val_loss: 0.2573 - val_accuracy: 0.9245\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2978 - accuracy: 0.9088 - val_loss: 0.2563 - val_accuracy: 0.9246\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3033 - accuracy: 0.9082 - val_loss: 0.2562 - val_accuracy: 0.9248\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2999 - accuracy: 0.9091 - val_loss: 0.2534 - val_accuracy: 0.9264\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2998 - accuracy: 0.9077 - val_loss: 0.2512 - val_accuracy: 0.9258\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2882 - accuracy: 0.9138 - val_loss: 0.2493 - val_accuracy: 0.9270\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.9125 - val_loss: 0.2484 - val_accuracy: 0.9262\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2885 - accuracy: 0.9123 - val_loss: 0.2473 - val_accuracy: 0.9272\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2916 - accuracy: 0.9118 - val_loss: 0.2449 - val_accuracy: 0.9277\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2842 - accuracy: 0.9160 - val_loss: 0.2442 - val_accuracy: 0.9279\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9178 - val_loss: 0.2415 - val_accuracy: 0.9294\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2751 - accuracy: 0.9168 - val_loss: 0.2407 - val_accuracy: 0.9290\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2830 - accuracy: 0.9147 - val_loss: 0.2384 - val_accuracy: 0.9294\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2805 - accuracy: 0.9175 - val_loss: 0.2386 - val_accuracy: 0.9311\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.9192 - val_loss: 0.2357 - val_accuracy: 0.9306\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2748 - accuracy: 0.9171 - val_loss: 0.2338 - val_accuracy: 0.9311\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2577 - accuracy: 0.9215 - val_loss: 0.2330 - val_accuracy: 0.9307\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2643 - accuracy: 0.9194 - val_loss: 0.2314 - val_accuracy: 0.9317\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 4ms/step - loss: 2.1257 - accuracy: 0.2492 - val_loss: 1.0393 - val_accuracy: 0.7538\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1910 - accuracy: 0.6009 - val_loss: 0.5856 - val_accuracy: 0.8467\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8424 - accuracy: 0.7242 - val_loss: 0.4550 - val_accuracy: 0.8740\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6957 - accuracy: 0.7796 - val_loss: 0.3924 - val_accuracy: 0.8884\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6089 - accuracy: 0.8090 - val_loss: 0.3570 - val_accuracy: 0.8957\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5590 - accuracy: 0.8274 - val_loss: 0.3311 - val_accuracy: 0.9038\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5134 - accuracy: 0.8460 - val_loss: 0.3145 - val_accuracy: 0.9060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4810 - accuracy: 0.8516 - val_loss: 0.2980 - val_accuracy: 0.9103\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4486 - accuracy: 0.8656 - val_loss: 0.2846 - val_accuracy: 0.9139\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.8730 - val_loss: 0.2729 - val_accuracy: 0.9172\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - accuracy: 0.8800 - val_loss: 0.2609 - val_accuracy: 0.9208\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3897 - accuracy: 0.8831 - val_loss: 0.2522 - val_accuracy: 0.9228\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3693 - accuracy: 0.8884 - val_loss: 0.2436 - val_accuracy: 0.9255\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.8948 - val_loss: 0.2363 - val_accuracy: 0.9270\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8992 - val_loss: 0.2290 - val_accuracy: 0.9304\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3297 - accuracy: 0.9018 - val_loss: 0.2223 - val_accuracy: 0.9327\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3172 - accuracy: 0.9059 - val_loss: 0.2166 - val_accuracy: 0.9338\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3060 - accuracy: 0.9094 - val_loss: 0.2106 - val_accuracy: 0.9348\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2999 - accuracy: 0.9100 - val_loss: 0.2066 - val_accuracy: 0.9372\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2934 - accuracy: 0.9140 - val_loss: 0.2004 - val_accuracy: 0.9382\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2820 - accuracy: 0.9168 - val_loss: 0.1954 - val_accuracy: 0.9392\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2615 - accuracy: 0.9227 - val_loss: 0.1915 - val_accuracy: 0.9405\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2611 - accuracy: 0.9243 - val_loss: 0.1872 - val_accuracy: 0.9423\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2520 - accuracy: 0.9255 - val_loss: 0.1847 - val_accuracy: 0.9438\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2479 - accuracy: 0.9263 - val_loss: 0.1803 - val_accuracy: 0.9452\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2358 - accuracy: 0.9306 - val_loss: 0.1791 - val_accuracy: 0.9448\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2329 - accuracy: 0.9315 - val_loss: 0.1736 - val_accuracy: 0.9463\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2265 - accuracy: 0.9338 - val_loss: 0.1713 - val_accuracy: 0.9472\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9348 - val_loss: 0.1688 - val_accuracy: 0.9484\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2164 - accuracy: 0.9378 - val_loss: 0.1670 - val_accuracy: 0.9488\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2148 - accuracy: 0.9362 - val_loss: 0.1642 - val_accuracy: 0.9500\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2016 - accuracy: 0.9409 - val_loss: 0.1620 - val_accuracy: 0.9506\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2026 - accuracy: 0.9404 - val_loss: 0.1603 - val_accuracy: 0.9509\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1907 - accuracy: 0.9427 - val_loss: 0.1584 - val_accuracy: 0.9514\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1867 - accuracy: 0.9451 - val_loss: 0.1559 - val_accuracy: 0.9524\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1878 - accuracy: 0.9449 - val_loss: 0.1540 - val_accuracy: 0.9530\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1793 - accuracy: 0.9460 - val_loss: 0.1531 - val_accuracy: 0.9539\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1758 - accuracy: 0.9491 - val_loss: 0.1514 - val_accuracy: 0.9532\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1756 - accuracy: 0.9472 - val_loss: 0.1496 - val_accuracy: 0.9540\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1732 - accuracy: 0.9477 - val_loss: 0.1482 - val_accuracy: 0.9549\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1671 - accuracy: 0.9517 - val_loss: 0.1469 - val_accuracy: 0.9543\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1608 - accuracy: 0.9529 - val_loss: 0.1461 - val_accuracy: 0.9553\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1632 - accuracy: 0.9513 - val_loss: 0.1443 - val_accuracy: 0.9558\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1570 - accuracy: 0.9533 - val_loss: 0.1436 - val_accuracy: 0.9560\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9543 - val_loss: 0.1430 - val_accuracy: 0.9565\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1485 - accuracy: 0.9565 - val_loss: 0.1420 - val_accuracy: 0.9574\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1451 - accuracy: 0.9569 - val_loss: 0.1418 - val_accuracy: 0.9561\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1441 - accuracy: 0.9574 - val_loss: 0.1396 - val_accuracy: 0.9574\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1439 - accuracy: 0.9567 - val_loss: 0.1394 - val_accuracy: 0.9572\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9595 - val_loss: 0.1385 - val_accuracy: 0.9574\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 4ms/step - loss: 2.0148 - accuracy: 0.2940 - val_loss: 0.7983 - val_accuracy: 0.8237\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9726 - accuracy: 0.6841 - val_loss: 0.4992 - val_accuracy: 0.8675\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7229 - accuracy: 0.7708 - val_loss: 0.4138 - val_accuracy: 0.8852\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6066 - accuracy: 0.8103 - val_loss: 0.3704 - val_accuracy: 0.8939\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5416 - accuracy: 0.8336 - val_loss: 0.3458 - val_accuracy: 0.8992\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5019 - accuracy: 0.8454 - val_loss: 0.3255 - val_accuracy: 0.9043\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4715 - accuracy: 0.8570 - val_loss: 0.3105 - val_accuracy: 0.9093\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8677 - val_loss: 0.2975 - val_accuracy: 0.9121\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4257 - accuracy: 0.8736 - val_loss: 0.2872 - val_accuracy: 0.9165\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3999 - accuracy: 0.8787 - val_loss: 0.2784 - val_accuracy: 0.9181\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3976 - accuracy: 0.8816 - val_loss: 0.2696 - val_accuracy: 0.9217\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3691 - accuracy: 0.8878 - val_loss: 0.2617 - val_accuracy: 0.9237\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3583 - accuracy: 0.8927 - val_loss: 0.2550 - val_accuracy: 0.9250\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3504 - accuracy: 0.8946 - val_loss: 0.2480 - val_accuracy: 0.9268\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.8972 - val_loss: 0.2419 - val_accuracy: 0.9289\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.9006 - val_loss: 0.2377 - val_accuracy: 0.9301\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3193 - accuracy: 0.9052 - val_loss: 0.2317 - val_accuracy: 0.9310\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3123 - accuracy: 0.9064 - val_loss: 0.2269 - val_accuracy: 0.9332\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.9095 - val_loss: 0.2218 - val_accuracy: 0.9341\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2929 - accuracy: 0.9140 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2929 - accuracy: 0.9135 - val_loss: 0.2141 - val_accuracy: 0.9364\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2752 - accuracy: 0.9182 - val_loss: 0.2103 - val_accuracy: 0.9382\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2748 - accuracy: 0.9171 - val_loss: 0.2074 - val_accuracy: 0.9384\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2691 - accuracy: 0.9198 - val_loss: 0.2034 - val_accuracy: 0.9402\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2612 - accuracy: 0.9202 - val_loss: 0.2001 - val_accuracy: 0.9417\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2542 - accuracy: 0.9252 - val_loss: 0.1968 - val_accuracy: 0.9424\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2446 - accuracy: 0.9279 - val_loss: 0.1943 - val_accuracy: 0.9430\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2447 - accuracy: 0.9266 - val_loss: 0.1902 - val_accuracy: 0.9442\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2433 - accuracy: 0.9268 - val_loss: 0.1876 - val_accuracy: 0.9452\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2390 - accuracy: 0.9271 - val_loss: 0.1865 - val_accuracy: 0.9447\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2311 - accuracy: 0.9292 - val_loss: 0.1825 - val_accuracy: 0.9459\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2236 - accuracy: 0.9339 - val_loss: 0.1808 - val_accuracy: 0.9461\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2202 - accuracy: 0.9323 - val_loss: 0.1799 - val_accuracy: 0.9468\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9354 - val_loss: 0.1768 - val_accuracy: 0.9471\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9366 - val_loss: 0.1741 - val_accuracy: 0.9483\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9364 - val_loss: 0.1723 - val_accuracy: 0.9485\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2088 - accuracy: 0.9379 - val_loss: 0.1707 - val_accuracy: 0.9495\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2017 - accuracy: 0.9387 - val_loss: 0.1698 - val_accuracy: 0.9489\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1979 - accuracy: 0.9404 - val_loss: 0.1682 - val_accuracy: 0.9499\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9398 - val_loss: 0.1660 - val_accuracy: 0.9506\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9423 - val_loss: 0.1652 - val_accuracy: 0.9506\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9462 - val_loss: 0.1632 - val_accuracy: 0.9512\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1872 - accuracy: 0.9422 - val_loss: 0.1620 - val_accuracy: 0.9517\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1865 - accuracy: 0.9441 - val_loss: 0.1620 - val_accuracy: 0.9511\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9473 - val_loss: 0.1589 - val_accuracy: 0.9527\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1799 - accuracy: 0.9452 - val_loss: 0.1576 - val_accuracy: 0.9527\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9497 - val_loss: 0.1569 - val_accuracy: 0.9531\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1713 - accuracy: 0.9484 - val_loss: 0.1557 - val_accuracy: 0.9539\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9474 - val_loss: 0.1550 - val_accuracy: 0.9538\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9502 - val_loss: 0.1539 - val_accuracy: 0.9542\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6155 - accuracy: 0.4580 - val_loss: 0.5246 - val_accuracy: 0.8568\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7037 - accuracy: 0.7746 - val_loss: 0.4131 - val_accuracy: 0.8803\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5716 - accuracy: 0.8214 - val_loss: 0.3744 - val_accuracy: 0.8882\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5289 - accuracy: 0.8344 - val_loss: 0.3552 - val_accuracy: 0.8926\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4975 - accuracy: 0.8472 - val_loss: 0.3385 - val_accuracy: 0.8976\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4688 - accuracy: 0.8564 - val_loss: 0.3272 - val_accuracy: 0.9009\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4480 - accuracy: 0.8620 - val_loss: 0.3214 - val_accuracy: 0.9022\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4380 - accuracy: 0.8662 - val_loss: 0.3120 - val_accuracy: 0.9064\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4193 - accuracy: 0.8720 - val_loss: 0.3068 - val_accuracy: 0.9084\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4087 - accuracy: 0.8746 - val_loss: 0.3003 - val_accuracy: 0.9105\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3952 - accuracy: 0.8810 - val_loss: 0.2963 - val_accuracy: 0.9117\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3929 - accuracy: 0.8810 - val_loss: 0.2888 - val_accuracy: 0.9134\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3818 - accuracy: 0.8853 - val_loss: 0.2843 - val_accuracy: 0.9153\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3665 - accuracy: 0.8890 - val_loss: 0.2804 - val_accuracy: 0.9158\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3630 - accuracy: 0.8894 - val_loss: 0.2765 - val_accuracy: 0.9174\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3597 - accuracy: 0.8906 - val_loss: 0.2719 - val_accuracy: 0.9183\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8942 - val_loss: 0.2679 - val_accuracy: 0.9197\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3457 - accuracy: 0.8932 - val_loss: 0.2649 - val_accuracy: 0.9203\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3420 - accuracy: 0.8962 - val_loss: 0.2608 - val_accuracy: 0.9219\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3269 - accuracy: 0.9003 - val_loss: 0.2573 - val_accuracy: 0.9224\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3259 - accuracy: 0.8992 - val_loss: 0.2543 - val_accuracy: 0.9232\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3200 - accuracy: 0.9021 - val_loss: 0.2515 - val_accuracy: 0.9247\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.9022 - val_loss: 0.2494 - val_accuracy: 0.9238\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.9045 - val_loss: 0.2445 - val_accuracy: 0.9256\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3077 - accuracy: 0.9056 - val_loss: 0.2417 - val_accuracy: 0.9280\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3078 - accuracy: 0.9068 - val_loss: 0.2387 - val_accuracy: 0.9291\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3040 - accuracy: 0.9088 - val_loss: 0.2366 - val_accuracy: 0.9295\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2913 - accuracy: 0.9109 - val_loss: 0.2333 - val_accuracy: 0.9301\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2921 - accuracy: 0.9112 - val_loss: 0.2302 - val_accuracy: 0.9314\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2871 - accuracy: 0.9124 - val_loss: 0.2290 - val_accuracy: 0.9310\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2747 - accuracy: 0.9164 - val_loss: 0.2251 - val_accuracy: 0.9328\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.9158 - val_loss: 0.2238 - val_accuracy: 0.9331\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2779 - accuracy: 0.9148 - val_loss: 0.2203 - val_accuracy: 0.9340\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2738 - accuracy: 0.9152 - val_loss: 0.2193 - val_accuracy: 0.9343\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2738 - accuracy: 0.9162 - val_loss: 0.2182 - val_accuracy: 0.9344\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.9170 - val_loss: 0.2157 - val_accuracy: 0.9358\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2654 - accuracy: 0.9190 - val_loss: 0.2143 - val_accuracy: 0.9353\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2610 - accuracy: 0.9192 - val_loss: 0.2124 - val_accuracy: 0.9363\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2532 - accuracy: 0.9225 - val_loss: 0.2091 - val_accuracy: 0.9379\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2479 - accuracy: 0.9241 - val_loss: 0.2081 - val_accuracy: 0.9377\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2532 - accuracy: 0.9240 - val_loss: 0.2052 - val_accuracy: 0.9397\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2440 - accuracy: 0.9250 - val_loss: 0.2035 - val_accuracy: 0.9394\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2470 - accuracy: 0.9268 - val_loss: 0.2015 - val_accuracy: 0.9394\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.9258 - val_loss: 0.2008 - val_accuracy: 0.9404\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2335 - accuracy: 0.9291 - val_loss: 0.1986 - val_accuracy: 0.9412\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2353 - accuracy: 0.9274 - val_loss: 0.1975 - val_accuracy: 0.9407\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2342 - accuracy: 0.9277 - val_loss: 0.1968 - val_accuracy: 0.9406\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2240 - accuracy: 0.9303 - val_loss: 0.1961 - val_accuracy: 0.9417\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2300 - accuracy: 0.9281 - val_loss: 0.1937 - val_accuracy: 0.9426\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2268 - accuracy: 0.9307 - val_loss: 0.1920 - val_accuracy: 0.9423\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5500 - accuracy: 0.5163 - val_loss: 0.4232 - val_accuracy: 0.8733\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6796 - accuracy: 0.7840 - val_loss: 0.3729 - val_accuracy: 0.8896\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5763 - accuracy: 0.8231 - val_loss: 0.3591 - val_accuracy: 0.8945\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5269 - accuracy: 0.8384 - val_loss: 0.3404 - val_accuracy: 0.9010\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5089 - accuracy: 0.8458 - val_loss: 0.3323 - val_accuracy: 0.9047\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4723 - accuracy: 0.8532 - val_loss: 0.3287 - val_accuracy: 0.9039\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4541 - accuracy: 0.8608 - val_loss: 0.3210 - val_accuracy: 0.9089\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4428 - accuracy: 0.8665 - val_loss: 0.3180 - val_accuracy: 0.9082\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4273 - accuracy: 0.8696 - val_loss: 0.3121 - val_accuracy: 0.9074\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4165 - accuracy: 0.8730 - val_loss: 0.3092 - val_accuracy: 0.9091\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4076 - accuracy: 0.8738 - val_loss: 0.3044 - val_accuracy: 0.9112\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3967 - accuracy: 0.8811 - val_loss: 0.3019 - val_accuracy: 0.9105\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4000 - accuracy: 0.8798 - val_loss: 0.2969 - val_accuracy: 0.9122\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8858 - val_loss: 0.2948 - val_accuracy: 0.9129\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3788 - accuracy: 0.8820 - val_loss: 0.2903 - val_accuracy: 0.9143\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3735 - accuracy: 0.8838 - val_loss: 0.2864 - val_accuracy: 0.9151\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3766 - accuracy: 0.8849 - val_loss: 0.2858 - val_accuracy: 0.9175\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.8897 - val_loss: 0.2840 - val_accuracy: 0.9164\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8958 - val_loss: 0.2793 - val_accuracy: 0.9176\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8920 - val_loss: 0.2748 - val_accuracy: 0.9197\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8927 - val_loss: 0.2752 - val_accuracy: 0.9192\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3347 - accuracy: 0.8969 - val_loss: 0.2715 - val_accuracy: 0.9195\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3337 - accuracy: 0.8955 - val_loss: 0.2688 - val_accuracy: 0.9203\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3333 - accuracy: 0.8973 - val_loss: 0.2654 - val_accuracy: 0.9212\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.8980 - val_loss: 0.2620 - val_accuracy: 0.9227\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3297 - accuracy: 0.8999 - val_loss: 0.2592 - val_accuracy: 0.9239\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3138 - accuracy: 0.9020 - val_loss: 0.2565 - val_accuracy: 0.9247\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3095 - accuracy: 0.9053 - val_loss: 0.2542 - val_accuracy: 0.9257\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3054 - accuracy: 0.9057 - val_loss: 0.2520 - val_accuracy: 0.9243\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3092 - accuracy: 0.9063 - val_loss: 0.2492 - val_accuracy: 0.9273\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3022 - accuracy: 0.9052 - val_loss: 0.2463 - val_accuracy: 0.9278\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3026 - accuracy: 0.9083 - val_loss: 0.2440 - val_accuracy: 0.9281\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3019 - accuracy: 0.9056 - val_loss: 0.2421 - val_accuracy: 0.9287\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2945 - accuracy: 0.9086 - val_loss: 0.2399 - val_accuracy: 0.9298\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.9112 - val_loss: 0.2380 - val_accuracy: 0.9303\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2959 - accuracy: 0.9088 - val_loss: 0.2351 - val_accuracy: 0.9321\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2760 - accuracy: 0.9153 - val_loss: 0.2319 - val_accuracy: 0.9316\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2778 - accuracy: 0.9127 - val_loss: 0.2301 - val_accuracy: 0.9325\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2804 - accuracy: 0.9132 - val_loss: 0.2282 - val_accuracy: 0.9329\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2704 - accuracy: 0.9161 - val_loss: 0.2251 - val_accuracy: 0.9347\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2684 - accuracy: 0.9172 - val_loss: 0.2237 - val_accuracy: 0.9339\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2679 - accuracy: 0.9175 - val_loss: 0.2215 - val_accuracy: 0.9352\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2644 - accuracy: 0.9185 - val_loss: 0.2208 - val_accuracy: 0.9355\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.9198 - val_loss: 0.2190 - val_accuracy: 0.9356\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2633 - accuracy: 0.9168 - val_loss: 0.2165 - val_accuracy: 0.9358\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.9171 - val_loss: 0.2158 - val_accuracy: 0.9362\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2566 - accuracy: 0.9200 - val_loss: 0.2153 - val_accuracy: 0.9368\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2560 - accuracy: 0.9194 - val_loss: 0.2115 - val_accuracy: 0.9381\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2570 - accuracy: 0.9208 - val_loss: 0.2107 - val_accuracy: 0.9385\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2582 - accuracy: 0.9206 - val_loss: 0.2088 - val_accuracy: 0.9387\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.1961 - accuracy: 0.2164 - val_loss: 1.3614 - val_accuracy: 0.7382\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2811 - accuracy: 0.6104 - val_loss: 0.6302 - val_accuracy: 0.8402\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8257 - accuracy: 0.7400 - val_loss: 0.4844 - val_accuracy: 0.8715\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6886 - accuracy: 0.7890 - val_loss: 0.4243 - val_accuracy: 0.8845\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5998 - accuracy: 0.8168 - val_loss: 0.3849 - val_accuracy: 0.8918\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5421 - accuracy: 0.8378 - val_loss: 0.3607 - val_accuracy: 0.8990\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4977 - accuracy: 0.8508 - val_loss: 0.3407 - val_accuracy: 0.9031\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4776 - accuracy: 0.8589 - val_loss: 0.3251 - val_accuracy: 0.9061\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4592 - accuracy: 0.8627 - val_loss: 0.3118 - val_accuracy: 0.9098\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4273 - accuracy: 0.8701 - val_loss: 0.2996 - val_accuracy: 0.9114\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4238 - accuracy: 0.8759 - val_loss: 0.2889 - val_accuracy: 0.9151\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3916 - accuracy: 0.8822 - val_loss: 0.2791 - val_accuracy: 0.9169\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3819 - accuracy: 0.8865 - val_loss: 0.2707 - val_accuracy: 0.9186\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3719 - accuracy: 0.8900 - val_loss: 0.2630 - val_accuracy: 0.9220\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8967 - val_loss: 0.2550 - val_accuracy: 0.9243\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3455 - accuracy: 0.8979 - val_loss: 0.2480 - val_accuracy: 0.9255\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3275 - accuracy: 0.9034 - val_loss: 0.2417 - val_accuracy: 0.9275\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3236 - accuracy: 0.9036 - val_loss: 0.2358 - val_accuracy: 0.9291\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3090 - accuracy: 0.9089 - val_loss: 0.2308 - val_accuracy: 0.9308\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3028 - accuracy: 0.9094 - val_loss: 0.2251 - val_accuracy: 0.9327\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2993 - accuracy: 0.9095 - val_loss: 0.2193 - val_accuracy: 0.9344\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2860 - accuracy: 0.9153 - val_loss: 0.2158 - val_accuracy: 0.9346\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2770 - accuracy: 0.9194 - val_loss: 0.2105 - val_accuracy: 0.9364\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2702 - accuracy: 0.9201 - val_loss: 0.2062 - val_accuracy: 0.9369\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2694 - accuracy: 0.9207 - val_loss: 0.2027 - val_accuracy: 0.9389\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2553 - accuracy: 0.9237 - val_loss: 0.1993 - val_accuracy: 0.9393\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2548 - accuracy: 0.9236 - val_loss: 0.1956 - val_accuracy: 0.9408\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2460 - accuracy: 0.9258 - val_loss: 0.1923 - val_accuracy: 0.9418\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2472 - accuracy: 0.9257 - val_loss: 0.1890 - val_accuracy: 0.9424\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2344 - accuracy: 0.9279 - val_loss: 0.1861 - val_accuracy: 0.9432\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2330 - accuracy: 0.9295 - val_loss: 0.1831 - val_accuracy: 0.9441\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2283 - accuracy: 0.9337 - val_loss: 0.1806 - val_accuracy: 0.9453\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2277 - accuracy: 0.9320 - val_loss: 0.1784 - val_accuracy: 0.9449\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2217 - accuracy: 0.9343 - val_loss: 0.1761 - val_accuracy: 0.9463\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2144 - accuracy: 0.9362 - val_loss: 0.1732 - val_accuracy: 0.9468\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2103 - accuracy: 0.9365 - val_loss: 0.1713 - val_accuracy: 0.9479\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2031 - accuracy: 0.9387 - val_loss: 0.1696 - val_accuracy: 0.9485\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2017 - accuracy: 0.9390 - val_loss: 0.1671 - val_accuracy: 0.9488\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2036 - accuracy: 0.9390 - val_loss: 0.1649 - val_accuracy: 0.9497\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1965 - accuracy: 0.9431 - val_loss: 0.1637 - val_accuracy: 0.9497\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1924 - accuracy: 0.9418 - val_loss: 0.1619 - val_accuracy: 0.9497\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1951 - accuracy: 0.9431 - val_loss: 0.1603 - val_accuracy: 0.9504\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1875 - accuracy: 0.9437 - val_loss: 0.1588 - val_accuracy: 0.9515\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1816 - accuracy: 0.9449 - val_loss: 0.1571 - val_accuracy: 0.9527\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1799 - accuracy: 0.9466 - val_loss: 0.1555 - val_accuracy: 0.9528\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1754 - accuracy: 0.9460 - val_loss: 0.1545 - val_accuracy: 0.9528\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1713 - accuracy: 0.9489 - val_loss: 0.1529 - val_accuracy: 0.9530\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1692 - accuracy: 0.9482 - val_loss: 0.1520 - val_accuracy: 0.9526\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9507 - val_loss: 0.1507 - val_accuracy: 0.9552\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1657 - accuracy: 0.9505 - val_loss: 0.1496 - val_accuracy: 0.9545\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.1884 - accuracy: 0.2455 - val_loss: 1.6140 - val_accuracy: 0.7075\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4498 - accuracy: 0.6083 - val_loss: 0.7425 - val_accuracy: 0.8304\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9066 - accuracy: 0.7192 - val_loss: 0.5397 - val_accuracy: 0.8596\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7216 - accuracy: 0.7770 - val_loss: 0.4644 - val_accuracy: 0.8733\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6236 - accuracy: 0.8094 - val_loss: 0.4210 - val_accuracy: 0.8829\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5723 - accuracy: 0.8266 - val_loss: 0.3923 - val_accuracy: 0.8886\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5398 - accuracy: 0.8388 - val_loss: 0.3716 - val_accuracy: 0.8931\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5074 - accuracy: 0.8483 - val_loss: 0.3558 - val_accuracy: 0.8971\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4864 - accuracy: 0.8551 - val_loss: 0.3421 - val_accuracy: 0.8989\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4619 - accuracy: 0.8622 - val_loss: 0.3316 - val_accuracy: 0.9019\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4352 - accuracy: 0.8688 - val_loss: 0.3224 - val_accuracy: 0.9042\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4280 - accuracy: 0.8718 - val_loss: 0.3154 - val_accuracy: 0.9053\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4187 - accuracy: 0.8734 - val_loss: 0.3054 - val_accuracy: 0.9079\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4057 - accuracy: 0.8785 - val_loss: 0.2984 - val_accuracy: 0.9102\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3911 - accuracy: 0.8828 - val_loss: 0.2919 - val_accuracy: 0.9121\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3897 - accuracy: 0.8833 - val_loss: 0.2857 - val_accuracy: 0.9133\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3759 - accuracy: 0.8872 - val_loss: 0.2800 - val_accuracy: 0.9157\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3647 - accuracy: 0.8910 - val_loss: 0.2750 - val_accuracy: 0.9161\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8916 - val_loss: 0.2704 - val_accuracy: 0.9170\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3560 - accuracy: 0.8949 - val_loss: 0.2657 - val_accuracy: 0.9192\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3452 - accuracy: 0.8970 - val_loss: 0.2602 - val_accuracy: 0.9210\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3368 - accuracy: 0.8988 - val_loss: 0.2563 - val_accuracy: 0.9214\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3317 - accuracy: 0.8997 - val_loss: 0.2523 - val_accuracy: 0.9223\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.9035 - val_loss: 0.2479 - val_accuracy: 0.9233\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.9010 - val_loss: 0.2445 - val_accuracy: 0.9247\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3101 - accuracy: 0.9050 - val_loss: 0.2412 - val_accuracy: 0.9262\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3133 - accuracy: 0.9070 - val_loss: 0.2370 - val_accuracy: 0.9278\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3003 - accuracy: 0.9106 - val_loss: 0.2336 - val_accuracy: 0.9291\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2933 - accuracy: 0.9123 - val_loss: 0.2308 - val_accuracy: 0.9294\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2929 - accuracy: 0.9117 - val_loss: 0.2271 - val_accuracy: 0.9308\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2862 - accuracy: 0.9135 - val_loss: 0.2240 - val_accuracy: 0.9321\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.9148 - val_loss: 0.2217 - val_accuracy: 0.9316\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2749 - accuracy: 0.9159 - val_loss: 0.2185 - val_accuracy: 0.9330\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2782 - accuracy: 0.9180 - val_loss: 0.2157 - val_accuracy: 0.9335\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2689 - accuracy: 0.9178 - val_loss: 0.2127 - val_accuracy: 0.9357\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2653 - accuracy: 0.9198 - val_loss: 0.2108 - val_accuracy: 0.9365\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2609 - accuracy: 0.9197 - val_loss: 0.2076 - val_accuracy: 0.9372\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2530 - accuracy: 0.9229 - val_loss: 0.2051 - val_accuracy: 0.9376\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2491 - accuracy: 0.9257 - val_loss: 0.2026 - val_accuracy: 0.9384\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2458 - accuracy: 0.9236 - val_loss: 0.2007 - val_accuracy: 0.9388\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2457 - accuracy: 0.9254 - val_loss: 0.1983 - val_accuracy: 0.9392\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2349 - accuracy: 0.9296 - val_loss: 0.1961 - val_accuracy: 0.9398\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2401 - accuracy: 0.9281 - val_loss: 0.1940 - val_accuracy: 0.9411\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2398 - accuracy: 0.9274 - val_loss: 0.1921 - val_accuracy: 0.9417\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2330 - accuracy: 0.9278 - val_loss: 0.1898 - val_accuracy: 0.9418\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2283 - accuracy: 0.9312 - val_loss: 0.1880 - val_accuracy: 0.9417\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2293 - accuracy: 0.9290 - val_loss: 0.1862 - val_accuracy: 0.9424\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2204 - accuracy: 0.9330 - val_loss: 0.1846 - val_accuracy: 0.9427\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2159 - accuracy: 0.9340 - val_loss: 0.1827 - val_accuracy: 0.9432\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2154 - accuracy: 0.9344 - val_loss: 0.1816 - val_accuracy: 0.9435\n",
            "{'loss': [1.1650047302246094, 0.6648600101470947, 0.5616602897644043, 0.5179184675216675, 0.48864224553108215, 0.4687733054161072, 0.44856876134872437, 0.4380916357040405, 0.4242800772190094, 0.41342899203300476, 0.4055749475955963, 0.3962901532649994, 0.3934352993965149, 0.38338756561279297, 0.3800586760044098, 0.37400761246681213, 0.3663060665130615, 0.36431246995925903, 0.3580589294433594, 0.35163185000419617, 0.34921085834503174, 0.34318897128105164, 0.34322893619537354, 0.3362010419368744, 0.33384066820144653, 0.3341507017612457, 0.32416167855262756, 0.322189599275589, 0.31929659843444824, 0.31671810150146484, 0.3124076724052429, 0.3128633201122284, 0.3036215007305145, 0.30453822016716003, 0.30396535992622375, 0.3004835546016693, 0.29629796743392944, 0.29271572828292847, 0.29240572452545166, 0.2885500490665436, 0.2852843105792999, 0.28291556239128113, 0.27565962076187134, 0.27479612827301025, 0.27576154470443726, 0.2739548683166504, 0.26946398615837097, 0.26933443546295166, 0.26591283082962036, 0.26506349444389343], 'accuracy': [0.6234583258628845, 0.7946458458900452, 0.8256041407585144, 0.8417916893959045, 0.8503541946411133, 0.8549166917800903, 0.8642500042915344, 0.8664583563804626, 0.8711249828338623, 0.8736041784286499, 0.8775833249092102, 0.8791458606719971, 0.8809791803359985, 0.8836458325386047, 0.8848541378974915, 0.8872083425521851, 0.8891875147819519, 0.8898541927337646, 0.8920624852180481, 0.8941666483879089, 0.8949791789054871, 0.8960416913032532, 0.8960000276565552, 0.8979791402816772, 0.9000416398048401, 0.8980833292007446, 0.9023958444595337, 0.9025416374206543, 0.9046041369438171, 0.903249979019165, 0.9049583077430725, 0.9068333506584167, 0.9090208411216736, 0.9070416688919067, 0.9077500104904175, 0.9098333120346069, 0.9096041917800903, 0.9117916822433472, 0.9117708206176758, 0.9129791855812073, 0.9121249914169312, 0.9146249890327454, 0.9164166450500488, 0.9179166555404663, 0.9160833358764648, 0.9193124771118164, 0.9182291626930237, 0.917145848274231, 0.9187708497047424, 0.9184166789054871], 'val_loss': [0.5267103314399719, 0.417365163564682, 0.37984952330589294, 0.35814446210861206, 0.3468318581581116, 0.3368266522884369, 0.33021649718284607, 0.32403990626335144, 0.3180777132511139, 0.31449753046035767, 0.310403436422348, 0.30692872405052185, 0.30327948927879333, 0.3012462854385376, 0.2971973121166229, 0.2953406870365143, 0.2935864329338074, 0.2905229330062866, 0.2866467237472534, 0.28458571434020996, 0.28392699360847473, 0.280036598443985, 0.2785835564136505, 0.276211678981781, 0.2734537124633789, 0.2715042531490326, 0.27019500732421875, 0.267422616481781, 0.2654423713684082, 0.2638975977897644, 0.2620944678783417, 0.2604188323020935, 0.2573464512825012, 0.2562805712223053, 0.2562236785888672, 0.25338006019592285, 0.2512038052082062, 0.24933463335037231, 0.248437762260437, 0.24730639159679413, 0.24493275582790375, 0.24415698647499084, 0.24145300686359406, 0.24065260589122772, 0.23841606080532074, 0.23862440884113312, 0.23572427034378052, 0.23382462561130524, 0.23302297294139862, 0.2314373403787613], 'val_accuracy': [0.8571666479110718, 0.8802499771118164, 0.887333333492279, 0.8949166536331177, 0.8976666927337646, 0.9009166955947876, 0.9024999737739563, 0.9049999713897705, 0.9067500233650208, 0.9075833559036255, 0.909583330154419, 0.9101666808128357, 0.9106666445732117, 0.9115833044052124, 0.9129166603088379, 0.9127500057220459, 0.9139166474342346, 0.9150000214576721, 0.9158333539962769, 0.9170833230018616, 0.9160000085830688, 0.9176666736602783, 0.9177500009536743, 0.9194166660308838, 0.9193333387374878, 0.9203333258628845, 0.921500027179718, 0.9210000038146973, 0.921999990940094, 0.92208331823349, 0.9232500195503235, 0.9234166741371155, 0.9244999885559082, 0.9245833158493042, 0.924833357334137, 0.9264166951179504, 0.9258333444595337, 0.9269999861717224, 0.9262499809265137, 0.9271666407585144, 0.9276666641235352, 0.9279166460037231, 0.9294166564941406, 0.9290000200271606, 0.9294166564941406, 0.9310833215713501, 0.9305833578109741, 0.9310833215713501, 0.9306666851043701, 0.9316666722297668]}\n",
            "{'loss': [1.8580437898635864, 1.0810178518295288, 0.8019664883613586, 0.6720196008682251, 0.5950505137443542, 0.5414102673530579, 0.504474401473999, 0.47188708186149597, 0.44641971588134766, 0.4171975553035736, 0.40031519532203674, 0.3794046938419342, 0.3670906722545624, 0.35206228494644165, 0.33908042311668396, 0.32837462425231934, 0.3149382472038269, 0.30391043424606323, 0.29469063878059387, 0.2868763506412506, 0.27774888277053833, 0.26748478412628174, 0.25936535000801086, 0.25039902329444885, 0.24614709615707397, 0.23434269428253174, 0.23134446144104004, 0.2261916697025299, 0.22077664732933044, 0.21543453633785248, 0.21168404817581177, 0.19961704313755035, 0.2014133781194687, 0.19517932832241058, 0.1906067430973053, 0.18474550545215607, 0.18236489593982697, 0.17855727672576904, 0.1748337745666504, 0.1729608178138733, 0.16600024700164795, 0.16273722052574158, 0.1621706783771515, 0.15650999546051025, 0.15114551782608032, 0.15048620104789734, 0.1474851816892624, 0.143208846449852, 0.14580713212490082, 0.1373768150806427], 'accuracy': [0.36274999380111694, 0.6395208239555359, 0.7400416731834412, 0.7872499823570251, 0.8144583106040955, 0.8337083458900452, 0.8477916717529297, 0.8559791445732117, 0.867270827293396, 0.875166654586792, 0.8810833096504211, 0.8863541483879089, 0.890250027179718, 0.8945833444595337, 0.898354172706604, 0.9026041626930237, 0.90645831823349, 0.9097916483879089, 0.9125416874885559, 0.9154999852180481, 0.9183333516120911, 0.9213958382606506, 0.9240624904632568, 0.9258333444595337, 0.926354169845581, 0.9309999942779541, 0.9323541522026062, 0.9330833554267883, 0.9350416660308838, 0.9370208382606506, 0.9379583597183228, 0.942020833492279, 0.9409375190734863, 0.9417291879653931, 0.9433749914169312, 0.9464374780654907, 0.9458125233650208, 0.948270857334137, 0.9481458067893982, 0.9478750228881836, 0.9512916803359985, 0.9517916440963745, 0.9520000219345093, 0.9543541669845581, 0.9543541669845581, 0.9553333520889282, 0.9563124775886536, 0.9573333263397217, 0.9564999938011169, 0.9600208401679993], 'val_loss': [1.0392588376998901, 0.585565984249115, 0.4549710154533386, 0.3923552930355072, 0.3570484220981598, 0.33114093542099, 0.3144877552986145, 0.2979545593261719, 0.28456583619117737, 0.27291610836982727, 0.2608785033226013, 0.2522042393684387, 0.24356578290462494, 0.23630903661251068, 0.22895818948745728, 0.22225870192050934, 0.21655452251434326, 0.21058890223503113, 0.20657892525196075, 0.20036740601062775, 0.19542032480239868, 0.19154080748558044, 0.18715038895606995, 0.1846613585948944, 0.18030771613121033, 0.17907080054283142, 0.17364689707756042, 0.17134246230125427, 0.1688496470451355, 0.16695386171340942, 0.1641552895307541, 0.16203877329826355, 0.16025026142597198, 0.15838293731212616, 0.15588828921318054, 0.15399977564811707, 0.1531020849943161, 0.15135951340198517, 0.1496075987815857, 0.1482132524251938, 0.1468755006790161, 0.14608225226402283, 0.14433516561985016, 0.14356917142868042, 0.14303863048553467, 0.14195019006729126, 0.14180666208267212, 0.13958171010017395, 0.13943324983119965, 0.13845032453536987], 'val_accuracy': [0.7538333535194397, 0.846666693687439, 0.8740000128746033, 0.8884166479110718, 0.8956666588783264, 0.9038333296775818, 0.906000018119812, 0.9102500081062317, 0.9139166474342346, 0.9172499775886536, 0.9208333492279053, 0.9228333234786987, 0.9254999756813049, 0.9269999861717224, 0.9304166436195374, 0.9326666593551636, 0.9338333606719971, 0.9347500205039978, 0.937166690826416, 0.9381666779518127, 0.9392499923706055, 0.940500020980835, 0.9423333406448364, 0.9437500238418579, 0.9451666474342346, 0.9448333382606506, 0.9462500214576721, 0.9471666812896729, 0.9484166502952576, 0.9488333463668823, 0.949999988079071, 0.9505833387374878, 0.9509166479110718, 0.9514166712760925, 0.9524166584014893, 0.953000009059906, 0.9539166688919067, 0.953249990940094, 0.9539999961853027, 0.9549166560173035, 0.9543333053588867, 0.9552500247955322, 0.9558333158493042, 0.9559999704360962, 0.9564999938011169, 0.9574166536331177, 0.956083357334137, 0.9574166536331177, 0.9571666717529297, 0.9574166536331177]}\n",
            "{'loss': [1.6692100763320923, 0.8905040621757507, 0.6809574961662292, 0.5881279706954956, 0.5310426950454712, 0.49385184049606323, 0.465229332447052, 0.44135838747024536, 0.4195709526538849, 0.4012053906917572, 0.38660120964050293, 0.3699086010456085, 0.3570830523967743, 0.347300261259079, 0.33692753314971924, 0.32616695761680603, 0.31544920802116394, 0.3096214532852173, 0.3033147156238556, 0.2927509844303131, 0.2876063883304596, 0.27866801619529724, 0.2683764398097992, 0.2672938406467438, 0.26165536046028137, 0.25350505113601685, 0.2476467341184616, 0.24554398655891418, 0.23925141990184784, 0.23446744680404663, 0.23180179297924042, 0.22575455904006958, 0.21943552792072296, 0.2170293927192688, 0.2088785022497177, 0.2098097801208496, 0.20807291567325592, 0.20072069764137268, 0.19842371344566345, 0.19554221630096436, 0.19066454470157623, 0.18675516545772552, 0.18473786115646362, 0.1833612620830536, 0.1775328814983368, 0.1775035560131073, 0.17214904725551605, 0.17097784578800201, 0.16758541762828827, 0.1674748659133911], 'accuracy': [0.4417708218097687, 0.711062490940094, 0.7853333353996277, 0.817229151725769, 0.8368541598320007, 0.8490833044052124, 0.8593124747276306, 0.8665000200271606, 0.8736249804496765, 0.8789791464805603, 0.8847083449363708, 0.8884791731834412, 0.8925625085830688, 0.8963333368301392, 0.8990208506584167, 0.9022291898727417, 0.906499981880188, 0.906541645526886, 0.9088958501815796, 0.9135208129882812, 0.9139999747276306, 0.916979193687439, 0.9194999933242798, 0.9205625057220459, 0.9215208292007446, 0.9250624775886536, 0.9262916445732117, 0.9262916445732117, 0.9280208349227905, 0.9296249747276306, 0.929937481880188, 0.932979166507721, 0.9331874847412109, 0.934374988079071, 0.937375009059906, 0.9367499947547913, 0.9371874928474426, 0.9396874904632568, 0.9400416612625122, 0.9413124918937683, 0.9432291388511658, 0.9441041946411133, 0.9438124895095825, 0.9444791674613953, 0.9463958144187927, 0.9460208415985107, 0.9496250152587891, 0.9488541483879089, 0.9488541483879089, 0.9492083191871643], 'val_loss': [0.7983088493347168, 0.49923765659332275, 0.4138241112232208, 0.37037378549575806, 0.3458060324192047, 0.32545334100723267, 0.3104538023471832, 0.2974720597267151, 0.2871861457824707, 0.27837011218070984, 0.2695869505405426, 0.26174110174179077, 0.2550220787525177, 0.24801647663116455, 0.2418520450592041, 0.23768717050552368, 0.23174642026424408, 0.22690895199775696, 0.22184081375598907, 0.21764762699604034, 0.21408671140670776, 0.2102714627981186, 0.20737336575984955, 0.20339858531951904, 0.2001252919435501, 0.1967829167842865, 0.19428493082523346, 0.1901962012052536, 0.18758085370063782, 0.18648050725460052, 0.18253353238105774, 0.18081848323345184, 0.17985957860946655, 0.17676426470279694, 0.17409799993038177, 0.17231805622577667, 0.1706722229719162, 0.16983705759048462, 0.1681901216506958, 0.16595983505249023, 0.16521215438842773, 0.16318674385547638, 0.1619735062122345, 0.1620383858680725, 0.15891410410404205, 0.15756630897521973, 0.1569414585828781, 0.15574675798416138, 0.15500517189502716, 0.15389297902584076], 'val_accuracy': [0.8236666917800903, 0.8675000071525574, 0.8851666450500488, 0.893916666507721, 0.8991666436195374, 0.9043333530426025, 0.909250020980835, 0.9120833277702332, 0.9164999723434448, 0.9180833101272583, 0.92166668176651, 0.9237499833106995, 0.925000011920929, 0.9268333315849304, 0.9289166927337646, 0.9300833344459534, 0.9309999942779541, 0.9331666827201843, 0.9340833425521851, 0.9361666440963745, 0.9364166855812073, 0.9381666779518127, 0.9384166598320007, 0.9401666522026062, 0.9416666626930237, 0.9424166679382324, 0.9430000185966492, 0.9442499876022339, 0.9451666474342346, 0.9446666836738586, 0.9459166526794434, 0.9460833072662354, 0.9468333125114441, 0.9470833539962769, 0.9483333230018616, 0.9484999775886536, 0.9495000243186951, 0.9489166736602783, 0.949916660785675, 0.9505833387374878, 0.9505833387374878, 0.9511666893959045, 0.9516666531562805, 0.9510833621025085, 0.9526666402816772, 0.9526666402816772, 0.953083336353302, 0.9539166688919067, 0.9538333415985107, 0.9541666507720947]}\n",
            "{'loss': [1.1810815334320068, 0.6568055748939514, 0.5593377351760864, 0.5135915279388428, 0.48880094289779663, 0.46135464310646057, 0.4448988437652588, 0.4329475164413452, 0.41704294085502625, 0.40735989809036255, 0.3936645984649658, 0.3894610106945038, 0.3781074583530426, 0.36534711718559265, 0.36211296916007996, 0.35899341106414795, 0.3536471426486969, 0.34133926033973694, 0.34087732434272766, 0.328858882188797, 0.32493776082992554, 0.32031115889549255, 0.3163493573665619, 0.3117953836917877, 0.3073587715625763, 0.3015785813331604, 0.30291983485221863, 0.2931080162525177, 0.2859708368778229, 0.2818366587162018, 0.27884137630462646, 0.27706485986709595, 0.2740285098552704, 0.2702745795249939, 0.2689259946346283, 0.26586976647377014, 0.25944408774375916, 0.25942763686180115, 0.2568252682685852, 0.2505474388599396, 0.25099289417266846, 0.2448395937681198, 0.24582132697105408, 0.23914749920368195, 0.23717144131660461, 0.23616410791873932, 0.2347927838563919, 0.2264765352010727, 0.22751612961292267, 0.2249244749546051], 'accuracy': [0.6149374842643738, 0.7928541898727417, 0.8261458277702332, 0.8397499918937683, 0.8492083549499512, 0.859250009059906, 0.8635833263397217, 0.8678125143051147, 0.8724583387374878, 0.8759375214576721, 0.8796250224113464, 0.8823541402816772, 0.8851666450500488, 0.8893958330154419, 0.8901875019073486, 0.8915833234786987, 0.8933958411216736, 0.8955833315849304, 0.8963333368301392, 0.8989583253860474, 0.9002500176429749, 0.9020208120346069, 0.9030208587646484, 0.9045000076293945, 0.90625, 0.9077708125114441, 0.9080625176429749, 0.9106875061988831, 0.9126874804496765, 0.9133750200271606, 0.9154999852180481, 0.9153333306312561, 0.9162083268165588, 0.9165416955947876, 0.9176666736602783, 0.9178749918937683, 0.9204583168029785, 0.9197708368301392, 0.921500027179718, 0.9228125214576721, 0.9243124723434448, 0.9251041412353516, 0.9254166483879089, 0.9261875152587891, 0.9275000095367432, 0.9265000224113464, 0.9288125038146973, 0.9298750162124634, 0.9296666383743286, 0.9311875104904175], 'val_loss': [0.5246458053588867, 0.41312333941459656, 0.3743840754032135, 0.355212926864624, 0.3384546637535095, 0.32722610235214233, 0.3214462101459503, 0.312012255191803, 0.3068477511405945, 0.3003176748752594, 0.29630085825920105, 0.28876638412475586, 0.2842648923397064, 0.2803684175014496, 0.2765158414840698, 0.2718994617462158, 0.2679184377193451, 0.26489973068237305, 0.26077979803085327, 0.2573148012161255, 0.25429341197013855, 0.25149160623550415, 0.2493506520986557, 0.24447549879550934, 0.24172194302082062, 0.2386641651391983, 0.23661334812641144, 0.2333153486251831, 0.23018154501914978, 0.22900734841823578, 0.22513693571090698, 0.22381214797496796, 0.22027082741260529, 0.21934787929058075, 0.21822328865528107, 0.2156589925289154, 0.21426993608474731, 0.21239124238491058, 0.2091093212366104, 0.2080550342798233, 0.20516256988048553, 0.20346279442310333, 0.20150315761566162, 0.20078735053539276, 0.1985597461462021, 0.19750264286994934, 0.19684691727161407, 0.1960604041814804, 0.19372296333312988, 0.19202396273612976], 'val_accuracy': [0.8567500114440918, 0.8803333044052124, 0.8882499933242798, 0.8925833106040955, 0.8975833058357239, 0.9009166955947876, 0.9021666646003723, 0.906416654586792, 0.9084166884422302, 0.9104999899864197, 0.9116666913032532, 0.9134166836738586, 0.9153333306312561, 0.9157500267028809, 0.9174166917800903, 0.9183333516120911, 0.9197499752044678, 0.9203333258628845, 0.921916663646698, 0.9224166870117188, 0.9231666922569275, 0.9247499704360962, 0.9238333106040955, 0.9255833625793457, 0.9279999732971191, 0.9290833473205566, 0.9294999837875366, 0.9300833344459534, 0.9314166903495789, 0.9309999942779541, 0.9328333139419556, 0.9330833554267883, 0.9340000152587891, 0.934333324432373, 0.934416651725769, 0.9358333349227905, 0.9353333115577698, 0.9363333582878113, 0.9379166960716248, 0.937666654586792, 0.9396666884422302, 0.9394166469573975, 0.9394166469573975, 0.940416693687439, 0.9411666393280029, 0.940666675567627, 0.940583348274231, 0.9417499899864197, 0.9425833225250244, 0.9423333406448364]}\n",
            "{'loss': [1.082022786140442, 0.6533096432685852, 0.5700708627700806, 0.520971417427063, 0.4979795217514038, 0.4717423617839813, 0.4553477466106415, 0.4400162398815155, 0.42786547541618347, 0.41589921712875366, 0.41075214743614197, 0.40001872181892395, 0.3912869393825531, 0.38557377457618713, 0.37915927171707153, 0.37213557958602905, 0.36419790983200073, 0.3582499921321869, 0.35379061102867126, 0.3529815375804901, 0.34526923298835754, 0.337418794631958, 0.338532030582428, 0.32990318536758423, 0.324439138174057, 0.3224776089191437, 0.3168848752975464, 0.3138827383518219, 0.31032538414001465, 0.30816614627838135, 0.30088597536087036, 0.29954180121421814, 0.2965549826622009, 0.2906069755554199, 0.28847819566726685, 0.28723862767219543, 0.27823418378829956, 0.2810511887073517, 0.2823265790939331, 0.274169385433197, 0.27274972200393677, 0.2694210708141327, 0.2681218683719635, 0.2655016779899597, 0.26406043767929077, 0.26065701246261597, 0.2571535110473633, 0.2564481198787689, 0.25422435998916626, 0.2498215287923813], 'accuracy': [0.6536458134651184, 0.7954791784286499, 0.8246458172798157, 0.8402708172798157, 0.8481041789054871, 0.8551874756813049, 0.8612708449363708, 0.8658124804496765, 0.8692708611488342, 0.8731250166893005, 0.8728333115577698, 0.8789791464805603, 0.8813750147819519, 0.8826666474342346, 0.8833125233650208, 0.886145830154419, 0.8891249895095825, 0.8892916440963745, 0.8922083377838135, 0.8912708163261414, 0.8944583535194397, 0.8955000042915344, 0.8950833082199097, 0.8977916836738586, 0.8992708325386047, 0.9019166827201843, 0.9022916555404663, 0.903291642665863, 0.9045000076293945, 0.9066041707992554, 0.906583309173584, 0.9086874723434448, 0.9073125123977661, 0.9096249938011169, 0.9103333353996277, 0.9106875061988831, 0.91385418176651, 0.9127708077430725, 0.9129166603088379, 0.9148125052452087, 0.9161458611488342, 0.9172083139419556, 0.9170833230018616, 0.9183541536331177, 0.9175208210945129, 0.9185624718666077, 0.9192500114440918, 0.9198541641235352, 0.92208331823349, 0.9231874942779541], 'val_loss': [0.42317134141921997, 0.3729190528392792, 0.35908886790275574, 0.3404218256473541, 0.33230510354042053, 0.328685998916626, 0.3209691047668457, 0.31804654002189636, 0.3121367394924164, 0.30923739075660706, 0.30439913272857666, 0.30186402797698975, 0.2968597114086151, 0.294817179441452, 0.2902880311012268, 0.2864232063293457, 0.2857981026172638, 0.2839544415473938, 0.2792906165122986, 0.2747913897037506, 0.2752138376235962, 0.2714538872241974, 0.2687627077102661, 0.2653977572917938, 0.2620396316051483, 0.25915515422821045, 0.2564941346645355, 0.25416719913482666, 0.25202304124832153, 0.24920782446861267, 0.24632816016674042, 0.2439860850572586, 0.24212127923965454, 0.23987407982349396, 0.23800554871559143, 0.23509706556797028, 0.23188485205173492, 0.23011299967765808, 0.22822527587413788, 0.22509728372097015, 0.22372861206531525, 0.22148092091083527, 0.22079262137413025, 0.21899159252643585, 0.21653051674365997, 0.21576333045959473, 0.2153044193983078, 0.21148519217967987, 0.21069848537445068, 0.20877443253993988], 'val_accuracy': [0.8732500076293945, 0.8895833492279053, 0.8945000171661377, 0.9010000228881836, 0.9046666622161865, 0.9039166569709778, 0.9089166522026062, 0.9082499742507935, 0.9074166417121887, 0.9090833067893982, 0.9112499952316284, 0.9104999899864197, 0.9121666550636292, 0.9129166603088379, 0.9142500162124634, 0.9150833487510681, 0.9175000190734863, 0.9164166450500488, 0.9175833463668823, 0.9196666479110718, 0.9191666841506958, 0.9194999933242798, 0.9203333258628845, 0.9211666584014893, 0.9226666688919067, 0.9239166378974915, 0.9246666431427002, 0.9256666898727417, 0.9243333339691162, 0.9273333549499512, 0.9278333187103271, 0.9280833601951599, 0.9286666512489319, 0.9298333525657654, 0.9303333163261414, 0.9320833086967468, 0.9315833449363708, 0.9325000047683716, 0.9329166412353516, 0.9346666932106018, 0.9339166879653931, 0.9351666569709778, 0.9355000257492065, 0.9355833530426025, 0.9358333349227905, 0.9361666440963745, 0.9368333220481873, 0.9380833506584167, 0.9384999871253967, 0.9386666417121887]}\n",
            "{'loss': [2.012110471725464, 1.120740294456482, 0.7814803123474121, 0.6606115102767944, 0.5867611765861511, 0.5347938537597656, 0.5005604028701782, 0.47264811396598816, 0.45123088359832764, 0.42757776379585266, 0.41377970576286316, 0.3958941698074341, 0.37964633107185364, 0.36835619807243347, 0.35500890016555786, 0.34374645352363586, 0.33046820759773254, 0.31969988346099854, 0.3115515410900116, 0.3019809424877167, 0.2954610288143158, 0.2854025065898895, 0.27631983160972595, 0.2719496488571167, 0.2670131027698517, 0.2583616375923157, 0.2525493800640106, 0.24656803905963898, 0.24240317940711975, 0.23729316890239716, 0.23109179735183716, 0.22699937224388123, 0.22219006717205048, 0.219883531332016, 0.21736222505569458, 0.20989176630973816, 0.20793958008289337, 0.2054864466190338, 0.20017553865909576, 0.19437994062900543, 0.19178776443004608, 0.19236743450164795, 0.18556606769561768, 0.181904599070549, 0.17992940545082092, 0.17499758303165436, 0.1749403476715088, 0.17087481915950775, 0.16767330467700958, 0.1644904613494873], 'accuracy': [0.3463541567325592, 0.651437520980835, 0.7551458477973938, 0.7967291474342346, 0.8208749890327454, 0.8389583230018616, 0.8509791493415833, 0.8608333468437195, 0.8655624985694885, 0.8726666569709778, 0.8789791464805603, 0.8821666836738586, 0.8867916464805603, 0.8911250233650208, 0.8960833549499512, 0.8984583616256714, 0.9025416374206543, 0.9055208563804626, 0.9085624814033508, 0.9103749990463257, 0.9121249914169312, 0.9153749942779541, 0.9180416464805603, 0.9195833206176758, 0.9207500219345093, 0.9231041669845581, 0.9244791865348816, 0.925208330154419, 0.9277708530426025, 0.9291041493415833, 0.9304999709129333, 0.9327083230018616, 0.9345625042915344, 0.9347291588783264, 0.9346458315849304, 0.9362499713897705, 0.937749981880188, 0.9376875162124634, 0.9394375085830688, 0.9434166550636292, 0.9429166913032532, 0.9429791569709778, 0.9448958039283752, 0.9448958039283752, 0.9463750123977661, 0.9472500085830688, 0.9480208158493042, 0.9481250047683716, 0.950208306312561, 0.9501875042915344], 'val_loss': [1.3613643646240234, 0.6301549673080444, 0.48437780141830444, 0.42430058121681213, 0.38487061858177185, 0.36065569519996643, 0.3407163918018341, 0.3250850737094879, 0.3117735981941223, 0.29959800839424133, 0.2889302968978882, 0.2791246473789215, 0.270725816488266, 0.2630305588245392, 0.2550267279148102, 0.24796143174171448, 0.241674542427063, 0.23575901985168457, 0.23080749809741974, 0.2251165807247162, 0.21929413080215454, 0.2158452570438385, 0.21049650013446808, 0.20620639622211456, 0.202653706073761, 0.19929277896881104, 0.19558051228523254, 0.1923101395368576, 0.18899554014205933, 0.18606439232826233, 0.18307161331176758, 0.18058335781097412, 0.1784074902534485, 0.17608213424682617, 0.17323486506938934, 0.1712639182806015, 0.1695871204137802, 0.16712604463100433, 0.16494353115558624, 0.1637069433927536, 0.16193562746047974, 0.16032347083091736, 0.15876168012619019, 0.15706177055835724, 0.15551330149173737, 0.15450410544872284, 0.15285933017730713, 0.15199320018291473, 0.15069440007209778, 0.14959631860256195], 'val_accuracy': [0.7381666898727417, 0.8401666879653931, 0.8715000152587891, 0.8845000267028809, 0.8918333053588867, 0.8989999890327454, 0.903083324432373, 0.906083345413208, 0.9098333120346069, 0.9114166498184204, 0.9150833487510681, 0.9169166684150696, 0.918583333492279, 0.921999990940094, 0.9242500066757202, 0.9254999756813049, 0.9275000095367432, 0.9290833473205566, 0.9308333396911621, 0.9326666593551636, 0.934416651725769, 0.934583306312561, 0.9364166855812073, 0.9369166493415833, 0.9389166831970215, 0.9393333196640015, 0.940750002861023, 0.9418333172798157, 0.9424166679382324, 0.9431666731834412, 0.9440833330154419, 0.9453333616256714, 0.9449166655540466, 0.9463333487510681, 0.9468333125114441, 0.9479166865348816, 0.9484999775886536, 0.9488333463668823, 0.9496666789054871, 0.9496666789054871, 0.9496666789054871, 0.9504166841506958, 0.9514999985694885, 0.9526666402816772, 0.952750027179718, 0.952750027179718, 0.953000009059906, 0.9525833129882812, 0.9551666378974915, 0.9545000195503235]}\n",
            "{'loss': [2.041156530380249, 1.2575719356536865, 0.8429118394851685, 0.6952505707740784, 0.6117719411849976, 0.5635033249855042, 0.5280196666717529, 0.5002695322036743, 0.4762031137943268, 0.4567423462867737, 0.4382052719593048, 0.42752954363822937, 0.41508248448371887, 0.40247419476509094, 0.39262890815734863, 0.3839721977710724, 0.3745502531528473, 0.3650013506412506, 0.3563779294490814, 0.35187235474586487, 0.34450995922088623, 0.3359326422214508, 0.3282783627510071, 0.323467880487442, 0.31872114539146423, 0.3101428151130676, 0.3053750991821289, 0.30115407705307007, 0.29422423243522644, 0.2908024191856384, 0.2841682434082031, 0.28044870495796204, 0.27488309144973755, 0.27261093258857727, 0.26751086115837097, 0.26291725039482117, 0.2611255645751953, 0.25412529706954956, 0.2516213357448578, 0.24831491708755493, 0.24280975759029388, 0.23920902609825134, 0.23894384503364563, 0.2342817187309265, 0.23270219564437866, 0.22774861752986908, 0.22503139078617096, 0.2224971503019333, 0.21485266089439392, 0.2148115038871765], 'accuracy': [0.3714166581630707, 0.6441666483879089, 0.7388333082199097, 0.7863125205039978, 0.8133124709129333, 0.8289374709129333, 0.8419791460037231, 0.8490208387374878, 0.8562291860580444, 0.8633958101272583, 0.8682916760444641, 0.8706458210945129, 0.8758749961853027, 0.8789166808128357, 0.8811458349227905, 0.8839791417121887, 0.8880416750907898, 0.890999972820282, 0.8928541541099548, 0.8944583535194397, 0.8958749771118164, 0.8984583616256714, 0.9019791483879089, 0.9032291769981384, 0.9031458497047424, 0.9051874876022339, 0.9083958268165588, 0.9084583520889282, 0.9115208387374878, 0.9123749732971191, 0.9135416746139526, 0.9155625104904175, 0.9160833358764648, 0.9187291860580444, 0.9181874990463257, 0.9194375276565552, 0.9196666479110718, 0.9225000143051147, 0.9244375228881836, 0.9240833520889282, 0.9257708191871643, 0.9277499914169312, 0.9279583096504211, 0.9287916421890259, 0.9285625219345093, 0.9305416941642761, 0.9314583539962769, 0.9327083230018616, 0.9346458315849304, 0.934166669845581], 'val_loss': [1.614048719406128, 0.742466151714325, 0.5397433638572693, 0.4644448161125183, 0.4210492670536041, 0.39226457476615906, 0.3715543746948242, 0.3557974100112915, 0.3421486020088196, 0.3315639793872833, 0.32236677408218384, 0.31539273262023926, 0.30543383955955505, 0.29836854338645935, 0.2918735444545746, 0.28566285967826843, 0.2799569368362427, 0.27502205967903137, 0.270447313785553, 0.26571106910705566, 0.26023727655410767, 0.2563215494155884, 0.2522834837436676, 0.2478543072938919, 0.24453522264957428, 0.24119095504283905, 0.23703527450561523, 0.23361662030220032, 0.23078183829784393, 0.22707875072956085, 0.22402635216712952, 0.22174356877803802, 0.21850693225860596, 0.21566924452781677, 0.2126808613538742, 0.2107929140329361, 0.207567498087883, 0.20506097376346588, 0.20264118909835815, 0.2007303237915039, 0.19829237461090088, 0.19609302282333374, 0.19399239122867584, 0.19205684959888458, 0.1898023933172226, 0.18804095685482025, 0.1862083524465561, 0.18461976945400238, 0.18265120685100555, 0.1815551221370697], 'val_accuracy': [0.7074999809265137, 0.8304166793823242, 0.85958331823349, 0.8732500076293945, 0.8829166889190674, 0.8885833621025085, 0.8930833339691162, 0.8970833420753479, 0.8989166617393494, 0.9019166827201843, 0.9041666388511658, 0.9052500128746033, 0.9079166650772095, 0.9101666808128357, 0.9120833277702332, 0.9133333563804626, 0.9156666398048401, 0.9160833358764648, 0.9169999957084656, 0.9191666841506958, 0.9210000038146973, 0.9214166402816772, 0.9223333597183228, 0.9233333468437195, 0.9247499704360962, 0.9261666536331177, 0.9278333187103271, 0.9290833473205566, 0.9294166564941406, 0.9307500123977661, 0.9320833086967468, 0.9315833449363708, 0.9330000281333923, 0.9334999918937683, 0.9356666803359985, 0.9365000128746033, 0.937166690826416, 0.937583327293396, 0.9384166598320007, 0.9388333559036255, 0.9392499923706055, 0.9397500157356262, 0.9410833120346069, 0.9416666626930237, 0.9418333172798157, 0.9416666626930237, 0.9424166679382324, 0.9426666498184204, 0.9431666731834412, 0.9434999823570251]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}