{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noinit_noise_6depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "f67437e8-7f99-450a-baad-921609e88d2f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 18s 6ms/step - loss: 2.1581 - accuracy: 0.2301 - val_loss: 1.1902 - val_accuracy: 0.7298\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5625 - accuracy: 0.4735 - val_loss: 0.8868 - val_accuracy: 0.8012\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3067 - accuracy: 0.5719 - val_loss: 0.7271 - val_accuracy: 0.8286\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1616 - accuracy: 0.6273 - val_loss: 0.6298 - val_accuracy: 0.8447\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0734 - accuracy: 0.6576 - val_loss: 0.5660 - val_accuracy: 0.8569\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9938 - accuracy: 0.6858 - val_loss: 0.5233 - val_accuracy: 0.8658\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9414 - accuracy: 0.7054 - val_loss: 0.4886 - val_accuracy: 0.8726\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8964 - accuracy: 0.7229 - val_loss: 0.4666 - val_accuracy: 0.8748\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8637 - accuracy: 0.7344 - val_loss: 0.4465 - val_accuracy: 0.8788\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8306 - accuracy: 0.7482 - val_loss: 0.4310 - val_accuracy: 0.8821\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8012 - accuracy: 0.7595 - val_loss: 0.4174 - val_accuracy: 0.8852\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7726 - accuracy: 0.7708 - val_loss: 0.4056 - val_accuracy: 0.8891\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7681 - accuracy: 0.7769 - val_loss: 0.3986 - val_accuracy: 0.8917\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7429 - accuracy: 0.7816 - val_loss: 0.3899 - val_accuracy: 0.8946\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7220 - accuracy: 0.7885 - val_loss: 0.3830 - val_accuracy: 0.8942\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7140 - accuracy: 0.7922 - val_loss: 0.3769 - val_accuracy: 0.8970\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.7989 - val_loss: 0.3719 - val_accuracy: 0.8996\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6814 - accuracy: 0.8122 - val_loss: 0.3688 - val_accuracy: 0.8997\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6762 - accuracy: 0.8080 - val_loss: 0.3622 - val_accuracy: 0.9008\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6556 - accuracy: 0.8170 - val_loss: 0.3601 - val_accuracy: 0.9026\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6527 - accuracy: 0.8176 - val_loss: 0.3545 - val_accuracy: 0.9038\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6329 - accuracy: 0.8261 - val_loss: 0.3507 - val_accuracy: 0.9047\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6248 - accuracy: 0.8286 - val_loss: 0.3475 - val_accuracy: 0.9068\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6128 - accuracy: 0.8330 - val_loss: 0.3462 - val_accuracy: 0.9071\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6015 - accuracy: 0.8348 - val_loss: 0.3451 - val_accuracy: 0.9088\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6117 - accuracy: 0.8350 - val_loss: 0.3394 - val_accuracy: 0.9107\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6011 - accuracy: 0.8360 - val_loss: 0.3365 - val_accuracy: 0.9108\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5794 - accuracy: 0.8419 - val_loss: 0.3337 - val_accuracy: 0.9120\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5694 - accuracy: 0.8463 - val_loss: 0.3344 - val_accuracy: 0.9140\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5793 - accuracy: 0.8424 - val_loss: 0.3307 - val_accuracy: 0.9143\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5538 - accuracy: 0.8525 - val_loss: 0.3271 - val_accuracy: 0.9151\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5611 - accuracy: 0.8500 - val_loss: 0.3243 - val_accuracy: 0.9147\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5487 - accuracy: 0.8556 - val_loss: 0.3207 - val_accuracy: 0.9166\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5554 - accuracy: 0.8528 - val_loss: 0.3189 - val_accuracy: 0.9178\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5462 - accuracy: 0.8541 - val_loss: 0.3169 - val_accuracy: 0.9187\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5326 - accuracy: 0.8594 - val_loss: 0.3130 - val_accuracy: 0.9190\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5356 - accuracy: 0.8589 - val_loss: 0.3132 - val_accuracy: 0.9203\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5151 - accuracy: 0.8648 - val_loss: 0.3104 - val_accuracy: 0.9202\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5224 - accuracy: 0.8643 - val_loss: 0.3098 - val_accuracy: 0.9208\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5291 - accuracy: 0.8608 - val_loss: 0.3069 - val_accuracy: 0.9226\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5160 - accuracy: 0.8653 - val_loss: 0.3045 - val_accuracy: 0.9237\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5128 - accuracy: 0.8690 - val_loss: 0.3008 - val_accuracy: 0.9243\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5046 - accuracy: 0.8664 - val_loss: 0.3014 - val_accuracy: 0.9246\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4970 - accuracy: 0.8701 - val_loss: 0.2966 - val_accuracy: 0.9255\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4945 - accuracy: 0.8716 - val_loss: 0.2942 - val_accuracy: 0.9260\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4818 - accuracy: 0.8743 - val_loss: 0.2938 - val_accuracy: 0.9273\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4807 - accuracy: 0.8740 - val_loss: 0.2928 - val_accuracy: 0.9278\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4824 - accuracy: 0.8749 - val_loss: 0.2894 - val_accuracy: 0.9286\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4789 - accuracy: 0.8756 - val_loss: 0.2864 - val_accuracy: 0.9293\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4815 - accuracy: 0.8773 - val_loss: 0.2861 - val_accuracy: 0.9298\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3078 - accuracy: 0.1178 - val_loss: 2.2283 - val_accuracy: 0.3254\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2306 - accuracy: 0.1706 - val_loss: 2.0071 - val_accuracy: 0.3903\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0873 - accuracy: 0.2308 - val_loss: 1.7712 - val_accuracy: 0.4179\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9384 - accuracy: 0.2811 - val_loss: 1.5733 - val_accuracy: 0.4773\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.8011 - accuracy: 0.3204 - val_loss: 1.4209 - val_accuracy: 0.5316\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7116 - accuracy: 0.3581 - val_loss: 1.2989 - val_accuracy: 0.5524\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.6095 - accuracy: 0.3975 - val_loss: 1.1921 - val_accuracy: 0.5661\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5124 - accuracy: 0.4282 - val_loss: 1.1035 - val_accuracy: 0.5785\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4365 - accuracy: 0.4519 - val_loss: 1.0439 - val_accuracy: 0.5913\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3745 - accuracy: 0.4744 - val_loss: 0.9812 - val_accuracy: 0.6150\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3061 - accuracy: 0.4935 - val_loss: 0.9521 - val_accuracy: 0.6801\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2706 - accuracy: 0.5116 - val_loss: 0.9061 - val_accuracy: 0.6871\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2178 - accuracy: 0.5354 - val_loss: 0.8649 - val_accuracy: 0.7247\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1814 - accuracy: 0.5509 - val_loss: 0.8140 - val_accuracy: 0.7591\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1367 - accuracy: 0.5725 - val_loss: 0.7681 - val_accuracy: 0.7593\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1061 - accuracy: 0.5964 - val_loss: 0.7138 - val_accuracy: 0.7736\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0764 - accuracy: 0.6109 - val_loss: 0.6806 - val_accuracy: 0.7878\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0253 - accuracy: 0.6288 - val_loss: 0.6461 - val_accuracy: 0.8015\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9964 - accuracy: 0.6481 - val_loss: 0.6081 - val_accuracy: 0.8268\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9554 - accuracy: 0.6622 - val_loss: 0.5846 - val_accuracy: 0.8269\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9440 - accuracy: 0.6625 - val_loss: 0.5590 - val_accuracy: 0.8371\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9056 - accuracy: 0.6786 - val_loss: 0.5364 - val_accuracy: 0.8485\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8816 - accuracy: 0.6906 - val_loss: 0.5196 - val_accuracy: 0.8571\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8590 - accuracy: 0.7005 - val_loss: 0.5015 - val_accuracy: 0.8701\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8471 - accuracy: 0.7071 - val_loss: 0.4885 - val_accuracy: 0.8687\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8196 - accuracy: 0.7198 - val_loss: 0.4767 - val_accuracy: 0.8828\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8003 - accuracy: 0.7267 - val_loss: 0.4593 - val_accuracy: 0.8811\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7899 - accuracy: 0.7385 - val_loss: 0.4494 - val_accuracy: 0.8901\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7599 - accuracy: 0.7470 - val_loss: 0.4397 - val_accuracy: 0.8942\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7479 - accuracy: 0.7500 - val_loss: 0.4207 - val_accuracy: 0.9054\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7273 - accuracy: 0.7621 - val_loss: 0.4127 - val_accuracy: 0.9100\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7191 - accuracy: 0.7653 - val_loss: 0.4005 - val_accuracy: 0.9144\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7102 - accuracy: 0.7713 - val_loss: 0.3884 - val_accuracy: 0.9158\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.7792 - val_loss: 0.3808 - val_accuracy: 0.9202\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6694 - accuracy: 0.7826 - val_loss: 0.3702 - val_accuracy: 0.9227\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6540 - accuracy: 0.7862 - val_loss: 0.3657 - val_accuracy: 0.9222\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6345 - accuracy: 0.7971 - val_loss: 0.3580 - val_accuracy: 0.9257\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6235 - accuracy: 0.8032 - val_loss: 0.3519 - val_accuracy: 0.9280\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5996 - accuracy: 0.8140 - val_loss: 0.3470 - val_accuracy: 0.9273\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5974 - accuracy: 0.8126 - val_loss: 0.3368 - val_accuracy: 0.9299\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5875 - accuracy: 0.8198 - val_loss: 0.3320 - val_accuracy: 0.9308\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5633 - accuracy: 0.8247 - val_loss: 0.3286 - val_accuracy: 0.9327\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5489 - accuracy: 0.8264 - val_loss: 0.3260 - val_accuracy: 0.9355\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5452 - accuracy: 0.8297 - val_loss: 0.3255 - val_accuracy: 0.9361\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5314 - accuracy: 0.8316 - val_loss: 0.3183 - val_accuracy: 0.9371\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5236 - accuracy: 0.8351 - val_loss: 0.3178 - val_accuracy: 0.9373\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5165 - accuracy: 0.8406 - val_loss: 0.3267 - val_accuracy: 0.9379\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5016 - accuracy: 0.8427 - val_loss: 0.3198 - val_accuracy: 0.9388\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4929 - accuracy: 0.8473 - val_loss: 0.3183 - val_accuracy: 0.9403\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4829 - accuracy: 0.8477 - val_loss: 0.3260 - val_accuracy: 0.9403\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.2950 - accuracy: 0.1231 - val_loss: 2.1143 - val_accuracy: 0.4093\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1152 - accuracy: 0.2392 - val_loss: 1.6330 - val_accuracy: 0.5213\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.8286 - accuracy: 0.3368 - val_loss: 1.2622 - val_accuracy: 0.6227\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5830 - accuracy: 0.4321 - val_loss: 1.0009 - val_accuracy: 0.7061\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3804 - accuracy: 0.5120 - val_loss: 0.8351 - val_accuracy: 0.7830\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2181 - accuracy: 0.5752 - val_loss: 0.7128 - val_accuracy: 0.8207\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1094 - accuracy: 0.6208 - val_loss: 0.6314 - val_accuracy: 0.8415\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0216 - accuracy: 0.6521 - val_loss: 0.5734 - val_accuracy: 0.8485\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9500 - accuracy: 0.6872 - val_loss: 0.5235 - val_accuracy: 0.8578\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9006 - accuracy: 0.7048 - val_loss: 0.4932 - val_accuracy: 0.8660\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8365 - accuracy: 0.7259 - val_loss: 0.4618 - val_accuracy: 0.8749\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8067 - accuracy: 0.7400 - val_loss: 0.4396 - val_accuracy: 0.8784\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7574 - accuracy: 0.7592 - val_loss: 0.4175 - val_accuracy: 0.8846\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7462 - accuracy: 0.7701 - val_loss: 0.4023 - val_accuracy: 0.8859\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7038 - accuracy: 0.7832 - val_loss: 0.3829 - val_accuracy: 0.8925\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6803 - accuracy: 0.7922 - val_loss: 0.3669 - val_accuracy: 0.8973\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6662 - accuracy: 0.7964 - val_loss: 0.3533 - val_accuracy: 0.9023\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6368 - accuracy: 0.8062 - val_loss: 0.3448 - val_accuracy: 0.9040\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6265 - accuracy: 0.8112 - val_loss: 0.3331 - val_accuracy: 0.9085\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6067 - accuracy: 0.8164 - val_loss: 0.3226 - val_accuracy: 0.9109\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6015 - accuracy: 0.8221 - val_loss: 0.3130 - val_accuracy: 0.9133\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5699 - accuracy: 0.8315 - val_loss: 0.3025 - val_accuracy: 0.9163\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5536 - accuracy: 0.8360 - val_loss: 0.2951 - val_accuracy: 0.9192\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5332 - accuracy: 0.8433 - val_loss: 0.2847 - val_accuracy: 0.9212\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5231 - accuracy: 0.8510 - val_loss: 0.2785 - val_accuracy: 0.9232\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5247 - accuracy: 0.8467 - val_loss: 0.2733 - val_accuracy: 0.9252\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5010 - accuracy: 0.8559 - val_loss: 0.2683 - val_accuracy: 0.9264\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4975 - accuracy: 0.8588 - val_loss: 0.2615 - val_accuracy: 0.9276\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4797 - accuracy: 0.8631 - val_loss: 0.2567 - val_accuracy: 0.9295\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4766 - accuracy: 0.8660 - val_loss: 0.2503 - val_accuracy: 0.9308\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4557 - accuracy: 0.8679 - val_loss: 0.2476 - val_accuracy: 0.9328\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4486 - accuracy: 0.8710 - val_loss: 0.2440 - val_accuracy: 0.9344\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4321 - accuracy: 0.8775 - val_loss: 0.2392 - val_accuracy: 0.9354\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4255 - accuracy: 0.8816 - val_loss: 0.2342 - val_accuracy: 0.9371\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4211 - accuracy: 0.8835 - val_loss: 0.2312 - val_accuracy: 0.9382\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3956 - accuracy: 0.8856 - val_loss: 0.2307 - val_accuracy: 0.9392\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4017 - accuracy: 0.8879 - val_loss: 0.2264 - val_accuracy: 0.9403\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4028 - accuracy: 0.8854 - val_loss: 0.2255 - val_accuracy: 0.9413\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3801 - accuracy: 0.8929 - val_loss: 0.2217 - val_accuracy: 0.9435\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3692 - accuracy: 0.8961 - val_loss: 0.2171 - val_accuracy: 0.9424\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3717 - accuracy: 0.8953 - val_loss: 0.2209 - val_accuracy: 0.9420\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3634 - accuracy: 0.8971 - val_loss: 0.2165 - val_accuracy: 0.9440\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.8986 - val_loss: 0.2150 - val_accuracy: 0.9448\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3500 - accuracy: 0.9012 - val_loss: 0.2161 - val_accuracy: 0.9459\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3458 - accuracy: 0.9051 - val_loss: 0.2126 - val_accuracy: 0.9459\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3417 - accuracy: 0.9018 - val_loss: 0.2097 - val_accuracy: 0.9471\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3259 - accuracy: 0.9074 - val_loss: 0.2092 - val_accuracy: 0.9468\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3271 - accuracy: 0.9076 - val_loss: 0.2098 - val_accuracy: 0.9473\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3261 - accuracy: 0.9093 - val_loss: 0.2084 - val_accuracy: 0.9477\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3077 - accuracy: 0.9142 - val_loss: 0.2056 - val_accuracy: 0.9493\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 2.1100 - accuracy: 0.2554 - val_loss: 0.9726 - val_accuracy: 0.7404\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4045 - accuracy: 0.5080 - val_loss: 0.6797 - val_accuracy: 0.8162\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1739 - accuracy: 0.5972 - val_loss: 0.5680 - val_accuracy: 0.8442\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0563 - accuracy: 0.6405 - val_loss: 0.5085 - val_accuracy: 0.8596\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9743 - accuracy: 0.6739 - val_loss: 0.4732 - val_accuracy: 0.8693\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9110 - accuracy: 0.6983 - val_loss: 0.4468 - val_accuracy: 0.8757\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8684 - accuracy: 0.7171 - val_loss: 0.4223 - val_accuracy: 0.8813\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8263 - accuracy: 0.7350 - val_loss: 0.4054 - val_accuracy: 0.8860\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7938 - accuracy: 0.7453 - val_loss: 0.3922 - val_accuracy: 0.8894\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7811 - accuracy: 0.7549 - val_loss: 0.3804 - val_accuracy: 0.8937\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7488 - accuracy: 0.7678 - val_loss: 0.3676 - val_accuracy: 0.8948\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7237 - accuracy: 0.7805 - val_loss: 0.3594 - val_accuracy: 0.8978\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7079 - accuracy: 0.7842 - val_loss: 0.3496 - val_accuracy: 0.8995\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7003 - accuracy: 0.7884 - val_loss: 0.3436 - val_accuracy: 0.9007\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6869 - accuracy: 0.7972 - val_loss: 0.3324 - val_accuracy: 0.9057\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6480 - accuracy: 0.8101 - val_loss: 0.3278 - val_accuracy: 0.9073\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6512 - accuracy: 0.8076 - val_loss: 0.3198 - val_accuracy: 0.9079\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6290 - accuracy: 0.8126 - val_loss: 0.3123 - val_accuracy: 0.9098\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6202 - accuracy: 0.8182 - val_loss: 0.3087 - val_accuracy: 0.9110\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6010 - accuracy: 0.8256 - val_loss: 0.3037 - val_accuracy: 0.9147\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5898 - accuracy: 0.8293 - val_loss: 0.2990 - val_accuracy: 0.9143\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5771 - accuracy: 0.8349 - val_loss: 0.2929 - val_accuracy: 0.9155\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5713 - accuracy: 0.8386 - val_loss: 0.2867 - val_accuracy: 0.9172\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.8433 - val_loss: 0.2839 - val_accuracy: 0.9193\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5608 - accuracy: 0.8410 - val_loss: 0.2787 - val_accuracy: 0.9193\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5342 - accuracy: 0.8499 - val_loss: 0.2757 - val_accuracy: 0.9204\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5193 - accuracy: 0.8518 - val_loss: 0.2721 - val_accuracy: 0.9201\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5194 - accuracy: 0.8555 - val_loss: 0.2687 - val_accuracy: 0.9212\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5211 - accuracy: 0.8532 - val_loss: 0.2662 - val_accuracy: 0.9227\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5143 - accuracy: 0.8570 - val_loss: 0.2619 - val_accuracy: 0.9252\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4908 - accuracy: 0.8637 - val_loss: 0.2595 - val_accuracy: 0.9254\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4839 - accuracy: 0.8640 - val_loss: 0.2581 - val_accuracy: 0.9267\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4810 - accuracy: 0.8672 - val_loss: 0.2562 - val_accuracy: 0.9273\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4755 - accuracy: 0.8693 - val_loss: 0.2541 - val_accuracy: 0.9286\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4738 - accuracy: 0.8692 - val_loss: 0.2472 - val_accuracy: 0.9283\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4540 - accuracy: 0.8742 - val_loss: 0.2448 - val_accuracy: 0.9312\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4446 - accuracy: 0.8760 - val_loss: 0.2420 - val_accuracy: 0.9321\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4540 - accuracy: 0.8766 - val_loss: 0.2384 - val_accuracy: 0.9329\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4459 - accuracy: 0.8766 - val_loss: 0.2367 - val_accuracy: 0.9328\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4491 - accuracy: 0.8740 - val_loss: 0.2356 - val_accuracy: 0.9336\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4487 - accuracy: 0.8769 - val_loss: 0.2315 - val_accuracy: 0.9348\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4281 - accuracy: 0.8833 - val_loss: 0.2312 - val_accuracy: 0.9360\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4240 - accuracy: 0.8833 - val_loss: 0.2280 - val_accuracy: 0.9354\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4226 - accuracy: 0.8833 - val_loss: 0.2277 - val_accuracy: 0.9369\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4160 - accuracy: 0.8861 - val_loss: 0.2261 - val_accuracy: 0.9372\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4150 - accuracy: 0.8877 - val_loss: 0.2222 - val_accuracy: 0.9378\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4075 - accuracy: 0.8856 - val_loss: 0.2224 - val_accuracy: 0.9389\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4044 - accuracy: 0.8900 - val_loss: 0.2219 - val_accuracy: 0.9411\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4037 - accuracy: 0.8883 - val_loss: 0.2195 - val_accuracy: 0.9405\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4035 - accuracy: 0.8916 - val_loss: 0.2176 - val_accuracy: 0.9394\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 2.5467 - accuracy: 0.2735 - val_loss: 0.6568 - val_accuracy: 0.8136\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3219 - accuracy: 0.5431 - val_loss: 0.5268 - val_accuracy: 0.8518\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0940 - accuracy: 0.6305 - val_loss: 0.4679 - val_accuracy: 0.8666\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9780 - accuracy: 0.6767 - val_loss: 0.4359 - val_accuracy: 0.8753\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8984 - accuracy: 0.7084 - val_loss: 0.4080 - val_accuracy: 0.8823\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8508 - accuracy: 0.7311 - val_loss: 0.3932 - val_accuracy: 0.8848\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8099 - accuracy: 0.7510 - val_loss: 0.3792 - val_accuracy: 0.8900\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7652 - accuracy: 0.7672 - val_loss: 0.3651 - val_accuracy: 0.8929\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7522 - accuracy: 0.7722 - val_loss: 0.3523 - val_accuracy: 0.8947\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7274 - accuracy: 0.7821 - val_loss: 0.3451 - val_accuracy: 0.8970\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6946 - accuracy: 0.7946 - val_loss: 0.3379 - val_accuracy: 0.8998\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6799 - accuracy: 0.8017 - val_loss: 0.3302 - val_accuracy: 0.9032\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6676 - accuracy: 0.8088 - val_loss: 0.3234 - val_accuracy: 0.9038\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6562 - accuracy: 0.8091 - val_loss: 0.3196 - val_accuracy: 0.9074\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6319 - accuracy: 0.8200 - val_loss: 0.3155 - val_accuracy: 0.9081\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6109 - accuracy: 0.8237 - val_loss: 0.3112 - val_accuracy: 0.9091\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6019 - accuracy: 0.8288 - val_loss: 0.3037 - val_accuracy: 0.9096\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5995 - accuracy: 0.8321 - val_loss: 0.2992 - val_accuracy: 0.9130\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5879 - accuracy: 0.8365 - val_loss: 0.2984 - val_accuracy: 0.9128\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5897 - accuracy: 0.8381 - val_loss: 0.2903 - val_accuracy: 0.9162\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5805 - accuracy: 0.8396 - val_loss: 0.2878 - val_accuracy: 0.9173\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.8395 - val_loss: 0.2857 - val_accuracy: 0.9177\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5389 - accuracy: 0.8492 - val_loss: 0.2815 - val_accuracy: 0.9179\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5377 - accuracy: 0.8489 - val_loss: 0.2804 - val_accuracy: 0.9179\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5388 - accuracy: 0.8515 - val_loss: 0.2771 - val_accuracy: 0.9202\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5273 - accuracy: 0.8547 - val_loss: 0.2707 - val_accuracy: 0.9232\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5261 - accuracy: 0.8565 - val_loss: 0.2703 - val_accuracy: 0.9236\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5228 - accuracy: 0.8585 - val_loss: 0.2660 - val_accuracy: 0.9243\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5114 - accuracy: 0.8593 - val_loss: 0.2632 - val_accuracy: 0.9247\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4965 - accuracy: 0.8638 - val_loss: 0.2618 - val_accuracy: 0.9265\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5068 - accuracy: 0.8645 - val_loss: 0.2608 - val_accuracy: 0.9262\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4853 - accuracy: 0.8686 - val_loss: 0.2567 - val_accuracy: 0.9287\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4848 - accuracy: 0.8688 - val_loss: 0.2544 - val_accuracy: 0.9287\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4788 - accuracy: 0.8677 - val_loss: 0.2495 - val_accuracy: 0.9287\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4668 - accuracy: 0.8725 - val_loss: 0.2525 - val_accuracy: 0.9296\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4561 - accuracy: 0.8759 - val_loss: 0.2475 - val_accuracy: 0.9309\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4629 - accuracy: 0.8744 - val_loss: 0.2470 - val_accuracy: 0.9316\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4519 - accuracy: 0.8802 - val_loss: 0.2461 - val_accuracy: 0.9311\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4466 - accuracy: 0.8785 - val_loss: 0.2426 - val_accuracy: 0.9329\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4367 - accuracy: 0.8800 - val_loss: 0.2405 - val_accuracy: 0.9332\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4266 - accuracy: 0.8835 - val_loss: 0.2370 - val_accuracy: 0.9342\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4182 - accuracy: 0.8881 - val_loss: 0.2401 - val_accuracy: 0.9344\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4247 - accuracy: 0.8846 - val_loss: 0.2361 - val_accuracy: 0.9353\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4211 - accuracy: 0.8855 - val_loss: 0.2368 - val_accuracy: 0.9343\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4144 - accuracy: 0.8880 - val_loss: 0.2375 - val_accuracy: 0.9352\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4042 - accuracy: 0.8912 - val_loss: 0.2322 - val_accuracy: 0.9358\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4164 - accuracy: 0.8889 - val_loss: 0.2291 - val_accuracy: 0.9363\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4075 - accuracy: 0.8925 - val_loss: 0.2308 - val_accuracy: 0.9374\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3986 - accuracy: 0.8925 - val_loss: 0.2253 - val_accuracy: 0.9380\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4033 - accuracy: 0.8911 - val_loss: 0.2271 - val_accuracy: 0.9386\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.3026 - accuracy: 0.1152 - val_loss: 2.2875 - val_accuracy: 0.1663\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2827 - accuracy: 0.1792 - val_loss: 2.2531 - val_accuracy: 0.2889\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2319 - accuracy: 0.2356 - val_loss: 2.0560 - val_accuracy: 0.3652\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0780 - accuracy: 0.2845 - val_loss: 1.8147 - val_accuracy: 0.4250\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9060 - accuracy: 0.3367 - val_loss: 1.4374 - val_accuracy: 0.5475\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6725 - accuracy: 0.4127 - val_loss: 1.1546 - val_accuracy: 0.6162\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4833 - accuracy: 0.4721 - val_loss: 0.9998 - val_accuracy: 0.6441\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3508 - accuracy: 0.5214 - val_loss: 0.8998 - val_accuracy: 0.6708\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2452 - accuracy: 0.5538 - val_loss: 0.8350 - val_accuracy: 0.7102\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1623 - accuracy: 0.5865 - val_loss: 0.7790 - val_accuracy: 0.7446\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1277 - accuracy: 0.5982 - val_loss: 0.7359 - val_accuracy: 0.7693\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0748 - accuracy: 0.6211 - val_loss: 0.6946 - val_accuracy: 0.7808\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0225 - accuracy: 0.6403 - val_loss: 0.6541 - val_accuracy: 0.8037\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9977 - accuracy: 0.6553 - val_loss: 0.6174 - val_accuracy: 0.8069\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9763 - accuracy: 0.6594 - val_loss: 0.5913 - val_accuracy: 0.8141\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9411 - accuracy: 0.6713 - val_loss: 0.5669 - val_accuracy: 0.8286\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9104 - accuracy: 0.6852 - val_loss: 0.5455 - val_accuracy: 0.8313\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8876 - accuracy: 0.6952 - val_loss: 0.5275 - val_accuracy: 0.8378\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8501 - accuracy: 0.7076 - val_loss: 0.5111 - val_accuracy: 0.8459\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8245 - accuracy: 0.7160 - val_loss: 0.4979 - val_accuracy: 0.8495\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8128 - accuracy: 0.7217 - val_loss: 0.4835 - val_accuracy: 0.8583\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7978 - accuracy: 0.7307 - val_loss: 0.4685 - val_accuracy: 0.8640\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7778 - accuracy: 0.7348 - val_loss: 0.4574 - val_accuracy: 0.8659\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7604 - accuracy: 0.7443 - val_loss: 0.4476 - val_accuracy: 0.8735\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7509 - accuracy: 0.7436 - val_loss: 0.4419 - val_accuracy: 0.8725\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7342 - accuracy: 0.7518 - val_loss: 0.4291 - val_accuracy: 0.8776\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7213 - accuracy: 0.7574 - val_loss: 0.4188 - val_accuracy: 0.8863\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7126 - accuracy: 0.7573 - val_loss: 0.4136 - val_accuracy: 0.8891\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.7667 - val_loss: 0.4043 - val_accuracy: 0.8927\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6758 - accuracy: 0.7739 - val_loss: 0.3943 - val_accuracy: 0.8996\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6672 - accuracy: 0.7783 - val_loss: 0.3852 - val_accuracy: 0.9023\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6606 - accuracy: 0.7844 - val_loss: 0.3780 - val_accuracy: 0.9032\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6480 - accuracy: 0.7897 - val_loss: 0.3706 - val_accuracy: 0.9053\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6465 - accuracy: 0.7899 - val_loss: 0.3606 - val_accuracy: 0.9087\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6309 - accuracy: 0.7972 - val_loss: 0.3546 - val_accuracy: 0.9126\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6123 - accuracy: 0.8034 - val_loss: 0.3476 - val_accuracy: 0.9117\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6004 - accuracy: 0.8032 - val_loss: 0.3408 - val_accuracy: 0.9183\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5831 - accuracy: 0.8129 - val_loss: 0.3304 - val_accuracy: 0.9183\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5866 - accuracy: 0.8121 - val_loss: 0.3250 - val_accuracy: 0.9199\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5711 - accuracy: 0.8202 - val_loss: 0.3167 - val_accuracy: 0.9233\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5658 - accuracy: 0.8213 - val_loss: 0.3124 - val_accuracy: 0.9254\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5528 - accuracy: 0.8266 - val_loss: 0.3070 - val_accuracy: 0.9262\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5506 - accuracy: 0.8264 - val_loss: 0.3003 - val_accuracy: 0.9277\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5388 - accuracy: 0.8318 - val_loss: 0.2932 - val_accuracy: 0.9302\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5267 - accuracy: 0.8353 - val_loss: 0.2914 - val_accuracy: 0.9300\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5169 - accuracy: 0.8392 - val_loss: 0.2848 - val_accuracy: 0.9318\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4991 - accuracy: 0.8449 - val_loss: 0.2807 - val_accuracy: 0.9327\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5079 - accuracy: 0.8430 - val_loss: 0.2786 - val_accuracy: 0.9337\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4955 - accuracy: 0.8475 - val_loss: 0.2721 - val_accuracy: 0.9362\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5037 - accuracy: 0.8444 - val_loss: 0.2664 - val_accuracy: 0.9361\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.2985 - accuracy: 0.1269 - val_loss: 2.2841 - val_accuracy: 0.2101\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2799 - accuracy: 0.1892 - val_loss: 2.2576 - val_accuracy: 0.2707\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2487 - accuracy: 0.2326 - val_loss: 2.1804 - val_accuracy: 0.3147\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1467 - accuracy: 0.2750 - val_loss: 1.9107 - val_accuracy: 0.3651\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9520 - accuracy: 0.3114 - val_loss: 1.6542 - val_accuracy: 0.4672\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7941 - accuracy: 0.3641 - val_loss: 1.4332 - val_accuracy: 0.5778\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6300 - accuracy: 0.4300 - val_loss: 1.2277 - val_accuracy: 0.6348\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4948 - accuracy: 0.4762 - val_loss: 1.0752 - val_accuracy: 0.6842\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3868 - accuracy: 0.5204 - val_loss: 0.9618 - val_accuracy: 0.7278\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2877 - accuracy: 0.5552 - val_loss: 0.8722 - val_accuracy: 0.7558\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2126 - accuracy: 0.5781 - val_loss: 0.8101 - val_accuracy: 0.7768\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1415 - accuracy: 0.6072 - val_loss: 0.7526 - val_accuracy: 0.7958\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1069 - accuracy: 0.6296 - val_loss: 0.7153 - val_accuracy: 0.8146\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0614 - accuracy: 0.6465 - val_loss: 0.6733 - val_accuracy: 0.8261\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0235 - accuracy: 0.6632 - val_loss: 0.6399 - val_accuracy: 0.8375\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9933 - accuracy: 0.6757 - val_loss: 0.6130 - val_accuracy: 0.8461\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9550 - accuracy: 0.6928 - val_loss: 0.5840 - val_accuracy: 0.8539\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9356 - accuracy: 0.6993 - val_loss: 0.5594 - val_accuracy: 0.8600\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9045 - accuracy: 0.7095 - val_loss: 0.5378 - val_accuracy: 0.8670\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8636 - accuracy: 0.7301 - val_loss: 0.5167 - val_accuracy: 0.8700\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8581 - accuracy: 0.7274 - val_loss: 0.4965 - val_accuracy: 0.8758\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8354 - accuracy: 0.7354 - val_loss: 0.4785 - val_accuracy: 0.8786\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8099 - accuracy: 0.7479 - val_loss: 0.4611 - val_accuracy: 0.8819\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7985 - accuracy: 0.7549 - val_loss: 0.4439 - val_accuracy: 0.8856\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7842 - accuracy: 0.7598 - val_loss: 0.4281 - val_accuracy: 0.8896\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7552 - accuracy: 0.7674 - val_loss: 0.4158 - val_accuracy: 0.8913\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7662 - accuracy: 0.7665 - val_loss: 0.4042 - val_accuracy: 0.8940\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7434 - accuracy: 0.7726 - val_loss: 0.3927 - val_accuracy: 0.8960\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7170 - accuracy: 0.7798 - val_loss: 0.3814 - val_accuracy: 0.8985\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7140 - accuracy: 0.7832 - val_loss: 0.3745 - val_accuracy: 0.8987\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.7856 - val_loss: 0.3615 - val_accuracy: 0.9016\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6894 - accuracy: 0.7925 - val_loss: 0.3547 - val_accuracy: 0.9038\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6788 - accuracy: 0.7983 - val_loss: 0.3461 - val_accuracy: 0.9053\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6527 - accuracy: 0.8015 - val_loss: 0.3402 - val_accuracy: 0.9072\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6514 - accuracy: 0.8030 - val_loss: 0.3317 - val_accuracy: 0.9079\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6448 - accuracy: 0.8073 - val_loss: 0.3260 - val_accuracy: 0.9112\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6351 - accuracy: 0.8098 - val_loss: 0.3191 - val_accuracy: 0.9147\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6165 - accuracy: 0.8165 - val_loss: 0.3122 - val_accuracy: 0.9147\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6017 - accuracy: 0.8193 - val_loss: 0.3066 - val_accuracy: 0.9167\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6044 - accuracy: 0.8190 - val_loss: 0.2991 - val_accuracy: 0.9187\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5876 - accuracy: 0.8220 - val_loss: 0.2935 - val_accuracy: 0.9203\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5832 - accuracy: 0.8308 - val_loss: 0.2897 - val_accuracy: 0.9219\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5853 - accuracy: 0.8254 - val_loss: 0.2845 - val_accuracy: 0.9225\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5630 - accuracy: 0.8322 - val_loss: 0.2796 - val_accuracy: 0.9237\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5650 - accuracy: 0.8354 - val_loss: 0.2769 - val_accuracy: 0.9256\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5515 - accuracy: 0.8397 - val_loss: 0.2716 - val_accuracy: 0.9262\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5534 - accuracy: 0.8399 - val_loss: 0.2691 - val_accuracy: 0.9273\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5470 - accuracy: 0.8400 - val_loss: 0.2639 - val_accuracy: 0.9284\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5220 - accuracy: 0.8472 - val_loss: 0.2613 - val_accuracy: 0.9283\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5289 - accuracy: 0.8431 - val_loss: 0.2574 - val_accuracy: 0.9305\n",
            "{'loss': [1.937291145324707, 1.4879341125488281, 1.2681760787963867, 1.1355541944503784, 1.0515568256378174, 0.9845706224441528, 0.9298555254936218, 0.8873840570449829, 0.8559727668762207, 0.8239778876304626, 0.8040027618408203, 0.7763125896453857, 0.7618128061294556, 0.7403151988983154, 0.7190925478935242, 0.7101656198501587, 0.690186619758606, 0.6793755888938904, 0.6714296340942383, 0.6521580815315247, 0.6480079889297485, 0.6313565969467163, 0.6315141320228577, 0.613839864730835, 0.6078180074691772, 0.604552686214447, 0.5957549810409546, 0.5854710936546326, 0.5702643394470215, 0.5739613175392151, 0.5650099515914917, 0.5596271753311157, 0.5518121123313904, 0.5440229773521423, 0.5426109433174133, 0.5352628827095032, 0.5376527905464172, 0.5255388617515564, 0.5195557475090027, 0.5170866847038269, 0.5125393867492676, 0.5103135704994202, 0.5008570551872253, 0.49707508087158203, 0.4986753463745117, 0.48661378026008606, 0.48217105865478516, 0.48368823528289795, 0.47981205582618713, 0.47175121307373047], 'accuracy': [0.3177500069141388, 0.5040208101272583, 0.5870833396911621, 0.6359583139419556, 0.6657083630561829, 0.6904374957084656, 0.7113541960716248, 0.726187527179718, 0.7381250262260437, 0.7501041889190674, 0.7587291598320007, 0.7696458101272583, 0.7769166827201843, 0.7824375033378601, 0.7899583578109741, 0.7951250076293945, 0.8025416731834412, 0.8108541369438171, 0.8114374876022339, 0.8176458477973938, 0.8190000057220459, 0.8240208625793457, 0.8258749842643738, 0.8321250081062317, 0.8332708477973938, 0.8386041522026062, 0.8378541469573975, 0.8425624966621399, 0.847083330154419, 0.8447916507720947, 0.8498541712760925, 0.8500000238418579, 0.8560000061988831, 0.8558124899864197, 0.8556041717529297, 0.8587708473205566, 0.859208345413208, 0.8625624775886536, 0.8645208477973938, 0.8644999861717224, 0.8656666874885559, 0.8681874871253967, 0.8685416579246521, 0.8708124756813049, 0.8715416789054871, 0.8729166388511658, 0.8753958344459534, 0.87479168176651, 0.8757500052452087, 0.8792083263397217], 'val_loss': [1.1902174949645996, 0.8867947459220886, 0.727081298828125, 0.6298450231552124, 0.565958559513092, 0.5233482122421265, 0.4886453151702881, 0.46661317348480225, 0.4464648365974426, 0.4310224950313568, 0.41740694642066956, 0.40561357140541077, 0.3985738158226013, 0.3898952603340149, 0.3830491006374359, 0.3769266903400421, 0.37193432450294495, 0.3688284158706665, 0.3622298240661621, 0.36011600494384766, 0.35449740290641785, 0.3507446348667145, 0.3474991023540497, 0.3461965024471283, 0.34505993127822876, 0.33940771222114563, 0.336516797542572, 0.33369505405426025, 0.33436405658721924, 0.3307143747806549, 0.32711461186408997, 0.324318528175354, 0.32071125507354736, 0.3189067244529724, 0.3169493079185486, 0.31302884221076965, 0.31322842836380005, 0.3103538751602173, 0.3097772002220154, 0.3068619668483734, 0.30452653765678406, 0.3008146286010742, 0.3013782501220703, 0.29662567377090454, 0.29424193501472473, 0.2937875986099243, 0.29281917214393616, 0.28943589329719543, 0.2863537669181824, 0.2860713005065918], 'val_accuracy': [0.7298333048820496, 0.8012499809265137, 0.8285833597183228, 0.8446666598320007, 0.8569166660308838, 0.8657500147819519, 0.8725833296775818, 0.874750018119812, 0.8787500262260437, 0.8820833563804626, 0.8851666450500488, 0.8890833258628845, 0.8916666507720947, 0.8945833444595337, 0.8941666483879089, 0.8970000147819519, 0.8995833396911621, 0.8996666669845581, 0.9008333086967468, 0.9025833606719971, 0.9038333296775818, 0.9046666622161865, 0.9067500233650208, 0.9070833325386047, 0.9088333249092102, 0.9107499718666077, 0.9108333587646484, 0.9120000004768372, 0.9139999747276306, 0.9142500162124634, 0.9150833487510681, 0.9146666526794434, 0.9165833592414856, 0.9177500009536743, 0.918666660785675, 0.9190000295639038, 0.9203333258628845, 0.9201666712760925, 0.9207500219345093, 0.9225833415985107, 0.9236666560173035, 0.9242500066757202, 0.9245833158493042, 0.9254999756813049, 0.9259999990463257, 0.9273333549499512, 0.9278333187103271, 0.9285833239555359, 0.9292500019073486, 0.9298333525657654]}\n",
            "{'loss': [2.2916746139526367, 2.199723243713379, 2.050316333770752, 1.905094861984253, 1.780542016029358, 1.6829928159713745, 1.5837419033050537, 1.4954895973205566, 1.4247517585754395, 1.3540573120117188, 1.2984977960586548, 1.2541583776474, 1.2098841667175293, 1.171669363975525, 1.129901647567749, 1.0895187854766846, 1.0581533908843994, 1.0197523832321167, 0.9852250814437866, 0.9544000029563904, 0.928157389163971, 0.901811420917511, 0.8787551522254944, 0.850922703742981, 0.8392841815948486, 0.8094810247421265, 0.7942453026771545, 0.7806893587112427, 0.758543848991394, 0.743650496006012, 0.7269017696380615, 0.7167584896087646, 0.6959869861602783, 0.6758236289024353, 0.6612943410873413, 0.6491991877555847, 0.6319404244422913, 0.6208599209785461, 0.6024268269538879, 0.6006487011909485, 0.5757846832275391, 0.5639973878860474, 0.5547261834144592, 0.5463436245918274, 0.5286397933959961, 0.5246773362159729, 0.5146752595901489, 0.5041259527206421, 0.4888056218624115, 0.48811572790145874], 'accuracy': [0.12725000083446503, 0.18402083218097687, 0.24631249904632568, 0.29002082347869873, 0.328166663646698, 0.3673958480358124, 0.40454167127609253, 0.4332500100135803, 0.4528749883174896, 0.48108333349227905, 0.49793750047683716, 0.5184583067893982, 0.538895845413208, 0.5560208559036255, 0.5798958539962769, 0.6017500162124634, 0.6180208325386047, 0.6332708597183228, 0.6503958106040955, 0.6622916460037231, 0.6709583401679993, 0.6807500123977661, 0.6916249990463257, 0.7041666507720947, 0.7121666669845581, 0.7241666913032532, 0.729604184627533, 0.7404166460037231, 0.7487291693687439, 0.7531041502952576, 0.761020839214325, 0.765541672706604, 0.7750833630561829, 0.7820624709129333, 0.7868124842643738, 0.7897916436195374, 0.7990000247955322, 0.804395854473114, 0.8103749752044678, 0.812416672706604, 0.8232083320617676, 0.8230208158493042, 0.8241875171661377, 0.8299166560173035, 0.8339583277702332, 0.8354583382606506, 0.840666651725769, 0.8412708044052124, 0.8470208048820496, 0.8457499742507935], 'val_loss': [2.2283389568328857, 2.0070607662200928, 1.7711559534072876, 1.5733425617218018, 1.4209144115447998, 1.2989280223846436, 1.1921305656433105, 1.1035001277923584, 1.043939232826233, 0.9812143445014954, 0.9521386027336121, 0.9060818552970886, 0.8649241328239441, 0.8139899373054504, 0.7680898308753967, 0.7138465046882629, 0.6806483268737793, 0.6460999250411987, 0.6081267595291138, 0.584615170955658, 0.5590319633483887, 0.5363991856575012, 0.5196335315704346, 0.5015121102333069, 0.48849382996559143, 0.4766996204853058, 0.4593107998371124, 0.44940710067749023, 0.4396975636482239, 0.4206724762916565, 0.41271117329597473, 0.40052324533462524, 0.38842257857322693, 0.38083475828170776, 0.37018075585365295, 0.3656889796257019, 0.35799935460090637, 0.35189488530158997, 0.34699547290802, 0.33680394291877747, 0.33203813433647156, 0.3286080062389374, 0.3259581923484802, 0.32546210289001465, 0.3183324933052063, 0.3178156018257141, 0.3267477750778198, 0.319813996553421, 0.3182845115661621, 0.3260127305984497], 'val_accuracy': [0.3254166543483734, 0.3903333246707916, 0.4179166555404663, 0.47725000977516174, 0.531583309173584, 0.5524166822433472, 0.5660833120346069, 0.578499972820282, 0.5913333296775818, 0.6150000095367432, 0.6800833344459534, 0.6870833039283752, 0.7246666550636292, 0.7590833306312561, 0.7593333125114441, 0.7735833525657654, 0.7878333330154419, 0.8015000224113464, 0.8268333077430725, 0.8269166946411133, 0.8370833396911621, 0.8485000133514404, 0.8570833206176758, 0.8700833320617676, 0.8686666488647461, 0.8828333616256714, 0.8810833096504211, 0.8900833129882812, 0.8942499756813049, 0.9054166674613953, 0.9100000262260437, 0.9144166707992554, 0.9157500267028809, 0.9201666712760925, 0.9227499961853027, 0.922249972820282, 0.9256666898727417, 0.9279999732971191, 0.9273333549499512, 0.9299166798591614, 0.9308333396911621, 0.9326666593551636, 0.9355000257492065, 0.9360833168029785, 0.9370833039283752, 0.937250018119812, 0.9379166960716248, 0.9387500286102295, 0.9403333067893982, 0.9403333067893982]}\n",
            "{'loss': [2.2656261920928955, 2.041685104370117, 1.7650854587554932, 1.5257489681243896, 1.3347676992416382, 1.1921329498291016, 1.0837030410766602, 1.0082591772079468, 0.932328462600708, 0.8844172358512878, 0.8345823287963867, 0.7990977168083191, 0.7595747709274292, 0.7324223518371582, 0.7059752345085144, 0.6757341623306274, 0.6588488817214966, 0.6372461318969727, 0.6250557899475098, 0.6008453965187073, 0.5913423895835876, 0.5723084211349487, 0.5549737811088562, 0.5382574796676636, 0.5284305810928345, 0.516950786113739, 0.4948852062225342, 0.49199649691581726, 0.47553616762161255, 0.4688073694705963, 0.4530501663684845, 0.4435026943683624, 0.43095386028289795, 0.4278944134712219, 0.41578125953674316, 0.39648714661598206, 0.40134814381599426, 0.39573368430137634, 0.3873012363910675, 0.3738879859447479, 0.3687789738178253, 0.36224254965782166, 0.3602846562862396, 0.3493347465991974, 0.3437832295894623, 0.33683478832244873, 0.3312867283821106, 0.32558655738830566, 0.31796613335609436, 0.3168378174304962], 'accuracy': [0.1497291624546051, 0.2626041769981384, 0.359333336353302, 0.45497918128967285, 0.531000018119812, 0.5847916603088379, 0.6293958425521851, 0.6600833535194397, 0.6917708516120911, 0.7106249928474426, 0.7274791598320007, 0.7447500228881836, 0.7587500214576721, 0.7746041417121887, 0.7834583520889282, 0.7933541536331177, 0.7993124723434448, 0.8070833086967468, 0.812624990940094, 0.8208541870117188, 0.8237708210945129, 0.8335208296775818, 0.8376874923706055, 0.8424791693687439, 0.8486250042915344, 0.8486875295639038, 0.856333315372467, 0.8579375147819519, 0.8630833625793457, 0.8672083616256714, 0.8693958520889282, 0.8730000257492065, 0.8768541812896729, 0.8790416717529297, 0.8836874961853027, 0.8861250281333923, 0.886145830154419, 0.8898749947547913, 0.8913750052452087, 0.8945208191871643, 0.8946041464805603, 0.8977916836738586, 0.8966458439826965, 0.9017916917800903, 0.9047708511352539, 0.9040625095367432, 0.9068541526794434, 0.9089375138282776, 0.9100833535194397, 0.9121875166893005], 'val_loss': [2.1143288612365723, 1.6329752206802368, 1.2621686458587646, 1.0009028911590576, 0.835054874420166, 0.7127963304519653, 0.6313782334327698, 0.5733584761619568, 0.5234873294830322, 0.4931574761867523, 0.46181368827819824, 0.4396471381187439, 0.41752326488494873, 0.4022619128227234, 0.38288354873657227, 0.36690014600753784, 0.35330480337142944, 0.3448428511619568, 0.3330584168434143, 0.32264232635498047, 0.31302908062934875, 0.30250266194343567, 0.29508206248283386, 0.28473782539367676, 0.27852171659469604, 0.27333396673202515, 0.2682799994945526, 0.26149237155914307, 0.25668907165527344, 0.2502775490283966, 0.24758444726467133, 0.243961364030838, 0.239242285490036, 0.2341707944869995, 0.23121120035648346, 0.23065969347953796, 0.22636981308460236, 0.22545689344406128, 0.22174452245235443, 0.21714095771312714, 0.22085797786712646, 0.2165033370256424, 0.21496286988258362, 0.21608364582061768, 0.21257714927196503, 0.20974549651145935, 0.20920705795288086, 0.20980162918567657, 0.20839935541152954, 0.2056499570608139], 'val_accuracy': [0.40933331847190857, 0.5212500095367432, 0.6226666569709778, 0.706083357334137, 0.7829999923706055, 0.8207499980926514, 0.8414999842643738, 0.8485000133514404, 0.8578333258628845, 0.8659999966621399, 0.874916672706604, 0.8784166574478149, 0.8845833539962769, 0.8859166502952576, 0.8924999833106995, 0.8973333239555359, 0.9023333191871643, 0.9039999842643738, 0.9085000157356262, 0.9109166860580444, 0.9133333563804626, 0.9163333177566528, 0.9191666841506958, 0.9212499856948853, 0.9231666922569275, 0.925166666507721, 0.9264166951179504, 0.9275833368301392, 0.9294999837875366, 0.9307500123977661, 0.9328333139419556, 0.934416651725769, 0.9354166388511658, 0.9370833039283752, 0.9381666779518127, 0.9391666650772095, 0.9403333067893982, 0.9412500262260437, 0.9434999823570251, 0.9424166679382324, 0.9419999718666077, 0.9440000057220459, 0.9447500109672546, 0.9459166526794434, 0.9459166526794434, 0.9470833539962769, 0.9468333125114441, 0.9472500085830688, 0.9477499723434448, 0.9493333101272583]}\n",
            "{'loss': [1.83931303024292, 1.3379144668579102, 1.1415090560913086, 1.0366790294647217, 0.9589048624038696, 0.902224063873291, 0.8574457764625549, 0.8242572546005249, 0.789234459400177, 0.7698166370391846, 0.7447608113288879, 0.721974790096283, 0.7109443545341492, 0.6913296580314636, 0.6781920790672302, 0.6483405232429504, 0.6468702554702759, 0.6301395297050476, 0.6100183129310608, 0.6012134552001953, 0.5876320600509644, 0.5763699412345886, 0.571319580078125, 0.5616592764854431, 0.5545167326927185, 0.5376771092414856, 0.5242359042167664, 0.5191067457199097, 0.5181302428245544, 0.5062732696533203, 0.492241770029068, 0.4804166257381439, 0.4830995202064514, 0.4723583161830902, 0.46608251333236694, 0.46410220861434937, 0.4497470557689667, 0.4492843449115753, 0.45233020186424255, 0.443703830242157, 0.439271479845047, 0.4263295829296112, 0.4246852993965149, 0.42000386118888855, 0.4176200330257416, 0.41391751170158386, 0.40828970074653625, 0.398520827293396, 0.400686115026474, 0.39639541506767273], 'accuracy': [0.3487708270549774, 0.531499981880188, 0.6107708215713501, 0.6502916812896729, 0.6820625066757202, 0.7051041722297668, 0.7227083444595337, 0.7356250286102295, 0.7501458525657654, 0.758104145526886, 0.7684375047683716, 0.7804999947547913, 0.784541666507721, 0.7926458120346069, 0.7997083067893982, 0.8083958625793457, 0.809499979019165, 0.8146874904632568, 0.8209583163261414, 0.8256875276565552, 0.828249990940094, 0.8359583616256714, 0.8374166488647461, 0.8414375185966492, 0.843625009059906, 0.8487291932106018, 0.8514583110809326, 0.8534166812896729, 0.8544583320617676, 0.8597708344459534, 0.8645208477973938, 0.863937497138977, 0.8652499914169312, 0.8695833086967468, 0.8712708353996277, 0.871958315372467, 0.875374972820282, 0.8765000104904175, 0.8751041889190674, 0.8771458268165588, 0.8800208568572998, 0.8840000033378601, 0.88302081823349, 0.8844375014305115, 0.8853750228881836, 0.8886458277702332, 0.8877708315849304, 0.8908958435058594, 0.89083331823349, 0.8927083611488342], 'val_loss': [0.9725833535194397, 0.6796786189079285, 0.5679500699043274, 0.508472740650177, 0.47318777441978455, 0.4467948079109192, 0.4223026931285858, 0.40543195605278015, 0.3922344148159027, 0.3803677260875702, 0.3676271140575409, 0.3594211935997009, 0.3495887815952301, 0.34356945753097534, 0.3323543965816498, 0.32776740193367004, 0.319828599691391, 0.312322735786438, 0.30872228741645813, 0.3037447929382324, 0.2990451157093048, 0.2929448187351227, 0.28665292263031006, 0.2838691473007202, 0.2786892354488373, 0.2756651043891907, 0.2720537483692169, 0.26866957545280457, 0.2661738097667694, 0.261898934841156, 0.2594936192035675, 0.2580592930316925, 0.2562355697154999, 0.25414082407951355, 0.24721260368824005, 0.24484391510486603, 0.2420416623353958, 0.23844586312770844, 0.2367010861635208, 0.23558148741722107, 0.23147472739219666, 0.23118849098682404, 0.22796396911144257, 0.22767072916030884, 0.22614610195159912, 0.22215977311134338, 0.22239051759243011, 0.22187894582748413, 0.21948906779289246, 0.21760772168636322], 'val_accuracy': [0.7404166460037231, 0.8161666393280029, 0.8441666960716248, 0.85958331823349, 0.8693333268165588, 0.8756666779518127, 0.8813333511352539, 0.8859999775886536, 0.8894166946411133, 0.893666684627533, 0.8948333263397217, 0.8977500200271606, 0.8995000123977661, 0.9007499814033508, 0.9057499766349792, 0.9073333144187927, 0.9079166650772095, 0.9098333120346069, 0.9110000133514404, 0.9146666526794434, 0.9142500162124634, 0.9154999852180481, 0.9171666502952576, 0.9193333387374878, 0.9192500114440918, 0.9204166531562805, 0.9200833439826965, 0.9211666584014893, 0.9226666688919067, 0.9252499938011169, 0.9254166483879089, 0.9266666769981384, 0.9273333549499512, 0.9285833239555359, 0.9283333420753479, 0.9312499761581421, 0.9320833086967468, 0.9329166412353516, 0.9328333139419556, 0.9335833191871643, 0.9347500205039978, 0.9359999895095825, 0.9354166388511658, 0.9369166493415833, 0.937166690826416, 0.937833309173584, 0.9389166831970215, 0.9410833120346069, 0.940500020980835, 0.9394166469573975]}\n",
            "{'loss': [1.9907124042510986, 1.250746726989746, 1.063699722290039, 0.9542039632797241, 0.8871371150016785, 0.8381202816963196, 0.7977176308631897, 0.7664663791656494, 0.7401056289672852, 0.7243161797523499, 0.6960171461105347, 0.6780815720558167, 0.6654247641563416, 0.6486285328865051, 0.6316282153129578, 0.6107195019721985, 0.6081280708312988, 0.5932648181915283, 0.5838636755943298, 0.576486349105835, 0.5774621963500977, 0.559313952922821, 0.5440548658370972, 0.5393545627593994, 0.5336433053016663, 0.5301214456558228, 0.5178701281547546, 0.5134031176567078, 0.5054996609687805, 0.4919492304325104, 0.49593228101730347, 0.4842316508293152, 0.4776565432548523, 0.4759750962257385, 0.46789562702178955, 0.4606562554836273, 0.4590091407299042, 0.4538228213787079, 0.44749340415000916, 0.4428063631057739, 0.43520092964172363, 0.42740893363952637, 0.4248791038990021, 0.42515310645103455, 0.41819143295288086, 0.4151032269001007, 0.4137203097343445, 0.4078308045864105, 0.40586838126182556, 0.4048371911048889], 'accuracy': [0.37681248784065247, 0.5680833458900452, 0.6428541541099548, 0.6884375214576721, 0.7141249775886536, 0.7362499833106995, 0.754520833492279, 0.7664791941642761, 0.7757499814033508, 0.7831666469573975, 0.7947499752044678, 0.8027083277702332, 0.809249997138977, 0.8126875162124634, 0.820604145526886, 0.8261666893959045, 0.8285208344459534, 0.8335208296775818, 0.8386874794960022, 0.8398125171661377, 0.8405625224113464, 0.843666672706604, 0.8482499718666077, 0.8502916693687439, 0.8514999747276306, 0.8530625104904175, 0.8589166402816772, 0.8609583377838135, 0.8618333339691162, 0.8647291660308838, 0.8668749928474426, 0.8681250214576721, 0.8706666827201843, 0.8692916631698608, 0.8722500205039978, 0.8744791746139526, 0.8742291927337646, 0.8790624737739563, 0.8806041479110718, 0.8807291388511658, 0.8823124766349792, 0.8842916488647461, 0.8849166631698608, 0.8849791884422302, 0.8869791626930237, 0.8884791731834412, 0.8885416388511658, 0.8908958435058594, 0.8910833597183228, 0.8906041383743286], 'val_loss': [0.6567911505699158, 0.5267801284790039, 0.46794629096984863, 0.43594738841056824, 0.4079637825489044, 0.3932010531425476, 0.3792262077331543, 0.36507555842399597, 0.35228514671325684, 0.34506651759147644, 0.3379431962966919, 0.33015525341033936, 0.3233853876590729, 0.3196355700492859, 0.31551364064216614, 0.3112470209598541, 0.30367112159729004, 0.2991556227207184, 0.29835909605026245, 0.29031580686569214, 0.2878367602825165, 0.2857252061367035, 0.28145164251327515, 0.280350923538208, 0.2771381735801697, 0.2707200348377228, 0.270294189453125, 0.26599711179733276, 0.26317650079727173, 0.2617587745189667, 0.2607578933238983, 0.256686806678772, 0.2543800175189972, 0.2494916021823883, 0.2525152564048767, 0.24748682975769043, 0.2469683587551117, 0.24605627357959747, 0.24263077974319458, 0.2405000478029251, 0.23695144057273865, 0.2400919795036316, 0.2360772341489792, 0.23681575059890747, 0.23749281466007233, 0.2321726232767105, 0.22905409336090088, 0.230782613158226, 0.22526568174362183, 0.22710879147052765], 'val_accuracy': [0.8135833144187927, 0.8517500162124634, 0.8665833473205566, 0.875333309173584, 0.8822500109672546, 0.8847500085830688, 0.8899999856948853, 0.8929166793823242, 0.8947499990463257, 0.8970000147819519, 0.8998333215713501, 0.903249979019165, 0.9038333296775818, 0.9074166417121887, 0.9080833196640015, 0.9090833067893982, 0.909583330154419, 0.9129999876022339, 0.9128333330154419, 0.9162499904632568, 0.9173333048820496, 0.9176666736602783, 0.9179166555404663, 0.9179166555404663, 0.9201666712760925, 0.9231666922569275, 0.9235833287239075, 0.9243333339691162, 0.9246666431427002, 0.9265000224113464, 0.9262499809265137, 0.9287499785423279, 0.9287499785423279, 0.9287499785423279, 0.9295833110809326, 0.9309166669845581, 0.9315833449363708, 0.9310833215713501, 0.9329166412353516, 0.9331666827201843, 0.934166669845581, 0.934416651725769, 0.9353333115577698, 0.934333324432373, 0.9351666569709778, 0.9357500076293945, 0.9363333582878113, 0.937416672706604, 0.9380000233650208, 0.9385833144187927]}\n",
            "{'loss': [2.298088312149048, 2.275942325592041, 2.1996498107910156, 2.0417823791503906, 1.848479151725769, 1.6130552291870117, 1.437869668006897, 1.3159717321395874, 1.2268900871276855, 1.153659462928772, 1.1157490015029907, 1.066294550895691, 1.0201572179794312, 0.9903727769851685, 0.9609445929527283, 0.9338931441307068, 0.9021568894386292, 0.8801862001419067, 0.851608395576477, 0.8297107815742493, 0.808836042881012, 0.7923994064331055, 0.772600531578064, 0.7608422040939331, 0.7483479976654053, 0.7293498516082764, 0.7173969745635986, 0.7086076140403748, 0.6932407021522522, 0.6730831861495972, 0.6652601957321167, 0.6591286063194275, 0.6452451348304749, 0.6380428075790405, 0.6240623593330383, 0.6098066568374634, 0.5991467833518982, 0.5902350544929504, 0.5790064930915833, 0.5739217400550842, 0.5667023658752441, 0.5553445219993591, 0.5405759215354919, 0.5377398133277893, 0.5243338942527771, 0.5168201327323914, 0.5054160356521606, 0.506011962890625, 0.4925926923751831, 0.49462586641311646], 'accuracy': [0.13195833563804626, 0.19195833802223206, 0.24806250631809235, 0.2914791703224182, 0.35499998927116394, 0.4338124990463257, 0.4886249899864197, 0.5315625071525574, 0.5619583129882812, 0.5882916450500488, 0.6025624871253967, 0.6244166493415833, 0.6412083506584167, 0.6542916893959045, 0.6666666865348816, 0.6760416626930237, 0.6893541812896729, 0.6992499828338623, 0.7087083458900452, 0.7153750061988831, 0.7239999771118164, 0.7300833463668823, 0.7365000247955322, 0.745145857334137, 0.7477083206176758, 0.7555416822433472, 0.7588958144187927, 0.7614166736602783, 0.7683125138282776, 0.7751666903495789, 0.7790625095367432, 0.7835624814033508, 0.7898749709129333, 0.7934583425521851, 0.7982708215713501, 0.8031666874885559, 0.8048333525657654, 0.8119791746139526, 0.8137083053588867, 0.8172500133514404, 0.820645809173584, 0.8253333568572998, 0.8274999856948853, 0.8318333625793457, 0.8364791870117188, 0.8389999866485596, 0.8436041474342346, 0.8441041707992554, 0.8481458425521851, 0.847041666507721], 'val_loss': [2.2875208854675293, 2.253066062927246, 2.055952548980713, 1.8147200345993042, 1.4374206066131592, 1.1545778512954712, 0.9998186230659485, 0.8998372554779053, 0.8349542021751404, 0.7789629101753235, 0.7359081506729126, 0.6946139931678772, 0.6541012525558472, 0.6173677444458008, 0.5912563800811768, 0.5669234395027161, 0.5455412864685059, 0.5274743437767029, 0.5111356377601624, 0.4978761374950409, 0.48345044255256653, 0.468456506729126, 0.4574471712112427, 0.4476301372051239, 0.4418981671333313, 0.4291064441204071, 0.41882795095443726, 0.41361063718795776, 0.4043312966823578, 0.3943244516849518, 0.3851860761642456, 0.3780097961425781, 0.37058189511299133, 0.36059537529945374, 0.3545598089694977, 0.34757474064826965, 0.3407665491104126, 0.33037281036376953, 0.32495397329330444, 0.31666266918182373, 0.3124081492424011, 0.30699458718299866, 0.30027228593826294, 0.29324275255203247, 0.29140791296958923, 0.2848002016544342, 0.28068509697914124, 0.27858391404151917, 0.2721085548400879, 0.26636606454849243], 'val_accuracy': [0.16633333265781403, 0.288916677236557, 0.36516666412353516, 0.42500001192092896, 0.5475000143051147, 0.6162499785423279, 0.6440833210945129, 0.6707500219345093, 0.7101666927337646, 0.7445833086967468, 0.7693333625793457, 0.7808333039283752, 0.8036666512489319, 0.8069166541099548, 0.8140833377838135, 0.8285833597183228, 0.831333339214325, 0.8378333449363708, 0.8459166884422302, 0.8495000004768372, 0.8583333492279053, 0.8640000224113464, 0.8659166693687439, 0.8734999895095825, 0.8725000023841858, 0.8775833249092102, 0.8863333463668823, 0.8890833258628845, 0.8926666378974915, 0.8995833396911621, 0.9023333191871643, 0.903166651725769, 0.9052500128746033, 0.9087499976158142, 0.9125833511352539, 0.9116666913032532, 0.9182500243186951, 0.9183333516120911, 0.9199166893959045, 0.9233333468437195, 0.9254166483879089, 0.9262499809265137, 0.9276666641235352, 0.9301666617393494, 0.9300000071525574, 0.9318333268165588, 0.9327499866485596, 0.9337499737739563, 0.9361666440963745, 0.9360833168029785]}\n",
            "{'loss': [2.2942304611206055, 2.2739017009735107, 2.23270320892334, 2.101099729537964, 1.912603497505188, 1.7521607875823975, 1.593347191810608, 1.464318871498108, 1.3565659523010254, 1.267602562904358, 1.1983708143234253, 1.1347763538360596, 1.0963093042373657, 1.0482397079467773, 1.0145657062530518, 0.9849672913551331, 0.9513738751411438, 0.9263269901275635, 0.8999125957489014, 0.8684841394424438, 0.8556075692176819, 0.8349631428718567, 0.8124180436134338, 0.7964129447937012, 0.7717770934104919, 0.7614374160766602, 0.7592648863792419, 0.7377345561981201, 0.7166485786437988, 0.712902843952179, 0.6901405453681946, 0.6855591535568237, 0.6722899079322815, 0.6605951189994812, 0.6506595015525818, 0.6449933052062988, 0.6340826749801636, 0.6190008521080017, 0.6102957725524902, 0.6018128395080566, 0.5870428681373596, 0.5789036750793457, 0.5787502527236938, 0.5673677921295166, 0.5586758255958557, 0.547570526599884, 0.5528659224510193, 0.5372385382652283, 0.527958869934082, 0.5308906435966492], 'accuracy': [0.1445208340883255, 0.20418749749660492, 0.2461249977350235, 0.2826666533946991, 0.3232916593551636, 0.38085415959358215, 0.4423958361148834, 0.4886666536331177, 0.5295000076293945, 0.5640833377838135, 0.5862083435058594, 0.6119166612625122, 0.6328125, 0.6524583101272583, 0.6650624871253967, 0.6785416603088379, 0.6937708258628845, 0.70291668176651, 0.713854193687439, 0.7270625233650208, 0.7308750152587891, 0.7384583353996277, 0.7491875290870667, 0.7515000104904175, 0.7622708082199097, 0.7672708630561829, 0.768958330154419, 0.7749999761581421, 0.7816458344459534, 0.7835416793823242, 0.7881666421890259, 0.7921249866485596, 0.7982500195503235, 0.7986666560173035, 0.8040833473205566, 0.8072291612625122, 0.8082083463668823, 0.8160416483879089, 0.8178333044052124, 0.8200416564941406, 0.823479175567627, 0.8285624980926514, 0.8276666402816772, 0.8305000066757202, 0.8355000019073486, 0.8396875262260437, 0.8389999866485596, 0.8425624966621399, 0.8454583287239075, 0.8427083492279053], 'val_loss': [2.284120559692383, 2.2575535774230957, 2.1803863048553467, 1.9106979370117188, 1.654193639755249, 1.4332436323165894, 1.2276802062988281, 1.0751923322677612, 0.9617853760719299, 0.8721666932106018, 0.8100516200065613, 0.7526000142097473, 0.7152723073959351, 0.6732890605926514, 0.6398910880088806, 0.6130198240280151, 0.5840021371841431, 0.55935138463974, 0.5378274917602539, 0.5166668891906738, 0.4964970648288727, 0.4784935414791107, 0.46107974648475647, 0.44388842582702637, 0.42812153697013855, 0.4157964289188385, 0.4042074680328369, 0.3927331268787384, 0.3813532292842865, 0.3745037913322449, 0.36145350337028503, 0.3547487258911133, 0.34609296917915344, 0.34023305773735046, 0.33165431022644043, 0.32595109939575195, 0.3190518915653229, 0.31216973066329956, 0.3065766394138336, 0.29911184310913086, 0.2935059368610382, 0.2896915078163147, 0.2845297157764435, 0.27964702248573303, 0.2769279479980469, 0.2715775966644287, 0.2690904140472412, 0.2638999819755554, 0.26131123304367065, 0.25738805532455444], 'val_accuracy': [0.21008333563804626, 0.2707499861717224, 0.31474998593330383, 0.36508333683013916, 0.4672499895095825, 0.577750027179718, 0.6347500085830688, 0.684166669845581, 0.7278333306312561, 0.7557500004768372, 0.7768333554267883, 0.7957500219345093, 0.8145833611488342, 0.8260833621025085, 0.8374999761581421, 0.8460833430290222, 0.8539166450500488, 0.8600000143051147, 0.8669999837875366, 0.8700000047683716, 0.8757500052452087, 0.8785833120346069, 0.8819166421890259, 0.8855833411216736, 0.8895833492279053, 0.8912500143051147, 0.8939999938011169, 0.8960000276565552, 0.8985000252723694, 0.8986666798591614, 0.9015833139419556, 0.9038333296775818, 0.9052500128746033, 0.9071666598320007, 0.9079166650772095, 0.9112499952316284, 0.9147499799728394, 0.9146666526794434, 0.9166666865348816, 0.918666660785675, 0.9203333258628845, 0.921916663646698, 0.9225000143051147, 0.9237499833106995, 0.9255833625793457, 0.9262499809265137, 0.9272500276565552, 0.9284166693687439, 0.9282500147819519, 0.9304999709129333]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}