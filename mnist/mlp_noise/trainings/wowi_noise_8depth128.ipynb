{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noinit_noise_8depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "88cb10f7-6cb4-4afb-a4a7-aff33f4fef6d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 17s 7ms/step - loss: 2.2056 - accuracy: 0.2059 - val_loss: 1.2659 - val_accuracy: 0.6393\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6262 - accuracy: 0.4256 - val_loss: 0.9812 - val_accuracy: 0.7462\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3914 - accuracy: 0.5223 - val_loss: 0.8070 - val_accuracy: 0.7926\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2382 - accuracy: 0.5842 - val_loss: 0.6893 - val_accuracy: 0.8238\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1294 - accuracy: 0.6357 - val_loss: 0.6046 - val_accuracy: 0.8433\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0433 - accuracy: 0.6631 - val_loss: 0.5514 - val_accuracy: 0.8547\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9801 - accuracy: 0.6919 - val_loss: 0.5095 - val_accuracy: 0.8656\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9133 - accuracy: 0.7249 - val_loss: 0.4780 - val_accuracy: 0.8727\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8810 - accuracy: 0.7355 - val_loss: 0.4591 - val_accuracy: 0.8773\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8391 - accuracy: 0.7507 - val_loss: 0.4401 - val_accuracy: 0.8808\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8084 - accuracy: 0.7624 - val_loss: 0.4310 - val_accuracy: 0.8841\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7879 - accuracy: 0.7736 - val_loss: 0.4188 - val_accuracy: 0.8894\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7551 - accuracy: 0.7856 - val_loss: 0.4087 - val_accuracy: 0.8934\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7431 - accuracy: 0.7936 - val_loss: 0.4010 - val_accuracy: 0.8940\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7135 - accuracy: 0.8019 - val_loss: 0.3947 - val_accuracy: 0.8981\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7075 - accuracy: 0.8027 - val_loss: 0.3912 - val_accuracy: 0.8971\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6968 - accuracy: 0.8096 - val_loss: 0.3831 - val_accuracy: 0.9010\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6732 - accuracy: 0.8136 - val_loss: 0.3798 - val_accuracy: 0.9028\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6602 - accuracy: 0.8229 - val_loss: 0.3739 - val_accuracy: 0.9036\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6602 - accuracy: 0.8219 - val_loss: 0.3710 - val_accuracy: 0.9062\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6257 - accuracy: 0.8317 - val_loss: 0.3670 - val_accuracy: 0.9060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6387 - accuracy: 0.8280 - val_loss: 0.3661 - val_accuracy: 0.9089\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6212 - accuracy: 0.8326 - val_loss: 0.3632 - val_accuracy: 0.9092\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6060 - accuracy: 0.8408 - val_loss: 0.3573 - val_accuracy: 0.9109\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6087 - accuracy: 0.8405 - val_loss: 0.3590 - val_accuracy: 0.9116\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6035 - accuracy: 0.8418 - val_loss: 0.3548 - val_accuracy: 0.9128\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5908 - accuracy: 0.8439 - val_loss: 0.3531 - val_accuracy: 0.9137\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5870 - accuracy: 0.8474 - val_loss: 0.3508 - val_accuracy: 0.9145\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5736 - accuracy: 0.8524 - val_loss: 0.3515 - val_accuracy: 0.9146\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5790 - accuracy: 0.8485 - val_loss: 0.3462 - val_accuracy: 0.9154\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5528 - accuracy: 0.8540 - val_loss: 0.3449 - val_accuracy: 0.9172\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5567 - accuracy: 0.8571 - val_loss: 0.3417 - val_accuracy: 0.9185\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5487 - accuracy: 0.8603 - val_loss: 0.3389 - val_accuracy: 0.9182\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5406 - accuracy: 0.8611 - val_loss: 0.3382 - val_accuracy: 0.9199\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5302 - accuracy: 0.8651 - val_loss: 0.3343 - val_accuracy: 0.9193\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5362 - accuracy: 0.8644 - val_loss: 0.3352 - val_accuracy: 0.9195\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5263 - accuracy: 0.8657 - val_loss: 0.3306 - val_accuracy: 0.9210\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5250 - accuracy: 0.8644 - val_loss: 0.3337 - val_accuracy: 0.9212\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5361 - accuracy: 0.8613 - val_loss: 0.3253 - val_accuracy: 0.9221\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5097 - accuracy: 0.8699 - val_loss: 0.3253 - val_accuracy: 0.9225\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5099 - accuracy: 0.8710 - val_loss: 0.3214 - val_accuracy: 0.9242\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5045 - accuracy: 0.8727 - val_loss: 0.3180 - val_accuracy: 0.9236\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4814 - accuracy: 0.8739 - val_loss: 0.3173 - val_accuracy: 0.9256\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4947 - accuracy: 0.8722 - val_loss: 0.3126 - val_accuracy: 0.9262\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4903 - accuracy: 0.8782 - val_loss: 0.3124 - val_accuracy: 0.9261\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4767 - accuracy: 0.8779 - val_loss: 0.3110 - val_accuracy: 0.9265\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4771 - accuracy: 0.8779 - val_loss: 0.3122 - val_accuracy: 0.9262\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4633 - accuracy: 0.8820 - val_loss: 0.3087 - val_accuracy: 0.9286\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4718 - accuracy: 0.8791 - val_loss: 0.3077 - val_accuracy: 0.9282\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4688 - accuracy: 0.8802 - val_loss: 0.3037 - val_accuracy: 0.9303\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3157 - accuracy: 0.1049 - val_loss: 2.2995 - val_accuracy: 0.1651\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2998 - accuracy: 0.1168 - val_loss: 2.2918 - val_accuracy: 0.1397\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2923 - accuracy: 0.1189 - val_loss: 2.2577 - val_accuracy: 0.2040\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2681 - accuracy: 0.1420 - val_loss: 2.1865 - val_accuracy: 0.2224\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2159 - accuracy: 0.1754 - val_loss: 2.0841 - val_accuracy: 0.2161\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1482 - accuracy: 0.1991 - val_loss: 1.9963 - val_accuracy: 0.2419\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0729 - accuracy: 0.2308 - val_loss: 1.8847 - val_accuracy: 0.3145\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9901 - accuracy: 0.2648 - val_loss: 1.7736 - val_accuracy: 0.3454\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9151 - accuracy: 0.2840 - val_loss: 1.6859 - val_accuracy: 0.3873\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8485 - accuracy: 0.3057 - val_loss: 1.6150 - val_accuracy: 0.4304\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7729 - accuracy: 0.3299 - val_loss: 1.5184 - val_accuracy: 0.4772\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7092 - accuracy: 0.3521 - val_loss: 1.4452 - val_accuracy: 0.5206\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6376 - accuracy: 0.3716 - val_loss: 1.3796 - val_accuracy: 0.5533\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5840 - accuracy: 0.3896 - val_loss: 1.3181 - val_accuracy: 0.5493\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5270 - accuracy: 0.4093 - val_loss: 1.2775 - val_accuracy: 0.5669\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4760 - accuracy: 0.4318 - val_loss: 1.2110 - val_accuracy: 0.5798\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4285 - accuracy: 0.4532 - val_loss: 1.1549 - val_accuracy: 0.6003\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3654 - accuracy: 0.4770 - val_loss: 1.0911 - val_accuracy: 0.6161\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3118 - accuracy: 0.4909 - val_loss: 1.0384 - val_accuracy: 0.6268\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2732 - accuracy: 0.5077 - val_loss: 0.9820 - val_accuracy: 0.6505\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2276 - accuracy: 0.5196 - val_loss: 0.9423 - val_accuracy: 0.6638\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1948 - accuracy: 0.5369 - val_loss: 0.9153 - val_accuracy: 0.7006\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1631 - accuracy: 0.5530 - val_loss: 0.8758 - val_accuracy: 0.7139\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1380 - accuracy: 0.5617 - val_loss: 0.8465 - val_accuracy: 0.7040\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1176 - accuracy: 0.5739 - val_loss: 0.8241 - val_accuracy: 0.7244\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0742 - accuracy: 0.5943 - val_loss: 0.7941 - val_accuracy: 0.7602\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0546 - accuracy: 0.6050 - val_loss: 0.7716 - val_accuracy: 0.7667\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0304 - accuracy: 0.6156 - val_loss: 0.7447 - val_accuracy: 0.7675\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0059 - accuracy: 0.6251 - val_loss: 0.7225 - val_accuracy: 0.7862\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9806 - accuracy: 0.6387 - val_loss: 0.6960 - val_accuracy: 0.7876\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9578 - accuracy: 0.6528 - val_loss: 0.6724 - val_accuracy: 0.8073\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9277 - accuracy: 0.6733 - val_loss: 0.6567 - val_accuracy: 0.8062\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9034 - accuracy: 0.6775 - val_loss: 0.6358 - val_accuracy: 0.8280\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8788 - accuracy: 0.6947 - val_loss: 0.6146 - val_accuracy: 0.8323\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8548 - accuracy: 0.7060 - val_loss: 0.6016 - val_accuracy: 0.8407\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8356 - accuracy: 0.7155 - val_loss: 0.5915 - val_accuracy: 0.8510\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8260 - accuracy: 0.7229 - val_loss: 0.5842 - val_accuracy: 0.8584\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8030 - accuracy: 0.7311 - val_loss: 0.5681 - val_accuracy: 0.8824\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7734 - accuracy: 0.7404 - val_loss: 0.5629 - val_accuracy: 0.8801\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7656 - accuracy: 0.7508 - val_loss: 0.5378 - val_accuracy: 0.8900\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7493 - accuracy: 0.7548 - val_loss: 0.5329 - val_accuracy: 0.8942\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7438 - accuracy: 0.7615 - val_loss: 0.5294 - val_accuracy: 0.9003\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7135 - accuracy: 0.7734 - val_loss: 0.5225 - val_accuracy: 0.9033\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7081 - accuracy: 0.7762 - val_loss: 0.5241 - val_accuracy: 0.9068\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6717 - accuracy: 0.7892 - val_loss: 0.5155 - val_accuracy: 0.9113\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6660 - accuracy: 0.7909 - val_loss: 0.5136 - val_accuracy: 0.9058\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6674 - accuracy: 0.7919 - val_loss: 0.5220 - val_accuracy: 0.8917\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6463 - accuracy: 0.7980 - val_loss: 0.5043 - val_accuracy: 0.9179\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6240 - accuracy: 0.8053 - val_loss: 0.4970 - val_accuracy: 0.9193\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6034 - accuracy: 0.8128 - val_loss: 0.4787 - val_accuracy: 0.9237\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 7ms/step - loss: 2.3112 - accuracy: 0.1099 - val_loss: 2.2718 - val_accuracy: 0.2390\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2621 - accuracy: 0.1657 - val_loss: 2.0771 - val_accuracy: 0.3607\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1177 - accuracy: 0.2394 - val_loss: 1.7739 - val_accuracy: 0.4885\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8994 - accuracy: 0.3347 - val_loss: 1.4680 - val_accuracy: 0.5927\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6954 - accuracy: 0.4001 - val_loss: 1.1963 - val_accuracy: 0.6550\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5001 - accuracy: 0.4640 - val_loss: 0.9810 - val_accuracy: 0.6660\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3354 - accuracy: 0.5221 - val_loss: 0.8480 - val_accuracy: 0.7015\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2046 - accuracy: 0.5606 - val_loss: 0.7684 - val_accuracy: 0.7143\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1063 - accuracy: 0.6017 - val_loss: 0.7087 - val_accuracy: 0.7383\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0380 - accuracy: 0.6255 - val_loss: 0.6634 - val_accuracy: 0.7663\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9709 - accuracy: 0.6500 - val_loss: 0.6252 - val_accuracy: 0.7774\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9265 - accuracy: 0.6681 - val_loss: 0.5986 - val_accuracy: 0.8006\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8948 - accuracy: 0.6872 - val_loss: 0.5684 - val_accuracy: 0.8179\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8632 - accuracy: 0.7021 - val_loss: 0.5403 - val_accuracy: 0.8337\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8203 - accuracy: 0.7199 - val_loss: 0.5173 - val_accuracy: 0.8417\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7888 - accuracy: 0.7357 - val_loss: 0.4873 - val_accuracy: 0.8628\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7631 - accuracy: 0.7432 - val_loss: 0.4656 - val_accuracy: 0.8730\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7374 - accuracy: 0.7533 - val_loss: 0.4440 - val_accuracy: 0.8747\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7041 - accuracy: 0.7695 - val_loss: 0.4248 - val_accuracy: 0.8823\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6785 - accuracy: 0.7759 - val_loss: 0.4121 - val_accuracy: 0.8824\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6624 - accuracy: 0.7845 - val_loss: 0.3972 - val_accuracy: 0.8873\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6330 - accuracy: 0.7982 - val_loss: 0.3878 - val_accuracy: 0.8975\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6187 - accuracy: 0.8004 - val_loss: 0.3713 - val_accuracy: 0.8983\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6218 - accuracy: 0.8070 - val_loss: 0.3571 - val_accuracy: 0.9090\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5931 - accuracy: 0.8132 - val_loss: 0.3486 - val_accuracy: 0.9116\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5696 - accuracy: 0.8228 - val_loss: 0.3338 - val_accuracy: 0.9167\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5550 - accuracy: 0.8296 - val_loss: 0.3227 - val_accuracy: 0.9217\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5407 - accuracy: 0.8349 - val_loss: 0.3082 - val_accuracy: 0.9252\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5159 - accuracy: 0.8441 - val_loss: 0.3001 - val_accuracy: 0.9262\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5121 - accuracy: 0.8448 - val_loss: 0.2868 - val_accuracy: 0.9289\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4959 - accuracy: 0.8511 - val_loss: 0.2824 - val_accuracy: 0.9312\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4778 - accuracy: 0.8573 - val_loss: 0.2738 - val_accuracy: 0.9329\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4676 - accuracy: 0.8606 - val_loss: 0.2704 - val_accuracy: 0.9335\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4562 - accuracy: 0.8654 - val_loss: 0.2623 - val_accuracy: 0.9363\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4473 - accuracy: 0.8688 - val_loss: 0.2592 - val_accuracy: 0.9345\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4305 - accuracy: 0.8751 - val_loss: 0.2550 - val_accuracy: 0.9361\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4220 - accuracy: 0.8755 - val_loss: 0.2522 - val_accuracy: 0.9383\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4130 - accuracy: 0.8807 - val_loss: 0.2438 - val_accuracy: 0.9411\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3925 - accuracy: 0.8832 - val_loss: 0.2416 - val_accuracy: 0.9402\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3858 - accuracy: 0.8857 - val_loss: 0.2368 - val_accuracy: 0.9423\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3824 - accuracy: 0.8899 - val_loss: 0.2403 - val_accuracy: 0.9430\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3766 - accuracy: 0.8900 - val_loss: 0.2367 - val_accuracy: 0.9438\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3672 - accuracy: 0.8949 - val_loss: 0.2345 - val_accuracy: 0.9438\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3598 - accuracy: 0.8979 - val_loss: 0.2266 - val_accuracy: 0.9453\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3438 - accuracy: 0.9001 - val_loss: 0.2281 - val_accuracy: 0.9474\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3378 - accuracy: 0.9015 - val_loss: 0.2230 - val_accuracy: 0.9474\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3315 - accuracy: 0.9058 - val_loss: 0.2238 - val_accuracy: 0.9476\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3233 - accuracy: 0.9080 - val_loss: 0.2257 - val_accuracy: 0.9477\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3198 - accuracy: 0.9117 - val_loss: 0.2251 - val_accuracy: 0.9487\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3053 - accuracy: 0.9140 - val_loss: 0.2289 - val_accuracy: 0.9507\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.1744 - accuracy: 0.2391 - val_loss: 0.9771 - val_accuracy: 0.7719\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4704 - accuracy: 0.4855 - val_loss: 0.6611 - val_accuracy: 0.8282\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2194 - accuracy: 0.5807 - val_loss: 0.5459 - val_accuracy: 0.8508\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0987 - accuracy: 0.6323 - val_loss: 0.4791 - val_accuracy: 0.8655\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9834 - accuracy: 0.6747 - val_loss: 0.4472 - val_accuracy: 0.8724\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9175 - accuracy: 0.7032 - val_loss: 0.4193 - val_accuracy: 0.8797\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8699 - accuracy: 0.7230 - val_loss: 0.3975 - val_accuracy: 0.8865\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8283 - accuracy: 0.7392 - val_loss: 0.3809 - val_accuracy: 0.8917\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7983 - accuracy: 0.7535 - val_loss: 0.3681 - val_accuracy: 0.8953\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7686 - accuracy: 0.7662 - val_loss: 0.3596 - val_accuracy: 0.8958\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7408 - accuracy: 0.7751 - val_loss: 0.3460 - val_accuracy: 0.9005\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7119 - accuracy: 0.7882 - val_loss: 0.3323 - val_accuracy: 0.9042\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6911 - accuracy: 0.7961 - val_loss: 0.3229 - val_accuracy: 0.9065\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6738 - accuracy: 0.8033 - val_loss: 0.3165 - val_accuracy: 0.9109\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6524 - accuracy: 0.8121 - val_loss: 0.3127 - val_accuracy: 0.9110\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6350 - accuracy: 0.8155 - val_loss: 0.3027 - val_accuracy: 0.9137\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6228 - accuracy: 0.8219 - val_loss: 0.2959 - val_accuracy: 0.9163\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6007 - accuracy: 0.8310 - val_loss: 0.2930 - val_accuracy: 0.9168\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5931 - accuracy: 0.8331 - val_loss: 0.2847 - val_accuracy: 0.9206\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5825 - accuracy: 0.8377 - val_loss: 0.2815 - val_accuracy: 0.9212\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5627 - accuracy: 0.8439 - val_loss: 0.2766 - val_accuracy: 0.9233\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5492 - accuracy: 0.8500 - val_loss: 0.2744 - val_accuracy: 0.9229\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5350 - accuracy: 0.8531 - val_loss: 0.2708 - val_accuracy: 0.9247\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5262 - accuracy: 0.8567 - val_loss: 0.2652 - val_accuracy: 0.9265\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5254 - accuracy: 0.8569 - val_loss: 0.2640 - val_accuracy: 0.9259\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5093 - accuracy: 0.8603 - val_loss: 0.2593 - val_accuracy: 0.9278\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4965 - accuracy: 0.8667 - val_loss: 0.2558 - val_accuracy: 0.9287\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4974 - accuracy: 0.8659 - val_loss: 0.2540 - val_accuracy: 0.9313\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4863 - accuracy: 0.8707 - val_loss: 0.2493 - val_accuracy: 0.9318\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4755 - accuracy: 0.8707 - val_loss: 0.2473 - val_accuracy: 0.9334\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4719 - accuracy: 0.8753 - val_loss: 0.2433 - val_accuracy: 0.9340\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4588 - accuracy: 0.8773 - val_loss: 0.2462 - val_accuracy: 0.9339\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4529 - accuracy: 0.8801 - val_loss: 0.2405 - val_accuracy: 0.9373\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4529 - accuracy: 0.8796 - val_loss: 0.2405 - val_accuracy: 0.9360\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4524 - accuracy: 0.8810 - val_loss: 0.2372 - val_accuracy: 0.9366\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4357 - accuracy: 0.8848 - val_loss: 0.2339 - val_accuracy: 0.9393\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4317 - accuracy: 0.8849 - val_loss: 0.2340 - val_accuracy: 0.9384\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4227 - accuracy: 0.8882 - val_loss: 0.2324 - val_accuracy: 0.9392\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4240 - accuracy: 0.8890 - val_loss: 0.2275 - val_accuracy: 0.9402\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4199 - accuracy: 0.8911 - val_loss: 0.2288 - val_accuracy: 0.9408\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4020 - accuracy: 0.8964 - val_loss: 0.2299 - val_accuracy: 0.9402\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4031 - accuracy: 0.8957 - val_loss: 0.2244 - val_accuracy: 0.9425\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3994 - accuracy: 0.8965 - val_loss: 0.2213 - val_accuracy: 0.9433\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3987 - accuracy: 0.8933 - val_loss: 0.2226 - val_accuracy: 0.9438\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3853 - accuracy: 0.9011 - val_loss: 0.2208 - val_accuracy: 0.9444\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3902 - accuracy: 0.8991 - val_loss: 0.2204 - val_accuracy: 0.9440\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3776 - accuracy: 0.9035 - val_loss: 0.2191 - val_accuracy: 0.9438\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3647 - accuracy: 0.9044 - val_loss: 0.2194 - val_accuracy: 0.9448\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3614 - accuracy: 0.9041 - val_loss: 0.2145 - val_accuracy: 0.9459\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3591 - accuracy: 0.9065 - val_loss: 0.2178 - val_accuracy: 0.9471\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.7274 - accuracy: 0.2526 - val_loss: 0.7439 - val_accuracy: 0.7866\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4029 - accuracy: 0.5173 - val_loss: 0.5959 - val_accuracy: 0.8340\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1302 - accuracy: 0.6118 - val_loss: 0.5122 - val_accuracy: 0.8601\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0122 - accuracy: 0.6666 - val_loss: 0.4699 - val_accuracy: 0.8692\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9184 - accuracy: 0.7015 - val_loss: 0.4310 - val_accuracy: 0.8793\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8614 - accuracy: 0.7319 - val_loss: 0.4053 - val_accuracy: 0.8888\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8205 - accuracy: 0.7494 - val_loss: 0.3898 - val_accuracy: 0.8921\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7793 - accuracy: 0.7682 - val_loss: 0.3700 - val_accuracy: 0.8977\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7458 - accuracy: 0.7801 - val_loss: 0.3573 - val_accuracy: 0.9016\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7086 - accuracy: 0.7912 - val_loss: 0.3514 - val_accuracy: 0.9019\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6942 - accuracy: 0.8038 - val_loss: 0.3397 - val_accuracy: 0.9069\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6797 - accuracy: 0.8044 - val_loss: 0.3357 - val_accuracy: 0.9091\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6469 - accuracy: 0.8200 - val_loss: 0.3294 - val_accuracy: 0.9114\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6320 - accuracy: 0.8237 - val_loss: 0.3199 - val_accuracy: 0.9146\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6253 - accuracy: 0.8278 - val_loss: 0.3203 - val_accuracy: 0.9155\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6108 - accuracy: 0.8337 - val_loss: 0.3114 - val_accuracy: 0.9171\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5826 - accuracy: 0.8399 - val_loss: 0.3070 - val_accuracy: 0.9187\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5798 - accuracy: 0.8439 - val_loss: 0.3058 - val_accuracy: 0.9175\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5730 - accuracy: 0.8453 - val_loss: 0.2986 - val_accuracy: 0.9200\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5552 - accuracy: 0.8514 - val_loss: 0.2934 - val_accuracy: 0.9204\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5434 - accuracy: 0.8566 - val_loss: 0.2889 - val_accuracy: 0.9222\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5310 - accuracy: 0.8588 - val_loss: 0.2857 - val_accuracy: 0.9235\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5265 - accuracy: 0.8603 - val_loss: 0.2772 - val_accuracy: 0.9259\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5174 - accuracy: 0.8618 - val_loss: 0.2779 - val_accuracy: 0.9263\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5121 - accuracy: 0.8668 - val_loss: 0.2772 - val_accuracy: 0.9265\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5022 - accuracy: 0.8705 - val_loss: 0.2683 - val_accuracy: 0.9289\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4885 - accuracy: 0.8701 - val_loss: 0.2698 - val_accuracy: 0.9298\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4804 - accuracy: 0.8751 - val_loss: 0.2669 - val_accuracy: 0.9293\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4803 - accuracy: 0.8734 - val_loss: 0.2629 - val_accuracy: 0.9319\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4742 - accuracy: 0.8751 - val_loss: 0.2576 - val_accuracy: 0.9320\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4670 - accuracy: 0.8797 - val_loss: 0.2556 - val_accuracy: 0.9341\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4623 - accuracy: 0.8767 - val_loss: 0.2522 - val_accuracy: 0.9343\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4406 - accuracy: 0.8860 - val_loss: 0.2498 - val_accuracy: 0.9335\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4386 - accuracy: 0.8871 - val_loss: 0.2466 - val_accuracy: 0.9354\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4463 - accuracy: 0.8839 - val_loss: 0.2492 - val_accuracy: 0.9355\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4341 - accuracy: 0.8879 - val_loss: 0.2437 - val_accuracy: 0.9381\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4259 - accuracy: 0.8915 - val_loss: 0.2417 - val_accuracy: 0.9371\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4221 - accuracy: 0.8900 - val_loss: 0.2417 - val_accuracy: 0.9384\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4233 - accuracy: 0.8916 - val_loss: 0.2361 - val_accuracy: 0.9392\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4138 - accuracy: 0.8945 - val_loss: 0.2367 - val_accuracy: 0.9401\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4080 - accuracy: 0.8978 - val_loss: 0.2384 - val_accuracy: 0.9384\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4005 - accuracy: 0.8989 - val_loss: 0.2348 - val_accuracy: 0.9417\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4066 - accuracy: 0.8940 - val_loss: 0.2333 - val_accuracy: 0.9417\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3898 - accuracy: 0.8991 - val_loss: 0.2358 - val_accuracy: 0.9413\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3821 - accuracy: 0.9035 - val_loss: 0.2301 - val_accuracy: 0.9419\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3898 - accuracy: 0.9015 - val_loss: 0.2413 - val_accuracy: 0.9412\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3751 - accuracy: 0.9045 - val_loss: 0.2339 - val_accuracy: 0.9434\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3859 - accuracy: 0.9039 - val_loss: 0.2328 - val_accuracy: 0.9436\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3723 - accuracy: 0.9057 - val_loss: 0.2321 - val_accuracy: 0.9434\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3714 - accuracy: 0.9047 - val_loss: 0.2304 - val_accuracy: 0.9442\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 8ms/step - loss: 2.3024 - accuracy: 0.1145 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2998 - accuracy: 0.1212 - val_loss: 2.2985 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2976 - accuracy: 0.1192 - val_loss: 2.2960 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2946 - accuracy: 0.1240 - val_loss: 2.2922 - val_accuracy: 0.1115\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2904 - accuracy: 0.1402 - val_loss: 2.2845 - val_accuracy: 0.1595\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2790 - accuracy: 0.1764 - val_loss: 2.2447 - val_accuracy: 0.2039\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2194 - accuracy: 0.2154 - val_loss: 2.0739 - val_accuracy: 0.2306\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.1116 - accuracy: 0.2191 - val_loss: 1.9772 - val_accuracy: 0.2676\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.0238 - accuracy: 0.2541 - val_loss: 1.8410 - val_accuracy: 0.3643\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.9084 - accuracy: 0.3076 - val_loss: 1.6132 - val_accuracy: 0.4588\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.7547 - accuracy: 0.3736 - val_loss: 1.3842 - val_accuracy: 0.5784\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.6094 - accuracy: 0.4332 - val_loss: 1.1858 - val_accuracy: 0.6357\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.4725 - accuracy: 0.4905 - val_loss: 1.0524 - val_accuracy: 0.6902\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.3474 - accuracy: 0.5415 - val_loss: 0.9445 - val_accuracy: 0.7418\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2717 - accuracy: 0.5813 - val_loss: 0.8561 - val_accuracy: 0.7761\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.1950 - accuracy: 0.6090 - val_loss: 0.7870 - val_accuracy: 0.7971\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.1429 - accuracy: 0.6321 - val_loss: 0.7364 - val_accuracy: 0.8157\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0920 - accuracy: 0.6468 - val_loss: 0.6949 - val_accuracy: 0.8302\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0463 - accuracy: 0.6639 - val_loss: 0.6525 - val_accuracy: 0.8413\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0149 - accuracy: 0.6776 - val_loss: 0.6262 - val_accuracy: 0.8532\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9733 - accuracy: 0.6955 - val_loss: 0.5986 - val_accuracy: 0.8601\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9622 - accuracy: 0.6970 - val_loss: 0.5734 - val_accuracy: 0.8667\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9143 - accuracy: 0.7140 - val_loss: 0.5548 - val_accuracy: 0.8709\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9027 - accuracy: 0.7203 - val_loss: 0.5335 - val_accuracy: 0.8752\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8825 - accuracy: 0.7253 - val_loss: 0.5173 - val_accuracy: 0.8802\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8605 - accuracy: 0.7365 - val_loss: 0.5004 - val_accuracy: 0.8833\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8334 - accuracy: 0.7415 - val_loss: 0.4857 - val_accuracy: 0.8890\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8325 - accuracy: 0.7459 - val_loss: 0.4717 - val_accuracy: 0.8911\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7990 - accuracy: 0.7547 - val_loss: 0.4579 - val_accuracy: 0.8944\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7748 - accuracy: 0.7626 - val_loss: 0.4456 - val_accuracy: 0.8980\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7741 - accuracy: 0.7635 - val_loss: 0.4324 - val_accuracy: 0.8987\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7551 - accuracy: 0.7729 - val_loss: 0.4224 - val_accuracy: 0.9017\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7439 - accuracy: 0.7776 - val_loss: 0.4119 - val_accuracy: 0.9039\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7286 - accuracy: 0.7783 - val_loss: 0.4021 - val_accuracy: 0.9076\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7068 - accuracy: 0.7884 - val_loss: 0.3928 - val_accuracy: 0.9087\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6992 - accuracy: 0.7878 - val_loss: 0.3840 - val_accuracy: 0.9100\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6762 - accuracy: 0.7954 - val_loss: 0.3757 - val_accuracy: 0.9118\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6669 - accuracy: 0.7974 - val_loss: 0.3684 - val_accuracy: 0.9144\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6662 - accuracy: 0.7978 - val_loss: 0.3584 - val_accuracy: 0.9164\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6387 - accuracy: 0.8086 - val_loss: 0.3538 - val_accuracy: 0.9171\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6338 - accuracy: 0.8113 - val_loss: 0.3462 - val_accuracy: 0.9201\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6222 - accuracy: 0.8115 - val_loss: 0.3416 - val_accuracy: 0.9208\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6222 - accuracy: 0.8127 - val_loss: 0.3338 - val_accuracy: 0.9243\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5931 - accuracy: 0.8242 - val_loss: 0.3325 - val_accuracy: 0.9225\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5885 - accuracy: 0.8242 - val_loss: 0.3231 - val_accuracy: 0.9256\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5845 - accuracy: 0.8229 - val_loss: 0.3230 - val_accuracy: 0.9265\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5682 - accuracy: 0.8323 - val_loss: 0.3133 - val_accuracy: 0.9279\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5717 - accuracy: 0.8294 - val_loss: 0.3139 - val_accuracy: 0.9286\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5629 - accuracy: 0.8325 - val_loss: 0.3122 - val_accuracy: 0.9296\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5539 - accuracy: 0.8349 - val_loss: 0.3094 - val_accuracy: 0.9318\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 8ms/step - loss: 2.3025 - accuracy: 0.1103 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1147 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2994 - accuracy: 0.1138 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2985 - accuracy: 0.1120 - val_loss: 2.2981 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2966 - accuracy: 0.1158 - val_loss: 2.2967 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2952 - accuracy: 0.1145 - val_loss: 2.2949 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2937 - accuracy: 0.1137 - val_loss: 2.2926 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2911 - accuracy: 0.1153 - val_loss: 2.2893 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2877 - accuracy: 0.1195 - val_loss: 2.2838 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2820 - accuracy: 0.1288 - val_loss: 2.2733 - val_accuracy: 0.1067\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2685 - accuracy: 0.1632 - val_loss: 2.2448 - val_accuracy: 0.2009\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2286 - accuracy: 0.2252 - val_loss: 2.0949 - val_accuracy: 0.3124\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.0876 - accuracy: 0.2525 - val_loss: 1.8815 - val_accuracy: 0.3504\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.9613 - accuracy: 0.2792 - val_loss: 1.7285 - val_accuracy: 0.3960\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8435 - accuracy: 0.3052 - val_loss: 1.5935 - val_accuracy: 0.4354\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.7384 - accuracy: 0.3337 - val_loss: 1.4936 - val_accuracy: 0.5004\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.6456 - accuracy: 0.3686 - val_loss: 1.3768 - val_accuracy: 0.5141\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5471 - accuracy: 0.4043 - val_loss: 1.2524 - val_accuracy: 0.5472\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4583 - accuracy: 0.4365 - val_loss: 1.1573 - val_accuracy: 0.5955\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.3810 - accuracy: 0.4713 - val_loss: 1.0692 - val_accuracy: 0.6446\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.3147 - accuracy: 0.5089 - val_loss: 0.9919 - val_accuracy: 0.6900\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2515 - accuracy: 0.5388 - val_loss: 0.9156 - val_accuracy: 0.7273\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2054 - accuracy: 0.5631 - val_loss: 0.8522 - val_accuracy: 0.7491\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.1576 - accuracy: 0.5789 - val_loss: 0.8001 - val_accuracy: 0.7639\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.1251 - accuracy: 0.6041 - val_loss: 0.7630 - val_accuracy: 0.7728\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0790 - accuracy: 0.6137 - val_loss: 0.7392 - val_accuracy: 0.7772\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0381 - accuracy: 0.6355 - val_loss: 0.7143 - val_accuracy: 0.7868\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0160 - accuracy: 0.6436 - val_loss: 0.6938 - val_accuracy: 0.7908\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0025 - accuracy: 0.6505 - val_loss: 0.6785 - val_accuracy: 0.7943\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9816 - accuracy: 0.6595 - val_loss: 0.6659 - val_accuracy: 0.7990\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9581 - accuracy: 0.6665 - val_loss: 0.6498 - val_accuracy: 0.8086\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9380 - accuracy: 0.6760 - val_loss: 0.6328 - val_accuracy: 0.8146\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9192 - accuracy: 0.6868 - val_loss: 0.6195 - val_accuracy: 0.8170\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9057 - accuracy: 0.6956 - val_loss: 0.6090 - val_accuracy: 0.8182\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8895 - accuracy: 0.6965 - val_loss: 0.5983 - val_accuracy: 0.8241\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8728 - accuracy: 0.7070 - val_loss: 0.5841 - val_accuracy: 0.8298\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8603 - accuracy: 0.7078 - val_loss: 0.5763 - val_accuracy: 0.8330\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8430 - accuracy: 0.7141 - val_loss: 0.5641 - val_accuracy: 0.8398\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8427 - accuracy: 0.7178 - val_loss: 0.5528 - val_accuracy: 0.8436\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8204 - accuracy: 0.7269 - val_loss: 0.5421 - val_accuracy: 0.8467\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.8098 - accuracy: 0.7346 - val_loss: 0.5320 - val_accuracy: 0.8510\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7984 - accuracy: 0.7381 - val_loss: 0.5209 - val_accuracy: 0.8569\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7768 - accuracy: 0.7453 - val_loss: 0.5101 - val_accuracy: 0.8638\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7765 - accuracy: 0.7469 - val_loss: 0.5008 - val_accuracy: 0.8662\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7645 - accuracy: 0.7497 - val_loss: 0.4925 - val_accuracy: 0.8729\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7456 - accuracy: 0.7564 - val_loss: 0.4804 - val_accuracy: 0.8752\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7496 - accuracy: 0.7621 - val_loss: 0.4711 - val_accuracy: 0.8787\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7291 - accuracy: 0.7668 - val_loss: 0.4621 - val_accuracy: 0.8808\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7066 - accuracy: 0.7747 - val_loss: 0.4542 - val_accuracy: 0.8830\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.6870 - accuracy: 0.7794 - val_loss: 0.4456 - val_accuracy: 0.8878\n",
            "{'loss': [1.9923087358474731, 1.5545600652694702, 1.3474632501602173, 1.206268548965454, 1.1065574884414673, 1.0234732627868652, 0.9676734209060669, 0.9028237462043762, 0.8707197308540344, 0.829050600528717, 0.8017942905426025, 0.7813315987586975, 0.7551541328430176, 0.736352801322937, 0.7229189276695251, 0.7067147493362427, 0.6861402988433838, 0.6681593060493469, 0.6580849289894104, 0.654438853263855, 0.6375529766082764, 0.6293565630912781, 0.6146103739738464, 0.6057879328727722, 0.6018486618995667, 0.598222553730011, 0.5889952182769775, 0.5791230201721191, 0.5688884258270264, 0.5702834725379944, 0.5580376982688904, 0.5561714172363281, 0.5512162446975708, 0.5388526916503906, 0.5350063443183899, 0.5333887338638306, 0.5233710408210754, 0.5183795690536499, 0.5192787647247314, 0.5047026872634888, 0.503416121006012, 0.4984170198440552, 0.4880062937736511, 0.4943890869617462, 0.48930713534355164, 0.4792989194393158, 0.4722007215023041, 0.47233566641807556, 0.46558117866516113, 0.47080114483833313], 'accuracy': [0.28308331966400146, 0.452979177236557, 0.5401666760444641, 0.5992500185966492, 0.6443958282470703, 0.6746458411216736, 0.7000625133514404, 0.7282083630561829, 0.7401458621025085, 0.7551458477973938, 0.7656458616256714, 0.7746041417121887, 0.7849166393280029, 0.7929791808128357, 0.799916684627533, 0.8039583563804626, 0.812166690826416, 0.8169999718666077, 0.8220833539962769, 0.8252500295639038, 0.8298541903495789, 0.8334166407585144, 0.8363958597183228, 0.840541660785675, 0.8425208330154419, 0.8424166440963745, 0.8457083106040955, 0.8496249914169312, 0.8531666398048401, 0.8517916798591614, 0.8541250228881836, 0.8557500243186951, 0.8577291369438171, 0.8609374761581421, 0.8633333444595337, 0.8646875023841858, 0.8678958415985107, 0.8669999837875366, 0.8676875233650208, 0.8710208535194397, 0.8718958497047424, 0.8738750219345093, 0.8734999895095825, 0.8738541603088379, 0.8773333430290222, 0.8762500286102295, 0.8806250095367432, 0.8794166445732117, 0.8815624713897705, 0.8792916536331177], 'val_loss': [1.2659486532211304, 0.9812089800834656, 0.8069872856140137, 0.6893399953842163, 0.6045840382575989, 0.5513874888420105, 0.5094982385635376, 0.4780120551586151, 0.4591176211833954, 0.4401238262653351, 0.43099138140678406, 0.41882315278053284, 0.408670574426651, 0.4009675681591034, 0.39466071128845215, 0.3912256956100464, 0.3830912411212921, 0.3798333704471588, 0.3738652467727661, 0.37097403407096863, 0.3670382797718048, 0.36606326699256897, 0.36316239833831787, 0.3573419153690338, 0.35903432965278625, 0.35479313135147095, 0.35311412811279297, 0.35077446699142456, 0.351511687040329, 0.34615185856819153, 0.34494978189468384, 0.3417377173900604, 0.3389320969581604, 0.3381526470184326, 0.3342524766921997, 0.33522018790245056, 0.3305932581424713, 0.3336946964263916, 0.3253106474876404, 0.32534027099609375, 0.32143187522888184, 0.3179588317871094, 0.31733444333076477, 0.3126254677772522, 0.3124094605445862, 0.3110198676586151, 0.3121892809867859, 0.3086669445037842, 0.30769485235214233, 0.3036780059337616], 'val_accuracy': [0.6393333077430725, 0.7462499737739563, 0.7925833463668823, 0.8237500190734863, 0.8433333039283752, 0.8546666502952576, 0.8655833601951599, 0.8727499842643738, 0.8772500157356262, 0.8808333277702332, 0.8840833306312561, 0.8894166946411133, 0.8934166431427002, 0.8939999938011169, 0.8980833292007446, 0.8970833420753479, 0.9010000228881836, 0.9028333425521851, 0.9035833477973938, 0.90625, 0.906000018119812, 0.9089166522026062, 0.909166693687439, 0.9109166860580444, 0.9115833044052124, 0.9127500057220459, 0.9137499928474426, 0.9144999980926514, 0.9145833253860474, 0.9154166579246521, 0.9172499775886536, 0.9185000061988831, 0.9181666374206543, 0.9199166893959045, 0.9192500114440918, 0.9194999933242798, 0.9210000038146973, 0.9211666584014893, 0.92208331823349, 0.9225000143051147, 0.9241666793823242, 0.9235833287239075, 0.9255833625793457, 0.9262499809265137, 0.9260833263397217, 0.9265000224113464, 0.9262499809265137, 0.9285833239555359, 0.9281666874885559, 0.9303333163261414]}\n",
            "{'loss': [2.3086249828338623, 2.298197031021118, 2.2872750759124756, 2.2551045417785645, 2.1997294425964355, 2.1318159103393555, 2.054198980331421, 1.9708720445632935, 1.894026517868042, 1.8253647089004517, 1.7507169246673584, 1.6853946447372437, 1.625397801399231, 1.5674272775650024, 1.514398455619812, 1.458844542503357, 1.4104570150375366, 1.3520758152008057, 1.3040324449539185, 1.2593498229980469, 1.2214691638946533, 1.1857976913452148, 1.1571917533874512, 1.130200982093811, 1.106844186782837, 1.0756819248199463, 1.052939772605896, 1.0261157751083374, 0.9988090991973877, 0.9742264151573181, 0.955888569355011, 0.9279918074607849, 0.9046784043312073, 0.8740870952606201, 0.8606033325195312, 0.8395702838897705, 0.816904604434967, 0.8017386198043823, 0.7758508324623108, 0.7685339450836182, 0.746727466583252, 0.7353139519691467, 0.7135543823242188, 0.7001422643661499, 0.684484601020813, 0.6685179471969604, 0.6590906977653503, 0.6436229944229126, 0.6270517110824585, 0.6082115769386292], 'accuracy': [0.10760416835546494, 0.11689583212137222, 0.12333333492279053, 0.1522916704416275, 0.18285416066646576, 0.20781250298023224, 0.23899999260902405, 0.2672083377838135, 0.2920416593551636, 0.31418749690055847, 0.33904168009757996, 0.35768750309944153, 0.3785833418369293, 0.3948333263397217, 0.4154583215713501, 0.43795832991600037, 0.46024999022483826, 0.4794583320617676, 0.49547916650772095, 0.515291690826416, 0.5261041522026062, 0.5403541922569275, 0.5571666955947876, 0.5656458139419556, 0.5802291631698608, 0.5953333377838135, 0.6054583191871643, 0.617229163646698, 0.6292916536331177, 0.643791675567627, 0.6548333168029785, 0.675208330154419, 0.6838124990463257, 0.6976875066757202, 0.7041458487510681, 0.715666651725769, 0.7265416383743286, 0.7316874861717224, 0.7418749928474426, 0.7505833506584167, 0.7558541893959045, 0.7650208473205566, 0.7727916836738586, 0.7782291769981384, 0.7856041789054871, 0.7902083396911621, 0.7952708601951599, 0.7997291684150696, 0.8067083358764648, 0.8150625228881836], 'val_loss': [2.299518346786499, 2.2918002605438232, 2.257688283920288, 2.1864728927612305, 2.0841219425201416, 1.9963409900665283, 1.884670615196228, 1.773589015007019, 1.6858893632888794, 1.6149791479110718, 1.5184122323989868, 1.4451513290405273, 1.3796230554580688, 1.3180524110794067, 1.2774639129638672, 1.2109999656677246, 1.1549246311187744, 1.0910550355911255, 1.0383917093276978, 0.9819990396499634, 0.9423434138298035, 0.9152728915214539, 0.8757882714271545, 0.8465102314949036, 0.8241450190544128, 0.7940813899040222, 0.7716398239135742, 0.744659423828125, 0.7225127816200256, 0.6959843039512634, 0.6724086999893188, 0.6566972136497498, 0.6357925534248352, 0.6146267056465149, 0.6015831828117371, 0.5914629101753235, 0.5842139720916748, 0.5680567026138306, 0.5628728270530701, 0.5377724766731262, 0.5328943133354187, 0.5294172167778015, 0.5224999189376831, 0.5241199731826782, 0.5154745578765869, 0.5135730504989624, 0.5219508409500122, 0.5042848587036133, 0.49700093269348145, 0.47866126894950867], 'val_accuracy': [0.16508333384990692, 0.13966666162014008, 0.20399999618530273, 0.22241666913032532, 0.2160833328962326, 0.24191667139530182, 0.31450000405311584, 0.3454166650772095, 0.38733333349227905, 0.43041667342185974, 0.47716665267944336, 0.5205833315849304, 0.5533333420753479, 0.5493333339691162, 0.5669166445732117, 0.5797500014305115, 0.6003333330154419, 0.6160833239555359, 0.6268333196640015, 0.6504999995231628, 0.6638333201408386, 0.7005833387374878, 0.7139166593551636, 0.7039999961853027, 0.7244166731834412, 0.7602499723434448, 0.7666666507720947, 0.7674999833106995, 0.7861666679382324, 0.7875833511352539, 0.8072500228881836, 0.8062499761581421, 0.828000009059906, 0.8323333263397217, 0.840749979019165, 0.8510000109672546, 0.8584166765213013, 0.8824166655540466, 0.8800833225250244, 0.8899999856948853, 0.8941666483879089, 0.9002500176429749, 0.903333306312561, 0.9068333506584167, 0.9113333225250244, 0.9058333039283752, 0.8916666507720947, 0.9179166555404663, 0.9193333387374878, 0.9236666560173035]}\n",
            "{'loss': [2.2997331619262695, 2.2345046997070312, 2.0674164295196533, 1.8508377075195312, 1.642194151878357, 1.452716588973999, 1.3008731603622437, 1.1827598810195923, 1.099087119102478, 1.0225307941436768, 0.9681194424629211, 0.9211403131484985, 0.8795520067214966, 0.8416084051132202, 0.8088844418525696, 0.7808664441108704, 0.7532168626785278, 0.7239658832550049, 0.7012537717819214, 0.6784082651138306, 0.6551547646522522, 0.6387661099433899, 0.6195374131202698, 0.6050669550895691, 0.5859224200248718, 0.5674287676811218, 0.5515837669372559, 0.5323924422264099, 0.5172231197357178, 0.5048288106918335, 0.4948568046092987, 0.4787558317184448, 0.46923336386680603, 0.4542844295501709, 0.44189679622650146, 0.4306985139846802, 0.4200442433357239, 0.40815478563308716, 0.3962786793708801, 0.38087761402130127, 0.3782463073730469, 0.3691791296005249, 0.3575499951839447, 0.35823819041252136, 0.3433491885662079, 0.3381919264793396, 0.32454022765159607, 0.320785254240036, 0.31353941559791565, 0.30414891242980957], 'accuracy': [0.12099999934434891, 0.1811458319425583, 0.2618750035762787, 0.35233333706855774, 0.41862499713897705, 0.4801041781902313, 0.5321249961853027, 0.5710833072662354, 0.6036041378974915, 0.629520833492279, 0.6532708406448364, 0.6736041903495789, 0.692229151725769, 0.7099166512489319, 0.7228124737739563, 0.737458348274231, 0.746833324432373, 0.7592708468437195, 0.7694583535194397, 0.778291642665863, 0.7874583601951599, 0.7978749871253967, 0.8023750185966492, 0.8106041550636292, 0.8164374828338623, 0.8239583373069763, 0.8304166793823242, 0.8366249799728394, 0.8446666598320007, 0.8486875295639038, 0.8516666889190674, 0.8574374914169312, 0.8616458177566528, 0.8663125038146973, 0.8729166388511658, 0.874958336353302, 0.8768749833106995, 0.8817291855812073, 0.8834375143051147, 0.8871666789054871, 0.8913541436195374, 0.8923541903495789, 0.8970000147819519, 0.8980208039283752, 0.901354193687439, 0.9022916555404663, 0.9066874980926514, 0.9089166522026062, 0.9115416407585144, 0.9129791855812073], 'val_loss': [2.2718472480773926, 2.0770652294158936, 1.773874044418335, 1.4680237770080566, 1.1963024139404297, 0.9810007214546204, 0.8480280041694641, 0.7683866620063782, 0.7086613774299622, 0.6633952856063843, 0.6252368092536926, 0.5986058115959167, 0.5684390068054199, 0.5402968525886536, 0.5173006653785706, 0.4872696101665497, 0.46555569767951965, 0.44399386644363403, 0.4247628152370453, 0.4120572507381439, 0.3972190022468567, 0.3877977430820465, 0.3713339567184448, 0.3570893406867981, 0.34858304262161255, 0.3338463008403778, 0.3227318823337555, 0.30819228291511536, 0.30008378624916077, 0.2867966294288635, 0.28241676092147827, 0.2737673819065094, 0.2704283893108368, 0.2623023986816406, 0.2592187821865082, 0.25499504804611206, 0.2521551251411438, 0.2438301146030426, 0.2415832132101059, 0.2368006408214569, 0.2402639538049698, 0.2366589903831482, 0.23446612060070038, 0.22655916213989258, 0.22808854281902313, 0.22303815186023712, 0.2238314151763916, 0.22572840750217438, 0.2251165211200714, 0.22887766361236572], 'val_accuracy': [0.23899999260902405, 0.3607499897480011, 0.4884999990463257, 0.5926666855812073, 0.6549999713897705, 0.6660000085830688, 0.7014999985694885, 0.7142500281333923, 0.7382500171661377, 0.7662500143051147, 0.7774166464805603, 0.8005833625793457, 0.8179166913032532, 0.8336666822433472, 0.8416666388511658, 0.8628333210945129, 0.8730000257492065, 0.874666690826416, 0.8822500109672546, 0.8824166655540466, 0.887333333492279, 0.8974999785423279, 0.8983333110809326, 0.9089999794960022, 0.9115833044052124, 0.9166666865348816, 0.92166668176651, 0.925166666507721, 0.9262499809265137, 0.9289166927337646, 0.9312499761581421, 0.9329166412353516, 0.9334999918937683, 0.9363333582878113, 0.934499979019165, 0.9360833168029785, 0.9383333325386047, 0.9410833120346069, 0.9402499794960022, 0.9422500133514404, 0.9430000185966492, 0.9438333511352539, 0.9437500238418579, 0.9453333616256714, 0.9474166631698608, 0.9474166631698608, 0.9475833177566528, 0.9477499723434448, 0.9486666917800903, 0.9506666660308838]}\n",
            "{'loss': [1.9102542400360107, 1.3967355489730835, 1.1811180114746094, 1.0622807741165161, 0.9707479476928711, 0.9087384343147278, 0.857960045337677, 0.8228178024291992, 0.7932057976722717, 0.7567452192306519, 0.7350309491157532, 0.7086146473884583, 0.6851651072502136, 0.6706060171127319, 0.6513786911964417, 0.6332643628120422, 0.6173179745674133, 0.6007053256034851, 0.5870219469070435, 0.5734103322029114, 0.562385618686676, 0.5527715086936951, 0.5365921854972839, 0.5276822447776794, 0.5238682627677917, 0.5101458430290222, 0.5029428601264954, 0.49010351300239563, 0.48277392983436584, 0.4769824147224426, 0.46937671303749084, 0.4547409117221832, 0.44890111684799194, 0.44484618306159973, 0.4453819692134857, 0.4373762309551239, 0.42581623792648315, 0.4196704924106598, 0.420918345451355, 0.4127015769481659, 0.40796229243278503, 0.4001877009868622, 0.39744827151298523, 0.39098143577575684, 0.38558661937713623, 0.38309407234191895, 0.37859705090522766, 0.3671138882637024, 0.36807116866111755, 0.36383554339408875], 'accuracy': [0.32895833253860474, 0.5140208601951599, 0.5962083339691162, 0.643791675567627, 0.6817499995231628, 0.706375002861023, 0.7269791960716248, 0.7436041831970215, 0.7576249837875366, 0.7707708477973938, 0.7775208353996277, 0.7904999852180481, 0.7958333492279053, 0.8038125038146973, 0.8130833506584167, 0.8162083625793457, 0.8241249918937683, 0.8301666378974915, 0.8352291584014893, 0.8409791588783264, 0.8448333144187927, 0.8491874933242798, 0.851687490940094, 0.8555833101272583, 0.856333315372467, 0.8605416417121887, 0.8650624752044678, 0.8671875, 0.8699791431427002, 0.8709166646003723, 0.8762500286102295, 0.8783125281333923, 0.879604160785675, 0.883145809173584, 0.8839374780654907, 0.8836666941642761, 0.8862708210945129, 0.8890416622161865, 0.8896041512489319, 0.8923333287239075, 0.893791675567627, 0.8949166536331177, 0.8969583511352539, 0.8966249823570251, 0.9019791483879089, 0.9002708196640015, 0.903291642665863, 0.9048958420753479, 0.9042500257492065, 0.9051250219345093], 'val_loss': [0.9771474599838257, 0.6610813140869141, 0.5459027290344238, 0.4790770411491394, 0.44718286395072937, 0.41930028796195984, 0.39749962091445923, 0.38089078664779663, 0.36805781722068787, 0.35962215065956116, 0.34601449966430664, 0.33230966329574585, 0.32289084792137146, 0.3164788484573364, 0.31266242265701294, 0.3027435541152954, 0.29585883021354675, 0.2929917871952057, 0.2847103178501129, 0.28151488304138184, 0.27655693888664246, 0.2744024395942688, 0.270840048789978, 0.26518121361732483, 0.26399630308151245, 0.25933313369750977, 0.2557872235774994, 0.25397610664367676, 0.24931305646896362, 0.2472769320011139, 0.2432687133550644, 0.24618525803089142, 0.24049243330955505, 0.2404632568359375, 0.23721618950366974, 0.2339230477809906, 0.23396049439907074, 0.23236319422721863, 0.2274668961763382, 0.22879502177238464, 0.22988422214984894, 0.22437983751296997, 0.22134526073932648, 0.22258445620536804, 0.22080354392528534, 0.22044682502746582, 0.21906471252441406, 0.2193654179573059, 0.2145473212003708, 0.21778380870819092], 'val_accuracy': [0.7719166874885559, 0.828166663646698, 0.8507500290870667, 0.8654999732971191, 0.8724166750907898, 0.8796666860580444, 0.8865000009536743, 0.8917499780654907, 0.8952500224113464, 0.8958333134651184, 0.9004999995231628, 0.9041666388511658, 0.906499981880188, 0.9109166860580444, 0.9110000133514404, 0.9137499928474426, 0.9163333177566528, 0.9168333411216736, 0.9205833077430725, 0.9211666584014893, 0.9233333468437195, 0.9229166507720947, 0.9246666431427002, 0.9265000224113464, 0.9259166717529297, 0.9278333187103271, 0.9287499785423279, 0.9313333630561829, 0.9318333268165588, 0.9334166646003723, 0.9340000152587891, 0.9339166879653931, 0.937333345413208, 0.9359999895095825, 0.9365833401679993, 0.9393333196640015, 0.9384166598320007, 0.9391666650772095, 0.9402499794960022, 0.940833330154419, 0.9401666522026062, 0.9424999952316284, 0.9432500004768372, 0.9437500238418579, 0.9444166421890259, 0.9440000057220459, 0.9438333511352539, 0.9448333382606506, 0.9459166526794434, 0.9470833539962769]}\n",
            "{'loss': [2.1205523014068604, 1.3084321022033691, 1.0946086645126343, 0.9928300976753235, 0.9019675254821777, 0.8558705449104309, 0.8117142915725708, 0.7712916135787964, 0.740454912185669, 0.7114396095275879, 0.6942036747932434, 0.6749807596206665, 0.6490004062652588, 0.6267333030700684, 0.6164961457252502, 0.6137229204177856, 0.5906952619552612, 0.5810040235519409, 0.57317715883255, 0.555402398109436, 0.5459830164909363, 0.5344217419624329, 0.5233380198478699, 0.5190790891647339, 0.5099872350692749, 0.5013986825942993, 0.49432218074798584, 0.48333609104156494, 0.48015764355659485, 0.47583889961242676, 0.4678090810775757, 0.45683524012565613, 0.44448918104171753, 0.4392814636230469, 0.4372711181640625, 0.4357393682003021, 0.42738077044487, 0.42270931601524353, 0.41939687728881836, 0.4097597599029541, 0.4143696427345276, 0.4009145200252533, 0.39906567335128784, 0.3937430679798126, 0.3873535990715027, 0.38503506779670715, 0.38044285774230957, 0.3779999315738678, 0.3699979782104492, 0.3635765016078949], 'accuracy': [0.34589582681655884, 0.5478125214576721, 0.6287708282470703, 0.6744791865348816, 0.710562527179718, 0.7353125214576721, 0.7533749938011169, 0.7696250081062317, 0.7847499847412109, 0.7932500243186951, 0.8031458258628845, 0.8097291588783264, 0.8182916641235352, 0.8265208601951599, 0.8303333520889282, 0.8332916498184204, 0.8401874899864197, 0.843458354473114, 0.8468958139419556, 0.8507916927337646, 0.8555416464805603, 0.859250009059906, 0.8612499833106995, 0.8627499938011169, 0.8663541674613953, 0.8694583177566528, 0.8705000281333923, 0.8733958601951599, 0.8735416531562805, 0.8759999871253967, 0.879895806312561, 0.8801458477973938, 0.8838541507720947, 0.8869791626930237, 0.8868958353996277, 0.8890625238418579, 0.8910833597183228, 0.890500009059906, 0.8927708268165588, 0.8956249952316284, 0.8964791893959045, 0.8982083201408386, 0.8961041569709778, 0.8990208506584167, 0.9031458497047424, 0.9026041626930237, 0.9038958549499512, 0.9041249752044678, 0.9057708382606506, 0.9071875214576721], 'val_loss': [0.7439292669296265, 0.595912516117096, 0.5121847987174988, 0.4698985517024994, 0.4309902489185333, 0.4053252041339874, 0.38979247212409973, 0.3700138032436371, 0.3573068082332611, 0.3513908386230469, 0.33970513939857483, 0.335692822933197, 0.32942646741867065, 0.3199375569820404, 0.32028669118881226, 0.311400443315506, 0.30698755383491516, 0.30580708384513855, 0.29857584834098816, 0.2934402525424957, 0.28888460993766785, 0.28567513823509216, 0.27719685435295105, 0.2779221832752228, 0.27723228931427, 0.26826176047325134, 0.2697727084159851, 0.26694154739379883, 0.26289886236190796, 0.2576104998588562, 0.2555805742740631, 0.2522348165512085, 0.2497892528772354, 0.24664480984210968, 0.24916188418865204, 0.24370454251766205, 0.24169309437274933, 0.2416941374540329, 0.23610074818134308, 0.23671738803386688, 0.23835577070713043, 0.23479494452476501, 0.23326554894447327, 0.23583833873271942, 0.23010258376598358, 0.2413470596075058, 0.23390859365463257, 0.23280535638332367, 0.23210376501083374, 0.23039068281650543], 'val_accuracy': [0.7865833044052124, 0.8339999914169312, 0.8600833415985107, 0.8692499995231628, 0.8793333172798157, 0.8888333439826965, 0.8920833468437195, 0.8976666927337646, 0.9015833139419556, 0.9019166827201843, 0.9069166779518127, 0.9090833067893982, 0.9114166498184204, 0.9145833253860474, 0.9154999852180481, 0.9170833230018616, 0.918666660785675, 0.9175000190734863, 0.9200000166893005, 0.9204166531562805, 0.922166645526886, 0.9235000014305115, 0.9259166717529297, 0.9263333082199097, 0.9265000224113464, 0.9289166927337646, 0.9298333525657654, 0.9292500019073486, 0.9319166541099548, 0.9319999814033508, 0.9340833425521851, 0.934333324432373, 0.9334999918937683, 0.9354166388511658, 0.9355000257492065, 0.9380833506584167, 0.9370833039283752, 0.9384166598320007, 0.9391666650772095, 0.9400833249092102, 0.9384166598320007, 0.9416666626930237, 0.9417499899864197, 0.9412500262260437, 0.9419166445732117, 0.9411666393280029, 0.9434166550636292, 0.9435833096504211, 0.9434166550636292, 0.9442499876022339]}\n",
            "{'loss': [2.301693916320801, 2.2992396354675293, 2.2968122959136963, 2.293736696243286, 2.28848934173584, 2.2724194526672363, 2.1917779445648193, 2.092947006225586, 1.9997259378433228, 1.8696138858795166, 1.7171599864959717, 1.5690518617630005, 1.4419267177581787, 1.3344660997390747, 1.2559493780136108, 1.1861412525177002, 1.1329097747802734, 1.0860943794250488, 1.0376719236373901, 1.0039951801300049, 0.970176100730896, 0.9500763416290283, 0.9138364791870117, 0.8930222988128662, 0.8744183778762817, 0.8516477346420288, 0.829042375087738, 0.8180805444717407, 0.7989091873168945, 0.7808037400245667, 0.7666173577308655, 0.7459006309509277, 0.7350550293922424, 0.7222120761871338, 0.7095345854759216, 0.6946684718132019, 0.680963397026062, 0.6724452376365662, 0.6545306444168091, 0.6430904865264893, 0.637438952922821, 0.6277852654457092, 0.6195487380027771, 0.5983684659004211, 0.6005110144615173, 0.5828911066055298, 0.5788242816925049, 0.5745161771774292, 0.5597255229949951, 0.5548776984214783], 'accuracy': [0.12022916972637177, 0.11954166740179062, 0.12012500315904617, 0.12537500262260437, 0.1469999998807907, 0.18514584004878998, 0.2160000056028366, 0.22572916746139526, 0.26529166102409363, 0.3240833282470703, 0.39243748784065247, 0.4505416750907898, 0.5025416612625122, 0.546750009059906, 0.5848541855812073, 0.6136249899864197, 0.6342708468437195, 0.6501874923706055, 0.6663958430290222, 0.6822500228881836, 0.6943125128746033, 0.7014166712760925, 0.7132916450500488, 0.7201666831970215, 0.7260833382606506, 0.7377916574478149, 0.7451666593551636, 0.7488124966621399, 0.7565833330154419, 0.7614166736602783, 0.7637500166893005, 0.7735000252723694, 0.7783958315849304, 0.7797499895095825, 0.7866250276565552, 0.7885000109672546, 0.7957291603088379, 0.7972708344459534, 0.8021666407585144, 0.8060625195503235, 0.8092291951179504, 0.8104583621025085, 0.8145208358764648, 0.8227708339691162, 0.8224166631698608, 0.8241249918937683, 0.8295416831970215, 0.8318125009536743, 0.8343541622161865, 0.8345208168029785], 'val_loss': [2.3005008697509766, 2.2984912395477295, 2.2960381507873535, 2.2922184467315674, 2.284456729888916, 2.2446529865264893, 2.0738754272460938, 1.9771571159362793, 1.840954303741455, 1.6132460832595825, 1.3842048645019531, 1.185832142829895, 1.0523818731307983, 0.9445170164108276, 0.8561474680900574, 0.7870091199874878, 0.7363660335540771, 0.6948882937431335, 0.6524547338485718, 0.62615567445755, 0.5985574722290039, 0.5734245777130127, 0.5548309087753296, 0.5334623456001282, 0.5173184275627136, 0.5004412531852722, 0.48568740487098694, 0.47165951132774353, 0.4578939974308014, 0.44555163383483887, 0.4323904514312744, 0.42240485548973083, 0.41191041469573975, 0.4021196663379669, 0.39278796315193176, 0.3840074837207794, 0.3757091462612152, 0.3683531880378723, 0.3584200441837311, 0.35380819439888, 0.3461805284023285, 0.3415760397911072, 0.333790123462677, 0.3325434923171997, 0.3230588436126709, 0.32302239537239075, 0.3132860064506531, 0.313896507024765, 0.3122199773788452, 0.3094177842140198], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.11150000244379044, 0.15950000286102295, 0.20391666889190674, 0.2305833399295807, 0.26758334040641785, 0.3643333315849304, 0.45883333683013916, 0.578416645526886, 0.6357499957084656, 0.6901666522026062, 0.7418333292007446, 0.7760833501815796, 0.79708331823349, 0.815666675567627, 0.8301666378974915, 0.8413333296775818, 0.8531666398048401, 0.8600833415985107, 0.8666666746139526, 0.8709166646003723, 0.875166654586792, 0.8802499771118164, 0.8833333253860474, 0.8889999985694885, 0.8910833597183228, 0.8944166898727417, 0.8980000019073486, 0.8986666798591614, 0.9016666412353516, 0.9039166569709778, 0.9075833559036255, 0.9086666703224182, 0.9100000262260437, 0.9117500185966492, 0.9144166707992554, 0.9164166450500488, 0.9170833230018616, 0.9200833439826965, 0.9208333492279053, 0.9243333339691162, 0.9225000143051147, 0.9255833625793457, 0.9265000224113464, 0.9279166460037231, 0.9285833239555359, 0.9295833110809326, 0.9318333268165588]}\n",
            "{'loss': [2.3020284175872803, 2.3003766536712646, 2.2990851402282715, 2.297907829284668, 2.296642780303955, 2.294968843460083, 2.29303240776062, 2.290304660797119, 2.2862560749053955, 2.2789182662963867, 2.2628352642059326, 2.202937126159668, 2.0545575618743896, 1.9316518306732178, 1.8167612552642822, 1.7193398475646973, 1.6280566453933716, 1.5263556241989136, 1.4419643878936768, 1.3615484237670898, 1.2965474128723145, 1.2458317279815674, 1.192960500717163, 1.1438853740692139, 1.1087398529052734, 1.0690969228744507, 1.035188913345337, 1.0173897743225098, 0.9944592118263245, 0.9755811095237732, 0.9556118249893188, 0.9346922039985657, 0.9205366373062134, 0.9087392687797546, 0.8897028565406799, 0.8721230626106262, 0.8570576906204224, 0.843769371509552, 0.8322798013687134, 0.8127670288085938, 0.802802324295044, 0.7925063371658325, 0.774390697479248, 0.7681107521057129, 0.7604525685310364, 0.745347261428833, 0.7409999966621399, 0.7257214188575745, 0.7117550373077393, 0.6962933540344238], 'accuracy': [0.1158749982714653, 0.1146041676402092, 0.11424999684095383, 0.11418750137090683, 0.11422916501760483, 0.11435416340827942, 0.11508333683013916, 0.11616666615009308, 0.12141666561365128, 0.13727083802223206, 0.1771875023841858, 0.23749999701976776, 0.2553333342075348, 0.2848750054836273, 0.3140000104904175, 0.3389583230018616, 0.37533333897590637, 0.4112916588783264, 0.44735416769981384, 0.4831874966621399, 0.5166249871253967, 0.5438958406448364, 0.5725625157356262, 0.5881666541099548, 0.6089166402816772, 0.6208958625793457, 0.6367083191871643, 0.6456458568572998, 0.6551250219345093, 0.664229154586792, 0.6688541769981384, 0.6772291660308838, 0.6860625147819519, 0.695687472820282, 0.6994583606719971, 0.7062291502952576, 0.7118750214576721, 0.7149791717529297, 0.7221875190734863, 0.7317708134651184, 0.7365624904632568, 0.7406666874885559, 0.7476249933242798, 0.7508958578109741, 0.7540416717529297, 0.7567291855812073, 0.7637291550636292, 0.768958330154419, 0.7735416889190674, 0.7769583463668823], 'val_loss': [2.301504135131836, 2.3003861904144287, 2.2993149757385254, 2.298119068145752, 2.296698808670044, 2.2949306964874268, 2.29258131980896, 2.2892520427703857, 2.283806562423706, 2.2732746601104736, 2.24480938911438, 2.094907760620117, 1.8815196752548218, 1.7284653186798096, 1.5934778451919556, 1.4936045408248901, 1.3768306970596313, 1.2524058818817139, 1.1572556495666504, 1.0691813230514526, 0.9918631911277771, 0.9155986309051514, 0.8521644473075867, 0.8001123070716858, 0.7630259394645691, 0.7392200231552124, 0.714258074760437, 0.6937823295593262, 0.6784902215003967, 0.6658957004547119, 0.6498235464096069, 0.6327667236328125, 0.6194729208946228, 0.6089507937431335, 0.5982586741447449, 0.5841111540794373, 0.576288104057312, 0.5640639066696167, 0.5527689456939697, 0.5421187877655029, 0.5320095419883728, 0.5209179520606995, 0.5100642442703247, 0.5008272528648376, 0.4925030469894409, 0.480368971824646, 0.47110962867736816, 0.4620596170425415, 0.45417749881744385, 0.44557347893714905], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.1067499965429306, 0.20091666281223297, 0.312416672706604, 0.3504166603088379, 0.3959999978542328, 0.43541666865348816, 0.5004166960716248, 0.5140833258628845, 0.547249972820282, 0.5954999923706055, 0.6445833444595337, 0.6899999976158142, 0.7273333072662354, 0.7490833401679993, 0.7639166712760925, 0.7727500200271606, 0.7771666646003723, 0.7868333458900452, 0.7907500267028809, 0.7943333387374878, 0.7990000247955322, 0.8085833191871643, 0.8145833611488342, 0.8169999718666077, 0.8181666731834412, 0.8240833282470703, 0.8298333287239075, 0.8330000042915344, 0.8398333191871643, 0.843583345413208, 0.846666693687439, 0.8510000109672546, 0.8569166660308838, 0.8638333082199097, 0.8661666512489319, 0.8729166388511658, 0.875166654586792, 0.8786666393280029, 0.8808333277702332, 0.8830000162124634, 0.8877500295639038]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}