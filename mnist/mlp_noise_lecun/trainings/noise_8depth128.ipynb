{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noise_8depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "8fcd6048-0c94-449c-e7d3-65532581da43"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 18s 6ms/step - loss: 2.1689 - accuracy: 0.1982 - val_loss: 1.3437 - val_accuracy: 0.6716\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.6391 - accuracy: 0.4392 - val_loss: 0.9992 - val_accuracy: 0.7598\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4016 - accuracy: 0.5321 - val_loss: 0.7981 - val_accuracy: 0.8119\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2302 - accuracy: 0.5916 - val_loss: 0.6713 - val_accuracy: 0.8399\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1112 - accuracy: 0.6376 - val_loss: 0.5928 - val_accuracy: 0.8477\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0425 - accuracy: 0.6661 - val_loss: 0.5391 - val_accuracy: 0.8590\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9707 - accuracy: 0.6919 - val_loss: 0.4981 - val_accuracy: 0.8650\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9128 - accuracy: 0.7146 - val_loss: 0.4655 - val_accuracy: 0.8723\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8753 - accuracy: 0.7305 - val_loss: 0.4459 - val_accuracy: 0.8768\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8358 - accuracy: 0.7445 - val_loss: 0.4260 - val_accuracy: 0.8809\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8002 - accuracy: 0.7627 - val_loss: 0.4128 - val_accuracy: 0.8852\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7833 - accuracy: 0.7709 - val_loss: 0.4001 - val_accuracy: 0.8892\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7571 - accuracy: 0.7781 - val_loss: 0.3910 - val_accuracy: 0.8931\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7344 - accuracy: 0.7912 - val_loss: 0.3844 - val_accuracy: 0.8945\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7049 - accuracy: 0.7990 - val_loss: 0.3791 - val_accuracy: 0.8980\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7049 - accuracy: 0.8021 - val_loss: 0.3717 - val_accuracy: 0.8990\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6699 - accuracy: 0.8158 - val_loss: 0.3646 - val_accuracy: 0.9032\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6743 - accuracy: 0.8192 - val_loss: 0.3647 - val_accuracy: 0.9036\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6520 - accuracy: 0.8220 - val_loss: 0.3556 - val_accuracy: 0.9068\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6343 - accuracy: 0.8317 - val_loss: 0.3563 - val_accuracy: 0.9062\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6328 - accuracy: 0.8320 - val_loss: 0.3514 - val_accuracy: 0.9088\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6211 - accuracy: 0.8353 - val_loss: 0.3488 - val_accuracy: 0.9090\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6027 - accuracy: 0.8413 - val_loss: 0.3500 - val_accuracy: 0.9103\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5983 - accuracy: 0.8418 - val_loss: 0.3471 - val_accuracy: 0.9111\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5820 - accuracy: 0.8469 - val_loss: 0.3470 - val_accuracy: 0.9127\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5748 - accuracy: 0.8496 - val_loss: 0.3437 - val_accuracy: 0.9137\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5815 - accuracy: 0.8517 - val_loss: 0.3406 - val_accuracy: 0.9139\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5600 - accuracy: 0.8524 - val_loss: 0.3376 - val_accuracy: 0.9152\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5643 - accuracy: 0.8568 - val_loss: 0.3401 - val_accuracy: 0.9150\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5487 - accuracy: 0.8591 - val_loss: 0.3360 - val_accuracy: 0.9169\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5393 - accuracy: 0.8622 - val_loss: 0.3323 - val_accuracy: 0.9178\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5362 - accuracy: 0.8611 - val_loss: 0.3323 - val_accuracy: 0.9164\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5342 - accuracy: 0.8642 - val_loss: 0.3285 - val_accuracy: 0.9190\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5357 - accuracy: 0.8661 - val_loss: 0.3272 - val_accuracy: 0.9200\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5093 - accuracy: 0.8687 - val_loss: 0.3291 - val_accuracy: 0.9195\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5146 - accuracy: 0.8711 - val_loss: 0.3260 - val_accuracy: 0.9197\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5150 - accuracy: 0.8707 - val_loss: 0.3205 - val_accuracy: 0.9229\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5147 - accuracy: 0.8734 - val_loss: 0.3169 - val_accuracy: 0.9238\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4990 - accuracy: 0.8736 - val_loss: 0.3170 - val_accuracy: 0.9238\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4973 - accuracy: 0.8765 - val_loss: 0.3192 - val_accuracy: 0.9236\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4947 - accuracy: 0.8778 - val_loss: 0.3186 - val_accuracy: 0.9244\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4890 - accuracy: 0.8783 - val_loss: 0.3172 - val_accuracy: 0.9238\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4857 - accuracy: 0.8780 - val_loss: 0.3144 - val_accuracy: 0.9252\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4824 - accuracy: 0.8795 - val_loss: 0.3124 - val_accuracy: 0.9252\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4704 - accuracy: 0.8824 - val_loss: 0.3137 - val_accuracy: 0.9268\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4734 - accuracy: 0.8832 - val_loss: 0.3096 - val_accuracy: 0.9268\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4674 - accuracy: 0.8842 - val_loss: 0.3086 - val_accuracy: 0.9273\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4637 - accuracy: 0.8859 - val_loss: 0.3029 - val_accuracy: 0.9291\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.8887 - val_loss: 0.3067 - val_accuracy: 0.9289\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4544 - accuracy: 0.8892 - val_loss: 0.3016 - val_accuracy: 0.9298\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.3066 - accuracy: 0.1108 - val_loss: 2.3009 - val_accuracy: 0.1069\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3004 - accuracy: 0.1183 - val_loss: 2.2991 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2981 - accuracy: 0.1206 - val_loss: 2.2938 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2957 - accuracy: 0.1256 - val_loss: 2.2808 - val_accuracy: 0.1107\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2864 - accuracy: 0.1330 - val_loss: 2.2464 - val_accuracy: 0.1992\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2560 - accuracy: 0.1517 - val_loss: 2.1276 - val_accuracy: 0.2342\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.1606 - accuracy: 0.1939 - val_loss: 1.9535 - val_accuracy: 0.3004\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.0467 - accuracy: 0.2353 - val_loss: 1.7920 - val_accuracy: 0.4174\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9159 - accuracy: 0.2844 - val_loss: 1.6200 - val_accuracy: 0.4437\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7850 - accuracy: 0.3340 - val_loss: 1.4733 - val_accuracy: 0.4612\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6819 - accuracy: 0.3675 - val_loss: 1.3215 - val_accuracy: 0.5039\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5667 - accuracy: 0.4141 - val_loss: 1.1993 - val_accuracy: 0.5500\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4727 - accuracy: 0.4418 - val_loss: 1.0995 - val_accuracy: 0.5982\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3925 - accuracy: 0.4712 - val_loss: 1.0184 - val_accuracy: 0.6288\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3269 - accuracy: 0.4875 - val_loss: 0.9608 - val_accuracy: 0.6371\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2614 - accuracy: 0.5109 - val_loss: 0.9130 - val_accuracy: 0.6366\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2158 - accuracy: 0.5234 - val_loss: 0.8823 - val_accuracy: 0.6476\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1675 - accuracy: 0.5427 - val_loss: 0.8588 - val_accuracy: 0.6558\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1411 - accuracy: 0.5587 - val_loss: 0.8326 - val_accuracy: 0.6725\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0975 - accuracy: 0.5687 - val_loss: 0.8139 - val_accuracy: 0.6733\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0835 - accuracy: 0.5756 - val_loss: 0.7940 - val_accuracy: 0.6903\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0459 - accuracy: 0.5941 - val_loss: 0.7750 - val_accuracy: 0.6936\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0214 - accuracy: 0.5998 - val_loss: 0.7646 - val_accuracy: 0.7122\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0060 - accuracy: 0.6126 - val_loss: 0.7533 - val_accuracy: 0.7311\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9820 - accuracy: 0.6246 - val_loss: 0.7351 - val_accuracy: 0.7332\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9406 - accuracy: 0.6374 - val_loss: 0.7148 - val_accuracy: 0.7473\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9233 - accuracy: 0.6497 - val_loss: 0.7027 - val_accuracy: 0.7542\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9132 - accuracy: 0.6529 - val_loss: 0.6917 - val_accuracy: 0.7847\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8947 - accuracy: 0.6671 - val_loss: 0.6717 - val_accuracy: 0.7998\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8719 - accuracy: 0.6810 - val_loss: 0.6691 - val_accuracy: 0.8098\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8634 - accuracy: 0.6899 - val_loss: 0.6522 - val_accuracy: 0.8148\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8531 - accuracy: 0.6976 - val_loss: 0.6276 - val_accuracy: 0.8273\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8150 - accuracy: 0.7117 - val_loss: 0.6070 - val_accuracy: 0.8223\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8045 - accuracy: 0.7200 - val_loss: 0.5976 - val_accuracy: 0.8525\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7882 - accuracy: 0.7273 - val_loss: 0.5898 - val_accuracy: 0.8522\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7656 - accuracy: 0.7413 - val_loss: 0.5806 - val_accuracy: 0.8672\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7528 - accuracy: 0.7502 - val_loss: 0.5796 - val_accuracy: 0.8689\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7282 - accuracy: 0.7588 - val_loss: 0.5546 - val_accuracy: 0.8820\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7131 - accuracy: 0.7650 - val_loss: 0.5317 - val_accuracy: 0.8803\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7098 - accuracy: 0.7748 - val_loss: 0.5307 - val_accuracy: 0.8857\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.7778 - val_loss: 0.5466 - val_accuracy: 0.8874\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6756 - accuracy: 0.7836 - val_loss: 0.5216 - val_accuracy: 0.8903\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6525 - accuracy: 0.7937 - val_loss: 0.5213 - val_accuracy: 0.8934\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6462 - accuracy: 0.7968 - val_loss: 0.5107 - val_accuracy: 0.8890\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6303 - accuracy: 0.8052 - val_loss: 0.5054 - val_accuracy: 0.8982\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6161 - accuracy: 0.8103 - val_loss: 0.4777 - val_accuracy: 0.9021\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6114 - accuracy: 0.8120 - val_loss: 0.4706 - val_accuracy: 0.9019\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5920 - accuracy: 0.8195 - val_loss: 0.4822 - val_accuracy: 0.9046\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5942 - accuracy: 0.8182 - val_loss: 0.4996 - val_accuracy: 0.9082\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5696 - accuracy: 0.8256 - val_loss: 0.4865 - val_accuracy: 0.9121\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3042 - accuracy: 0.1045 - val_loss: 2.2952 - val_accuracy: 0.1203\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2940 - accuracy: 0.1337 - val_loss: 2.2683 - val_accuracy: 0.1955\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2692 - accuracy: 0.1550 - val_loss: 2.1625 - val_accuracy: 0.3248\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1815 - accuracy: 0.2034 - val_loss: 1.9208 - val_accuracy: 0.3758\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0157 - accuracy: 0.2686 - val_loss: 1.6435 - val_accuracy: 0.4688\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8396 - accuracy: 0.3387 - val_loss: 1.4081 - val_accuracy: 0.5465\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6704 - accuracy: 0.3972 - val_loss: 1.2246 - val_accuracy: 0.6478\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5217 - accuracy: 0.4646 - val_loss: 1.0907 - val_accuracy: 0.7296\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4015 - accuracy: 0.5239 - val_loss: 0.9653 - val_accuracy: 0.7794\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2914 - accuracy: 0.5786 - val_loss: 0.8375 - val_accuracy: 0.8139\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1871 - accuracy: 0.6295 - val_loss: 0.7329 - val_accuracy: 0.8378\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0995 - accuracy: 0.6555 - val_loss: 0.6452 - val_accuracy: 0.8562\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0057 - accuracy: 0.6902 - val_loss: 0.5733 - val_accuracy: 0.8691\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9431 - accuracy: 0.7143 - val_loss: 0.5173 - val_accuracy: 0.8762\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8691 - accuracy: 0.7333 - val_loss: 0.4716 - val_accuracy: 0.8849\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8061 - accuracy: 0.7591 - val_loss: 0.4366 - val_accuracy: 0.8919\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7664 - accuracy: 0.7686 - val_loss: 0.4114 - val_accuracy: 0.8963\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7333 - accuracy: 0.7816 - val_loss: 0.3855 - val_accuracy: 0.9030\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6891 - accuracy: 0.7932 - val_loss: 0.3663 - val_accuracy: 0.9078\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6645 - accuracy: 0.8050 - val_loss: 0.3530 - val_accuracy: 0.9121\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6300 - accuracy: 0.8131 - val_loss: 0.3361 - val_accuracy: 0.9146\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6043 - accuracy: 0.8205 - val_loss: 0.3239 - val_accuracy: 0.9182\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5820 - accuracy: 0.8280 - val_loss: 0.3119 - val_accuracy: 0.9218\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5567 - accuracy: 0.8383 - val_loss: 0.3029 - val_accuracy: 0.9227\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5436 - accuracy: 0.8408 - val_loss: 0.2911 - val_accuracy: 0.9262\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5202 - accuracy: 0.8469 - val_loss: 0.2862 - val_accuracy: 0.9273\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5138 - accuracy: 0.8490 - val_loss: 0.2826 - val_accuracy: 0.9267\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4865 - accuracy: 0.8585 - val_loss: 0.2707 - val_accuracy: 0.9323\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4641 - accuracy: 0.8641 - val_loss: 0.2720 - val_accuracy: 0.9318\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4648 - accuracy: 0.8694 - val_loss: 0.2616 - val_accuracy: 0.9349\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4490 - accuracy: 0.8700 - val_loss: 0.2529 - val_accuracy: 0.9361\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4204 - accuracy: 0.8794 - val_loss: 0.2505 - val_accuracy: 0.9372\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4174 - accuracy: 0.8808 - val_loss: 0.2534 - val_accuracy: 0.9367\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4098 - accuracy: 0.8842 - val_loss: 0.2413 - val_accuracy: 0.9393\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4052 - accuracy: 0.8846 - val_loss: 0.2400 - val_accuracy: 0.9411\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3843 - accuracy: 0.8893 - val_loss: 0.2436 - val_accuracy: 0.9402\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3769 - accuracy: 0.8975 - val_loss: 0.2367 - val_accuracy: 0.9421\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3647 - accuracy: 0.8953 - val_loss: 0.2312 - val_accuracy: 0.9441\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8992 - val_loss: 0.2338 - val_accuracy: 0.9419\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3559 - accuracy: 0.8988 - val_loss: 0.2284 - val_accuracy: 0.9433\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3331 - accuracy: 0.9064 - val_loss: 0.2337 - val_accuracy: 0.9450\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3318 - accuracy: 0.9059 - val_loss: 0.2299 - val_accuracy: 0.9473\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3282 - accuracy: 0.9085 - val_loss: 0.2220 - val_accuracy: 0.9472\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3216 - accuracy: 0.9115 - val_loss: 0.2302 - val_accuracy: 0.9453\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3028 - accuracy: 0.9134 - val_loss: 0.2201 - val_accuracy: 0.9475\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3092 - accuracy: 0.9158 - val_loss: 0.2211 - val_accuracy: 0.9501\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3000 - accuracy: 0.9152 - val_loss: 0.2253 - val_accuracy: 0.9503\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2915 - accuracy: 0.9183 - val_loss: 0.2182 - val_accuracy: 0.9498\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2903 - accuracy: 0.9159 - val_loss: 0.2265 - val_accuracy: 0.9510\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2695 - accuracy: 0.9255 - val_loss: 0.2153 - val_accuracy: 0.9510\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.1533 - accuracy: 0.2106 - val_loss: 1.1482 - val_accuracy: 0.7148\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4954 - accuracy: 0.4706 - val_loss: 0.7604 - val_accuracy: 0.7987\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2207 - accuracy: 0.5798 - val_loss: 0.5998 - val_accuracy: 0.8353\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0597 - accuracy: 0.6406 - val_loss: 0.5206 - val_accuracy: 0.8561\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9677 - accuracy: 0.6788 - val_loss: 0.4709 - val_accuracy: 0.8709\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9043 - accuracy: 0.7075 - val_loss: 0.4371 - val_accuracy: 0.8802\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8453 - accuracy: 0.7322 - val_loss: 0.4107 - val_accuracy: 0.8869\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8173 - accuracy: 0.7490 - val_loss: 0.3907 - val_accuracy: 0.8919\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7735 - accuracy: 0.7674 - val_loss: 0.3746 - val_accuracy: 0.8962\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7511 - accuracy: 0.7727 - val_loss: 0.3624 - val_accuracy: 0.8992\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7271 - accuracy: 0.7848 - val_loss: 0.3499 - val_accuracy: 0.9036\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7021 - accuracy: 0.7955 - val_loss: 0.3422 - val_accuracy: 0.9039\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6836 - accuracy: 0.8005 - val_loss: 0.3307 - val_accuracy: 0.9084\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6604 - accuracy: 0.8085 - val_loss: 0.3277 - val_accuracy: 0.9078\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6379 - accuracy: 0.8174 - val_loss: 0.3180 - val_accuracy: 0.9112\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6273 - accuracy: 0.8212 - val_loss: 0.3119 - val_accuracy: 0.9129\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6237 - accuracy: 0.8250 - val_loss: 0.3081 - val_accuracy: 0.9140\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6113 - accuracy: 0.8286 - val_loss: 0.3026 - val_accuracy: 0.9151\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6004 - accuracy: 0.8338 - val_loss: 0.3034 - val_accuracy: 0.9150\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5859 - accuracy: 0.8387 - val_loss: 0.2949 - val_accuracy: 0.9183\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5728 - accuracy: 0.8445 - val_loss: 0.2883 - val_accuracy: 0.9197\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5703 - accuracy: 0.8434 - val_loss: 0.2898 - val_accuracy: 0.9199\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5556 - accuracy: 0.8509 - val_loss: 0.2836 - val_accuracy: 0.9208\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5267 - accuracy: 0.8560 - val_loss: 0.2803 - val_accuracy: 0.9217\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5326 - accuracy: 0.8557 - val_loss: 0.2749 - val_accuracy: 0.9240\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5176 - accuracy: 0.8617 - val_loss: 0.2715 - val_accuracy: 0.9247\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5063 - accuracy: 0.8637 - val_loss: 0.2720 - val_accuracy: 0.9251\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5011 - accuracy: 0.8647 - val_loss: 0.2702 - val_accuracy: 0.9261\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4781 - accuracy: 0.8720 - val_loss: 0.2625 - val_accuracy: 0.9288\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4779 - accuracy: 0.8755 - val_loss: 0.2613 - val_accuracy: 0.9283\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4833 - accuracy: 0.8711 - val_loss: 0.2587 - val_accuracy: 0.9306\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4723 - accuracy: 0.8792 - val_loss: 0.2572 - val_accuracy: 0.9293\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4709 - accuracy: 0.8750 - val_loss: 0.2567 - val_accuracy: 0.9312\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4405 - accuracy: 0.8853 - val_loss: 0.2490 - val_accuracy: 0.9330\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4483 - accuracy: 0.8836 - val_loss: 0.2461 - val_accuracy: 0.9333\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4531 - accuracy: 0.8828 - val_loss: 0.2503 - val_accuracy: 0.9337\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4383 - accuracy: 0.8869 - val_loss: 0.2461 - val_accuracy: 0.9341\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4325 - accuracy: 0.8865 - val_loss: 0.2447 - val_accuracy: 0.9347\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4190 - accuracy: 0.8902 - val_loss: 0.2376 - val_accuracy: 0.9360\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4212 - accuracy: 0.8906 - val_loss: 0.2415 - val_accuracy: 0.9359\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4202 - accuracy: 0.8881 - val_loss: 0.2360 - val_accuracy: 0.9374\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4083 - accuracy: 0.8933 - val_loss: 0.2314 - val_accuracy: 0.9386\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3958 - accuracy: 0.8962 - val_loss: 0.2331 - val_accuracy: 0.9389\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3961 - accuracy: 0.8979 - val_loss: 0.2288 - val_accuracy: 0.9391\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3861 - accuracy: 0.9020 - val_loss: 0.2296 - val_accuracy: 0.9385\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3909 - accuracy: 0.9001 - val_loss: 0.2289 - val_accuracy: 0.9398\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3904 - accuracy: 0.9005 - val_loss: 0.2278 - val_accuracy: 0.9398\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3786 - accuracy: 0.9008 - val_loss: 0.2257 - val_accuracy: 0.9407\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3718 - accuracy: 0.9049 - val_loss: 0.2281 - val_accuracy: 0.9408\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3722 - accuracy: 0.9029 - val_loss: 0.2224 - val_accuracy: 0.9413\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.3673 - accuracy: 0.2705 - val_loss: 0.6584 - val_accuracy: 0.8168\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3083 - accuracy: 0.5507 - val_loss: 0.5192 - val_accuracy: 0.8562\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0741 - accuracy: 0.6385 - val_loss: 0.4624 - val_accuracy: 0.8681\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9443 - accuracy: 0.6926 - val_loss: 0.4268 - val_accuracy: 0.8787\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8706 - accuracy: 0.7229 - val_loss: 0.4086 - val_accuracy: 0.8858\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8337 - accuracy: 0.7466 - val_loss: 0.3904 - val_accuracy: 0.8897\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7845 - accuracy: 0.7644 - val_loss: 0.3778 - val_accuracy: 0.8937\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7331 - accuracy: 0.7813 - val_loss: 0.3658 - val_accuracy: 0.8967\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7338 - accuracy: 0.7866 - val_loss: 0.3562 - val_accuracy: 0.8982\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6998 - accuracy: 0.7982 - val_loss: 0.3482 - val_accuracy: 0.9023\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6840 - accuracy: 0.8063 - val_loss: 0.3392 - val_accuracy: 0.9044\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6576 - accuracy: 0.8157 - val_loss: 0.3333 - val_accuracy: 0.9051\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6289 - accuracy: 0.8246 - val_loss: 0.3242 - val_accuracy: 0.9103\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6160 - accuracy: 0.8280 - val_loss: 0.3217 - val_accuracy: 0.9105\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6056 - accuracy: 0.8363 - val_loss: 0.3146 - val_accuracy: 0.9126\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5846 - accuracy: 0.8431 - val_loss: 0.3090 - val_accuracy: 0.9143\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5802 - accuracy: 0.8428 - val_loss: 0.3045 - val_accuracy: 0.9158\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5728 - accuracy: 0.8474 - val_loss: 0.3005 - val_accuracy: 0.9170\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5502 - accuracy: 0.8537 - val_loss: 0.2982 - val_accuracy: 0.9161\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5434 - accuracy: 0.8538 - val_loss: 0.2943 - val_accuracy: 0.9191\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5259 - accuracy: 0.8582 - val_loss: 0.2912 - val_accuracy: 0.9217\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5270 - accuracy: 0.8616 - val_loss: 0.2858 - val_accuracy: 0.9216\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5145 - accuracy: 0.8626 - val_loss: 0.2824 - val_accuracy: 0.9229\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5135 - accuracy: 0.8638 - val_loss: 0.2787 - val_accuracy: 0.9235\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5055 - accuracy: 0.8661 - val_loss: 0.2725 - val_accuracy: 0.9252\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4843 - accuracy: 0.8736 - val_loss: 0.2728 - val_accuracy: 0.9268\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4849 - accuracy: 0.8749 - val_loss: 0.2710 - val_accuracy: 0.9268\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4700 - accuracy: 0.8756 - val_loss: 0.2643 - val_accuracy: 0.9289\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4627 - accuracy: 0.8825 - val_loss: 0.2645 - val_accuracy: 0.9301\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4540 - accuracy: 0.8798 - val_loss: 0.2622 - val_accuracy: 0.9293\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4477 - accuracy: 0.8860 - val_loss: 0.2624 - val_accuracy: 0.9303\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4527 - accuracy: 0.8812 - val_loss: 0.2557 - val_accuracy: 0.9322\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4397 - accuracy: 0.8845 - val_loss: 0.2534 - val_accuracy: 0.9327\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4404 - accuracy: 0.8857 - val_loss: 0.2531 - val_accuracy: 0.9337\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4279 - accuracy: 0.8892 - val_loss: 0.2535 - val_accuracy: 0.9337\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.8907 - val_loss: 0.2501 - val_accuracy: 0.9351\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4238 - accuracy: 0.8884 - val_loss: 0.2468 - val_accuracy: 0.9358\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4113 - accuracy: 0.8936 - val_loss: 0.2449 - val_accuracy: 0.9347\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4046 - accuracy: 0.8953 - val_loss: 0.2420 - val_accuracy: 0.9363\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4084 - accuracy: 0.8929 - val_loss: 0.2408 - val_accuracy: 0.9373\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3983 - accuracy: 0.8965 - val_loss: 0.2413 - val_accuracy: 0.9373\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4031 - accuracy: 0.8965 - val_loss: 0.2396 - val_accuracy: 0.9371\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3894 - accuracy: 0.8990 - val_loss: 0.2444 - val_accuracy: 0.9373\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3791 - accuracy: 0.9021 - val_loss: 0.2410 - val_accuracy: 0.9383\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3874 - accuracy: 0.9007 - val_loss: 0.2365 - val_accuracy: 0.9403\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3740 - accuracy: 0.9053 - val_loss: 0.2323 - val_accuracy: 0.9406\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3717 - accuracy: 0.9038 - val_loss: 0.2308 - val_accuracy: 0.9415\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3720 - accuracy: 0.9055 - val_loss: 0.2307 - val_accuracy: 0.9421\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3752 - accuracy: 0.9041 - val_loss: 0.2324 - val_accuracy: 0.9427\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3569 - accuracy: 0.9072 - val_loss: 0.2295 - val_accuracy: 0.9431\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.3023 - accuracy: 0.1144 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1133 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1144 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1147 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1142 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2991 - accuracy: 0.1186 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2994 - accuracy: 0.1158 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2989 - accuracy: 0.1130 - val_loss: 2.2997 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2992 - accuracy: 0.1127 - val_loss: 2.2992 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2982 - accuracy: 0.1140 - val_loss: 2.2986 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2973 - accuracy: 0.1133 - val_loss: 2.2977 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2967 - accuracy: 0.1130 - val_loss: 2.2965 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2950 - accuracy: 0.1162 - val_loss: 2.2947 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2934 - accuracy: 0.1192 - val_loss: 2.2916 - val_accuracy: 0.1063\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2895 - accuracy: 0.1314 - val_loss: 2.2848 - val_accuracy: 0.1434\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2812 - accuracy: 0.1562 - val_loss: 2.2643 - val_accuracy: 0.2216\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2546 - accuracy: 0.1875 - val_loss: 2.1996 - val_accuracy: 0.2123\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1953 - accuracy: 0.1962 - val_loss: 2.0841 - val_accuracy: 0.2255\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1191 - accuracy: 0.2111 - val_loss: 1.9786 - val_accuracy: 0.2522\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0462 - accuracy: 0.2446 - val_loss: 1.8982 - val_accuracy: 0.2822\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9857 - accuracy: 0.2702 - val_loss: 1.8333 - val_accuracy: 0.3132\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9243 - accuracy: 0.2933 - val_loss: 1.7745 - val_accuracy: 0.3372\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8627 - accuracy: 0.3195 - val_loss: 1.7306 - val_accuracy: 0.3714\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8183 - accuracy: 0.3313 - val_loss: 1.6875 - val_accuracy: 0.3854\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7716 - accuracy: 0.3531 - val_loss: 1.6479 - val_accuracy: 0.4015\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7366 - accuracy: 0.3587 - val_loss: 1.6056 - val_accuracy: 0.4168\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6983 - accuracy: 0.3706 - val_loss: 1.5602 - val_accuracy: 0.4464\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6653 - accuracy: 0.3811 - val_loss: 1.5168 - val_accuracy: 0.4588\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6295 - accuracy: 0.3883 - val_loss: 1.4723 - val_accuracy: 0.4698\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5865 - accuracy: 0.4026 - val_loss: 1.4307 - val_accuracy: 0.4815\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5514 - accuracy: 0.4048 - val_loss: 1.3957 - val_accuracy: 0.4922\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5178 - accuracy: 0.4183 - val_loss: 1.3562 - val_accuracy: 0.5048\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4863 - accuracy: 0.4310 - val_loss: 1.3166 - val_accuracy: 0.5340\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4634 - accuracy: 0.4337 - val_loss: 1.2808 - val_accuracy: 0.5515\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4287 - accuracy: 0.4573 - val_loss: 1.2360 - val_accuracy: 0.5901\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3868 - accuracy: 0.4706 - val_loss: 1.1789 - val_accuracy: 0.6417\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3351 - accuracy: 0.4974 - val_loss: 1.1109 - val_accuracy: 0.6701\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3006 - accuracy: 0.5200 - val_loss: 1.0553 - val_accuracy: 0.6863\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2483 - accuracy: 0.5464 - val_loss: 0.9968 - val_accuracy: 0.7097\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2079 - accuracy: 0.5687 - val_loss: 0.9546 - val_accuracy: 0.7399\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1789 - accuracy: 0.5882 - val_loss: 0.9023 - val_accuracy: 0.7626\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1338 - accuracy: 0.6163 - val_loss: 0.8590 - val_accuracy: 0.7851\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0857 - accuracy: 0.6331 - val_loss: 0.8117 - val_accuracy: 0.8016\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0479 - accuracy: 0.6506 - val_loss: 0.7684 - val_accuracy: 0.8173\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0104 - accuracy: 0.6648 - val_loss: 0.7246 - val_accuracy: 0.8297\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9818 - accuracy: 0.6830 - val_loss: 0.6886 - val_accuracy: 0.8439\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9500 - accuracy: 0.6908 - val_loss: 0.6498 - val_accuracy: 0.8493\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9033 - accuracy: 0.7079 - val_loss: 0.6200 - val_accuracy: 0.8628\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8874 - accuracy: 0.7151 - val_loss: 0.5988 - val_accuracy: 0.8704\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8484 - accuracy: 0.7261 - val_loss: 0.5710 - val_accuracy: 0.8775\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3022 - accuracy: 0.1137 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3007 - accuracy: 0.1130 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3002 - accuracy: 0.1124 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2996 - accuracy: 0.1130 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2995 - accuracy: 0.1138 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2989 - accuracy: 0.1147 - val_loss: 2.2997 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2985 - accuracy: 0.1153 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2985 - accuracy: 0.1130 - val_loss: 2.2987 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2981 - accuracy: 0.1112 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2971 - accuracy: 0.1138 - val_loss: 2.2974 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2961 - accuracy: 0.1145 - val_loss: 2.2964 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2954 - accuracy: 0.1146 - val_loss: 2.2951 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2939 - accuracy: 0.1186 - val_loss: 2.2930 - val_accuracy: 0.1084\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2911 - accuracy: 0.1315 - val_loss: 2.2894 - val_accuracy: 0.1396\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2869 - accuracy: 0.1535 - val_loss: 2.2811 - val_accuracy: 0.1902\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2747 - accuracy: 0.1908 - val_loss: 2.2308 - val_accuracy: 0.2084\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2109 - accuracy: 0.2177 - val_loss: 2.1134 - val_accuracy: 0.2181\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1354 - accuracy: 0.2151 - val_loss: 2.0589 - val_accuracy: 0.2225\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0933 - accuracy: 0.2195 - val_loss: 2.0188 - val_accuracy: 0.2384\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0621 - accuracy: 0.2380 - val_loss: 1.9786 - val_accuracy: 0.2574\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0150 - accuracy: 0.2590 - val_loss: 1.9160 - val_accuracy: 0.2851\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9653 - accuracy: 0.2801 - val_loss: 1.8455 - val_accuracy: 0.3161\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9184 - accuracy: 0.2981 - val_loss: 1.7843 - val_accuracy: 0.3491\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8602 - accuracy: 0.3168 - val_loss: 1.7212 - val_accuracy: 0.3740\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7978 - accuracy: 0.3413 - val_loss: 1.6049 - val_accuracy: 0.4016\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7036 - accuracy: 0.3701 - val_loss: 1.4712 - val_accuracy: 0.4430\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6044 - accuracy: 0.3979 - val_loss: 1.3789 - val_accuracy: 0.4794\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5380 - accuracy: 0.4166 - val_loss: 1.3185 - val_accuracy: 0.5096\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4816 - accuracy: 0.4323 - val_loss: 1.2690 - val_accuracy: 0.5355\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4427 - accuracy: 0.4405 - val_loss: 1.2345 - val_accuracy: 0.5355\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4044 - accuracy: 0.4530 - val_loss: 1.2091 - val_accuracy: 0.5337\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3784 - accuracy: 0.4609 - val_loss: 1.1853 - val_accuracy: 0.5628\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3504 - accuracy: 0.4743 - val_loss: 1.1608 - val_accuracy: 0.5658\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3321 - accuracy: 0.4854 - val_loss: 1.1406 - val_accuracy: 0.5799\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3048 - accuracy: 0.4918 - val_loss: 1.1201 - val_accuracy: 0.5900\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2900 - accuracy: 0.5063 - val_loss: 1.0893 - val_accuracy: 0.6132\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2593 - accuracy: 0.5162 - val_loss: 1.0581 - val_accuracy: 0.6263\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2297 - accuracy: 0.5375 - val_loss: 1.0186 - val_accuracy: 0.6428\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2030 - accuracy: 0.5520 - val_loss: 0.9684 - val_accuracy: 0.6611\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1615 - accuracy: 0.5711 - val_loss: 0.9181 - val_accuracy: 0.6862\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1282 - accuracy: 0.5816 - val_loss: 0.8795 - val_accuracy: 0.7059\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1040 - accuracy: 0.5943 - val_loss: 0.8394 - val_accuracy: 0.7306\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0840 - accuracy: 0.6104 - val_loss: 0.8083 - val_accuracy: 0.7443\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0524 - accuracy: 0.6228 - val_loss: 0.7751 - val_accuracy: 0.7581\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0262 - accuracy: 0.6334 - val_loss: 0.7460 - val_accuracy: 0.7666\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0075 - accuracy: 0.6449 - val_loss: 0.7190 - val_accuracy: 0.7837\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9959 - accuracy: 0.6553 - val_loss: 0.6941 - val_accuracy: 0.7891\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9608 - accuracy: 0.6646 - val_loss: 0.6712 - val_accuracy: 0.8036\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9277 - accuracy: 0.6776 - val_loss: 0.6503 - val_accuracy: 0.8094\n",
            "{'loss': [1.9900351762771606, 1.5691248178482056, 1.3520863056182861, 1.2014833688735962, 1.0887185335159302, 1.0215537548065186, 0.9587840437889099, 0.9056186676025391, 0.8660088777542114, 0.8283658623695374, 0.8015800714492798, 0.7756693363189697, 0.7463871836662292, 0.7290751338005066, 0.7048473358154297, 0.6962977051734924, 0.67179274559021, 0.6672936677932739, 0.6500653624534607, 0.6385003924369812, 0.6267116665840149, 0.6168079376220703, 0.6052564382553101, 0.5956192016601562, 0.5883830785751343, 0.5757667422294617, 0.5794357657432556, 0.5625898241996765, 0.5616509914398193, 0.5526790618896484, 0.5494939088821411, 0.5377665162086487, 0.5349463224411011, 0.5309336185455322, 0.518017590045929, 0.5156877636909485, 0.5110430717468262, 0.506005048751831, 0.5014569759368896, 0.49612513184547424, 0.4940057098865509, 0.4908847510814667, 0.48417967557907104, 0.4769424498081207, 0.4728240966796875, 0.4672548472881317, 0.4648715853691101, 0.45934659242630005, 0.4499562680721283, 0.45549309253692627], 'accuracy': [0.2748958468437195, 0.46943750977516174, 0.5502291917800903, 0.6044374704360962, 0.6462916731834412, 0.6731874942779541, 0.6962500214576721, 0.7175208330154419, 0.7355416417121887, 0.7491666674613953, 0.7627708315849304, 0.7735416889190674, 0.7837083339691162, 0.7927291393280029, 0.8004375100135803, 0.8059166669845581, 0.8151666522026062, 0.8208958506584167, 0.8225416541099548, 0.8307916522026062, 0.8316875100135803, 0.8370000123977661, 0.8411041498184204, 0.8435208201408386, 0.8454166650772095, 0.8502916693687439, 0.851312518119812, 0.8534791469573975, 0.8566250205039978, 0.8599374890327454, 0.8603125214576721, 0.8628125190734863, 0.8654375076293945, 0.8676666617393494, 0.8685625195503235, 0.8708541393280029, 0.8702083230018616, 0.8742708563804626, 0.8743333220481873, 0.8760416507720947, 0.8764166831970215, 0.878333330154419, 0.8787708282470703, 0.8809166550636292, 0.8817916512489319, 0.8850625157356262, 0.8839583396911621, 0.8871041536331177, 0.8884791731834412, 0.8889999985694885], 'val_loss': [1.3436522483825684, 0.9991590976715088, 0.7980863451957703, 0.6712785363197327, 0.5928060412406921, 0.5391373038291931, 0.49805209040641785, 0.4654538631439209, 0.4459169805049896, 0.4259571135044098, 0.41281917691230774, 0.40012022852897644, 0.390962153673172, 0.38439029455184937, 0.3791167438030243, 0.3716804087162018, 0.36459973454475403, 0.3647324740886688, 0.3555828332901001, 0.35632047057151794, 0.3513527512550354, 0.3487693965435028, 0.35003331303596497, 0.34706294536590576, 0.34704363346099854, 0.3437146842479706, 0.3405883312225342, 0.3376060128211975, 0.34010517597198486, 0.3360415995121002, 0.33230769634246826, 0.33234381675720215, 0.3285010755062103, 0.32717132568359375, 0.3290500342845917, 0.32602694630622864, 0.320505291223526, 0.3168511986732483, 0.3169982135295868, 0.3192230463027954, 0.3185701370239258, 0.31718865036964417, 0.3144357204437256, 0.3123507499694824, 0.31368905305862427, 0.3095790147781372, 0.30855080485343933, 0.30289971828460693, 0.3066502511501312, 0.3016248047351837], 'val_accuracy': [0.671583354473114, 0.7598333358764648, 0.8119166493415833, 0.8399166464805603, 0.8476666808128357, 0.859000027179718, 0.8650000095367432, 0.8723333477973938, 0.8768333196640015, 0.8809166550636292, 0.8851666450500488, 0.8891666531562805, 0.8930833339691162, 0.8945000171661377, 0.8980000019073486, 0.8989999890327454, 0.903166651725769, 0.9035833477973938, 0.9068333506584167, 0.906166672706604, 0.9088333249092102, 0.9089999794960022, 0.9102500081062317, 0.9110833406448364, 0.9126666784286499, 0.9137499928474426, 0.9139166474342346, 0.9151666760444641, 0.9150000214576721, 0.9169166684150696, 0.9178333282470703, 0.9164166450500488, 0.9190000295639038, 0.9200000166893005, 0.9194999933242798, 0.9196666479110718, 0.9229166507720947, 0.9238333106040955, 0.9238333106040955, 0.9235833287239075, 0.9244166612625122, 0.9238333106040955, 0.925166666507721, 0.925166666507721, 0.9268333315849304, 0.9267500042915344, 0.9273333549499512, 0.9290833473205566, 0.9289166927337646, 0.9298333525657654]}\n",
            "{'loss': [2.3047902584075928, 2.3004117012023926, 2.2978405952453613, 2.2936861515045166, 2.2826907634735107, 2.237761974334717, 2.1332004070281982, 2.008803606033325, 1.8820897340774536, 1.759169578552246, 1.6447999477386475, 1.5419106483459473, 1.4511094093322754, 1.3751002550125122, 1.3110414743423462, 1.2511262893676758, 1.2064518928527832, 1.1657047271728516, 1.131944179534912, 1.0952560901641846, 1.072412371635437, 1.0436662435531616, 1.024261713027954, 0.9991419315338135, 0.9709635972976685, 0.953345775604248, 0.9318059682846069, 0.9124566912651062, 0.8900649547576904, 0.8713701963424683, 0.8552396893501282, 0.8425828218460083, 0.8163797855377197, 0.8029667139053345, 0.787850022315979, 0.7611268758773804, 0.7466751337051392, 0.7292233109474182, 0.7142560482025146, 0.7093936204910278, 0.6828221678733826, 0.666417121887207, 0.6527321934700012, 0.6453271508216858, 0.6266310811042786, 0.6114541292190552, 0.6138938665390015, 0.59459388256073, 0.590563952922821, 0.5708680152893066], 'accuracy': [0.11174999922513962, 0.12052083015441895, 0.12193749845027924, 0.12695834040641785, 0.13587500154972076, 0.16043749451637268, 0.2044374942779541, 0.24952083826065063, 0.29897916316986084, 0.3412083387374878, 0.382770836353302, 0.4182499945163727, 0.4515833258628845, 0.4777916669845581, 0.492020845413208, 0.5133958458900452, 0.5285208225250244, 0.5431458353996277, 0.5582916736602783, 0.5707708597183228, 0.5805000066757202, 0.5939375162124634, 0.6006666421890259, 0.6165416836738586, 0.6260208487510681, 0.6353333592414856, 0.6477708220481873, 0.6565208435058594, 0.668749988079071, 0.6821249723434448, 0.6919583082199097, 0.6988124847412109, 0.7120000123977661, 0.7213958501815796, 0.7277500033378601, 0.7426041960716248, 0.7516250014305115, 0.7593125104904175, 0.7664791941642761, 0.7753333449363708, 0.7804166674613953, 0.7867708206176758, 0.7942291498184204, 0.7983124852180481, 0.8059583306312561, 0.8118958473205566, 0.812416672706604, 0.8208541870117188, 0.8195208311080933, 0.8265625238418579], 'val_loss': [2.3008532524108887, 2.2990915775299072, 2.293835163116455, 2.280848979949951, 2.2463858127593994, 2.1275792121887207, 1.9535040855407715, 1.792026162147522, 1.6199856996536255, 1.4732598066329956, 1.3215217590332031, 1.1992846727371216, 1.0994582176208496, 1.0183709859848022, 0.960806131362915, 0.9129683971405029, 0.882297694683075, 0.8588029742240906, 0.8326253890991211, 0.8138654232025146, 0.7939770221710205, 0.7750344276428223, 0.7645674347877502, 0.7533304691314697, 0.7350573539733887, 0.7147781848907471, 0.7026669383049011, 0.6917119026184082, 0.6717278361320496, 0.6691402792930603, 0.6522261500358582, 0.6276058554649353, 0.6070266366004944, 0.5976279973983765, 0.5897564888000488, 0.5806114673614502, 0.5795615911483765, 0.5546166896820068, 0.5317155718803406, 0.5307175517082214, 0.5466464161872864, 0.5216345191001892, 0.5213207006454468, 0.5107306838035583, 0.5054380297660828, 0.47774556279182434, 0.47055113315582275, 0.4821966886520386, 0.49963465332984924, 0.4865231215953827], 'val_accuracy': [0.10691666603088379, 0.10599999874830246, 0.10599999874830246, 0.1107499971985817, 0.1992499977350235, 0.2342499941587448, 0.3004166781902313, 0.41741666197776794, 0.4436666667461395, 0.4611666798591614, 0.5039166808128357, 0.550000011920929, 0.5981666445732117, 0.6287500262260437, 0.6370833516120911, 0.6365833282470703, 0.6475833058357239, 0.6558333039283752, 0.6725000143051147, 0.6732500195503235, 0.6903333067893982, 0.6935833096504211, 0.7122499942779541, 0.731083333492279, 0.7331666946411133, 0.7472500205039978, 0.7542499899864197, 0.7846666574478149, 0.799833357334137, 0.8098333477973938, 0.8147500157356262, 0.8273333311080933, 0.8223333358764648, 0.8525000214576721, 0.8522499799728394, 0.8671666383743286, 0.8689166903495789, 0.8820000290870667, 0.8803333044052124, 0.8857499957084656, 0.887416660785675, 0.890250027179718, 0.8934166431427002, 0.8889999985694885, 0.8981666564941406, 0.9020833373069763, 0.9019166827201843, 0.9045833349227905, 0.9081666469573975, 0.9120833277702332]}\n",
            "{'loss': [2.3015310764312744, 2.2904584407806396, 2.255110740661621, 2.1451470851898193, 1.96940279006958, 1.7895011901855469, 1.6238692998886108, 1.4915677309036255, 1.3819563388824463, 1.2693759202957153, 1.161110281944275, 1.0770407915115356, 0.9942290782928467, 0.9209864735603333, 0.8572009801864624, 0.7969707250595093, 0.752994954586029, 0.723087728023529, 0.6779769659042358, 0.6510389447212219, 0.6255626678466797, 0.6020572781562805, 0.5764209628105164, 0.5590643286705017, 0.5407463908195496, 0.5211471915245056, 0.5001078844070435, 0.48109856247901917, 0.46646973490715027, 0.45471814274787903, 0.44725504517555237, 0.4250137507915497, 0.4165598154067993, 0.4054447412490845, 0.39369815587997437, 0.3833193778991699, 0.3764817416667938, 0.3642165958881378, 0.3594662547111511, 0.355978786945343, 0.3380696475505829, 0.32868584990501404, 0.32133007049560547, 0.31397905945777893, 0.30574506521224976, 0.30432459712028503, 0.29477351903915405, 0.2873169481754303, 0.2849442660808563, 0.2749021351337433], 'accuracy': [0.11245833337306976, 0.13862499594688416, 0.16366666555404663, 0.218791663646698, 0.28810417652130127, 0.35495832562446594, 0.4168750047683716, 0.48231250047683716, 0.5381875038146973, 0.5864166617393494, 0.6387708187103271, 0.6656666398048401, 0.6941041946411133, 0.7202500104904175, 0.7385208606719971, 0.7593125104904175, 0.7737500071525574, 0.7838749885559082, 0.796999990940094, 0.8066666722297668, 0.8153541684150696, 0.8223958611488342, 0.8300208449363708, 0.8384166955947876, 0.8434374928474426, 0.8489375114440918, 0.8539166450500488, 0.8601666688919067, 0.8659583330154419, 0.8706041574478149, 0.8723958134651184, 0.8778125047683716, 0.8820208311080933, 0.8843333125114441, 0.8883333206176758, 0.8896250128746033, 0.8944583535194397, 0.8965833187103271, 0.898812472820282, 0.8996458053588867, 0.9048958420753479, 0.9068958163261414, 0.9112708568572998, 0.9119166731834412, 0.9140416383743286, 0.9157083630561829, 0.9172916412353516, 0.9208541512489319, 0.918624997138977, 0.9233333468437195], 'val_loss': [2.2952072620391846, 2.268327236175537, 2.1624536514282227, 1.9208030700683594, 1.6434681415557861, 1.4080735445022583, 1.2246243953704834, 1.090665578842163, 0.9653355479240417, 0.8375027775764465, 0.7328912615776062, 0.6452229619026184, 0.5733321905136108, 0.5173003077507019, 0.4716145694255829, 0.43656009435653687, 0.4113696813583374, 0.38550469279289246, 0.36632588505744934, 0.3529617190361023, 0.3360635042190552, 0.3238813877105713, 0.3118862509727478, 0.3028815984725952, 0.29106390476226807, 0.2862055003643036, 0.2825816571712494, 0.2706909477710724, 0.27199944853782654, 0.2616303563117981, 0.252857506275177, 0.2504598796367645, 0.2533760964870453, 0.24133211374282837, 0.2399616837501526, 0.24361079931259155, 0.23665355145931244, 0.23119193315505981, 0.23375345766544342, 0.2284185141324997, 0.23371420800685883, 0.22990958392620087, 0.22200247645378113, 0.2301996499300003, 0.22009839117527008, 0.22106389701366425, 0.22529996931552887, 0.2182483971118927, 0.2265332043170929, 0.2153092473745346], 'val_accuracy': [0.12033333629369736, 0.19550000131130219, 0.32475000619888306, 0.37583333253860474, 0.46875, 0.546500027179718, 0.6477500200271606, 0.7295833230018616, 0.7794166803359985, 0.8139166831970215, 0.8377500176429749, 0.856166660785675, 0.8690833449363708, 0.8761666417121887, 0.8849166631698608, 0.8919166922569275, 0.8963333368301392, 0.902999997138977, 0.9077500104904175, 0.9120833277702332, 0.9145833253860474, 0.9181666374206543, 0.921750009059906, 0.9227499961853027, 0.9262499809265137, 0.9272500276565552, 0.9266666769981384, 0.9323333501815796, 0.9318333268165588, 0.9349166750907898, 0.9360833168029785, 0.937166690826416, 0.9366666674613953, 0.9393333196640015, 0.9410833120346069, 0.9401666522026062, 0.9420833587646484, 0.9440833330154419, 0.9419166445732117, 0.9432500004768372, 0.9449999928474426, 0.9473333358764648, 0.9471666812896729, 0.9453333616256714, 0.9474999904632568, 0.950083315372467, 0.9502500295639038, 0.949833333492279, 0.9509999752044678, 0.9509999752044678]}\n",
            "{'loss': [1.9426666498184204, 1.4097843170166016, 1.1808525323867798, 1.0374549627304077, 0.947169840335846, 0.8886727094650269, 0.8372541666030884, 0.8020798563957214, 0.7738532423973083, 0.7490041255950928, 0.7225925922393799, 0.6982918977737427, 0.6863365769386292, 0.6593150496482849, 0.6432292461395264, 0.6313899755477905, 0.6229893565177917, 0.5997949242591858, 0.591284453868866, 0.5813490152359009, 0.5702929496765137, 0.5613677501678467, 0.5523062944412231, 0.5357957482337952, 0.5302725434303284, 0.5176257491111755, 0.5083987712860107, 0.5053492188453674, 0.4869878888130188, 0.47926244139671326, 0.47866150736808777, 0.46886157989501953, 0.4669325649738312, 0.4507555067539215, 0.4496671259403229, 0.4411560893058777, 0.4342395067214966, 0.4323677122592926, 0.4285876750946045, 0.4161083996295929, 0.41937699913978577, 0.41019177436828613, 0.40157756209373474, 0.3966011106967926, 0.39044731855392456, 0.3841402232646942, 0.3867197334766388, 0.3790736496448517, 0.3748153746128082, 0.3698391616344452], 'accuracy': [0.29739582538604736, 0.5064791440963745, 0.5948125123977661, 0.6504166722297668, 0.6894791722297668, 0.7146666646003723, 0.7371666431427002, 0.752958357334137, 0.7685208320617676, 0.7752708196640015, 0.788687527179718, 0.79666668176651, 0.8015833497047424, 0.8104791641235352, 0.8154791593551636, 0.82052081823349, 0.8263333439826965, 0.831458330154419, 0.835812509059906, 0.8396458625793457, 0.844041645526886, 0.8454166650772095, 0.8501874804496765, 0.8541874885559082, 0.8576666712760925, 0.8606458306312561, 0.864104151725769, 0.8644999861717224, 0.8708333373069763, 0.8737499713897705, 0.8737916946411133, 0.878041684627533, 0.8759999871253967, 0.8823541402816772, 0.8839583396911621, 0.8853124976158142, 0.8877916932106018, 0.8880416750907898, 0.8898333311080933, 0.8920000195503235, 0.8908541798591614, 0.8928541541099548, 0.8955416679382324, 0.8974166512489319, 0.8996458053588867, 0.9008749723434448, 0.8998958468437195, 0.9010208249092102, 0.9042291641235352, 0.9044791460037231], 'val_loss': [1.148176908493042, 0.7604339718818665, 0.5997713208198547, 0.5205512046813965, 0.4709053039550781, 0.43709054589271545, 0.41073209047317505, 0.3906514346599579, 0.37461674213409424, 0.3623700439929962, 0.3498995006084442, 0.3422486186027527, 0.3306896984577179, 0.327682763338089, 0.3179554343223572, 0.31194818019866943, 0.3080892562866211, 0.30262619256973267, 0.3033682405948639, 0.2949167788028717, 0.2883353531360626, 0.28982749581336975, 0.28361275792121887, 0.2803194522857666, 0.2748553454875946, 0.2715432047843933, 0.2719908654689789, 0.2701708674430847, 0.2625460922718048, 0.2613295614719391, 0.25870901346206665, 0.2571547031402588, 0.2566879987716675, 0.24897542595863342, 0.24609874188899994, 0.250274658203125, 0.2460831254720688, 0.2447376549243927, 0.2375529557466507, 0.2415405660867691, 0.23601995408535004, 0.23137521743774414, 0.23308975994586945, 0.2288035750389099, 0.22962427139282227, 0.22891756892204285, 0.2277592420578003, 0.22565922141075134, 0.22807130217552185, 0.22239424288272858], 'val_accuracy': [0.7148333191871643, 0.7987499833106995, 0.8353333473205566, 0.856083333492279, 0.8709166646003723, 0.8802499771118164, 0.8869166374206543, 0.8919166922569275, 0.8961666822433472, 0.8991666436195374, 0.9035833477973938, 0.9039166569709778, 0.9084166884422302, 0.9077500104904175, 0.9112499952316284, 0.9129166603088379, 0.9139999747276306, 0.9150833487510681, 0.9150000214576721, 0.9183333516120911, 0.9196666479110718, 0.9199166893959045, 0.9208333492279053, 0.92166668176651, 0.9240000247955322, 0.9247499704360962, 0.925083339214325, 0.9260833263397217, 0.9288333058357239, 0.9282500147819519, 0.9305833578109741, 0.9292500019073486, 0.9311666488647461, 0.9330000281333923, 0.9333333373069763, 0.9336666464805603, 0.9340833425521851, 0.9346666932106018, 0.9359999895095825, 0.9359166622161865, 0.937416672706604, 0.9385833144187927, 0.9389166831970215, 0.9390833377838135, 0.9384999871253967, 0.9398333430290222, 0.9397500157356262, 0.940666675567627, 0.940833330154419, 0.9412500262260437]}\n",
            "{'loss': [1.9079616069793701, 1.2312219142913818, 1.031944751739502, 0.9281952381134033, 0.8602206110954285, 0.8145371079444885, 0.776344895362854, 0.7403796315193176, 0.7233062386512756, 0.6937355995178223, 0.6724042296409607, 0.6543661952018738, 0.6335092186927795, 0.6206211447715759, 0.605915904045105, 0.589251697063446, 0.5816247463226318, 0.5683518648147583, 0.5557927489280701, 0.5445927381515503, 0.5275688767433167, 0.5188681483268738, 0.5115183591842651, 0.5077160000801086, 0.49996617436408997, 0.4831477403640747, 0.480439692735672, 0.4696246385574341, 0.46496057510375977, 0.4569494128227234, 0.4521082043647766, 0.4442320168018341, 0.44021549820899963, 0.43246081471443176, 0.42852839827537537, 0.4268857538700104, 0.41768595576286316, 0.4117991030216217, 0.414681613445282, 0.406891793012619, 0.3982415795326233, 0.39579692482948303, 0.39301562309265137, 0.38894951343536377, 0.3872981667518616, 0.37865591049194336, 0.37680864334106445, 0.37040501832962036, 0.37231385707855225, 0.3641766309738159], 'accuracy': [0.3737500011920929, 0.577750027179718, 0.6550416946411133, 0.7003750205039978, 0.7287708520889282, 0.7509791851043701, 0.7664166688919067, 0.7811041474342346, 0.7885624766349792, 0.801520824432373, 0.8089374899864197, 0.8172500133514404, 0.8241249918937683, 0.8281041383743286, 0.8346874713897705, 0.8414791822433472, 0.8430416584014893, 0.8479375243186951, 0.8514166474342346, 0.8542916774749756, 0.8589791655540466, 0.8634999990463257, 0.8644999861717224, 0.8665416836738586, 0.8688541650772095, 0.8735208511352539, 0.8747708201408386, 0.8771666884422302, 0.8801666498184204, 0.8803750276565552, 0.8842291831970215, 0.8842499852180481, 0.8843125104904175, 0.8887291550636292, 0.8884999752044678, 0.890500009059906, 0.8905624747276306, 0.8936041593551636, 0.8925625085830688, 0.8949166536331177, 0.8972291946411133, 0.8974999785423279, 0.898354172706604, 0.9003333449363708, 0.9007708430290222, 0.9037708044052124, 0.9025416374206543, 0.9052291512489319, 0.9039791822433472, 0.9052291512489319], 'val_loss': [0.6584081053733826, 0.5192471742630005, 0.4624015688896179, 0.42682063579559326, 0.40860122442245483, 0.39040684700012207, 0.37775784730911255, 0.36582258343696594, 0.3562089800834656, 0.34815698862075806, 0.3391832113265991, 0.33333250880241394, 0.3242020905017853, 0.3216905891895294, 0.314596951007843, 0.30901792645454407, 0.3045101463794708, 0.30048295855522156, 0.29824113845825195, 0.29433536529541016, 0.2911643385887146, 0.28575652837753296, 0.2824023365974426, 0.2787218391895294, 0.27250462770462036, 0.27282997965812683, 0.2709672749042511, 0.2642623782157898, 0.2644871473312378, 0.2621917426586151, 0.2624351382255554, 0.255738228559494, 0.2534155547618866, 0.2530650496482849, 0.25353917479515076, 0.25008365511894226, 0.24680429697036743, 0.24487505853176117, 0.24204374849796295, 0.24077866971492767, 0.24129807949066162, 0.2396238148212433, 0.24441516399383545, 0.24099387228488922, 0.23651015758514404, 0.2322671115398407, 0.23081731796264648, 0.23065464198589325, 0.23244045674800873, 0.22950270771980286], 'val_accuracy': [0.8168333172798157, 0.856166660785675, 0.8680833578109741, 0.8786666393280029, 0.8858333230018616, 0.8896666765213013, 0.893666684627533, 0.8967499732971191, 0.8981666564941406, 0.9023333191871643, 0.9044166803359985, 0.9050833582878113, 0.9103333353996277, 0.9104999899864197, 0.9125833511352539, 0.9142500162124634, 0.9157500267028809, 0.9169999957084656, 0.9160833358764648, 0.9190833568572998, 0.92166668176651, 0.921583354473114, 0.9229166507720947, 0.9235000014305115, 0.9252499938011169, 0.9268333315849304, 0.9267500042915344, 0.9289166927337646, 0.9300833344459534, 0.9292500019073486, 0.9303333163261414, 0.9321666955947876, 0.9327499866485596, 0.9336666464805603, 0.9336666464805603, 0.9350833296775818, 0.9357500076293945, 0.9346666932106018, 0.9363333582878113, 0.937250018119812, 0.937333345413208, 0.9370833039283752, 0.937250018119812, 0.9382500052452087, 0.9403333067893982, 0.940583348274231, 0.9415000081062317, 0.9420833587646484, 0.9427499771118164, 0.9430833458900452]}\n",
            "{'loss': [2.302152395248413, 2.3012444972991943, 2.300809144973755, 2.3004281520843506, 2.3000500202178955, 2.299746036529541, 2.299304962158203, 2.298907995223999, 2.29844069480896, 2.2979071140289307, 2.2970993518829346, 2.296123743057251, 2.294581890106201, 2.2922887802124023, 2.2876341342926025, 2.2763423919677734, 2.2431750297546387, 2.173675537109375, 2.097288131713867, 2.0280702114105225, 1.964266300201416, 1.9054430723190308, 1.852532982826233, 1.8101128339767456, 1.7700550556182861, 1.7289236783981323, 1.691740870475769, 1.657423496246338, 1.6196051836013794, 1.580723762512207, 1.5463865995407104, 1.5130295753479004, 1.4824886322021484, 1.4534261226654053, 1.4153562784194946, 1.3800395727157593, 1.3308614492416382, 1.293797492980957, 1.2399495840072632, 1.1997069120407104, 1.1623859405517578, 1.1240912675857544, 1.0853787660598755, 1.0475826263427734, 1.0029616355895996, 0.9686504602432251, 0.9372092485427856, 0.9032500982284546, 0.8791138529777527, 0.8507900238037109], 'accuracy': [0.1146249994635582, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11395833641290665, 0.11397916823625565, 0.11397916823625565, 0.11395833641290665, 0.11395833641290665, 0.11410416662693024, 0.11406250298023224, 0.11539583653211594, 0.11570833623409271, 0.12250000238418579, 0.13987499475479126, 0.16577082872390747, 0.1902083307504654, 0.19891667366027832, 0.2202291637659073, 0.25204166769981384, 0.2769583463668823, 0.3003750145435333, 0.32116666436195374, 0.33522915840148926, 0.35239583253860474, 0.359479159116745, 0.3713749945163727, 0.3816041648387909, 0.3894791603088379, 0.4021250009536743, 0.4074375033378601, 0.4207916557788849, 0.43041667342185974, 0.44212499260902405, 0.46160417795181274, 0.47695833444595337, 0.5050208568572998, 0.5247291922569275, 0.5527708530426025, 0.5733749866485596, 0.5943124890327454, 0.6188541650772095, 0.635729193687439, 0.6519374847412109, 0.6692708134651184, 0.6850416660308838, 0.6963958144187927, 0.7090833187103271, 0.7171249985694885, 0.7256041765213013], 'val_loss': [2.3020520210266113, 2.3017020225524902, 2.3013908863067627, 2.3011388778686523, 2.300861358642578, 2.3005118370056152, 2.3001439571380615, 2.299711227416992, 2.2992238998413086, 2.298557996749878, 2.29772686958313, 2.2965469360351562, 2.2947299480438232, 2.291585683822632, 2.2848081588745117, 2.2643377780914307, 2.1995983123779297, 2.0841119289398193, 1.9785655736923218, 1.8981894254684448, 1.8333326578140259, 1.77445650100708, 1.7306206226348877, 1.6874674558639526, 1.6479214429855347, 1.605570912361145, 1.5601890087127686, 1.5167758464813232, 1.4723256826400757, 1.4307341575622559, 1.3956881761550903, 1.35619056224823, 1.3165847063064575, 1.2807594537734985, 1.2360355854034424, 1.1789166927337646, 1.1108726263046265, 1.0552542209625244, 0.9968178868293762, 0.9546390771865845, 0.9023011326789856, 0.8589958548545837, 0.8116727471351624, 0.7684034705162048, 0.7245734333992004, 0.6886043548583984, 0.6498312950134277, 0.6199549436569214, 0.5988194346427917, 0.570973813533783], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10625000298023224, 0.14341667294502258, 0.22158333659172058, 0.2123333364725113, 0.22550000250339508, 0.25224998593330383, 0.28216665983200073, 0.31316667795181274, 0.3372499942779541, 0.3714166581630707, 0.3854166567325592, 0.40149998664855957, 0.4167500138282776, 0.4464166760444641, 0.45883333683013916, 0.4698333442211151, 0.4814999997615814, 0.492249995470047, 0.5047500133514404, 0.5339999794960022, 0.5515000224113464, 0.5900833606719971, 0.6416666507720947, 0.6700833439826965, 0.6863333582878113, 0.7096666693687439, 0.7399166822433472, 0.762583315372467, 0.7850833535194397, 0.8015833497047424, 0.8173333406448364, 0.8296666741371155, 0.843916654586792, 0.8493333458900452, 0.8628333210945129, 0.8704166412353516, 0.8774999976158142]}\n",
            "{'loss': [2.301936388015747, 2.3009963035583496, 2.3005619049072266, 2.300051212310791, 2.2997443675994873, 2.299326181411743, 2.2989799976348877, 2.298651933670044, 2.2981021404266357, 2.2974722385406494, 2.296860694885254, 2.295950174331665, 2.294874906539917, 2.2932682037353516, 2.290400505065918, 2.285144805908203, 2.265749454498291, 2.192117929458618, 2.1229658126831055, 2.082261562347412, 2.0474445819854736, 2.0027284622192383, 1.9521757364273071, 1.9023069143295288, 1.8483983278274536, 1.7783862352371216, 1.684037446975708, 1.5923516750335693, 1.5274916887283325, 1.4699915647506714, 1.4347525835037231, 1.4015147686004639, 1.375477910041809, 1.344437599182129, 1.325716257095337, 1.3038884401321411, 1.2821120023727417, 1.2549996376037598, 1.2304224967956543, 1.194080114364624, 1.1569812297821045, 1.1273932456970215, 1.0975860357284546, 1.0685383081436157, 1.040668249130249, 1.0171374082565308, 0.9993303418159485, 0.9781333804130554, 0.9547587037086487, 0.9353631734848022], 'accuracy': [0.1145416647195816, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11397916823625565, 0.11412499845027924, 0.11404166370630264, 0.11485416442155838, 0.117145836353302, 0.12127083539962769, 0.13612499833106995, 0.16114583611488342, 0.19997917115688324, 0.2163124978542328, 0.21435417234897614, 0.2226666659116745, 0.24497917294502258, 0.265583336353302, 0.2841250002384186, 0.30412501096725464, 0.3232916593551636, 0.3473333418369293, 0.37704166769981384, 0.40056249499320984, 0.42012500762939453, 0.43531250953674316, 0.445291668176651, 0.4569999873638153, 0.46418750286102295, 0.47856250405311584, 0.48774999380111694, 0.49791666865348816, 0.508104145526886, 0.5195624828338623, 0.5378958582878113, 0.5522083044052124, 0.5712083578109741, 0.5849791765213013, 0.5978749990463257, 0.6135208606719971, 0.6270624995231628, 0.6389999985694885, 0.6480208039283752, 0.6590833067893982, 0.6681249737739563, 0.6762708425521851], 'val_loss': [2.301738977432251, 2.3013556003570557, 2.301058053970337, 2.3008060455322266, 2.3004512786865234, 2.3001153469085693, 2.2996926307678223, 2.299262285232544, 2.2987303733825684, 2.2981579303741455, 2.2974069118499756, 2.29636812210083, 2.295053243637085, 2.29304575920105, 2.289449453353882, 2.2811222076416016, 2.2308294773101807, 2.1133906841278076, 2.0589370727539062, 2.018786668777466, 1.9785802364349365, 1.9160226583480835, 1.8455361127853394, 1.7842504978179932, 1.721200704574585, 1.6049336194992065, 1.471151351928711, 1.3788999319076538, 1.3185245990753174, 1.2690383195877075, 1.2344894409179688, 1.2090548276901245, 1.185336709022522, 1.1607948541641235, 1.140560269355774, 1.1201287508010864, 1.0893057584762573, 1.0581475496292114, 1.0186289548873901, 0.968422532081604, 0.9181188344955444, 0.8795152902603149, 0.8393977880477905, 0.8082900643348694, 0.775082528591156, 0.7459658980369568, 0.7190240621566772, 0.6940639615058899, 0.671152651309967, 0.6503267288208008], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10841666907072067, 0.13958333432674408, 0.1902499943971634, 0.2084166705608368, 0.21808333694934845, 0.2224999964237213, 0.2384166717529297, 0.25741666555404663, 0.2850833237171173, 0.3160833418369293, 0.3490833342075348, 0.37400001287460327, 0.40158334374427795, 0.4429999887943268, 0.4794166684150696, 0.5095833539962769, 0.5354999899864197, 0.5354999899864197, 0.5337499976158142, 0.562833309173584, 0.565750002861023, 0.5799166560173035, 0.5899999737739563, 0.6131666898727417, 0.6262500286102295, 0.6428333520889282, 0.6610833406448364, 0.6861666440963745, 0.7059166431427002, 0.7305833101272583, 0.7443333268165588, 0.7580833435058594, 0.7665833234786987, 0.7836666703224182, 0.7890833616256714, 0.8035833239555359, 0.809416651725769]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}