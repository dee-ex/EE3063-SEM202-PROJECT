{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "aea94b5d-f94c-41c5-982c-13909251d1b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 17s 7ms/step - loss: 2.1656 - accuracy: 0.2075 - val_loss: 1.3121 - val_accuracy: 0.6198\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6195 - accuracy: 0.4402 - val_loss: 1.0045 - val_accuracy: 0.7421\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3828 - accuracy: 0.5292 - val_loss: 0.8459 - val_accuracy: 0.7920\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2492 - accuracy: 0.5818 - val_loss: 0.7418 - val_accuracy: 0.8123\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1402 - accuracy: 0.6225 - val_loss: 0.6779 - val_accuracy: 0.8243\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0750 - accuracy: 0.6513 - val_loss: 0.6303 - val_accuracy: 0.8366\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0188 - accuracy: 0.6741 - val_loss: 0.5936 - val_accuracy: 0.8457\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9712 - accuracy: 0.6906 - val_loss: 0.5636 - val_accuracy: 0.8530\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9354 - accuracy: 0.7074 - val_loss: 0.5415 - val_accuracy: 0.8607\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9148 - accuracy: 0.7142 - val_loss: 0.5167 - val_accuracy: 0.8655\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8816 - accuracy: 0.7297 - val_loss: 0.4987 - val_accuracy: 0.8689\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8579 - accuracy: 0.7436 - val_loss: 0.4802 - val_accuracy: 0.8735\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8218 - accuracy: 0.7569 - val_loss: 0.4665 - val_accuracy: 0.8777\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8049 - accuracy: 0.7637 - val_loss: 0.4567 - val_accuracy: 0.8802\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7881 - accuracy: 0.7738 - val_loss: 0.4401 - val_accuracy: 0.8858\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7707 - accuracy: 0.7842 - val_loss: 0.4278 - val_accuracy: 0.8868\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7431 - accuracy: 0.7947 - val_loss: 0.4164 - val_accuracy: 0.8906\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7276 - accuracy: 0.8014 - val_loss: 0.4134 - val_accuracy: 0.8938\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7119 - accuracy: 0.8047 - val_loss: 0.3977 - val_accuracy: 0.8972\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7041 - accuracy: 0.8119 - val_loss: 0.4003 - val_accuracy: 0.8975\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6783 - accuracy: 0.8206 - val_loss: 0.3909 - val_accuracy: 0.8983\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6757 - accuracy: 0.8181 - val_loss: 0.3806 - val_accuracy: 0.9024\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6666 - accuracy: 0.8244 - val_loss: 0.3815 - val_accuracy: 0.9028\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6386 - accuracy: 0.8279 - val_loss: 0.3780 - val_accuracy: 0.9050\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6321 - accuracy: 0.8362 - val_loss: 0.3693 - val_accuracy: 0.9068\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6304 - accuracy: 0.8377 - val_loss: 0.3680 - val_accuracy: 0.9064\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6128 - accuracy: 0.8427 - val_loss: 0.3642 - val_accuracy: 0.9100\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6102 - accuracy: 0.8445 - val_loss: 0.3602 - val_accuracy: 0.9102\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5894 - accuracy: 0.8495 - val_loss: 0.3574 - val_accuracy: 0.9111\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5868 - accuracy: 0.8493 - val_loss: 0.3577 - val_accuracy: 0.9126\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5729 - accuracy: 0.8568 - val_loss: 0.3513 - val_accuracy: 0.9147\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5797 - accuracy: 0.8559 - val_loss: 0.3556 - val_accuracy: 0.9138\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5716 - accuracy: 0.8575 - val_loss: 0.3513 - val_accuracy: 0.9125\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5509 - accuracy: 0.8599 - val_loss: 0.3493 - val_accuracy: 0.9158\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5600 - accuracy: 0.8619 - val_loss: 0.3465 - val_accuracy: 0.9155\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5524 - accuracy: 0.8631 - val_loss: 0.3453 - val_accuracy: 0.9159\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5362 - accuracy: 0.8679 - val_loss: 0.3415 - val_accuracy: 0.9180\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5406 - accuracy: 0.8653 - val_loss: 0.3378 - val_accuracy: 0.9202\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5275 - accuracy: 0.8688 - val_loss: 0.3432 - val_accuracy: 0.9185\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5283 - accuracy: 0.8704 - val_loss: 0.3353 - val_accuracy: 0.9200\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5157 - accuracy: 0.8730 - val_loss: 0.3331 - val_accuracy: 0.9222\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5024 - accuracy: 0.8785 - val_loss: 0.3296 - val_accuracy: 0.9218\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5014 - accuracy: 0.8799 - val_loss: 0.3249 - val_accuracy: 0.9222\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5045 - accuracy: 0.8761 - val_loss: 0.3191 - val_accuracy: 0.9238\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5011 - accuracy: 0.8802 - val_loss: 0.3231 - val_accuracy: 0.9235\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4983 - accuracy: 0.8797 - val_loss: 0.3195 - val_accuracy: 0.9248\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4914 - accuracy: 0.8814 - val_loss: 0.3186 - val_accuracy: 0.9249\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4857 - accuracy: 0.8834 - val_loss: 0.3208 - val_accuracy: 0.9249\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4803 - accuracy: 0.8851 - val_loss: 0.3135 - val_accuracy: 0.9263\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4772 - accuracy: 0.8854 - val_loss: 0.3132 - val_accuracy: 0.9274\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.3045 - accuracy: 0.1071 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3022 - accuracy: 0.1166 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1147 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2996 - accuracy: 0.1152 - val_loss: 2.2992 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2983 - accuracy: 0.1151 - val_loss: 2.2957 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2954 - accuracy: 0.1158 - val_loss: 2.2888 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2912 - accuracy: 0.1147 - val_loss: 2.2710 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2772 - accuracy: 0.1182 - val_loss: 2.2058 - val_accuracy: 0.2522\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2213 - accuracy: 0.1699 - val_loss: 2.0862 - val_accuracy: 0.2091\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1430 - accuracy: 0.1989 - val_loss: 2.0172 - val_accuracy: 0.2321\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0802 - accuracy: 0.2125 - val_loss: 1.9479 - val_accuracy: 0.2841\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0142 - accuracy: 0.2434 - val_loss: 1.8609 - val_accuracy: 0.3758\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9371 - accuracy: 0.2853 - val_loss: 1.7562 - val_accuracy: 0.4165\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8576 - accuracy: 0.3190 - val_loss: 1.6664 - val_accuracy: 0.4433\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7803 - accuracy: 0.3432 - val_loss: 1.5960 - val_accuracy: 0.4769\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7066 - accuracy: 0.3680 - val_loss: 1.5085 - val_accuracy: 0.5041\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6467 - accuracy: 0.3923 - val_loss: 1.4360 - val_accuracy: 0.5325\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5801 - accuracy: 0.4124 - val_loss: 1.3630 - val_accuracy: 0.5603\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5385 - accuracy: 0.4208 - val_loss: 1.2964 - val_accuracy: 0.5773\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4714 - accuracy: 0.4429 - val_loss: 1.2499 - val_accuracy: 0.5886\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4364 - accuracy: 0.4586 - val_loss: 1.2053 - val_accuracy: 0.5962\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3841 - accuracy: 0.4734 - val_loss: 1.1614 - val_accuracy: 0.6099\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3501 - accuracy: 0.4846 - val_loss: 1.1260 - val_accuracy: 0.6212\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3067 - accuracy: 0.4960 - val_loss: 1.0871 - val_accuracy: 0.6350\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2674 - accuracy: 0.5150 - val_loss: 1.0452 - val_accuracy: 0.6424\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2468 - accuracy: 0.5277 - val_loss: 0.9992 - val_accuracy: 0.6641\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2192 - accuracy: 0.5393 - val_loss: 0.9834 - val_accuracy: 0.6663\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1810 - accuracy: 0.5557 - val_loss: 0.9623 - val_accuracy: 0.6761\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1535 - accuracy: 0.5704 - val_loss: 0.9215 - val_accuracy: 0.6992\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1400 - accuracy: 0.5833 - val_loss: 0.9015 - val_accuracy: 0.7175\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1113 - accuracy: 0.5912 - val_loss: 0.8804 - val_accuracy: 0.7366\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0740 - accuracy: 0.6108 - val_loss: 0.8621 - val_accuracy: 0.7566\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0494 - accuracy: 0.6184 - val_loss: 0.8581 - val_accuracy: 0.7468\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0383 - accuracy: 0.6290 - val_loss: 0.8232 - val_accuracy: 0.7836\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0004 - accuracy: 0.6410 - val_loss: 0.7990 - val_accuracy: 0.7851\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9951 - accuracy: 0.6383 - val_loss: 0.7884 - val_accuracy: 0.7905\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9654 - accuracy: 0.6500 - val_loss: 0.7684 - val_accuracy: 0.7893\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9374 - accuracy: 0.6658 - val_loss: 0.7524 - val_accuracy: 0.7984\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9279 - accuracy: 0.6676 - val_loss: 0.7437 - val_accuracy: 0.7944\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9072 - accuracy: 0.6731 - val_loss: 0.7089 - val_accuracy: 0.8108\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8837 - accuracy: 0.6813 - val_loss: 0.7066 - val_accuracy: 0.8098\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8631 - accuracy: 0.6967 - val_loss: 0.6893 - val_accuracy: 0.8212\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8471 - accuracy: 0.7019 - val_loss: 0.6584 - val_accuracy: 0.8476\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8282 - accuracy: 0.7106 - val_loss: 0.6534 - val_accuracy: 0.8489\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8113 - accuracy: 0.7184 - val_loss: 0.6261 - val_accuracy: 0.8564\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7895 - accuracy: 0.7240 - val_loss: 0.6148 - val_accuracy: 0.8700\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7732 - accuracy: 0.7331 - val_loss: 0.6017 - val_accuracy: 0.8777\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7570 - accuracy: 0.7398 - val_loss: 0.5964 - val_accuracy: 0.8449\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7401 - accuracy: 0.7420 - val_loss: 0.5856 - val_accuracy: 0.8659\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.3062 - accuracy: 0.1058 - val_loss: 2.2991 - val_accuracy: 0.1062\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2974 - accuracy: 0.1331 - val_loss: 2.2816 - val_accuracy: 0.1662\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2762 - accuracy: 0.1526 - val_loss: 2.1570 - val_accuracy: 0.1968\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1646 - accuracy: 0.2005 - val_loss: 1.9557 - val_accuracy: 0.2936\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0335 - accuracy: 0.2234 - val_loss: 1.8574 - val_accuracy: 0.3092\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9517 - accuracy: 0.2310 - val_loss: 1.7803 - val_accuracy: 0.3192\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8776 - accuracy: 0.2613 - val_loss: 1.6293 - val_accuracy: 0.3337\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7557 - accuracy: 0.3094 - val_loss: 1.4622 - val_accuracy: 0.4026\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6427 - accuracy: 0.3548 - val_loss: 1.3258 - val_accuracy: 0.5112\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5295 - accuracy: 0.4081 - val_loss: 1.1790 - val_accuracy: 0.5328\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4171 - accuracy: 0.4570 - val_loss: 1.0696 - val_accuracy: 0.5883\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3192 - accuracy: 0.5025 - val_loss: 0.9773 - val_accuracy: 0.6492\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2314 - accuracy: 0.5372 - val_loss: 0.8812 - val_accuracy: 0.7232\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1425 - accuracy: 0.5785 - val_loss: 0.8039 - val_accuracy: 0.7432\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0687 - accuracy: 0.6170 - val_loss: 0.7483 - val_accuracy: 0.7579\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0223 - accuracy: 0.6338 - val_loss: 0.7076 - val_accuracy: 0.7393\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9583 - accuracy: 0.6557 - val_loss: 0.6673 - val_accuracy: 0.7856\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9172 - accuracy: 0.6770 - val_loss: 0.6394 - val_accuracy: 0.7764\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8803 - accuracy: 0.6896 - val_loss: 0.6099 - val_accuracy: 0.8165\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8495 - accuracy: 0.7053 - val_loss: 0.5790 - val_accuracy: 0.8414\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8183 - accuracy: 0.7279 - val_loss: 0.5597 - val_accuracy: 0.8277\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7870 - accuracy: 0.7365 - val_loss: 0.5290 - val_accuracy: 0.8493\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7565 - accuracy: 0.7550 - val_loss: 0.5054 - val_accuracy: 0.8658\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7230 - accuracy: 0.7662 - val_loss: 0.4855 - val_accuracy: 0.8796\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6990 - accuracy: 0.7795 - val_loss: 0.4648 - val_accuracy: 0.8894\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6727 - accuracy: 0.7891 - val_loss: 0.4511 - val_accuracy: 0.8970\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6551 - accuracy: 0.7999 - val_loss: 0.4384 - val_accuracy: 0.9034\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6327 - accuracy: 0.8063 - val_loss: 0.4261 - val_accuracy: 0.9087\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6147 - accuracy: 0.8189 - val_loss: 0.4175 - val_accuracy: 0.9105\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5978 - accuracy: 0.8252 - val_loss: 0.3993 - val_accuracy: 0.9149\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5768 - accuracy: 0.8330 - val_loss: 0.3957 - val_accuracy: 0.9130\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5505 - accuracy: 0.8413 - val_loss: 0.3916 - val_accuracy: 0.9167\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5487 - accuracy: 0.8462 - val_loss: 0.3842 - val_accuracy: 0.9204\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5192 - accuracy: 0.8537 - val_loss: 0.3700 - val_accuracy: 0.9219\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5207 - accuracy: 0.8532 - val_loss: 0.3739 - val_accuracy: 0.9223\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4943 - accuracy: 0.8603 - val_loss: 0.3733 - val_accuracy: 0.9236\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4731 - accuracy: 0.8661 - val_loss: 0.3643 - val_accuracy: 0.9265\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4667 - accuracy: 0.8704 - val_loss: 0.3579 - val_accuracy: 0.9270\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4469 - accuracy: 0.8742 - val_loss: 0.3602 - val_accuracy: 0.9277\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4391 - accuracy: 0.8779 - val_loss: 0.3506 - val_accuracy: 0.9307\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4341 - accuracy: 0.8814 - val_loss: 0.3554 - val_accuracy: 0.9293\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4318 - accuracy: 0.8826 - val_loss: 0.3491 - val_accuracy: 0.9309\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4212 - accuracy: 0.8843 - val_loss: 0.3472 - val_accuracy: 0.9325\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4108 - accuracy: 0.8886 - val_loss: 0.3533 - val_accuracy: 0.9322\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3868 - accuracy: 0.8956 - val_loss: 0.3498 - val_accuracy: 0.9343\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3738 - accuracy: 0.8991 - val_loss: 0.3441 - val_accuracy: 0.9355\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3720 - accuracy: 0.8973 - val_loss: 0.3579 - val_accuracy: 0.9355\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3606 - accuracy: 0.9020 - val_loss: 0.3372 - val_accuracy: 0.9366\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3660 - accuracy: 0.8992 - val_loss: 0.3412 - val_accuracy: 0.9382\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3581 - accuracy: 0.9048 - val_loss: 0.3420 - val_accuracy: 0.9401\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.1560 - accuracy: 0.2202 - val_loss: 1.1940 - val_accuracy: 0.6105\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5443 - accuracy: 0.4487 - val_loss: 0.8263 - val_accuracy: 0.7730\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2801 - accuracy: 0.5463 - val_loss: 0.6787 - val_accuracy: 0.8166\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1347 - accuracy: 0.6056 - val_loss: 0.6034 - val_accuracy: 0.8433\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0437 - accuracy: 0.6484 - val_loss: 0.5404 - val_accuracy: 0.8576\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9842 - accuracy: 0.6790 - val_loss: 0.4988 - val_accuracy: 0.8624\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9285 - accuracy: 0.6974 - val_loss: 0.4645 - val_accuracy: 0.8739\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8699 - accuracy: 0.7202 - val_loss: 0.4471 - val_accuracy: 0.8780\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8467 - accuracy: 0.7356 - val_loss: 0.4264 - val_accuracy: 0.8838\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8287 - accuracy: 0.7415 - val_loss: 0.4127 - val_accuracy: 0.8892\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7982 - accuracy: 0.7534 - val_loss: 0.3998 - val_accuracy: 0.8903\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7581 - accuracy: 0.7720 - val_loss: 0.3881 - val_accuracy: 0.8942\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7514 - accuracy: 0.7711 - val_loss: 0.3836 - val_accuracy: 0.8978\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7313 - accuracy: 0.7809 - val_loss: 0.3722 - val_accuracy: 0.9000\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7202 - accuracy: 0.7860 - val_loss: 0.3632 - val_accuracy: 0.9016\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.7979 - val_loss: 0.3514 - val_accuracy: 0.9050\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6762 - accuracy: 0.8035 - val_loss: 0.3500 - val_accuracy: 0.9058\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6571 - accuracy: 0.8096 - val_loss: 0.3413 - val_accuracy: 0.9079\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6470 - accuracy: 0.8168 - val_loss: 0.3361 - val_accuracy: 0.9085\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6259 - accuracy: 0.8245 - val_loss: 0.3293 - val_accuracy: 0.9115\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6113 - accuracy: 0.8271 - val_loss: 0.3208 - val_accuracy: 0.9138\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6100 - accuracy: 0.8303 - val_loss: 0.3138 - val_accuracy: 0.9158\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5923 - accuracy: 0.8331 - val_loss: 0.3066 - val_accuracy: 0.9175\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5767 - accuracy: 0.8406 - val_loss: 0.3067 - val_accuracy: 0.9158\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5757 - accuracy: 0.8385 - val_loss: 0.2972 - val_accuracy: 0.9196\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5537 - accuracy: 0.8492 - val_loss: 0.3011 - val_accuracy: 0.9173\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5468 - accuracy: 0.8499 - val_loss: 0.2894 - val_accuracy: 0.9217\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5309 - accuracy: 0.8540 - val_loss: 0.2840 - val_accuracy: 0.9236\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5245 - accuracy: 0.8589 - val_loss: 0.2837 - val_accuracy: 0.9220\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5306 - accuracy: 0.8536 - val_loss: 0.2824 - val_accuracy: 0.9251\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5123 - accuracy: 0.8647 - val_loss: 0.2756 - val_accuracy: 0.9253\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5106 - accuracy: 0.8629 - val_loss: 0.2721 - val_accuracy: 0.9269\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4999 - accuracy: 0.8657 - val_loss: 0.2717 - val_accuracy: 0.9268\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4882 - accuracy: 0.8718 - val_loss: 0.2676 - val_accuracy: 0.9293\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4868 - accuracy: 0.8721 - val_loss: 0.2634 - val_accuracy: 0.9292\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4760 - accuracy: 0.8744 - val_loss: 0.2653 - val_accuracy: 0.9291\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4680 - accuracy: 0.8762 - val_loss: 0.2610 - val_accuracy: 0.9299\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4652 - accuracy: 0.8767 - val_loss: 0.2565 - val_accuracy: 0.9317\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4486 - accuracy: 0.8820 - val_loss: 0.2516 - val_accuracy: 0.9340\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4593 - accuracy: 0.8783 - val_loss: 0.2510 - val_accuracy: 0.9342\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4399 - accuracy: 0.8867 - val_loss: 0.2453 - val_accuracy: 0.9344\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4431 - accuracy: 0.8865 - val_loss: 0.2438 - val_accuracy: 0.9378\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4391 - accuracy: 0.8860 - val_loss: 0.2427 - val_accuracy: 0.9377\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4210 - accuracy: 0.8909 - val_loss: 0.2371 - val_accuracy: 0.9383\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4191 - accuracy: 0.8944 - val_loss: 0.2435 - val_accuracy: 0.9373\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4204 - accuracy: 0.8913 - val_loss: 0.2409 - val_accuracy: 0.9379\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4164 - accuracy: 0.8936 - val_loss: 0.2364 - val_accuracy: 0.9388\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3980 - accuracy: 0.8972 - val_loss: 0.2341 - val_accuracy: 0.9402\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3989 - accuracy: 0.8969 - val_loss: 0.2292 - val_accuracy: 0.9413\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3931 - accuracy: 0.8999 - val_loss: 0.2352 - val_accuracy: 0.9399\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.5747 - accuracy: 0.2416 - val_loss: 0.7316 - val_accuracy: 0.7954\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3828 - accuracy: 0.5144 - val_loss: 0.6026 - val_accuracy: 0.8313\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1426 - accuracy: 0.6097 - val_loss: 0.5344 - val_accuracy: 0.8511\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0341 - accuracy: 0.6545 - val_loss: 0.4986 - val_accuracy: 0.8592\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9459 - accuracy: 0.6926 - val_loss: 0.4656 - val_accuracy: 0.8707\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8856 - accuracy: 0.7190 - val_loss: 0.4421 - val_accuracy: 0.8743\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8507 - accuracy: 0.7319 - val_loss: 0.4234 - val_accuracy: 0.8851\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7997 - accuracy: 0.7545 - val_loss: 0.4084 - val_accuracy: 0.8891\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7787 - accuracy: 0.7643 - val_loss: 0.3927 - val_accuracy: 0.8918\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7462 - accuracy: 0.7793 - val_loss: 0.3841 - val_accuracy: 0.8985\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7322 - accuracy: 0.7870 - val_loss: 0.3734 - val_accuracy: 0.8988\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7295 - accuracy: 0.7900 - val_loss: 0.3681 - val_accuracy: 0.9012\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6875 - accuracy: 0.8056 - val_loss: 0.3639 - val_accuracy: 0.9025\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6737 - accuracy: 0.8108 - val_loss: 0.3536 - val_accuracy: 0.9072\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6490 - accuracy: 0.8178 - val_loss: 0.3475 - val_accuracy: 0.9089\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6405 - accuracy: 0.8246 - val_loss: 0.3383 - val_accuracy: 0.9107\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6275 - accuracy: 0.8294 - val_loss: 0.3347 - val_accuracy: 0.9124\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6123 - accuracy: 0.8358 - val_loss: 0.3249 - val_accuracy: 0.9133\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5990 - accuracy: 0.8415 - val_loss: 0.3224 - val_accuracy: 0.9153\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5916 - accuracy: 0.8448 - val_loss: 0.3218 - val_accuracy: 0.9158\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5695 - accuracy: 0.8478 - val_loss: 0.3168 - val_accuracy: 0.9175\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5669 - accuracy: 0.8504 - val_loss: 0.3115 - val_accuracy: 0.9203\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5486 - accuracy: 0.8543 - val_loss: 0.3042 - val_accuracy: 0.9218\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5394 - accuracy: 0.8595 - val_loss: 0.3032 - val_accuracy: 0.9224\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5387 - accuracy: 0.8618 - val_loss: 0.2999 - val_accuracy: 0.9237\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5259 - accuracy: 0.8617 - val_loss: 0.2984 - val_accuracy: 0.9248\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5085 - accuracy: 0.8675 - val_loss: 0.2923 - val_accuracy: 0.9264\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5106 - accuracy: 0.8662 - val_loss: 0.2871 - val_accuracy: 0.9277\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4994 - accuracy: 0.8736 - val_loss: 0.2884 - val_accuracy: 0.9293\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4867 - accuracy: 0.8731 - val_loss: 0.2817 - val_accuracy: 0.9291\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4835 - accuracy: 0.8724 - val_loss: 0.2815 - val_accuracy: 0.9302\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4733 - accuracy: 0.8779 - val_loss: 0.2783 - val_accuracy: 0.9309\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4763 - accuracy: 0.8789 - val_loss: 0.2810 - val_accuracy: 0.9303\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4649 - accuracy: 0.8807 - val_loss: 0.2735 - val_accuracy: 0.9329\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4539 - accuracy: 0.8821 - val_loss: 0.2765 - val_accuracy: 0.9323\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4311 - accuracy: 0.8886 - val_loss: 0.2753 - val_accuracy: 0.9336\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4405 - accuracy: 0.8864 - val_loss: 0.2667 - val_accuracy: 0.9348\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4403 - accuracy: 0.8864 - val_loss: 0.2665 - val_accuracy: 0.9342\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4379 - accuracy: 0.8890 - val_loss: 0.2644 - val_accuracy: 0.9338\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4305 - accuracy: 0.8890 - val_loss: 0.2642 - val_accuracy: 0.9356\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4259 - accuracy: 0.8926 - val_loss: 0.2611 - val_accuracy: 0.9361\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4182 - accuracy: 0.8927 - val_loss: 0.2565 - val_accuracy: 0.9367\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4173 - accuracy: 0.8962 - val_loss: 0.2619 - val_accuracy: 0.9350\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4099 - accuracy: 0.8941 - val_loss: 0.2586 - val_accuracy: 0.9377\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4096 - accuracy: 0.8967 - val_loss: 0.2546 - val_accuracy: 0.9369\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4072 - accuracy: 0.8949 - val_loss: 0.2519 - val_accuracy: 0.9381\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4168 - accuracy: 0.8944 - val_loss: 0.2495 - val_accuracy: 0.9388\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3908 - accuracy: 0.9025 - val_loss: 0.2469 - val_accuracy: 0.9410\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3884 - accuracy: 0.9031 - val_loss: 0.2466 - val_accuracy: 0.9404\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3901 - accuracy: 0.9002 - val_loss: 0.2472 - val_accuracy: 0.9406\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 8ms/step - loss: 2.3023 - accuracy: 0.1125 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3015 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1110 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1155 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1141 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1135 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1141 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1121 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1147 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1144 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1127 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1143 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2998 - accuracy: 0.1171 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1132 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2998 - accuracy: 0.1141 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2994 - accuracy: 0.1142 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2998 - accuracy: 0.1139 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1133 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2996 - accuracy: 0.1134 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2992 - accuracy: 0.1139 - val_loss: 2.3002 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2993 - accuracy: 0.1117 - val_loss: 2.3000 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2992 - accuracy: 0.1121 - val_loss: 2.2998 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2989 - accuracy: 0.1130 - val_loss: 2.2995 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2986 - accuracy: 0.1136 - val_loss: 2.2991 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2974 - accuracy: 0.1159 - val_loss: 2.2987 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2978 - accuracy: 0.1120 - val_loss: 2.2981 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2969 - accuracy: 0.1141 - val_loss: 2.2974 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2960 - accuracy: 0.1170 - val_loss: 2.2965 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2951 - accuracy: 0.1154 - val_loss: 2.2951 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2933 - accuracy: 0.1226 - val_loss: 2.2928 - val_accuracy: 0.1065\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2908 - accuracy: 0.1339 - val_loss: 2.2885 - val_accuracy: 0.1181\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2857 - accuracy: 0.1459 - val_loss: 2.2777 - val_accuracy: 0.1749\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2714 - accuracy: 0.1749 - val_loss: 2.2287 - val_accuracy: 0.2325\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2121 - accuracy: 0.2133 - val_loss: 2.0401 - val_accuracy: 0.2968\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1000 - accuracy: 0.2424 - val_loss: 1.8898 - val_accuracy: 0.3043\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0068 - accuracy: 0.2604 - val_loss: 1.7807 - val_accuracy: 0.3155\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.9185 - accuracy: 0.2803 - val_loss: 1.6761 - val_accuracy: 0.3409\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8156 - accuracy: 0.3092 - val_loss: 1.5833 - val_accuracy: 0.4039\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7263 - accuracy: 0.3444 - val_loss: 1.4810 - val_accuracy: 0.4656\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6358 - accuracy: 0.3882 - val_loss: 1.3904 - val_accuracy: 0.5207\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5719 - accuracy: 0.4180 - val_loss: 1.3122 - val_accuracy: 0.5555\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5084 - accuracy: 0.4509 - val_loss: 1.2467 - val_accuracy: 0.5889\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4420 - accuracy: 0.4727 - val_loss: 1.1859 - val_accuracy: 0.6208\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3938 - accuracy: 0.4912 - val_loss: 1.1331 - val_accuracy: 0.6415\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.3428 - accuracy: 0.5123 - val_loss: 1.0705 - val_accuracy: 0.6639\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3085 - accuracy: 0.5208 - val_loss: 1.0228 - val_accuracy: 0.6703\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2476 - accuracy: 0.5420 - val_loss: 0.9737 - val_accuracy: 0.6937\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2115 - accuracy: 0.5538 - val_loss: 0.9368 - val_accuracy: 0.7012\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.3021 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1146 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1160 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1153 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1137 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1130 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1123 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1142 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1141 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1125 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1157 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1152 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1130 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2995 - accuracy: 0.1153 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1144 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2997 - accuracy: 0.1147 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2995 - accuracy: 0.1138 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2992 - accuracy: 0.1157 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2995 - accuracy: 0.1144 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2991 - accuracy: 0.1162 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2994 - accuracy: 0.1135 - val_loss: 2.2999 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2988 - accuracy: 0.1147 - val_loss: 2.2996 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2985 - accuracy: 0.1129 - val_loss: 2.2994 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2980 - accuracy: 0.1165 - val_loss: 2.2991 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2980 - accuracy: 0.1131 - val_loss: 2.2987 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2978 - accuracy: 0.1139 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2972 - accuracy: 0.1137 - val_loss: 2.2976 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2965 - accuracy: 0.1135 - val_loss: 2.2969 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2961 - accuracy: 0.1113 - val_loss: 2.2958 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2949 - accuracy: 0.1137 - val_loss: 2.2941 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2930 - accuracy: 0.1151 - val_loss: 2.2916 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2902 - accuracy: 0.1210 - val_loss: 2.2868 - val_accuracy: 0.1100\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2841 - accuracy: 0.1342 - val_loss: 2.2741 - val_accuracy: 0.1587\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2660 - accuracy: 0.1590 - val_loss: 2.1918 - val_accuracy: 0.1867\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1770 - accuracy: 0.2053 - val_loss: 2.0279 - val_accuracy: 0.2694\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0848 - accuracy: 0.2197 - val_loss: 1.9601 - val_accuracy: 0.2578\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0219 - accuracy: 0.2287 - val_loss: 1.9299 - val_accuracy: 0.2731\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9917 - accuracy: 0.2380 - val_loss: 1.9041 - val_accuracy: 0.2853\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9686 - accuracy: 0.2532 - val_loss: 1.8782 - val_accuracy: 0.3006\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9452 - accuracy: 0.2623 - val_loss: 1.8500 - val_accuracy: 0.3051\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.9280 - accuracy: 0.2647 - val_loss: 1.8165 - val_accuracy: 0.3166\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8984 - accuracy: 0.2729 - val_loss: 1.7797 - val_accuracy: 0.3290\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8622 - accuracy: 0.2858 - val_loss: 1.7315 - val_accuracy: 0.3401\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8261 - accuracy: 0.3012 - val_loss: 1.6844 - val_accuracy: 0.3631\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7861 - accuracy: 0.3237 - val_loss: 1.6442 - val_accuracy: 0.3948\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7494 - accuracy: 0.3401 - val_loss: 1.6055 - val_accuracy: 0.4151\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7076 - accuracy: 0.3627 - val_loss: 1.5661 - val_accuracy: 0.4321\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6744 - accuracy: 0.3765 - val_loss: 1.5370 - val_accuracy: 0.4563\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6346 - accuracy: 0.3945 - val_loss: 1.5018 - val_accuracy: 0.4626\n",
      "{'loss': [1.9912551641464233, 1.5481847524642944, 1.3417705297470093, 1.2185438871383667, 1.1198909282684326, 1.0592647790908813, 1.0095441341400146, 0.9633620381355286, 0.9274986982345581, 0.9011305570602417, 0.8726043105125427, 0.8499413132667542, 0.8154175877571106, 0.8040450811386108, 0.7795343995094299, 0.7529541254043579, 0.7415804862976074, 0.7255823016166687, 0.7056707143783569, 0.698915421962738, 0.6789412498474121, 0.6710595488548279, 0.6577063798904419, 0.6425992250442505, 0.6371729969978333, 0.6267035603523254, 0.610572874546051, 0.6090347170829773, 0.5929757356643677, 0.586106538772583, 0.5743556618690491, 0.5770032405853271, 0.5640331506729126, 0.5572641491889954, 0.5477118492126465, 0.5477747917175293, 0.539268434047699, 0.5373495817184448, 0.5272486805915833, 0.5179047584533691, 0.5160292387008667, 0.5060474276542664, 0.5014487504959106, 0.5022836923599243, 0.5027968883514404, 0.4975942075252533, 0.48748257756233215, 0.484651654958725, 0.4779815375804901, 0.4712505340576172], 'accuracy': [0.2842291593551636, 0.46668750047683716, 0.5431666374206543, 0.5901666879653931, 0.6299999952316284, 0.6547708511352539, 0.6777499914169312, 0.6933125257492065, 0.7123125195503235, 0.7217291593551636, 0.7348541617393494, 0.747041642665863, 0.7584166526794434, 0.7645208239555359, 0.7759166955947876, 0.7880416512489319, 0.7943958044052124, 0.801354169845581, 0.8068125247955322, 0.8111249804496765, 0.8195208311080933, 0.8224166631698608, 0.825083315372467, 0.8297708630561829, 0.8352916836738586, 0.8373749852180481, 0.8445208072662354, 0.8452083468437195, 0.8498541712760925, 0.8505625128746033, 0.8559374809265137, 0.8561458587646484, 0.8597291707992554, 0.859624981880188, 0.8638749718666077, 0.8650416731834412, 0.8661458492279053, 0.8670416474342346, 0.8707291483879089, 0.871999979019165, 0.8737708330154419, 0.8774999976158142, 0.8774583339691162, 0.8776249885559082, 0.8792499899864197, 0.8794999718666077, 0.88260418176651, 0.8834999799728394, 0.8843958377838135, 0.8862500190734863], 'val_loss': [1.3120945692062378, 1.0044561624526978, 0.84590744972229, 0.7418491244316101, 0.6778591275215149, 0.630302906036377, 0.5936126112937927, 0.5635635256767273, 0.5414960384368896, 0.5167221426963806, 0.4987444281578064, 0.4801707863807678, 0.46648815274238586, 0.4567277729511261, 0.44005200266838074, 0.42780473828315735, 0.41637948155403137, 0.41338658332824707, 0.39765703678131104, 0.40030229091644287, 0.3909470736980438, 0.3806007504463196, 0.38153088092803955, 0.3780078589916229, 0.3693224787712097, 0.36803773045539856, 0.36417585611343384, 0.36017993092536926, 0.35735151171684265, 0.3576818108558655, 0.3512720465660095, 0.3555706739425659, 0.35131534934043884, 0.34925276041030884, 0.34649115800857544, 0.3453039526939392, 0.3414939045906067, 0.33784058690071106, 0.3432457745075226, 0.3352970480918884, 0.3331279158592224, 0.3295575678348541, 0.32494357228279114, 0.3190633952617645, 0.3231331706047058, 0.319458931684494, 0.31864112615585327, 0.3208152949810028, 0.3135063946247101, 0.3131501078605652], 'val_accuracy': [0.6198333501815796, 0.7420833110809326, 0.7919999957084656, 0.812250018119812, 0.8243333101272583, 0.8365833163261414, 0.8456666469573975, 0.8529999852180481, 0.8606666922569275, 0.8654999732971191, 0.8689166903495789, 0.8734999895095825, 0.8776666522026062, 0.8802499771118164, 0.8858333230018616, 0.8868333101272583, 0.890583336353302, 0.893750011920929, 0.8971666693687439, 0.8974999785423279, 0.8983333110809326, 0.9024166464805603, 0.9027500152587891, 0.9049999713897705, 0.9067500233650208, 0.906416654586792, 0.9100000262260437, 0.9101666808128357, 0.9110833406448364, 0.9125833511352539, 0.9147499799728394, 0.9138333201408386, 0.9125000238418579, 0.9157500267028809, 0.9154999852180481, 0.9159166812896729, 0.9179999828338623, 0.9201666712760925, 0.9185000061988831, 0.9200000166893005, 0.922249972820282, 0.921750009059906, 0.922166645526886, 0.9238333106040955, 0.9235000014305115, 0.924833357334137, 0.924916684627533, 0.924916684627533, 0.9263333082199097, 0.9274166822433472]}\n",
      "{'loss': [2.303421974182129, 2.30182147026062, 2.3012475967407227, 2.3005173206329346, 2.299565553665161, 2.298110008239746, 2.295724630355835, 2.2888729572296143, 2.2670178413391113, 2.200289487838745, 2.1263368129730225, 2.0643601417541504, 1.9948270320892334, 1.9198194742202759, 1.8382805585861206, 1.763091802597046, 1.6965513229370117, 1.6309359073638916, 1.5721815824508667, 1.5168970823287964, 1.4628336429595947, 1.4236798286437988, 1.3793543577194214, 1.3434839248657227, 1.3028348684310913, 1.2677611112594604, 1.2383955717086792, 1.2105772495269775, 1.1732492446899414, 1.1465861797332764, 1.1268930435180664, 1.1005122661590576, 1.0677850246429443, 1.0509597063064575, 1.0273836851119995, 1.0077842473983765, 0.9858140349388123, 0.96294766664505, 0.9369879364967346, 0.9312933087348938, 0.9018779993057251, 0.8871598839759827, 0.8631970286369324, 0.8454542756080627, 0.8305683732032776, 0.8116210699081421, 0.7943397760391235, 0.779244065284729, 0.7586780786514282, 0.7392324209213257], 'accuracy': [0.1133541688323021, 0.11539583653211594, 0.11470833420753479, 0.11439583450555801, 0.11408333480358124, 0.1133541688323021, 0.11295833438634872, 0.11397916823625565, 0.12947916984558105, 0.18052083253860474, 0.20289583504199982, 0.21718749403953552, 0.2537499964237213, 0.29339584708213806, 0.3252708315849304, 0.3480624854564667, 0.3739166557788849, 0.39506250619888306, 0.4156875014305115, 0.4283958375453949, 0.445437490940094, 0.46295833587646484, 0.4735416769981384, 0.48752084374427795, 0.5029374957084656, 0.5149166584014893, 0.5301874876022339, 0.5439375042915344, 0.5589583516120911, 0.5756458044052124, 0.5861666798591614, 0.5979166626930237, 0.6132500171661377, 0.6221666932106018, 0.6315624713897705, 0.6396458148956299, 0.6442708373069763, 0.6534166932106018, 0.6659374833106995, 0.667187511920929, 0.6754791736602783, 0.6813750267028809, 0.694937527179718, 0.703000009059906, 0.7102500200271606, 0.7160208225250244, 0.7244374752044678, 0.7337916493415833, 0.7383333444595337, 0.7460416555404663], 'val_loss': [2.302154541015625, 2.301938533782959, 2.301492929458618, 2.300593137741089, 2.2991843223571777, 2.2957401275634766, 2.2887637615203857, 2.2709884643554688, 2.205840587615967, 2.086226224899292, 2.0171608924865723, 1.9478651285171509, 1.8608585596084595, 1.7561570405960083, 1.6664334535598755, 1.5960243940353394, 1.5085426568984985, 1.4360496997833252, 1.3629844188690186, 1.2963958978652954, 1.249897837638855, 1.205291986465454, 1.1614283323287964, 1.1260396242141724, 1.08712637424469, 1.0451549291610718, 0.9991582036018372, 0.9834229946136475, 0.9622642993927002, 0.9214991331100464, 0.901479184627533, 0.8804236650466919, 0.8621214032173157, 0.8580628037452698, 0.8231724500656128, 0.799001157283783, 0.7884011268615723, 0.7683981657028198, 0.752434492111206, 0.7436559200286865, 0.7088954448699951, 0.7066214084625244, 0.6893105506896973, 0.6584213972091675, 0.65335613489151, 0.6261065006256104, 0.614793598651886, 0.6016779541969299, 0.5964322686195374, 0.5855990648269653], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.25224998593330383, 0.20908333361148834, 0.23208333551883698, 0.2840833365917206, 0.37575000524520874, 0.4165000021457672, 0.44333332777023315, 0.47691667079925537, 0.5040833353996277, 0.5325000286102295, 0.5603333115577698, 0.5772500038146973, 0.5885833501815796, 0.5962499976158142, 0.6099166870117188, 0.6211666464805603, 0.6349999904632568, 0.6424166560173035, 0.6640833616256714, 0.6663333177566528, 0.6760833263397217, 0.6991666555404663, 0.7174999713897705, 0.7365833520889282, 0.7565833330154419, 0.746833324432373, 0.7835833430290222, 0.7850833535194397, 0.7904999852180481, 0.7893333435058594, 0.7984166741371155, 0.7944166660308838, 0.8108333349227905, 0.8098333477973938, 0.8211666941642761, 0.8475833535194397, 0.8489166498184204, 0.856416642665863, 0.8700000047683716, 0.8777499794960022, 0.8449166417121887, 0.8659166693687439]}\n",
      "{'loss': [2.3035008907318115, 2.295020341873169, 2.2591159343719482, 2.12860107421875, 2.011582612991333, 1.9391283988952637, 1.8493880033493042, 1.7287375926971436, 1.6162803173065186, 1.497847318649292, 1.3901134729385376, 1.2998006343841553, 1.2067853212356567, 1.124234914779663, 1.060787558555603, 1.0078433752059937, 0.956845760345459, 0.9084916710853577, 0.8749841451644897, 0.8398969173431396, 0.8078197240829468, 0.7778601050376892, 0.7518866658210754, 0.7218946814537048, 0.6954729557037354, 0.6717722415924072, 0.6546765565872192, 0.6286357045173645, 0.6093647480010986, 0.5914313793182373, 0.5703805685043335, 0.5564045310020447, 0.5429289937019348, 0.5250009298324585, 0.511989951133728, 0.4998883903026581, 0.47604113817214966, 0.46742650866508484, 0.4556340277194977, 0.4415165185928345, 0.4353533983230591, 0.4315122961997986, 0.4175771474838257, 0.40893885493278503, 0.39591458439826965, 0.3815552592277527, 0.37002721428871155, 0.3713546693325043, 0.36248499155044556, 0.3562467396259308], 'accuracy': [0.11166666448116302, 0.13564583659172058, 0.15997916460037231, 0.20785416662693024, 0.22331249713897705, 0.23506249487400055, 0.27272915840148926, 0.3161666691303253, 0.3659166693687439, 0.4195416569709778, 0.4648541808128357, 0.5089166760444641, 0.5476041436195374, 0.5878333449363708, 0.620229184627533, 0.6382916569709778, 0.6598958373069763, 0.6822708249092102, 0.6933541893959045, 0.710562527179718, 0.7305416464805603, 0.7442708611488342, 0.7578750252723694, 0.7680000066757202, 0.7821458578109741, 0.7913541793823242, 0.8015833497047424, 0.8090416789054871, 0.8202916383743286, 0.8268958330154419, 0.8352500200271606, 0.840791642665863, 0.8472916483879089, 0.8528541922569275, 0.8558958172798157, 0.8601041436195374, 0.8666666746139526, 0.8705416917800903, 0.8723750114440918, 0.8786458373069763, 0.8811041712760925, 0.8815000057220459, 0.886145830154419, 0.8871250152587891, 0.893625020980835, 0.8964375257492065, 0.8980833292007446, 0.8999791741371155, 0.9014166593551636, 0.9044374823570251], 'val_loss': [2.299135446548462, 2.281607151031494, 2.1570258140563965, 1.9556692838668823, 1.8574061393737793, 1.780277132987976, 1.6292773485183716, 1.4621604681015015, 1.3257944583892822, 1.1789500713348389, 1.0695923566818237, 0.977255642414093, 0.881211519241333, 0.8039497137069702, 0.748341977596283, 0.7075775265693665, 0.6673280000686646, 0.6393897533416748, 0.6099220514297485, 0.5790478587150574, 0.5596669912338257, 0.5290367007255554, 0.5053600072860718, 0.48549169301986694, 0.4648047387599945, 0.4510878026485443, 0.43837934732437134, 0.4261302053928375, 0.4175328016281128, 0.3992598354816437, 0.39573946595191956, 0.39160266518592834, 0.3842407763004303, 0.36999133229255676, 0.37392285466194153, 0.3733151853084564, 0.3642956614494324, 0.35793888568878174, 0.3601788878440857, 0.3505907654762268, 0.35541146993637085, 0.3491458296775818, 0.34720173478126526, 0.35329577326774597, 0.3498428463935852, 0.34408071637153625, 0.35786983370780945, 0.3372468948364258, 0.34119677543640137, 0.3419826626777649], 'val_accuracy': [0.10616666823625565, 0.16616666316986084, 0.19683332741260529, 0.29358333349227905, 0.30924999713897705, 0.3192499876022339, 0.3336666524410248, 0.4025833308696747, 0.5111666917800903, 0.5327500104904175, 0.5883333086967468, 0.6492499709129333, 0.7232499718666077, 0.7431666851043701, 0.7579166889190674, 0.7392500042915344, 0.7855833172798157, 0.7764166593551636, 0.8165000081062317, 0.8414166569709778, 0.8276666402816772, 0.8493333458900452, 0.8657500147819519, 0.8795833587646484, 0.8894166946411133, 0.8970000147819519, 0.9034166932106018, 0.9087499976158142, 0.9104999899864197, 0.9149166941642761, 0.9129999876022339, 0.9166666865348816, 0.9204166531562805, 0.921916663646698, 0.9223333597183228, 0.9235833287239075, 0.9265000224113464, 0.9269999861717224, 0.9276666641235352, 0.9306666851043701, 0.9292500019073486, 0.9309166669845581, 0.9325000047683716, 0.9321666955947876, 0.934333324432373, 0.9355000257492065, 0.9355000257492065, 0.9365833401679993, 0.9381666779518127, 0.9400833249092102]}\n",
      "{'loss': [1.9508249759674072, 1.4672914743423462, 1.240541934967041, 1.1153790950775146, 1.0266789197921753, 0.9628942608833313, 0.9168072938919067, 0.8737472295761108, 0.8428269624710083, 0.816430926322937, 0.7854472398757935, 0.7584068775177002, 0.7469283938407898, 0.724709153175354, 0.7142446041107178, 0.6868814826011658, 0.6700160503387451, 0.6571224927902222, 0.6413491368293762, 0.6230724453926086, 0.6202404499053955, 0.6049434542655945, 0.5852546095848083, 0.5807790756225586, 0.5707322359085083, 0.5544233322143555, 0.5472811460494995, 0.5365833044052124, 0.5244441032409668, 0.5223598480224609, 0.5168598890304565, 0.5004542469978333, 0.5030388236045837, 0.4877585470676422, 0.4861876964569092, 0.4757069945335388, 0.47053685784339905, 0.457113116979599, 0.4564412534236908, 0.45161768794059753, 0.4447813034057617, 0.4387165904045105, 0.4356020987033844, 0.42787572741508484, 0.42179855704307556, 0.4183642566204071, 0.4133750796318054, 0.4021810293197632, 0.40588390827178955, 0.3939635753631592], 'accuracy': [0.2979375123977661, 0.4781041741371155, 0.5640416741371155, 0.6166250109672546, 0.6562708616256714, 0.6854583621025085, 0.7041875123977661, 0.7214791774749756, 0.7365624904632568, 0.745437502861023, 0.7588333487510681, 0.7712083458900452, 0.7744791507720947, 0.7834583520889282, 0.7873541712760925, 0.7979375123977661, 0.8044583201408386, 0.809166669845581, 0.817229151725769, 0.8237500190734863, 0.824874997138977, 0.8308958411216736, 0.8351041674613953, 0.8403750061988831, 0.840666651725769, 0.8487916588783264, 0.8508750200271606, 0.8536875247955322, 0.8590208292007446, 0.8573750257492065, 0.8629375100135803, 0.8660833239555359, 0.8652708530426025, 0.8715416789054871, 0.8726875185966492, 0.8736249804496765, 0.8760208487510681, 0.8794375061988831, 0.8790208101272583, 0.8810208439826965, 0.8844166398048401, 0.8855000138282776, 0.8876458406448364, 0.8892083168029785, 0.8923541903495789, 0.8917083144187927, 0.8937291502952576, 0.8972708582878113, 0.8956875205039978, 0.8998958468437195], 'val_loss': [1.1940048933029175, 0.8262806534767151, 0.6787121295928955, 0.6034165024757385, 0.5404312014579773, 0.49878743290901184, 0.4644966721534729, 0.44712740182876587, 0.4263542890548706, 0.41274571418762207, 0.39979708194732666, 0.3880557119846344, 0.3836330473423004, 0.3721942901611328, 0.3632480502128601, 0.3514200747013092, 0.35003575682640076, 0.34129369258880615, 0.33606889843940735, 0.329317569732666, 0.32082316279411316, 0.3137522339820862, 0.30662909150123596, 0.30670368671417236, 0.2972216308116913, 0.30109694600105286, 0.28936731815338135, 0.2839896082878113, 0.2836863696575165, 0.28244394063949585, 0.2756198048591614, 0.2721463441848755, 0.2717129588127136, 0.2675630450248718, 0.26343008875846863, 0.2652558386325836, 0.2609659731388092, 0.25647681951522827, 0.2516104280948639, 0.2509547173976898, 0.24530290067195892, 0.24384675920009613, 0.2426689863204956, 0.23709049820899963, 0.24352213740348816, 0.24091655015945435, 0.23643749952316284, 0.23414760828018188, 0.22915656864643097, 0.23521751165390015], 'val_accuracy': [0.6104999780654907, 0.7730000019073486, 0.8165833353996277, 0.8433333039283752, 0.8575833439826965, 0.862416684627533, 0.8739166855812073, 0.878000020980835, 0.8837500214576721, 0.8891666531562805, 0.890250027179718, 0.8941666483879089, 0.8978333473205566, 0.8999999761581421, 0.9015833139419556, 0.9049999713897705, 0.9058333039283752, 0.9079166650772095, 0.9085000157356262, 0.9114999771118164, 0.9138333201408386, 0.9158333539962769, 0.9175000190734863, 0.9157500267028809, 0.9195833206176758, 0.9173333048820496, 0.92166668176651, 0.9235833287239075, 0.921999990940094, 0.925083339214325, 0.9253333210945129, 0.9269166588783264, 0.9268333315849304, 0.9292500019073486, 0.9291666746139526, 0.9290833473205566, 0.9299166798591614, 0.9316666722297668, 0.9340000152587891, 0.934166669845581, 0.934416651725769, 0.937833309173584, 0.937666654586792, 0.9383333325386047, 0.937333345413208, 0.9379166960716248, 0.9388333559036255, 0.9402499794960022, 0.9412500262260437, 0.9399166703224182]}\n",
      "{'loss': [2.054579019546509, 1.3099071979522705, 1.108997106552124, 1.0013611316680908, 0.9293647408485413, 0.8810315728187561, 0.8355777263641357, 0.7977234125137329, 0.7675355672836304, 0.742202639579773, 0.720488429069519, 0.7086714506149292, 0.6791912317276001, 0.6674678921699524, 0.6507916450500488, 0.6450203657150269, 0.6225874423980713, 0.6048721671104431, 0.5959363579750061, 0.5885287523269653, 0.5684616565704346, 0.559744656085968, 0.547635555267334, 0.5419882535934448, 0.5318403840065002, 0.5222746729850769, 0.5106541514396667, 0.5055310726165771, 0.4992729127407074, 0.4911063313484192, 0.48217806220054626, 0.47209247946739197, 0.46928051114082336, 0.4612957239151001, 0.45472896099090576, 0.44367745518684387, 0.44616588950157166, 0.43681490421295166, 0.43780505657196045, 0.43328219652175903, 0.4284096956253052, 0.42033377289772034, 0.41562288999557495, 0.41152095794677734, 0.4105432629585266, 0.4043126702308655, 0.4054836332798004, 0.39740902185440063, 0.3889814019203186, 0.3852507770061493], 'accuracy': [0.3356874883174896, 0.5437291860580444, 0.6231041550636292, 0.6680625081062317, 0.7004791498184204, 0.7223125100135803, 0.7385416626930237, 0.7574999928474426, 0.7676249742507935, 0.7816874980926514, 0.7904375195503235, 0.7963958382606506, 0.8069166541099548, 0.8144375085830688, 0.820020854473114, 0.823437511920929, 0.831250011920929, 0.8359166383743286, 0.8387291431427002, 0.8432499766349792, 0.848395824432373, 0.8525416851043701, 0.8557083606719971, 0.8580208420753479, 0.8620833158493042, 0.8640833497047424, 0.8655624985694885, 0.8677291870117188, 0.8724791407585144, 0.8727083206176758, 0.8738541603088379, 0.8780624866485596, 0.8800208568572998, 0.8815416693687439, 0.8826666474342346, 0.8862291574478149, 0.8858749866485596, 0.8872708082199097, 0.8890625238418579, 0.8888958096504211, 0.8915833234786987, 0.8925208449363708, 0.8941458463668823, 0.8949375152587891, 0.895479142665863, 0.8967083096504211, 0.8963750004768372, 0.9001041650772095, 0.9024999737739563, 0.9026041626930237], 'val_loss': [0.7315987944602966, 0.6025876402854919, 0.5343999266624451, 0.4985632002353668, 0.465606689453125, 0.44210273027420044, 0.4234243929386139, 0.40837976336479187, 0.3926650285720825, 0.3840876817703247, 0.37340885400772095, 0.3680955767631531, 0.3638981580734253, 0.3535903990268707, 0.34750524163246155, 0.33826518058776855, 0.3346642553806305, 0.32489603757858276, 0.3223741948604584, 0.32183098793029785, 0.31675800681114197, 0.31154534220695496, 0.3041563034057617, 0.3032122850418091, 0.29987671971321106, 0.29836854338645935, 0.29234176874160767, 0.28705716133117676, 0.28842195868492126, 0.2816627323627472, 0.28153592348098755, 0.27831918001174927, 0.28099751472473145, 0.2735425531864166, 0.2765337824821472, 0.2752954065799713, 0.2667064368724823, 0.26654675602912903, 0.26435884833335876, 0.2642148733139038, 0.2611341178417206, 0.25651711225509644, 0.2619107961654663, 0.2586296796798706, 0.25460657477378845, 0.25188398361206055, 0.24951578676700592, 0.24694295227527618, 0.24656467139720917, 0.2472449690103531], 'val_accuracy': [0.7954166531562805, 0.831333339214325, 0.8510833382606506, 0.85916668176651, 0.8706666827201843, 0.8743333220481873, 0.8850833177566528, 0.8890833258628845, 0.8918333053588867, 0.8985000252723694, 0.8988333344459534, 0.9011666774749756, 0.9024999737739563, 0.9071666598320007, 0.9089166522026062, 0.9106666445732117, 0.9124166369438171, 0.9133333563804626, 0.9153333306312561, 0.9157500267028809, 0.9175000190734863, 0.9203333258628845, 0.921833336353302, 0.9224166870117188, 0.9236666560173035, 0.924833357334137, 0.9264166951179504, 0.9276666641235352, 0.9293333292007446, 0.9290833473205566, 0.9301666617393494, 0.9309166669845581, 0.9303333163261414, 0.9329166412353516, 0.9323333501815796, 0.9335833191871643, 0.9348333477973938, 0.934249997138977, 0.9338333606719971, 0.9355833530426025, 0.9360833168029785, 0.9367499947547913, 0.9350000023841858, 0.937666654586792, 0.9369166493415833, 0.9380833506584167, 0.9388333559036255, 0.9409999847412109, 0.940416693687439, 0.940583348274231]}\n",
      "{'loss': [2.30208683013916, 2.3014206886291504, 2.3011209964752197, 2.3009817600250244, 2.300820827484131, 2.3008339405059814, 2.300724744796753, 2.3006038665771484, 2.300572633743286, 2.3005008697509766, 2.3004143238067627, 2.3003973960876465, 2.3002512454986572, 2.3002071380615234, 2.3001341819763184, 2.3000099658966064, 2.299889087677002, 2.299806594848633, 2.299710988998413, 2.2994794845581055, 2.299346685409546, 2.2991225719451904, 2.2989888191223145, 2.2987942695617676, 2.2985172271728516, 2.298229217529297, 2.297780990600586, 2.2973663806915283, 2.2967686653137207, 2.2959306240081787, 2.294654369354248, 2.29292631149292, 2.2899692058563232, 2.283433198928833, 2.2625632286071777, 2.182013750076294, 2.0758771896362305, 1.9827951192855835, 1.889150857925415, 1.796856164932251, 1.703203797340393, 1.6234878301620483, 1.5547932386398315, 1.4880051612854004, 1.4315881729125977, 1.3867478370666504, 1.332067608833313, 1.294245958328247, 1.2423608303070068, 1.2034798860549927], 'accuracy': [0.11508333683013916, 0.11397916823625565, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11395833641290665, 0.11400000005960464, 0.11404166370630264, 0.11424999684095383, 0.11470833420753479, 0.11518750339746475, 0.11800000071525574, 0.12425000220537186, 0.13568750023841858, 0.15327084064483643, 0.18639583885669708, 0.22289583086967468, 0.24720832705497742, 0.2630208432674408, 0.28718748688697815, 0.3148750066757202, 0.35460415482521057, 0.40049999952316284, 0.4269374907016754, 0.45631250739097595, 0.4763541519641876, 0.49131250381469727, 0.5148958563804626, 0.5246458053588867, 0.5454583168029785, 0.5565000176429749], 'val_loss': [2.3020431995391846, 2.301875352859497, 2.301827907562256, 2.301809072494507, 2.30175518989563, 2.301743507385254, 2.3016839027404785, 2.301628828048706, 2.3015785217285156, 2.301523208618164, 2.301455497741699, 2.3013927936553955, 2.3013007640838623, 2.3012266159057617, 2.301114559173584, 2.301029920578003, 2.3009071350097656, 2.300813674926758, 2.3006441593170166, 2.300555944442749, 2.3003790378570557, 2.300215721130371, 2.299997568130493, 2.2997806072235107, 2.299480438232422, 2.299131393432617, 2.298696517944336, 2.2981250286102295, 2.2974417209625244, 2.2964999675750732, 2.2950539588928223, 2.2927849292755127, 2.288546562194824, 2.277693271636963, 2.228652238845825, 2.0401434898376465, 1.889837384223938, 1.7807114124298096, 1.6761033535003662, 1.5832942724227905, 1.4810348749160767, 1.3903850317001343, 1.3121564388275146, 1.2466543912887573, 1.1859219074249268, 1.1331316232681274, 1.0704675912857056, 1.0228065252304077, 0.9737280011177063, 0.9367929100990295], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10649999976158142, 0.11808333545923233, 0.17491666972637177, 0.23250000178813934, 0.296833336353302, 0.30433332920074463, 0.3154999911785126, 0.3409166634082794, 0.4039166569709778, 0.46558332443237305, 0.5207499861717224, 0.5554999709129333, 0.5889166593551636, 0.6208333373069763, 0.6414999961853027, 0.6639166474342346, 0.6703333258628845, 0.6936666369438171, 0.7011666893959045]}\n",
      "{'loss': [2.3019285202026367, 2.301323175430298, 2.3010478019714355, 2.300945520401001, 2.3007493019104004, 2.3006973266601562, 2.3007025718688965, 2.300615072250366, 2.300468921661377, 2.3003766536712646, 2.3002781867980957, 2.300278425216675, 2.300168514251709, 2.3000378608703613, 2.3000082969665527, 2.2998650074005127, 2.2997238636016846, 2.299567461013794, 2.299544095993042, 2.2993054389953613, 2.2991650104522705, 2.2990126609802246, 2.2988102436065674, 2.2985668182373047, 2.298264265060425, 2.2979466915130615, 2.2974891662597656, 2.296935558319092, 2.2963032722473145, 2.295546770095825, 2.294186592102051, 2.292508363723755, 2.289123773574829, 2.2817773818969727, 2.252389430999756, 2.148256301879883, 2.0626823902130127, 2.0176799297332764, 1.9853248596191406, 1.9660191535949707, 1.9402612447738647, 1.9157322645187378, 1.8881837129592896, 1.8549376726150513, 1.8175063133239746, 1.777125358581543, 1.7379471063613892, 1.6949764490127563, 1.6652987003326416, 1.628968596458435], 'accuracy': [0.11349999904632568, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11395833641290665, 0.11402083188295364, 0.11427083611488342, 0.11504166573286057, 0.1171249970793724, 0.12347916513681412, 0.14010415971279144, 0.16739583015441895, 0.2121874988079071, 0.22208333015441895, 0.22947916388511658, 0.24160416424274445, 0.2553125023841858, 0.2626041769981384, 0.2684791684150696, 0.27652081847190857, 0.28949999809265137, 0.3057708442211151, 0.3278958201408386, 0.34718748927116394, 0.3687291741371155, 0.37975001335144043, 0.39633333683013916], 'val_loss': [2.3019635677337646, 2.301825761795044, 2.3017847537994385, 2.301732063293457, 2.301715612411499, 2.3016622066497803, 2.301595449447632, 2.3015129566192627, 2.3014602661132812, 2.301398515701294, 2.301321506500244, 2.301223039627075, 2.3011457920074463, 2.3010647296905518, 2.300899028778076, 2.300819158554077, 2.3007071018218994, 2.3005964756011963, 2.3004183769226074, 2.3002772331237793, 2.300077199935913, 2.2998697757720947, 2.299619197845459, 2.2993650436401367, 2.299051523208618, 2.2986836433410645, 2.2982048988342285, 2.297623872756958, 2.296856164932251, 2.2957568168640137, 2.2941417694091797, 2.2916295528411865, 2.286835193634033, 2.274122953414917, 2.191765069961548, 2.027864694595337, 1.9600759744644165, 1.929867148399353, 1.904070496559143, 1.8782265186309814, 1.8499795198440552, 1.8164833784103394, 1.7796831130981445, 1.7314966917037964, 1.6843714714050293, 1.644243597984314, 1.605521321296692, 1.5661238431930542, 1.5370138883590698, 1.501787781715393], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10999999940395355, 0.1586666703224182, 0.18674999475479126, 0.2694166600704193, 0.257750004529953, 0.27308332920074463, 0.2853333353996277, 0.3005833327770233, 0.30508333444595337, 0.3165833353996277, 0.32899999618530273, 0.3400833308696747, 0.3630833327770233, 0.3948333263397217, 0.4150833189487457, 0.4320833384990692, 0.45633333921432495, 0.4625833332538605]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "9depth128.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
