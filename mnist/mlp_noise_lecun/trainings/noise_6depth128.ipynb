{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noise_6depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "705e4f22-889a-4d5a-fd55-f1fdcd437268"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 18s 6ms/step - loss: 2.0655 - accuracy: 0.2457 - val_loss: 1.1870 - val_accuracy: 0.7122\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4845 - accuracy: 0.4861 - val_loss: 0.8953 - val_accuracy: 0.7964\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2764 - accuracy: 0.5696 - val_loss: 0.7344 - val_accuracy: 0.8319\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1342 - accuracy: 0.6248 - val_loss: 0.6300 - val_accuracy: 0.8521\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0456 - accuracy: 0.6566 - val_loss: 0.5649 - val_accuracy: 0.8606\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9766 - accuracy: 0.6864 - val_loss: 0.5136 - val_accuracy: 0.8700\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9097 - accuracy: 0.7126 - val_loss: 0.4806 - val_accuracy: 0.8750\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8798 - accuracy: 0.7207 - val_loss: 0.4536 - val_accuracy: 0.8801\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8405 - accuracy: 0.7380 - val_loss: 0.4349 - val_accuracy: 0.8836\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8173 - accuracy: 0.7462 - val_loss: 0.4191 - val_accuracy: 0.8871\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7914 - accuracy: 0.7570 - val_loss: 0.4037 - val_accuracy: 0.8908\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7701 - accuracy: 0.7669 - val_loss: 0.3913 - val_accuracy: 0.8950\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7476 - accuracy: 0.7736 - val_loss: 0.3834 - val_accuracy: 0.8958\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7266 - accuracy: 0.7826 - val_loss: 0.3745 - val_accuracy: 0.8979\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7115 - accuracy: 0.7906 - val_loss: 0.3685 - val_accuracy: 0.8988\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.7943 - val_loss: 0.3627 - val_accuracy: 0.9000\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6872 - accuracy: 0.7981 - val_loss: 0.3528 - val_accuracy: 0.9032\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6753 - accuracy: 0.8036 - val_loss: 0.3504 - val_accuracy: 0.9043\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6596 - accuracy: 0.8130 - val_loss: 0.3471 - val_accuracy: 0.9049\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6428 - accuracy: 0.8173 - val_loss: 0.3419 - val_accuracy: 0.9068\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6463 - accuracy: 0.8175 - val_loss: 0.3385 - val_accuracy: 0.9071\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6314 - accuracy: 0.8237 - val_loss: 0.3357 - val_accuracy: 0.9063\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6095 - accuracy: 0.8280 - val_loss: 0.3309 - val_accuracy: 0.9096\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6069 - accuracy: 0.8294 - val_loss: 0.3290 - val_accuracy: 0.9100\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5962 - accuracy: 0.8364 - val_loss: 0.3263 - val_accuracy: 0.9109\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5904 - accuracy: 0.8377 - val_loss: 0.3258 - val_accuracy: 0.9118\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5875 - accuracy: 0.8361 - val_loss: 0.3222 - val_accuracy: 0.9126\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5770 - accuracy: 0.8434 - val_loss: 0.3205 - val_accuracy: 0.9135\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5719 - accuracy: 0.8421 - val_loss: 0.3189 - val_accuracy: 0.9148\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5713 - accuracy: 0.8445 - val_loss: 0.3166 - val_accuracy: 0.9157\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5507 - accuracy: 0.8497 - val_loss: 0.3174 - val_accuracy: 0.9159\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5576 - accuracy: 0.8478 - val_loss: 0.3150 - val_accuracy: 0.9156\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5466 - accuracy: 0.8521 - val_loss: 0.3119 - val_accuracy: 0.9178\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5409 - accuracy: 0.8548 - val_loss: 0.3095 - val_accuracy: 0.9178\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5297 - accuracy: 0.8589 - val_loss: 0.3080 - val_accuracy: 0.9190\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5178 - accuracy: 0.8609 - val_loss: 0.3077 - val_accuracy: 0.9187\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5313 - accuracy: 0.8566 - val_loss: 0.3042 - val_accuracy: 0.9196\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5254 - accuracy: 0.8607 - val_loss: 0.3018 - val_accuracy: 0.9210\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5103 - accuracy: 0.8628 - val_loss: 0.3008 - val_accuracy: 0.9212\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5032 - accuracy: 0.8668 - val_loss: 0.3004 - val_accuracy: 0.9213\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5048 - accuracy: 0.8640 - val_loss: 0.3017 - val_accuracy: 0.9209\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4929 - accuracy: 0.8692 - val_loss: 0.2989 - val_accuracy: 0.9217\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4911 - accuracy: 0.8695 - val_loss: 0.2981 - val_accuracy: 0.9240\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5089 - accuracy: 0.8655 - val_loss: 0.2949 - val_accuracy: 0.9233\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4844 - accuracy: 0.8719 - val_loss: 0.2932 - val_accuracy: 0.9239\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4788 - accuracy: 0.8732 - val_loss: 0.2928 - val_accuracy: 0.9257\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4713 - accuracy: 0.8759 - val_loss: 0.2912 - val_accuracy: 0.9257\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4811 - accuracy: 0.8718 - val_loss: 0.2885 - val_accuracy: 0.9268\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4701 - accuracy: 0.8739 - val_loss: 0.2881 - val_accuracy: 0.9271\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4661 - accuracy: 0.8780 - val_loss: 0.2826 - val_accuracy: 0.9283\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.3056 - accuracy: 0.1128 - val_loss: 2.2781 - val_accuracy: 0.2802\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2832 - accuracy: 0.1416 - val_loss: 2.2003 - val_accuracy: 0.3419\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2148 - accuracy: 0.1868 - val_loss: 1.9554 - val_accuracy: 0.3923\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0499 - accuracy: 0.2519 - val_loss: 1.7563 - val_accuracy: 0.4309\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9183 - accuracy: 0.2935 - val_loss: 1.6137 - val_accuracy: 0.4803\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8127 - accuracy: 0.3305 - val_loss: 1.4716 - val_accuracy: 0.5276\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6956 - accuracy: 0.3776 - val_loss: 1.3026 - val_accuracy: 0.5908\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5694 - accuracy: 0.4239 - val_loss: 1.1579 - val_accuracy: 0.6543\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4555 - accuracy: 0.4650 - val_loss: 1.0597 - val_accuracy: 0.7138\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3620 - accuracy: 0.5031 - val_loss: 0.9663 - val_accuracy: 0.7677\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2907 - accuracy: 0.5313 - val_loss: 0.8977 - val_accuracy: 0.7663\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2119 - accuracy: 0.5696 - val_loss: 0.8303 - val_accuracy: 0.7963\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1763 - accuracy: 0.5894 - val_loss: 0.7684 - val_accuracy: 0.8159\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1316 - accuracy: 0.6045 - val_loss: 0.7242 - val_accuracy: 0.8229\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0741 - accuracy: 0.6241 - val_loss: 0.6766 - val_accuracy: 0.8223\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0431 - accuracy: 0.6385 - val_loss: 0.6323 - val_accuracy: 0.8322\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0109 - accuracy: 0.6499 - val_loss: 0.6083 - val_accuracy: 0.8545\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9734 - accuracy: 0.6640 - val_loss: 0.5774 - val_accuracy: 0.8597\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9420 - accuracy: 0.6712 - val_loss: 0.5476 - val_accuracy: 0.8683\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9081 - accuracy: 0.6874 - val_loss: 0.5256 - val_accuracy: 0.8774\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8964 - accuracy: 0.6993 - val_loss: 0.5094 - val_accuracy: 0.8800\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8631 - accuracy: 0.7066 - val_loss: 0.4843 - val_accuracy: 0.8967\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8529 - accuracy: 0.7170 - val_loss: 0.4645 - val_accuracy: 0.8983\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8198 - accuracy: 0.7281 - val_loss: 0.4466 - val_accuracy: 0.9057\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8095 - accuracy: 0.7333 - val_loss: 0.4318 - val_accuracy: 0.9108\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7951 - accuracy: 0.7425 - val_loss: 0.4174 - val_accuracy: 0.9145\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7643 - accuracy: 0.7510 - val_loss: 0.4032 - val_accuracy: 0.9178\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7372 - accuracy: 0.7581 - val_loss: 0.3928 - val_accuracy: 0.9191\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7281 - accuracy: 0.7619 - val_loss: 0.3816 - val_accuracy: 0.9222\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7079 - accuracy: 0.7718 - val_loss: 0.3690 - val_accuracy: 0.9243\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7128 - accuracy: 0.7693 - val_loss: 0.3625 - val_accuracy: 0.9273\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6895 - accuracy: 0.7810 - val_loss: 0.3518 - val_accuracy: 0.9296\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6772 - accuracy: 0.7830 - val_loss: 0.3509 - val_accuracy: 0.9302\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6568 - accuracy: 0.7899 - val_loss: 0.3394 - val_accuracy: 0.9344\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6513 - accuracy: 0.7967 - val_loss: 0.3332 - val_accuracy: 0.9333\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6272 - accuracy: 0.8048 - val_loss: 0.3231 - val_accuracy: 0.9358\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6276 - accuracy: 0.8000 - val_loss: 0.3291 - val_accuracy: 0.9349\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6094 - accuracy: 0.8116 - val_loss: 0.3231 - val_accuracy: 0.9366\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5979 - accuracy: 0.8117 - val_loss: 0.3136 - val_accuracy: 0.9377\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5995 - accuracy: 0.8140 - val_loss: 0.3088 - val_accuracy: 0.9380\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5738 - accuracy: 0.8157 - val_loss: 0.3096 - val_accuracy: 0.9377\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5625 - accuracy: 0.8255 - val_loss: 0.3057 - val_accuracy: 0.9413\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.8245 - val_loss: 0.3050 - val_accuracy: 0.9428\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5469 - accuracy: 0.8297 - val_loss: 0.3067 - val_accuracy: 0.9431\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5306 - accuracy: 0.8333 - val_loss: 0.3027 - val_accuracy: 0.9438\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5294 - accuracy: 0.8352 - val_loss: 0.2951 - val_accuracy: 0.9451\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5257 - accuracy: 0.8387 - val_loss: 0.3139 - val_accuracy: 0.9452\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5118 - accuracy: 0.8435 - val_loss: 0.3057 - val_accuracy: 0.9470\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.8430 - val_loss: 0.3068 - val_accuracy: 0.9469\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5015 - accuracy: 0.8426 - val_loss: 0.3072 - val_accuracy: 0.9457\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.2976 - accuracy: 0.1209 - val_loss: 2.1982 - val_accuracy: 0.3688\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.1666 - accuracy: 0.2183 - val_loss: 1.7837 - val_accuracy: 0.3741\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9008 - accuracy: 0.3046 - val_loss: 1.4441 - val_accuracy: 0.5299\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6636 - accuracy: 0.3922 - val_loss: 1.1698 - val_accuracy: 0.6143\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4816 - accuracy: 0.4592 - val_loss: 0.9896 - val_accuracy: 0.6910\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3207 - accuracy: 0.5223 - val_loss: 0.8614 - val_accuracy: 0.7637\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2097 - accuracy: 0.5774 - val_loss: 0.7432 - val_accuracy: 0.8058\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1077 - accuracy: 0.6188 - val_loss: 0.6562 - val_accuracy: 0.8317\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0177 - accuracy: 0.6603 - val_loss: 0.5893 - val_accuracy: 0.8454\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9494 - accuracy: 0.6886 - val_loss: 0.5459 - val_accuracy: 0.8533\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9008 - accuracy: 0.7045 - val_loss: 0.5079 - val_accuracy: 0.8612\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8484 - accuracy: 0.7247 - val_loss: 0.4809 - val_accuracy: 0.8733\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8088 - accuracy: 0.7435 - val_loss: 0.4560 - val_accuracy: 0.8796\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7800 - accuracy: 0.7535 - val_loss: 0.4387 - val_accuracy: 0.8863\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7563 - accuracy: 0.7632 - val_loss: 0.4208 - val_accuracy: 0.8893\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7059 - accuracy: 0.7766 - val_loss: 0.4018 - val_accuracy: 0.8944\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.7855 - val_loss: 0.3854 - val_accuracy: 0.9007\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6603 - accuracy: 0.8008 - val_loss: 0.3713 - val_accuracy: 0.9048\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6446 - accuracy: 0.8001 - val_loss: 0.3587 - val_accuracy: 0.9078\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6165 - accuracy: 0.8153 - val_loss: 0.3466 - val_accuracy: 0.9115\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6071 - accuracy: 0.8163 - val_loss: 0.3371 - val_accuracy: 0.9161\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5772 - accuracy: 0.8260 - val_loss: 0.3268 - val_accuracy: 0.9178\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5582 - accuracy: 0.8305 - val_loss: 0.3166 - val_accuracy: 0.9202\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5412 - accuracy: 0.8379 - val_loss: 0.3078 - val_accuracy: 0.9223\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5203 - accuracy: 0.8458 - val_loss: 0.3022 - val_accuracy: 0.9232\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5020 - accuracy: 0.8510 - val_loss: 0.2972 - val_accuracy: 0.9232\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5018 - accuracy: 0.8522 - val_loss: 0.2906 - val_accuracy: 0.9272\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5017 - accuracy: 0.8514 - val_loss: 0.2834 - val_accuracy: 0.9277\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4811 - accuracy: 0.8589 - val_loss: 0.2761 - val_accuracy: 0.9291\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4724 - accuracy: 0.8634 - val_loss: 0.2732 - val_accuracy: 0.9310\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4660 - accuracy: 0.8678 - val_loss: 0.2685 - val_accuracy: 0.9308\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4422 - accuracy: 0.8686 - val_loss: 0.2656 - val_accuracy: 0.9334\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4337 - accuracy: 0.8737 - val_loss: 0.2622 - val_accuracy: 0.9348\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4201 - accuracy: 0.8767 - val_loss: 0.2591 - val_accuracy: 0.9355\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.8812 - val_loss: 0.2540 - val_accuracy: 0.9359\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4063 - accuracy: 0.8839 - val_loss: 0.2522 - val_accuracy: 0.9370\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3919 - accuracy: 0.8848 - val_loss: 0.2539 - val_accuracy: 0.9377\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3900 - accuracy: 0.8892 - val_loss: 0.2492 - val_accuracy: 0.9383\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3636 - accuracy: 0.8913 - val_loss: 0.2414 - val_accuracy: 0.9392\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3706 - accuracy: 0.8954 - val_loss: 0.2419 - val_accuracy: 0.9403\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3635 - accuracy: 0.8957 - val_loss: 0.2426 - val_accuracy: 0.9411\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8989 - val_loss: 0.2420 - val_accuracy: 0.9411\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3550 - accuracy: 0.8979 - val_loss: 0.2397 - val_accuracy: 0.9423\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8996 - val_loss: 0.2417 - val_accuracy: 0.9419\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3268 - accuracy: 0.9089 - val_loss: 0.2413 - val_accuracy: 0.9442\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3222 - accuracy: 0.9087 - val_loss: 0.2388 - val_accuracy: 0.9425\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.9072 - val_loss: 0.2375 - val_accuracy: 0.9442\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3130 - accuracy: 0.9108 - val_loss: 0.2352 - val_accuracy: 0.9450\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3113 - accuracy: 0.9146 - val_loss: 0.2376 - val_accuracy: 0.9439\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3070 - accuracy: 0.9121 - val_loss: 0.2322 - val_accuracy: 0.9463\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.1227 - accuracy: 0.2307 - val_loss: 1.1792 - val_accuracy: 0.6729\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4920 - accuracy: 0.4744 - val_loss: 0.8478 - val_accuracy: 0.7684\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2517 - accuracy: 0.5669 - val_loss: 0.6688 - val_accuracy: 0.8315\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1084 - accuracy: 0.6207 - val_loss: 0.5506 - val_accuracy: 0.8564\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9917 - accuracy: 0.6711 - val_loss: 0.4908 - val_accuracy: 0.8698\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9155 - accuracy: 0.7017 - val_loss: 0.4571 - val_accuracy: 0.8783\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8822 - accuracy: 0.7155 - val_loss: 0.4268 - val_accuracy: 0.8841\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8391 - accuracy: 0.7315 - val_loss: 0.4090 - val_accuracy: 0.8866\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8063 - accuracy: 0.7462 - val_loss: 0.3930 - val_accuracy: 0.8899\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7823 - accuracy: 0.7597 - val_loss: 0.3783 - val_accuracy: 0.8934\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7559 - accuracy: 0.7678 - val_loss: 0.3665 - val_accuracy: 0.8984\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7270 - accuracy: 0.7754 - val_loss: 0.3550 - val_accuracy: 0.8996\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7103 - accuracy: 0.7842 - val_loss: 0.3476 - val_accuracy: 0.9013\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6790 - accuracy: 0.7955 - val_loss: 0.3384 - val_accuracy: 0.9020\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6667 - accuracy: 0.8021 - val_loss: 0.3316 - val_accuracy: 0.9056\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6582 - accuracy: 0.8033 - val_loss: 0.3256 - val_accuracy: 0.9057\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6280 - accuracy: 0.8155 - val_loss: 0.3198 - val_accuracy: 0.9080\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6309 - accuracy: 0.8175 - val_loss: 0.3121 - val_accuracy: 0.9099\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6210 - accuracy: 0.8211 - val_loss: 0.3107 - val_accuracy: 0.9110\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.8288 - val_loss: 0.3014 - val_accuracy: 0.9110\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5962 - accuracy: 0.8271 - val_loss: 0.2979 - val_accuracy: 0.9121\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5810 - accuracy: 0.8352 - val_loss: 0.2945 - val_accuracy: 0.9148\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5794 - accuracy: 0.8332 - val_loss: 0.2925 - val_accuracy: 0.9151\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5639 - accuracy: 0.8432 - val_loss: 0.2876 - val_accuracy: 0.9156\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5501 - accuracy: 0.8414 - val_loss: 0.2849 - val_accuracy: 0.9168\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5428 - accuracy: 0.8483 - val_loss: 0.2828 - val_accuracy: 0.9173\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5399 - accuracy: 0.8499 - val_loss: 0.2793 - val_accuracy: 0.9168\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5190 - accuracy: 0.8566 - val_loss: 0.2766 - val_accuracy: 0.9197\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5197 - accuracy: 0.8525 - val_loss: 0.2745 - val_accuracy: 0.9214\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5125 - accuracy: 0.8579 - val_loss: 0.2736 - val_accuracy: 0.9225\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4962 - accuracy: 0.8614 - val_loss: 0.2726 - val_accuracy: 0.9225\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4970 - accuracy: 0.8637 - val_loss: 0.2640 - val_accuracy: 0.9230\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4911 - accuracy: 0.8628 - val_loss: 0.2626 - val_accuracy: 0.9258\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4785 - accuracy: 0.8677 - val_loss: 0.2600 - val_accuracy: 0.9262\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4750 - accuracy: 0.8710 - val_loss: 0.2554 - val_accuracy: 0.9281\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4709 - accuracy: 0.8693 - val_loss: 0.2533 - val_accuracy: 0.9274\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4564 - accuracy: 0.8745 - val_loss: 0.2524 - val_accuracy: 0.9294\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4600 - accuracy: 0.8744 - val_loss: 0.2490 - val_accuracy: 0.9298\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4469 - accuracy: 0.8776 - val_loss: 0.2504 - val_accuracy: 0.9304\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4309 - accuracy: 0.8813 - val_loss: 0.2452 - val_accuracy: 0.9301\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4365 - accuracy: 0.8828 - val_loss: 0.2431 - val_accuracy: 0.9324\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4338 - accuracy: 0.8827 - val_loss: 0.2412 - val_accuracy: 0.9336\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4327 - accuracy: 0.8835 - val_loss: 0.2414 - val_accuracy: 0.9337\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4167 - accuracy: 0.8869 - val_loss: 0.2391 - val_accuracy: 0.9344\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4166 - accuracy: 0.8860 - val_loss: 0.2371 - val_accuracy: 0.9355\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4072 - accuracy: 0.8881 - val_loss: 0.2356 - val_accuracy: 0.9362\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8896 - val_loss: 0.2357 - val_accuracy: 0.9352\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3933 - accuracy: 0.8946 - val_loss: 0.2342 - val_accuracy: 0.9367\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3966 - accuracy: 0.8915 - val_loss: 0.2301 - val_accuracy: 0.9381\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3930 - accuracy: 0.8936 - val_loss: 0.2290 - val_accuracy: 0.9386\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.2193 - accuracy: 0.3141 - val_loss: 0.7031 - val_accuracy: 0.7968\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3007 - accuracy: 0.5545 - val_loss: 0.5364 - val_accuracy: 0.8558\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0819 - accuracy: 0.6294 - val_loss: 0.4729 - val_accuracy: 0.8695\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9521 - accuracy: 0.6841 - val_loss: 0.4302 - val_accuracy: 0.8784\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8780 - accuracy: 0.7108 - val_loss: 0.4060 - val_accuracy: 0.8831\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8267 - accuracy: 0.7382 - val_loss: 0.3919 - val_accuracy: 0.8867\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7862 - accuracy: 0.7569 - val_loss: 0.3707 - val_accuracy: 0.8909\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7551 - accuracy: 0.7689 - val_loss: 0.3590 - val_accuracy: 0.8933\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7157 - accuracy: 0.7846 - val_loss: 0.3479 - val_accuracy: 0.8962\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7084 - accuracy: 0.7865 - val_loss: 0.3407 - val_accuracy: 0.8980\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6859 - accuracy: 0.7949 - val_loss: 0.3333 - val_accuracy: 0.8992\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6628 - accuracy: 0.8051 - val_loss: 0.3287 - val_accuracy: 0.9014\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6521 - accuracy: 0.8084 - val_loss: 0.3221 - val_accuracy: 0.9042\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6315 - accuracy: 0.8184 - val_loss: 0.3170 - val_accuracy: 0.9053\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6172 - accuracy: 0.8230 - val_loss: 0.3135 - val_accuracy: 0.9059\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6107 - accuracy: 0.8235 - val_loss: 0.3128 - val_accuracy: 0.9073\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5929 - accuracy: 0.8316 - val_loss: 0.3044 - val_accuracy: 0.9079\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5923 - accuracy: 0.8351 - val_loss: 0.2993 - val_accuracy: 0.9109\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5781 - accuracy: 0.8348 - val_loss: 0.2986 - val_accuracy: 0.9108\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5720 - accuracy: 0.8391 - val_loss: 0.2948 - val_accuracy: 0.9110\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5496 - accuracy: 0.8464 - val_loss: 0.2906 - val_accuracy: 0.9130\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5371 - accuracy: 0.8502 - val_loss: 0.2904 - val_accuracy: 0.9133\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5442 - accuracy: 0.8477 - val_loss: 0.2846 - val_accuracy: 0.9147\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5423 - accuracy: 0.8486 - val_loss: 0.2823 - val_accuracy: 0.9158\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5258 - accuracy: 0.8535 - val_loss: 0.2822 - val_accuracy: 0.9163\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5096 - accuracy: 0.8577 - val_loss: 0.2783 - val_accuracy: 0.9161\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5119 - accuracy: 0.8584 - val_loss: 0.2767 - val_accuracy: 0.9171\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5025 - accuracy: 0.8597 - val_loss: 0.2763 - val_accuracy: 0.9174\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4975 - accuracy: 0.8634 - val_loss: 0.2728 - val_accuracy: 0.9199\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4860 - accuracy: 0.8653 - val_loss: 0.2706 - val_accuracy: 0.9215\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4895 - accuracy: 0.8654 - val_loss: 0.2670 - val_accuracy: 0.9209\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4819 - accuracy: 0.8678 - val_loss: 0.2659 - val_accuracy: 0.9217\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4709 - accuracy: 0.8690 - val_loss: 0.2661 - val_accuracy: 0.9227\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4644 - accuracy: 0.8723 - val_loss: 0.2631 - val_accuracy: 0.9232\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4668 - accuracy: 0.8720 - val_loss: 0.2589 - val_accuracy: 0.9235\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4551 - accuracy: 0.8753 - val_loss: 0.2576 - val_accuracy: 0.9250\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4614 - accuracy: 0.8743 - val_loss: 0.2591 - val_accuracy: 0.9242\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4541 - accuracy: 0.8736 - val_loss: 0.2545 - val_accuracy: 0.9263\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4470 - accuracy: 0.8772 - val_loss: 0.2526 - val_accuracy: 0.9265\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4473 - accuracy: 0.8806 - val_loss: 0.2539 - val_accuracy: 0.9273\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4293 - accuracy: 0.8845 - val_loss: 0.2521 - val_accuracy: 0.9277\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4275 - accuracy: 0.8847 - val_loss: 0.2499 - val_accuracy: 0.9289\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4341 - accuracy: 0.8820 - val_loss: 0.2472 - val_accuracy: 0.9294\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4321 - accuracy: 0.8845 - val_loss: 0.2469 - val_accuracy: 0.9302\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4312 - accuracy: 0.8856 - val_loss: 0.2496 - val_accuracy: 0.9293\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4187 - accuracy: 0.8859 - val_loss: 0.2441 - val_accuracy: 0.9298\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4112 - accuracy: 0.8869 - val_loss: 0.2458 - val_accuracy: 0.9295\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4003 - accuracy: 0.8894 - val_loss: 0.2455 - val_accuracy: 0.9303\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4029 - accuracy: 0.8917 - val_loss: 0.2434 - val_accuracy: 0.9309\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4007 - accuracy: 0.8915 - val_loss: 0.2383 - val_accuracy: 0.9332\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3022 - accuracy: 0.1113 - val_loss: 2.2994 - val_accuracy: 0.1063\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2978 - accuracy: 0.1299 - val_loss: 2.2953 - val_accuracy: 0.1061\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2936 - accuracy: 0.1274 - val_loss: 2.2896 - val_accuracy: 0.1064\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2867 - accuracy: 0.1322 - val_loss: 2.2786 - val_accuracy: 0.1233\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2732 - accuracy: 0.1516 - val_loss: 2.2416 - val_accuracy: 0.2121\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2167 - accuracy: 0.2064 - val_loss: 2.0503 - val_accuracy: 0.3460\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0682 - accuracy: 0.2613 - val_loss: 1.8376 - val_accuracy: 0.4247\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9275 - accuracy: 0.3126 - val_loss: 1.6644 - val_accuracy: 0.4975\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7983 - accuracy: 0.3598 - val_loss: 1.4735 - val_accuracy: 0.5400\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6663 - accuracy: 0.4134 - val_loss: 1.3057 - val_accuracy: 0.5717\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5457 - accuracy: 0.4522 - val_loss: 1.1813 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4373 - accuracy: 0.4868 - val_loss: 1.0893 - val_accuracy: 0.6463\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3558 - accuracy: 0.5183 - val_loss: 1.0165 - val_accuracy: 0.6711\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3077 - accuracy: 0.5390 - val_loss: 0.9530 - val_accuracy: 0.7035\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2416 - accuracy: 0.5672 - val_loss: 0.9023 - val_accuracy: 0.7362\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1874 - accuracy: 0.5968 - val_loss: 0.8426 - val_accuracy: 0.7682\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1459 - accuracy: 0.6101 - val_loss: 0.7799 - val_accuracy: 0.8098\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0949 - accuracy: 0.6396 - val_loss: 0.7244 - val_accuracy: 0.8274\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0526 - accuracy: 0.6616 - val_loss: 0.6766 - val_accuracy: 0.8387\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0152 - accuracy: 0.6693 - val_loss: 0.6386 - val_accuracy: 0.8506\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9659 - accuracy: 0.6903 - val_loss: 0.6022 - val_accuracy: 0.8597\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9473 - accuracy: 0.6993 - val_loss: 0.5760 - val_accuracy: 0.8639\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9250 - accuracy: 0.7083 - val_loss: 0.5558 - val_accuracy: 0.8713\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8941 - accuracy: 0.7185 - val_loss: 0.5334 - val_accuracy: 0.8758\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8680 - accuracy: 0.7273 - val_loss: 0.5159 - val_accuracy: 0.8790\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8345 - accuracy: 0.7363 - val_loss: 0.4991 - val_accuracy: 0.8839\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8301 - accuracy: 0.7420 - val_loss: 0.4859 - val_accuracy: 0.8852\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8037 - accuracy: 0.7498 - val_loss: 0.4698 - val_accuracy: 0.8898\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7919 - accuracy: 0.7510 - val_loss: 0.4557 - val_accuracy: 0.8942\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7736 - accuracy: 0.7621 - val_loss: 0.4407 - val_accuracy: 0.8982\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7627 - accuracy: 0.7655 - val_loss: 0.4334 - val_accuracy: 0.8963\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7394 - accuracy: 0.7762 - val_loss: 0.4182 - val_accuracy: 0.9011\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7195 - accuracy: 0.7831 - val_loss: 0.4078 - val_accuracy: 0.9018\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7159 - accuracy: 0.7830 - val_loss: 0.3990 - val_accuracy: 0.9070\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6937 - accuracy: 0.7864 - val_loss: 0.3892 - val_accuracy: 0.9072\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6836 - accuracy: 0.7930 - val_loss: 0.3783 - val_accuracy: 0.9103\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6669 - accuracy: 0.7980 - val_loss: 0.3685 - val_accuracy: 0.9141\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6539 - accuracy: 0.7999 - val_loss: 0.3618 - val_accuracy: 0.9145\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6464 - accuracy: 0.8061 - val_loss: 0.3539 - val_accuracy: 0.9169\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6263 - accuracy: 0.8098 - val_loss: 0.3463 - val_accuracy: 0.9188\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6268 - accuracy: 0.8096 - val_loss: 0.3423 - val_accuracy: 0.9208\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6139 - accuracy: 0.8186 - val_loss: 0.3357 - val_accuracy: 0.9231\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6001 - accuracy: 0.8192 - val_loss: 0.3269 - val_accuracy: 0.9246\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5837 - accuracy: 0.8243 - val_loss: 0.3211 - val_accuracy: 0.9259\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5798 - accuracy: 0.8259 - val_loss: 0.3178 - val_accuracy: 0.9267\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5671 - accuracy: 0.8300 - val_loss: 0.3095 - val_accuracy: 0.9279\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5651 - accuracy: 0.8291 - val_loss: 0.3031 - val_accuracy: 0.9296\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5560 - accuracy: 0.8306 - val_loss: 0.3016 - val_accuracy: 0.9310\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5320 - accuracy: 0.8399 - val_loss: 0.2965 - val_accuracy: 0.9316\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5297 - accuracy: 0.8427 - val_loss: 0.2934 - val_accuracy: 0.9331\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3025 - accuracy: 0.1054 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2981 - accuracy: 0.1273 - val_loss: 2.2955 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2940 - accuracy: 0.1273 - val_loss: 2.2907 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2884 - accuracy: 0.1350 - val_loss: 2.2833 - val_accuracy: 0.1156\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2806 - accuracy: 0.1607 - val_loss: 2.2687 - val_accuracy: 0.1798\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2630 - accuracy: 0.2004 - val_loss: 2.2255 - val_accuracy: 0.2888\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2074 - accuracy: 0.2221 - val_loss: 2.0741 - val_accuracy: 0.2285\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0903 - accuracy: 0.2329 - val_loss: 1.9242 - val_accuracy: 0.3155\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9815 - accuracy: 0.2844 - val_loss: 1.7300 - val_accuracy: 0.4282\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8191 - accuracy: 0.3514 - val_loss: 1.5066 - val_accuracy: 0.4879\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6706 - accuracy: 0.4028 - val_loss: 1.3146 - val_accuracy: 0.5724\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5448 - accuracy: 0.4586 - val_loss: 1.1629 - val_accuracy: 0.6470\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4343 - accuracy: 0.5004 - val_loss: 1.0381 - val_accuracy: 0.6994\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3447 - accuracy: 0.5363 - val_loss: 0.9317 - val_accuracy: 0.7361\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2575 - accuracy: 0.5743 - val_loss: 0.8461 - val_accuracy: 0.7675\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1842 - accuracy: 0.6016 - val_loss: 0.7737 - val_accuracy: 0.7889\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1258 - accuracy: 0.6211 - val_loss: 0.7165 - val_accuracy: 0.8083\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0726 - accuracy: 0.6435 - val_loss: 0.6665 - val_accuracy: 0.8224\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0245 - accuracy: 0.6624 - val_loss: 0.6264 - val_accuracy: 0.8367\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9907 - accuracy: 0.6738 - val_loss: 0.5959 - val_accuracy: 0.8454\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9491 - accuracy: 0.6918 - val_loss: 0.5678 - val_accuracy: 0.8526\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9260 - accuracy: 0.7002 - val_loss: 0.5481 - val_accuracy: 0.8564\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9019 - accuracy: 0.7075 - val_loss: 0.5320 - val_accuracy: 0.8606\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8742 - accuracy: 0.7181 - val_loss: 0.5166 - val_accuracy: 0.8658\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8548 - accuracy: 0.7255 - val_loss: 0.5056 - val_accuracy: 0.8692\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8423 - accuracy: 0.7289 - val_loss: 0.4929 - val_accuracy: 0.8733\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8189 - accuracy: 0.7399 - val_loss: 0.4833 - val_accuracy: 0.8763\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8003 - accuracy: 0.7444 - val_loss: 0.4727 - val_accuracy: 0.8788\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7894 - accuracy: 0.7501 - val_loss: 0.4599 - val_accuracy: 0.8820\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7713 - accuracy: 0.7573 - val_loss: 0.4511 - val_accuracy: 0.8842\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7631 - accuracy: 0.7578 - val_loss: 0.4410 - val_accuracy: 0.8865\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7482 - accuracy: 0.7623 - val_loss: 0.4330 - val_accuracy: 0.8884\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7427 - accuracy: 0.7685 - val_loss: 0.4225 - val_accuracy: 0.8928\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7271 - accuracy: 0.7733 - val_loss: 0.4136 - val_accuracy: 0.8955\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7193 - accuracy: 0.7743 - val_loss: 0.4057 - val_accuracy: 0.8961\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6943 - accuracy: 0.7837 - val_loss: 0.3974 - val_accuracy: 0.8981\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6963 - accuracy: 0.7860 - val_loss: 0.3896 - val_accuracy: 0.8994\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6798 - accuracy: 0.7910 - val_loss: 0.3791 - val_accuracy: 0.9023\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6611 - accuracy: 0.7966 - val_loss: 0.3712 - val_accuracy: 0.9042\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6522 - accuracy: 0.7940 - val_loss: 0.3630 - val_accuracy: 0.9080\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6495 - accuracy: 0.8022 - val_loss: 0.3588 - val_accuracy: 0.9089\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6411 - accuracy: 0.8035 - val_loss: 0.3496 - val_accuracy: 0.9119\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6303 - accuracy: 0.8106 - val_loss: 0.3409 - val_accuracy: 0.9137\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6239 - accuracy: 0.8129 - val_loss: 0.3345 - val_accuracy: 0.9148\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6162 - accuracy: 0.8096 - val_loss: 0.3303 - val_accuracy: 0.9167\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6115 - accuracy: 0.8117 - val_loss: 0.3247 - val_accuracy: 0.9194\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6011 - accuracy: 0.8186 - val_loss: 0.3205 - val_accuracy: 0.9205\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5909 - accuracy: 0.8203 - val_loss: 0.3111 - val_accuracy: 0.9210\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5826 - accuracy: 0.8236 - val_loss: 0.3097 - val_accuracy: 0.9213\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5715 - accuracy: 0.8264 - val_loss: 0.3016 - val_accuracy: 0.9234\n",
            "{'loss': [1.8454041481018066, 1.42039155960083, 1.2382256984710693, 1.108667016029358, 1.03003990650177, 0.9635924696922302, 0.90786212682724, 0.8733683228492737, 0.8362956643104553, 0.8125432133674622, 0.7892394065856934, 0.7639080286026001, 0.7409355640411377, 0.7238824963569641, 0.7099558115005493, 0.6991657018661499, 0.6833059191703796, 0.6634217500686646, 0.6605589985847473, 0.6444581151008606, 0.6360862851142883, 0.6285199522972107, 0.613720715045929, 0.6048371195793152, 0.5944880247116089, 0.5939048528671265, 0.586113452911377, 0.5803745985031128, 0.569723904132843, 0.5588852763175964, 0.5468999147415161, 0.5527958273887634, 0.5479909181594849, 0.5399255752563477, 0.532143771648407, 0.5239874124526978, 0.5282557606697083, 0.5225939750671387, 0.5128834247589111, 0.5075439810752869, 0.5030277371406555, 0.5009980201721191, 0.4995364546775818, 0.4954454004764557, 0.48728975653648376, 0.48323294520378113, 0.4744400680065155, 0.48566731810569763, 0.47126567363739014, 0.4667101502418518], 'accuracy': [0.3371041715145111, 0.5138541460037231, 0.5855208039283752, 0.6347708106040955, 0.6623958349227905, 0.6913541555404663, 0.7123958468437195, 0.7261458039283752, 0.7386666536331177, 0.7490000128746033, 0.7594583630561829, 0.7688541412353516, 0.7759583592414856, 0.7852500081062317, 0.7915416955947876, 0.7947499752044678, 0.801687479019165, 0.8088333606719971, 0.8126875162124634, 0.8167083263397217, 0.82052081823349, 0.823395848274231, 0.8270000219345093, 0.8308125138282776, 0.835854172706604, 0.8373541831970215, 0.8376458287239075, 0.8415833115577698, 0.8428750038146973, 0.8477083444595337, 0.8501458168029785, 0.8482916951179504, 0.8521666526794434, 0.854645848274231, 0.8565000295639038, 0.859499990940094, 0.859083354473114, 0.8611249923706055, 0.862375020980835, 0.8649166822433472, 0.8636458516120911, 0.867062509059906, 0.8677291870117188, 0.8694375157356262, 0.8708333373069763, 0.871791660785675, 0.875249981880188, 0.8709375262260437, 0.8736458420753479, 0.8778958320617676], 'val_loss': [1.1870431900024414, 0.8953219652175903, 0.7343879342079163, 0.6299718618392944, 0.5649270415306091, 0.5135830044746399, 0.48058682680130005, 0.45355817675590515, 0.43488821387290955, 0.41905951499938965, 0.40373528003692627, 0.3913295865058899, 0.38340693712234497, 0.37453266978263855, 0.3684740662574768, 0.3626549541950226, 0.35275790095329285, 0.3503589332103729, 0.3471222221851349, 0.3419128358364105, 0.3384614586830139, 0.3356756567955017, 0.3309474587440491, 0.32901304960250854, 0.32634568214416504, 0.32581961154937744, 0.32221847772598267, 0.32053399085998535, 0.3188726305961609, 0.3165509104728699, 0.3173830807209015, 0.3150447905063629, 0.3118954598903656, 0.30952030420303345, 0.3079736828804016, 0.307694673538208, 0.3041677176952362, 0.3018023669719696, 0.30079808831214905, 0.30035558342933655, 0.3017122447490692, 0.2988901436328888, 0.29810839891433716, 0.29491862654685974, 0.29319989681243896, 0.292824387550354, 0.29122787714004517, 0.28851380944252014, 0.28806746006011963, 0.28259333968162537], 'val_accuracy': [0.7122499942779541, 0.7964166402816772, 0.8319166898727417, 0.8520833253860474, 0.8605833053588867, 0.8700000047683716, 0.875, 0.8800833225250244, 0.8835833072662354, 0.8870833516120911, 0.89083331823349, 0.8949999809265137, 0.8958333134651184, 0.8979166746139526, 0.8988333344459534, 0.8999999761581421, 0.903249979019165, 0.9042500257492065, 0.9049166440963745, 0.9068333506584167, 0.9070833325386047, 0.906333327293396, 0.909583330154419, 0.9100000262260437, 0.9109166860580444, 0.9118333458900452, 0.9125833511352539, 0.9135000109672546, 0.9148333072662354, 0.9156666398048401, 0.9159166812896729, 0.9155833125114441, 0.9178333282470703, 0.9178333282470703, 0.9190000295639038, 0.918749988079071, 0.9195833206176758, 0.9210000038146973, 0.9212499856948853, 0.9213333129882812, 0.9209166765213013, 0.92166668176651, 0.9240000247955322, 0.9233333468437195, 0.9239166378974915, 0.9256666898727417, 0.9256666898727417, 0.9267500042915344, 0.9270833134651184, 0.9282500147819519]}\n",
            "{'loss': [2.299541473388672, 2.273699998855591, 2.178274631500244, 2.01531720161438, 1.8922845125198364, 1.7845906019210815, 1.662096381187439, 1.5377639532089233, 1.4335497617721558, 1.3477824926376343, 1.2727752923965454, 1.2051582336425781, 1.1549650430679321, 1.1171486377716064, 1.0663090944290161, 1.0293962955474854, 1.002062201499939, 0.9697878360748291, 0.9422219395637512, 0.9084979891777039, 0.8876616954803467, 0.8602763414382935, 0.8540544509887695, 0.8163350224494934, 0.8098621964454651, 0.7830019593238831, 0.7609058618545532, 0.7481997609138489, 0.7314732074737549, 0.7124335169792175, 0.7111750245094299, 0.6838755011558533, 0.6755337119102478, 0.663568913936615, 0.6440751552581787, 0.6293490529060364, 0.6177192330360413, 0.6075029373168945, 0.6070423126220703, 0.593001663684845, 0.5802887082099915, 0.5675708651542664, 0.5536726117134094, 0.5486995577812195, 0.536098837852478, 0.5331066250801086, 0.5226226449012756, 0.5163404941558838, 0.5091872811317444, 0.5025926232337952], 'accuracy': [0.11906249821186066, 0.14912499487400055, 0.20418749749660492, 0.26106250286102295, 0.30258333683013916, 0.34427082538604736, 0.38874998688697815, 0.4337916672229767, 0.47483333945274353, 0.5086249709129333, 0.542187511920929, 0.5714374780654907, 0.5952083468437195, 0.6111458539962769, 0.6268333196640015, 0.6433749794960022, 0.6545208096504211, 0.667062520980835, 0.6742291450500488, 0.6898958086967468, 0.700166642665863, 0.7080416679382324, 0.7163958549499512, 0.7281875014305115, 0.7330416440963745, 0.7452916502952576, 0.7522291541099548, 0.7577499747276306, 0.7623541951179504, 0.7694374918937683, 0.7720416784286499, 0.7818958163261414, 0.784416675567627, 0.7910208106040955, 0.79708331823349, 0.8028125166893005, 0.8061458468437195, 0.8107708096504211, 0.8091041445732117, 0.8153541684150696, 0.8175833225250244, 0.8238750100135803, 0.8291875123977661, 0.8296041488647461, 0.8332083225250244, 0.8355208039283752, 0.8385208249092102, 0.840416669845581, 0.8429791927337646, 0.8437708616256714], 'val_loss': [2.2781150341033936, 2.2002718448638916, 1.955378532409668, 1.7562593221664429, 1.6137090921401978, 1.4715787172317505, 1.3025749921798706, 1.1579493284225464, 1.0597440004348755, 0.9662829637527466, 0.8977271318435669, 0.8302716612815857, 0.768403947353363, 0.7242046594619751, 0.6766431331634521, 0.6323491334915161, 0.6083183884620667, 0.5773665904998779, 0.5475595593452454, 0.525590717792511, 0.5093591213226318, 0.4843417704105377, 0.464506059885025, 0.44664305448532104, 0.431784063577652, 0.4174014925956726, 0.403237909078598, 0.3927745223045349, 0.3816152811050415, 0.36902403831481934, 0.362450510263443, 0.351765900850296, 0.35092127323150635, 0.33940690755844116, 0.3332440257072449, 0.32309195399284363, 0.32912006974220276, 0.3230639100074768, 0.3135666251182556, 0.30875250697135925, 0.3096468448638916, 0.3057482838630676, 0.30499809980392456, 0.3066801428794861, 0.3027034103870392, 0.29506075382232666, 0.31388339400291443, 0.30573341250419617, 0.3068467676639557, 0.3072415888309479], 'val_accuracy': [0.2801666557788849, 0.34191668033599854, 0.39233332872390747, 0.4309166669845581, 0.4803333282470703, 0.5275833606719971, 0.590833306312561, 0.6543333530426025, 0.7138333320617676, 0.7676666378974915, 0.7662500143051147, 0.7963333129882812, 0.8159166574478149, 0.8229166865348816, 0.8223333358764648, 0.8321666717529297, 0.8544999957084656, 0.859666645526886, 0.8682500123977661, 0.8774166703224182, 0.8799999952316284, 0.8966666460037231, 0.8983333110809326, 0.9056666493415833, 0.9108333587646484, 0.9144999980926514, 0.9177500009536743, 0.9190833568572998, 0.922166645526886, 0.9242500066757202, 0.9272500276565552, 0.9295833110809326, 0.9301666617393494, 0.934416651725769, 0.9333333373069763, 0.9357500076293945, 0.9349166750907898, 0.9365833401679993, 0.937666654586792, 0.9380000233650208, 0.937666654586792, 0.9413333535194397, 0.9428333044052124, 0.9430833458900452, 0.9437500238418579, 0.9450833201408386, 0.9451666474342346, 0.9470000267028809, 0.9469166398048401, 0.9456666707992554]}\n",
            "{'loss': [2.278836488723755, 2.0984532833099365, 1.8343746662139893, 1.6124619245529175, 1.4383076429367065, 1.2950161695480347, 1.1807258129119873, 1.0846441984176636, 0.9971901774406433, 0.9348942637443542, 0.8793559670448303, 0.8399174809455872, 0.8018288016319275, 0.7714685797691345, 0.7396382093429565, 0.7078437209129333, 0.6814206838607788, 0.6560769081115723, 0.6375872492790222, 0.6151812076568604, 0.5987523794174194, 0.5835155248641968, 0.5697103142738342, 0.5416843295097351, 0.5259085297584534, 0.5100634098052979, 0.5051202178001404, 0.49353817105293274, 0.47964218258857727, 0.46716663241386414, 0.4596714675426483, 0.4376717209815979, 0.43043339252471924, 0.41379252076148987, 0.41406023502349854, 0.40125879645347595, 0.3904276490211487, 0.3841484487056732, 0.3763817846775055, 0.3669905960559845, 0.35810738801956177, 0.35010775923728943, 0.3484308123588562, 0.3388049006462097, 0.33039355278015137, 0.3237934708595276, 0.32219937443733215, 0.3104298412799835, 0.3049938678741455, 0.3051075339317322], 'accuracy': [0.14295832812786102, 0.24025000631809235, 0.32906249165534973, 0.4088541567325592, 0.47843751311302185, 0.53885418176651, 0.5899791717529297, 0.6304583549499512, 0.6677500009536743, 0.6932916641235352, 0.7118124961853027, 0.7300000190734863, 0.7432708144187927, 0.7572500109672546, 0.7672708630561829, 0.7792916893959045, 0.7898541688919067, 0.7990624904632568, 0.8035833239555359, 0.8143125176429749, 0.819937527179718, 0.8261041641235352, 0.8295624852180481, 0.8394583463668823, 0.8453124761581421, 0.8486666679382324, 0.8521249890327454, 0.8541874885559082, 0.8599374890327454, 0.8630833625793457, 0.8682083487510681, 0.8712708353996277, 0.8758541941642761, 0.878125011920929, 0.8817083239555359, 0.8853750228881836, 0.886145830154419, 0.8894583582878113, 0.8909375071525574, 0.8962500095367432, 0.8971250057220459, 0.8999166488647461, 0.8996666669845581, 0.9012916684150696, 0.9071666598320007, 0.9086874723434448, 0.9075416922569275, 0.910770833492279, 0.9144166707992554, 0.9134791493415833], 'val_loss': [2.198219060897827, 1.7837194204330444, 1.4441416263580322, 1.1698402166366577, 0.9896156191825867, 0.8614386916160583, 0.7431540489196777, 0.6561843752861023, 0.5892931222915649, 0.5458724498748779, 0.5079201459884644, 0.4808555543422699, 0.4560474753379822, 0.43866169452667236, 0.4207924008369446, 0.4017545282840729, 0.3853849172592163, 0.3713495135307312, 0.3586835265159607, 0.3465835452079773, 0.33709052205085754, 0.3268023133277893, 0.3166409432888031, 0.30777332186698914, 0.30221331119537354, 0.29722368717193604, 0.2905968725681305, 0.2834395468235016, 0.27605536580085754, 0.2731517255306244, 0.2685467004776001, 0.2656027376651764, 0.2621881663799286, 0.2590939700603485, 0.2539777159690857, 0.2521776258945465, 0.253868967294693, 0.2492353469133377, 0.24136078357696533, 0.2418854832649231, 0.24256740510463715, 0.242020383477211, 0.23969334363937378, 0.24167656898498535, 0.24131689965724945, 0.23877549171447754, 0.23746559023857117, 0.2352415919303894, 0.23756001889705658, 0.2321527898311615], 'val_accuracy': [0.3688333332538605, 0.37408334016799927, 0.5299166440963745, 0.6143333315849304, 0.6909999847412109, 0.7636666893959045, 0.8058333396911621, 0.8316666483879089, 0.8454166650772095, 0.8533333539962769, 0.8612499833106995, 0.8733333349227905, 0.8795833587646484, 0.8862500190734863, 0.8893333077430725, 0.8944166898727417, 0.9007499814033508, 0.9048333168029785, 0.9077500104904175, 0.9114999771118164, 0.9160833358764648, 0.9178333282470703, 0.9201666712760925, 0.9223333597183228, 0.9231666922569275, 0.9231666922569275, 0.9271666407585144, 0.9276666641235352, 0.9290833473205566, 0.9309999942779541, 0.9307500123977661, 0.9334166646003723, 0.9348333477973938, 0.9355000257492065, 0.9359166622161865, 0.9369999766349792, 0.937749981880188, 0.9382500052452087, 0.9392499923706055, 0.9403333067893982, 0.9410833120346069, 0.9410833120346069, 0.9422500133514404, 0.9419166445732117, 0.9442499876022339, 0.9424999952316284, 0.9441666603088379, 0.9449999928474426, 0.9439166784286499, 0.9463333487510681]}\n",
            "{'loss': [1.9058945178985596, 1.4282662868499756, 1.2155104875564575, 1.0737934112548828, 0.9749001264572144, 0.9099280834197998, 0.8579567670822144, 0.823091447353363, 0.7950274348258972, 0.7681845426559448, 0.7450819611549377, 0.721427321434021, 0.7114517688751221, 0.6801632642745972, 0.6690123081207275, 0.6534426212310791, 0.6382119655609131, 0.627593994140625, 0.6214655637741089, 0.6059833765029907, 0.5960514545440674, 0.5815640091896057, 0.5692240595817566, 0.5615190267562866, 0.5531076788902283, 0.5424887537956238, 0.5326940417289734, 0.5210851430892944, 0.5147461295127869, 0.5087071657180786, 0.49788451194763184, 0.4966188073158264, 0.4882570505142212, 0.48403581976890564, 0.47286662459373474, 0.4675540328025818, 0.4579869508743286, 0.45738285779953003, 0.44383877515792847, 0.4389042854309082, 0.43590036034584045, 0.43409082293510437, 0.4270259141921997, 0.41718789935112, 0.41942861676216125, 0.4038906395435333, 0.4112010896205902, 0.40187206864356995, 0.3974077105522156, 0.39427387714385986], 'accuracy': [0.3189791738986969, 0.49956250190734863, 0.5808333158493042, 0.636062502861023, 0.6778125166893005, 0.7028958201408386, 0.7218541502952576, 0.7370416522026062, 0.74979168176651, 0.7627916932106018, 0.768875002861023, 0.7806458473205566, 0.7848125100135803, 0.7956041693687439, 0.8019166588783264, 0.8058958053588867, 0.8127291798591614, 0.8186041712760925, 0.8198541402816772, 0.825041651725769, 0.8273541927337646, 0.8346666693687439, 0.836229145526886, 0.8425416946411133, 0.8422291874885559, 0.8483333587646484, 0.8501874804496765, 0.8555833101272583, 0.854895830154419, 0.8587083220481873, 0.8612708449363708, 0.8646666407585144, 0.8647291660308838, 0.8667916655540466, 0.8708958625793457, 0.871791660785675, 0.8742708563804626, 0.874958336353302, 0.8783958554267883, 0.8805000185966492, 0.8821874856948853, 0.882937490940094, 0.8838333487510681, 0.8877291679382324, 0.885812520980835, 0.8899166584014893, 0.8899999856948853, 0.8922708630561829, 0.8932916522026062, 0.8933541774749756], 'val_loss': [1.1791623830795288, 0.8478288054466248, 0.6688144207000732, 0.5505639910697937, 0.49083295464515686, 0.4570821225643158, 0.42675256729125977, 0.4090253412723541, 0.3929673731327057, 0.3782788813114166, 0.3664645254611969, 0.3550052344799042, 0.3476448953151703, 0.3384001553058624, 0.3315815329551697, 0.32560715079307556, 0.31981363892555237, 0.3121311366558075, 0.31067392230033875, 0.30140823125839233, 0.2979286015033722, 0.29449135065078735, 0.29252585768699646, 0.28761565685272217, 0.2848542034626007, 0.28276658058166504, 0.27926114201545715, 0.2766011655330658, 0.2745095491409302, 0.27361127734184265, 0.27258560061454773, 0.2639785706996918, 0.26258668303489685, 0.26001253724098206, 0.2554444968700409, 0.2533460557460785, 0.25238847732543945, 0.2489689737558365, 0.2504153847694397, 0.2451966404914856, 0.24306054413318634, 0.2411746382713318, 0.2414078712463379, 0.23908206820487976, 0.23709222674369812, 0.23563902080059052, 0.23567956686019897, 0.23419800400733948, 0.23012293875217438, 0.2289937138557434], 'val_accuracy': [0.6729166507720947, 0.7684166431427002, 0.8314999938011169, 0.856416642665863, 0.8697500228881836, 0.878250002861023, 0.8840833306312561, 0.8865833282470703, 0.8899166584014893, 0.8934166431427002, 0.8984166383743286, 0.8995833396911621, 0.9012500047683716, 0.9020000100135803, 0.9055833220481873, 0.9056666493415833, 0.9079999923706055, 0.9099166393280029, 0.9110000133514404, 0.9110000133514404, 0.9120833277702332, 0.9148333072662354, 0.9150833487510681, 0.9155833125114441, 0.9168333411216736, 0.9173333048820496, 0.9167500138282776, 0.9196666479110718, 0.9214166402816772, 0.9225000143051147, 0.9225000143051147, 0.9229999780654907, 0.9257500171661377, 0.9261666536331177, 0.9280833601951599, 0.9274166822433472, 0.9294166564941406, 0.9297500252723694, 0.9304166436195374, 0.9300833344459534, 0.9324166774749756, 0.9335833191871643, 0.9337499737739563, 0.934416651725769, 0.9355000257492065, 0.9361666440963745, 0.9351666569709778, 0.9367499947547913, 0.9380833506584167, 0.9385833144187927]}\n",
            "{'loss': [1.8129512071609497, 1.2306243181228638, 1.0354835987091064, 0.9300304651260376, 0.8633050322532654, 0.8153775334358215, 0.7754964232444763, 0.7421963810920715, 0.7198189496994019, 0.6997367143630981, 0.676717221736908, 0.6641491055488586, 0.6458615660667419, 0.6271347403526306, 0.6180265545845032, 0.6072936058044434, 0.595339834690094, 0.5851202607154846, 0.5716050267219543, 0.5663223266601562, 0.5503810048103333, 0.5411445498466492, 0.5402377247810364, 0.5339051485061646, 0.524817943572998, 0.5173744559288025, 0.5162034630775452, 0.5041841268539429, 0.5039526224136353, 0.4942004382610321, 0.48464950919151306, 0.4805982708930969, 0.4737790822982788, 0.47217968106269836, 0.46486860513687134, 0.4636533260345459, 0.4565100073814392, 0.4501706659793854, 0.44326087832450867, 0.4423094093799591, 0.43479013442993164, 0.43435612320899963, 0.4330448806285858, 0.42475199699401855, 0.4244643449783325, 0.42501920461654663, 0.41319242119789124, 0.4065239131450653, 0.4004179835319519, 0.4029379189014435], 'accuracy': [0.4098125100135803, 0.5792499780654907, 0.6502500176429749, 0.6930416822433472, 0.7193541526794434, 0.74197918176651, 0.7601458430290222, 0.7746875286102295, 0.7837916612625122, 0.7898333072662354, 0.7997291684150696, 0.8043333292007446, 0.8118333220481873, 0.8180000185966492, 0.8227083086967468, 0.8260208368301392, 0.8322499990463257, 0.8352500200271606, 0.8364375233650208, 0.840791642665863, 0.8459374904632568, 0.8492083549499512, 0.8488541841506958, 0.8515833616256714, 0.854812502861023, 0.856416642665863, 0.8569791913032532, 0.8606041669845581, 0.8627291917800903, 0.8644791841506958, 0.8679166436195374, 0.8682500123977661, 0.8680624961853027, 0.871749997138977, 0.871708333492279, 0.8743125200271606, 0.8757708072662354, 0.8746458292007446, 0.8780624866485596, 0.8799375295639038, 0.882770836353302, 0.8825833201408386, 0.8832916617393494, 0.8863750100135803, 0.8851666450500488, 0.8856041431427002, 0.8865000009536743, 0.8882916569709778, 0.8912083506584167, 0.8916666507720947], 'val_loss': [0.7031415104866028, 0.5364388227462769, 0.47292011976242065, 0.43015405535697937, 0.40602660179138184, 0.3918647766113281, 0.3706772029399872, 0.3590005338191986, 0.34786397218704224, 0.3406713604927063, 0.3332737386226654, 0.32866552472114563, 0.32210469245910645, 0.3169693648815155, 0.3134745955467224, 0.31284135580062866, 0.3044402599334717, 0.2992979884147644, 0.2986260652542114, 0.29479488730430603, 0.29062989354133606, 0.2903881371021271, 0.28458234667778015, 0.28228580951690674, 0.2821770906448364, 0.2782866656780243, 0.27674832940101624, 0.2763049304485321, 0.27282989025115967, 0.2705793082714081, 0.26701754331588745, 0.2658855617046356, 0.26609140634536743, 0.2631256878376007, 0.25888365507125854, 0.257594496011734, 0.25905126333236694, 0.2544698417186737, 0.2526109218597412, 0.2539122998714447, 0.2520879805088043, 0.24986711144447327, 0.24715884029865265, 0.24686025083065033, 0.2496374100446701, 0.24412569403648376, 0.2457585483789444, 0.24550344049930573, 0.24344941973686218, 0.23831221461296082], 'val_accuracy': [0.796750009059906, 0.8558333516120911, 0.8694999814033508, 0.8784166574478149, 0.8830833435058594, 0.8867499828338623, 0.890916645526886, 0.8933333158493042, 0.8961666822433472, 0.8980000019073486, 0.8992499709129333, 0.9014166593551636, 0.9041666388511658, 0.9052500128746033, 0.905916690826416, 0.9073333144187927, 0.9079166650772095, 0.9109166860580444, 0.9108333587646484, 0.9110000133514404, 0.9129999876022339, 0.9132500290870667, 0.9147499799728394, 0.9157500267028809, 0.9163333177566528, 0.9160833358764648, 0.9170833230018616, 0.9174166917800903, 0.9199166893959045, 0.921500027179718, 0.9209166765213013, 0.92166668176651, 0.9226666688919067, 0.9231666922569275, 0.9235000014305115, 0.925000011920929, 0.9241666793823242, 0.9263333082199097, 0.9265000224113464, 0.9273333549499512, 0.9276666641235352, 0.9289166927337646, 0.9294166564941406, 0.9302499890327454, 0.9292500019073486, 0.9297500252723694, 0.9294999837875366, 0.9303333163261414, 0.9309166669845581, 0.9331666827201843]}\n",
            "{'loss': [2.3012759685516357, 2.297022819519043, 2.2923831939697266, 2.2843096256256104, 2.265113353729248, 2.1816062927246094, 2.0298373699188232, 1.8991315364837646, 1.764888048171997, 1.6336954832077026, 1.5141689777374268, 1.4282907247543335, 1.34666907787323, 1.2919833660125732, 1.2285648584365845, 1.1770797967910767, 1.1275861263275146, 1.081180453300476, 1.0406420230865479, 1.00251305103302, 0.9603874683380127, 0.9295895099639893, 0.9104336500167847, 0.8868927359580994, 0.8605629801750183, 0.8369927406311035, 0.8209152221679688, 0.7989916205406189, 0.785435140132904, 0.768887460231781, 0.7467967867851257, 0.7377134561538696, 0.7210465669631958, 0.7099053263664246, 0.6946284174919128, 0.6791999936103821, 0.6627358794212341, 0.6505934000015259, 0.6454958319664001, 0.6308772563934326, 0.6196599006652832, 0.6139280796051025, 0.6054611802101135, 0.5888741612434387, 0.5747668147087097, 0.5676712393760681, 0.5577918291091919, 0.5489248633384705, 0.5386495590209961, 0.5283023715019226], 'accuracy': [0.12052083015441895, 0.12916666269302368, 0.1274166703224182, 0.1353749930858612, 0.16200000047683716, 0.2253541648387909, 0.27668750286102295, 0.3213333189487457, 0.37422916293144226, 0.42247915267944336, 0.4647291600704193, 0.49258333444595337, 0.523145854473114, 0.5458750128746033, 0.5737291574478149, 0.5998541712760925, 0.6206250190734863, 0.6430208086967468, 0.664312481880188, 0.6757500171661377, 0.6919583082199097, 0.7037500143051147, 0.7121041417121887, 0.7208958268165588, 0.7289166450500488, 0.7369375228881836, 0.7443541884422302, 0.7513750195503235, 0.7552083134651184, 0.7633749842643738, 0.768583357334137, 0.7746875286102295, 0.7812291383743286, 0.7839375138282776, 0.7882916927337646, 0.7957291603088379, 0.8008750081062317, 0.8007708191871643, 0.807687520980835, 0.8084166646003723, 0.8110416531562805, 0.8164374828338623, 0.8175416588783264, 0.8233749866485596, 0.8286458253860474, 0.827750027179718, 0.8317499756813049, 0.8344166874885559, 0.8385624885559082, 0.8436874747276306], 'val_loss': [2.299354076385498, 2.2953076362609863, 2.2896058559417725, 2.278597354888916, 2.2415518760681152, 2.050318479537964, 1.8375619649887085, 1.6644011735916138, 1.4734745025634766, 1.3056782484054565, 1.1813205480575562, 1.089313268661499, 1.0164825916290283, 0.9530261754989624, 0.9023364782333374, 0.8426486849784851, 0.7799060940742493, 0.7243590354919434, 0.6765707731246948, 0.6386249661445618, 0.6021807789802551, 0.576029360294342, 0.5558310747146606, 0.5334105491638184, 0.5158804655075073, 0.49914127588272095, 0.4859059751033783, 0.4698094129562378, 0.4556735157966614, 0.4406818449497223, 0.4334174394607544, 0.41817647218704224, 0.40776899456977844, 0.39897894859313965, 0.38916340470314026, 0.37830138206481934, 0.3685249388217926, 0.36184391379356384, 0.3538837432861328, 0.3463154435157776, 0.3423069715499878, 0.33569982647895813, 0.32689228653907776, 0.3211134374141693, 0.3177611529827118, 0.3095470666885376, 0.30309513211250305, 0.3016310930252075, 0.29647502303123474, 0.29338666796684265], 'val_accuracy': [0.10625000298023224, 0.10608333349227905, 0.10641666501760483, 0.12325000017881393, 0.2120833396911621, 0.34599998593330383, 0.4246666729450226, 0.4975000023841858, 0.5400000214576721, 0.5716666579246521, 0.6000000238418579, 0.6463333368301392, 0.6710833311080933, 0.703499972820282, 0.7361666560173035, 0.7682499885559082, 0.8098333477973938, 0.8274166584014893, 0.8386666774749756, 0.8505833148956299, 0.859666645526886, 0.8639166951179504, 0.8713333606719971, 0.8757500052452087, 0.8790000081062317, 0.8839166760444641, 0.8852499723434448, 0.8898333311080933, 0.8941666483879089, 0.8981666564941406, 0.8962500095367432, 0.9010833501815796, 0.9017500281333923, 0.9070000052452087, 0.9071666598320007, 0.9102500081062317, 0.9140833616256714, 0.9144999980926514, 0.9169166684150696, 0.918833315372467, 0.9207500219345093, 0.9230833053588867, 0.9245833158493042, 0.9259166717529297, 0.9266666769981384, 0.9279166460037231, 0.9295833110809326, 0.9309999942779541, 0.9315833449363708, 0.9330833554267883]}\n",
            "{'loss': [2.3012866973876953, 2.297278881072998, 2.2929818630218506, 2.2869327068328857, 2.2769670486450195, 2.2539713382720947, 2.177563190460205, 2.0632054805755615, 1.9436780214309692, 1.7842674255371094, 1.636395812034607, 1.5144320726394653, 1.411330223083496, 1.3169596195220947, 1.2365676164627075, 1.1679083108901978, 1.115743637084961, 1.062633991241455, 1.0158034563064575, 0.9812927842140198, 0.9435558319091797, 0.917432427406311, 0.8951516151428223, 0.873554527759552, 0.8543773889541626, 0.8357200622558594, 0.8141640424728394, 0.7992324233055115, 0.7886354327201843, 0.7746387720108032, 0.7616556882858276, 0.7493250966072083, 0.7379149794578552, 0.7293541431427002, 0.7170093059539795, 0.7001432180404663, 0.6942915916442871, 0.6785129308700562, 0.6668335795402527, 0.6590294241905212, 0.6527127623558044, 0.6388421058654785, 0.626313328742981, 0.6215720772743225, 0.6105158925056458, 0.6053609848022461, 0.5982446670532227, 0.5874224305152893, 0.5769618153572083, 0.5701575875282288], 'accuracy': [0.11497917026281357, 0.12597917020320892, 0.1274791657924652, 0.1366875022649765, 0.16968749463558197, 0.21029166877269745, 0.2239583283662796, 0.24302083253860474, 0.3021250069141388, 0.36385416984558105, 0.41989582777023315, 0.4684999883174896, 0.5104583501815796, 0.5468541383743286, 0.581208348274231, 0.6058750152587891, 0.6244999766349792, 0.6460000276565552, 0.6649166941642761, 0.6773124933242798, 0.6920833587646484, 0.7024791836738586, 0.7095416784286499, 0.7166041731834412, 0.7257291674613953, 0.7300000190734863, 0.7403541803359985, 0.7462916374206543, 0.7494791746139526, 0.7567083239555359, 0.7600625157356262, 0.7636250257492065, 0.7694791555404663, 0.7718750238418579, 0.7769166827201843, 0.7819583415985107, 0.7864583134651184, 0.7907291650772095, 0.7946249842643738, 0.7947499752044678, 0.801562488079071, 0.8055208325386047, 0.8112708330154419, 0.8119166493415833, 0.812874972820282, 0.8139583468437195, 0.8186666369438171, 0.8223749995231628, 0.8261250257492065, 0.8273541927337646], 'val_loss': [2.299304246902466, 2.295454502105713, 2.2907378673553467, 2.283308267593384, 2.268677234649658, 2.2255237102508545, 2.0741190910339355, 1.9242032766342163, 1.7299665212631226, 1.5066317319869995, 1.3145655393600464, 1.1628893613815308, 1.0380538702011108, 0.9317399263381958, 0.8460822701454163, 0.773708164691925, 0.7165178060531616, 0.6665043830871582, 0.6264240741729736, 0.5959238409996033, 0.5677750110626221, 0.548134446144104, 0.5320180058479309, 0.5166031122207642, 0.5055779814720154, 0.4928662180900574, 0.48328080773353577, 0.47273188829421997, 0.4598565697669983, 0.45113879442214966, 0.4410138726234436, 0.4330489933490753, 0.42249324917793274, 0.41357019543647766, 0.405701220035553, 0.3974452316761017, 0.3895893096923828, 0.3790763318538666, 0.37120580673217773, 0.3629527986049652, 0.3588370084762573, 0.3495975732803345, 0.3409386873245239, 0.33451512455940247, 0.33032652735710144, 0.32473722100257874, 0.3205036222934723, 0.3111426532268524, 0.30968692898750305, 0.30163252353668213], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.11558333039283752, 0.1798333376646042, 0.2888333201408386, 0.22849999368190765, 0.3154999911785126, 0.4281666576862335, 0.4879166781902313, 0.5724166631698608, 0.6470000147819519, 0.6994166374206543, 0.7360833287239075, 0.7674999833106995, 0.7889166474342346, 0.8082500100135803, 0.8224166631698608, 0.8366666436195374, 0.8454166650772095, 0.8525833487510681, 0.856416642665863, 0.8605833053588867, 0.8658333420753479, 0.8691666722297668, 0.8732500076293945, 0.8763333559036255, 0.8787500262260437, 0.8820000290870667, 0.8842499852180481, 0.8865000009536743, 0.8884166479110718, 0.8927500247955322, 0.8955000042915344, 0.8960833549499512, 0.8980833292007446, 0.8994166851043701, 0.9023333191871643, 0.9041666388511658, 0.9079999923706055, 0.9089166522026062, 0.9119166731834412, 0.9137499928474426, 0.9148333072662354, 0.9166666865348816, 0.9194166660308838, 0.9204999804496765, 0.9210000038146973, 0.9213333129882812, 0.9234166741371155]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}