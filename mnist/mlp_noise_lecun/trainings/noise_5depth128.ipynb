{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "09889568-9176-4e91-ce35-4ce5395e7aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 16s 5ms/step - loss: 1.9891 - accuracy: 0.2915 - val_loss: 0.8789 - val_accuracy: 0.7896\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1567 - accuracy: 0.6279 - val_loss: 0.6131 - val_accuracy: 0.8426\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9318 - accuracy: 0.7056 - val_loss: 0.5037 - val_accuracy: 0.8651\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8142 - accuracy: 0.7453 - val_loss: 0.4419 - val_accuracy: 0.8780\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7437 - accuracy: 0.7704 - val_loss: 0.4098 - val_accuracy: 0.8848\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6903 - accuracy: 0.7898 - val_loss: 0.3843 - val_accuracy: 0.8892\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6578 - accuracy: 0.7999 - val_loss: 0.3698 - val_accuracy: 0.8917\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6295 - accuracy: 0.8113 - val_loss: 0.3546 - val_accuracy: 0.8952\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6044 - accuracy: 0.8216 - val_loss: 0.3444 - val_accuracy: 0.8969\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5721 - accuracy: 0.8306 - val_loss: 0.3375 - val_accuracy: 0.8983\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5663 - accuracy: 0.8332 - val_loss: 0.3291 - val_accuracy: 0.9003\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5556 - accuracy: 0.8381 - val_loss: 0.3241 - val_accuracy: 0.9024\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5444 - accuracy: 0.8405 - val_loss: 0.3190 - val_accuracy: 0.9056\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5317 - accuracy: 0.8447 - val_loss: 0.3134 - val_accuracy: 0.9053\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5170 - accuracy: 0.8510 - val_loss: 0.3098 - val_accuracy: 0.9078\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4912 - accuracy: 0.8563 - val_loss: 0.3039 - val_accuracy: 0.9086\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.8559 - val_loss: 0.3021 - val_accuracy: 0.9102\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4787 - accuracy: 0.8609 - val_loss: 0.2997 - val_accuracy: 0.9105\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4705 - accuracy: 0.8651 - val_loss: 0.2973 - val_accuracy: 0.9131\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4673 - accuracy: 0.8661 - val_loss: 0.2940 - val_accuracy: 0.9122\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4596 - accuracy: 0.8706 - val_loss: 0.2912 - val_accuracy: 0.9140\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4498 - accuracy: 0.8743 - val_loss: 0.2888 - val_accuracy: 0.9141\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.8715 - val_loss: 0.2871 - val_accuracy: 0.9147\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4457 - accuracy: 0.8760 - val_loss: 0.2855 - val_accuracy: 0.9147\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4313 - accuracy: 0.8793 - val_loss: 0.2825 - val_accuracy: 0.9169\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4350 - accuracy: 0.8784 - val_loss: 0.2811 - val_accuracy: 0.9168\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4160 - accuracy: 0.8831 - val_loss: 0.2794 - val_accuracy: 0.9182\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4101 - accuracy: 0.8848 - val_loss: 0.2774 - val_accuracy: 0.9187\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - accuracy: 0.8861 - val_loss: 0.2740 - val_accuracy: 0.9198\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - accuracy: 0.8862 - val_loss: 0.2724 - val_accuracy: 0.9205\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4078 - accuracy: 0.8851 - val_loss: 0.2714 - val_accuracy: 0.9217\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3852 - accuracy: 0.8918 - val_loss: 0.2695 - val_accuracy: 0.9208\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3896 - accuracy: 0.8922 - val_loss: 0.2683 - val_accuracy: 0.9218\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8913 - val_loss: 0.2683 - val_accuracy: 0.9212\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3810 - accuracy: 0.8931 - val_loss: 0.2655 - val_accuracy: 0.9225\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8948 - val_loss: 0.2640 - val_accuracy: 0.9237\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3795 - accuracy: 0.8949 - val_loss: 0.2616 - val_accuracy: 0.9249\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8986 - val_loss: 0.2615 - val_accuracy: 0.9249\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3718 - accuracy: 0.8972 - val_loss: 0.2594 - val_accuracy: 0.9256\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8985 - val_loss: 0.2572 - val_accuracy: 0.9257\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3556 - accuracy: 0.9012 - val_loss: 0.2553 - val_accuracy: 0.9261\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3582 - accuracy: 0.9009 - val_loss: 0.2540 - val_accuracy: 0.9270\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3563 - accuracy: 0.9014 - val_loss: 0.2542 - val_accuracy: 0.9262\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3568 - accuracy: 0.9021 - val_loss: 0.2518 - val_accuracy: 0.9271\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3441 - accuracy: 0.9046 - val_loss: 0.2514 - val_accuracy: 0.9283\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.9041 - val_loss: 0.2511 - val_accuracy: 0.9288\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.9072 - val_loss: 0.2491 - val_accuracy: 0.9278\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.9095 - val_loss: 0.2458 - val_accuracy: 0.9296\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.9064 - val_loss: 0.2470 - val_accuracy: 0.9298\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.9088 - val_loss: 0.2451 - val_accuracy: 0.9309\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.3018 - accuracy: 0.1140 - val_loss: 2.2146 - val_accuracy: 0.3936\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2135 - accuracy: 0.1936 - val_loss: 1.8413 - val_accuracy: 0.4910\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9246 - accuracy: 0.3106 - val_loss: 1.3806 - val_accuracy: 0.5570\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6029 - accuracy: 0.4191 - val_loss: 1.0548 - val_accuracy: 0.7083\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3688 - accuracy: 0.5126 - val_loss: 0.8219 - val_accuracy: 0.7937\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1704 - accuracy: 0.5924 - val_loss: 0.6832 - val_accuracy: 0.8288\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0518 - accuracy: 0.6432 - val_loss: 0.5782 - val_accuracy: 0.8553\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9413 - accuracy: 0.6920 - val_loss: 0.5123 - val_accuracy: 0.8747\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8762 - accuracy: 0.7172 - val_loss: 0.4599 - val_accuracy: 0.8859\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8240 - accuracy: 0.7423 - val_loss: 0.4231 - val_accuracy: 0.8940\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7548 - accuracy: 0.7698 - val_loss: 0.3936 - val_accuracy: 0.8989\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7066 - accuracy: 0.7858 - val_loss: 0.3684 - val_accuracy: 0.9032\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6750 - accuracy: 0.8027 - val_loss: 0.3434 - val_accuracy: 0.9090\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6305 - accuracy: 0.8146 - val_loss: 0.3263 - val_accuracy: 0.9116\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6100 - accuracy: 0.8231 - val_loss: 0.3104 - val_accuracy: 0.9157\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5811 - accuracy: 0.8344 - val_loss: 0.2933 - val_accuracy: 0.9192\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5597 - accuracy: 0.8417 - val_loss: 0.2817 - val_accuracy: 0.9213\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5364 - accuracy: 0.8463 - val_loss: 0.2709 - val_accuracy: 0.9250\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5067 - accuracy: 0.8562 - val_loss: 0.2625 - val_accuracy: 0.9286\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4976 - accuracy: 0.8612 - val_loss: 0.2539 - val_accuracy: 0.9312\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4777 - accuracy: 0.8676 - val_loss: 0.2433 - val_accuracy: 0.9349\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4492 - accuracy: 0.8745 - val_loss: 0.2369 - val_accuracy: 0.9355\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.8780 - val_loss: 0.2310 - val_accuracy: 0.9375\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4269 - accuracy: 0.8847 - val_loss: 0.2253 - val_accuracy: 0.9388\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4142 - accuracy: 0.8871 - val_loss: 0.2200 - val_accuracy: 0.9402\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3934 - accuracy: 0.8928 - val_loss: 0.2162 - val_accuracy: 0.9417\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3815 - accuracy: 0.8983 - val_loss: 0.2110 - val_accuracy: 0.9431\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3694 - accuracy: 0.9006 - val_loss: 0.2086 - val_accuracy: 0.9449\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3564 - accuracy: 0.9052 - val_loss: 0.2039 - val_accuracy: 0.9448\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3417 - accuracy: 0.9078 - val_loss: 0.2018 - val_accuracy: 0.9461\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.9107 - val_loss: 0.1984 - val_accuracy: 0.9475\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.9082 - val_loss: 0.1973 - val_accuracy: 0.9482\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3181 - accuracy: 0.9154 - val_loss: 0.1924 - val_accuracy: 0.9489\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.9174 - val_loss: 0.1903 - val_accuracy: 0.9501\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2987 - accuracy: 0.9201 - val_loss: 0.1888 - val_accuracy: 0.9508\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2942 - accuracy: 0.9217 - val_loss: 0.1872 - val_accuracy: 0.9509\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2856 - accuracy: 0.9229 - val_loss: 0.1863 - val_accuracy: 0.9517\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2808 - accuracy: 0.9230 - val_loss: 0.1833 - val_accuracy: 0.9524\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9285 - val_loss: 0.1808 - val_accuracy: 0.9529\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2500 - accuracy: 0.9317 - val_loss: 0.1843 - val_accuracy: 0.9530\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2529 - accuracy: 0.9318 - val_loss: 0.1803 - val_accuracy: 0.9546\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.9352 - val_loss: 0.1805 - val_accuracy: 0.9546\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.9346 - val_loss: 0.1756 - val_accuracy: 0.9555\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2363 - accuracy: 0.9366 - val_loss: 0.1766 - val_accuracy: 0.9554\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2352 - accuracy: 0.9376 - val_loss: 0.1748 - val_accuracy: 0.9561\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2282 - accuracy: 0.9372 - val_loss: 0.1762 - val_accuracy: 0.9561\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2117 - accuracy: 0.9416 - val_loss: 0.1750 - val_accuracy: 0.9572\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9440 - val_loss: 0.1772 - val_accuracy: 0.9576\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9439 - val_loss: 0.1767 - val_accuracy: 0.9582\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1906 - accuracy: 0.9485 - val_loss: 0.1747 - val_accuracy: 0.9578\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2917 - accuracy: 0.1293 - val_loss: 2.0890 - val_accuracy: 0.4606\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0251 - accuracy: 0.3105 - val_loss: 1.4075 - val_accuracy: 0.5707\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5615 - accuracy: 0.4597 - val_loss: 0.9385 - val_accuracy: 0.7312\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2334 - accuracy: 0.5820 - val_loss: 0.6797 - val_accuracy: 0.8213\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0272 - accuracy: 0.6639 - val_loss: 0.5370 - val_accuracy: 0.8563\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8747 - accuracy: 0.7215 - val_loss: 0.4628 - val_accuracy: 0.8712\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7727 - accuracy: 0.7596 - val_loss: 0.4128 - val_accuracy: 0.8826\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7169 - accuracy: 0.7809 - val_loss: 0.3800 - val_accuracy: 0.8916\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6639 - accuracy: 0.8021 - val_loss: 0.3620 - val_accuracy: 0.8945\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6248 - accuracy: 0.8155 - val_loss: 0.3363 - val_accuracy: 0.9023\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5809 - accuracy: 0.8326 - val_loss: 0.3218 - val_accuracy: 0.9052\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5565 - accuracy: 0.8424 - val_loss: 0.3084 - val_accuracy: 0.9094\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.8510 - val_loss: 0.2974 - val_accuracy: 0.9129\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.8566 - val_loss: 0.2866 - val_accuracy: 0.9147\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4745 - accuracy: 0.8652 - val_loss: 0.2763 - val_accuracy: 0.9172\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4626 - accuracy: 0.8721 - val_loss: 0.2676 - val_accuracy: 0.9208\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.8749 - val_loss: 0.2619 - val_accuracy: 0.9217\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4225 - accuracy: 0.8814 - val_loss: 0.2558 - val_accuracy: 0.9242\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4075 - accuracy: 0.8882 - val_loss: 0.2477 - val_accuracy: 0.9256\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4041 - accuracy: 0.8918 - val_loss: 0.2429 - val_accuracy: 0.9277\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3867 - accuracy: 0.8930 - val_loss: 0.2392 - val_accuracy: 0.9283\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3723 - accuracy: 0.8995 - val_loss: 0.2302 - val_accuracy: 0.9298\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3694 - accuracy: 0.9017 - val_loss: 0.2279 - val_accuracy: 0.9321\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3544 - accuracy: 0.9020 - val_loss: 0.2233 - val_accuracy: 0.9333\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3528 - accuracy: 0.9029 - val_loss: 0.2181 - val_accuracy: 0.9345\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3284 - accuracy: 0.9113 - val_loss: 0.2135 - val_accuracy: 0.9367\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.9078 - val_loss: 0.2098 - val_accuracy: 0.9380\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3140 - accuracy: 0.9153 - val_loss: 0.2085 - val_accuracy: 0.9370\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3113 - accuracy: 0.9162 - val_loss: 0.2055 - val_accuracy: 0.9390\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3086 - accuracy: 0.9175 - val_loss: 0.2007 - val_accuracy: 0.9413\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.9185 - val_loss: 0.1983 - val_accuracy: 0.9422\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2941 - accuracy: 0.9205 - val_loss: 0.1959 - val_accuracy: 0.9427\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2816 - accuracy: 0.9226 - val_loss: 0.1940 - val_accuracy: 0.9437\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9256 - val_loss: 0.1902 - val_accuracy: 0.9443\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2677 - accuracy: 0.9282 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2642 - accuracy: 0.9292 - val_loss: 0.1862 - val_accuracy: 0.9461\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2578 - accuracy: 0.9303 - val_loss: 0.1850 - val_accuracy: 0.9452\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2511 - accuracy: 0.9332 - val_loss: 0.1851 - val_accuracy: 0.9455\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2483 - accuracy: 0.9343 - val_loss: 0.1821 - val_accuracy: 0.9470\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2426 - accuracy: 0.9363 - val_loss: 0.1802 - val_accuracy: 0.9471\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2394 - accuracy: 0.9353 - val_loss: 0.1780 - val_accuracy: 0.9495\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2302 - accuracy: 0.9388 - val_loss: 0.1769 - val_accuracy: 0.9495\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2240 - accuracy: 0.9405 - val_loss: 0.1756 - val_accuracy: 0.9503\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2256 - accuracy: 0.9394 - val_loss: 0.1750 - val_accuracy: 0.9502\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9435 - val_loss: 0.1731 - val_accuracy: 0.9514\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9425 - val_loss: 0.1733 - val_accuracy: 0.9513\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9449 - val_loss: 0.1721 - val_accuracy: 0.9514\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9432 - val_loss: 0.1708 - val_accuracy: 0.9516\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1982 - accuracy: 0.9462 - val_loss: 0.1705 - val_accuracy: 0.9508\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9466 - val_loss: 0.1723 - val_accuracy: 0.9514\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 1.9561 - accuracy: 0.3109 - val_loss: 0.7926 - val_accuracy: 0.8092\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0626 - accuracy: 0.6463 - val_loss: 0.5525 - val_accuracy: 0.8491\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8662 - accuracy: 0.7168 - val_loss: 0.4586 - val_accuracy: 0.8694\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7603 - accuracy: 0.7577 - val_loss: 0.4106 - val_accuracy: 0.8817\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7008 - accuracy: 0.7778 - val_loss: 0.3814 - val_accuracy: 0.8888\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6593 - accuracy: 0.7989 - val_loss: 0.3606 - val_accuracy: 0.8938\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6122 - accuracy: 0.8099 - val_loss: 0.3466 - val_accuracy: 0.8994\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5880 - accuracy: 0.8199 - val_loss: 0.3322 - val_accuracy: 0.9013\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5717 - accuracy: 0.8293 - val_loss: 0.3221 - val_accuracy: 0.9045\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5493 - accuracy: 0.8362 - val_loss: 0.3145 - val_accuracy: 0.9057\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5333 - accuracy: 0.8398 - val_loss: 0.3053 - val_accuracy: 0.9101\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.8445 - val_loss: 0.2990 - val_accuracy: 0.9104\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4999 - accuracy: 0.8535 - val_loss: 0.2917 - val_accuracy: 0.9133\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5020 - accuracy: 0.8533 - val_loss: 0.2861 - val_accuracy: 0.9148\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4756 - accuracy: 0.8608 - val_loss: 0.2830 - val_accuracy: 0.9153\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4688 - accuracy: 0.8638 - val_loss: 0.2779 - val_accuracy: 0.9164\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4648 - accuracy: 0.8664 - val_loss: 0.2723 - val_accuracy: 0.9187\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4559 - accuracy: 0.8677 - val_loss: 0.2672 - val_accuracy: 0.9216\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.8692 - val_loss: 0.2638 - val_accuracy: 0.9227\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4308 - accuracy: 0.8761 - val_loss: 0.2591 - val_accuracy: 0.9226\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.8740 - val_loss: 0.2572 - val_accuracy: 0.9227\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4145 - accuracy: 0.8812 - val_loss: 0.2516 - val_accuracy: 0.9252\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.8800 - val_loss: 0.2489 - val_accuracy: 0.9267\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - accuracy: 0.8846 - val_loss: 0.2461 - val_accuracy: 0.9269\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3935 - accuracy: 0.8889 - val_loss: 0.2428 - val_accuracy: 0.9283\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3882 - accuracy: 0.8883 - val_loss: 0.2399 - val_accuracy: 0.9296\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3907 - accuracy: 0.8867 - val_loss: 0.2369 - val_accuracy: 0.9300\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8927 - val_loss: 0.2331 - val_accuracy: 0.9305\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3664 - accuracy: 0.8946 - val_loss: 0.2330 - val_accuracy: 0.9309\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3624 - accuracy: 0.8948 - val_loss: 0.2280 - val_accuracy: 0.9322\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8979 - val_loss: 0.2256 - val_accuracy: 0.9332\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3571 - accuracy: 0.8975 - val_loss: 0.2221 - val_accuracy: 0.9351\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3479 - accuracy: 0.9002 - val_loss: 0.2220 - val_accuracy: 0.9345\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.9021 - val_loss: 0.2179 - val_accuracy: 0.9363\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.9018 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.9054 - val_loss: 0.2134 - val_accuracy: 0.9373\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3196 - accuracy: 0.9084 - val_loss: 0.2138 - val_accuracy: 0.9375\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.9055 - val_loss: 0.2113 - val_accuracy: 0.9377\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.9084 - val_loss: 0.2099 - val_accuracy: 0.9386\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3159 - accuracy: 0.9105 - val_loss: 0.2086 - val_accuracy: 0.9390\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3106 - accuracy: 0.9112 - val_loss: 0.2061 - val_accuracy: 0.9405\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3208 - accuracy: 0.9111 - val_loss: 0.2039 - val_accuracy: 0.9408\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3036 - accuracy: 0.9122 - val_loss: 0.2050 - val_accuracy: 0.9409\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2975 - accuracy: 0.9141 - val_loss: 0.2022 - val_accuracy: 0.9418\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3031 - accuracy: 0.9143 - val_loss: 0.1993 - val_accuracy: 0.9433\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2882 - accuracy: 0.9185 - val_loss: 0.1993 - val_accuracy: 0.9425\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2884 - accuracy: 0.9185 - val_loss: 0.1963 - val_accuracy: 0.9436\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.9173 - val_loss: 0.1957 - val_accuracy: 0.9434\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2873 - accuracy: 0.9186 - val_loss: 0.1951 - val_accuracy: 0.9433\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2764 - accuracy: 0.9223 - val_loss: 0.1930 - val_accuracy: 0.9443\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 1.8825 - accuracy: 0.4099 - val_loss: 0.4911 - val_accuracy: 0.8545\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9534 - accuracy: 0.6877 - val_loss: 0.4088 - val_accuracy: 0.8833\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7968 - accuracy: 0.7455 - val_loss: 0.3761 - val_accuracy: 0.8907\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7106 - accuracy: 0.7788 - val_loss: 0.3584 - val_accuracy: 0.8958\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.7951 - val_loss: 0.3498 - val_accuracy: 0.8989\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6236 - accuracy: 0.8101 - val_loss: 0.3389 - val_accuracy: 0.9010\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5940 - accuracy: 0.8207 - val_loss: 0.3241 - val_accuracy: 0.9043\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5725 - accuracy: 0.8303 - val_loss: 0.3159 - val_accuracy: 0.9065\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5515 - accuracy: 0.8352 - val_loss: 0.3104 - val_accuracy: 0.9077\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5257 - accuracy: 0.8430 - val_loss: 0.3057 - val_accuracy: 0.9099\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5294 - accuracy: 0.8457 - val_loss: 0.3017 - val_accuracy: 0.9103\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.8508 - val_loss: 0.2951 - val_accuracy: 0.9118\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.8565 - val_loss: 0.2917 - val_accuracy: 0.9136\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4728 - accuracy: 0.8592 - val_loss: 0.2873 - val_accuracy: 0.9145\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4705 - accuracy: 0.8608 - val_loss: 0.2824 - val_accuracy: 0.9149\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4564 - accuracy: 0.8661 - val_loss: 0.2789 - val_accuracy: 0.9165\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.8674 - val_loss: 0.2760 - val_accuracy: 0.9172\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8693 - val_loss: 0.2745 - val_accuracy: 0.9173\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.8737 - val_loss: 0.2700 - val_accuracy: 0.9189\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4209 - accuracy: 0.8799 - val_loss: 0.2693 - val_accuracy: 0.9194\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8799 - val_loss: 0.2651 - val_accuracy: 0.9208\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4000 - accuracy: 0.8815 - val_loss: 0.2606 - val_accuracy: 0.9222\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - accuracy: 0.8795 - val_loss: 0.2611 - val_accuracy: 0.9217\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3970 - accuracy: 0.8858 - val_loss: 0.2579 - val_accuracy: 0.9226\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3941 - accuracy: 0.8841 - val_loss: 0.2529 - val_accuracy: 0.9238\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3933 - accuracy: 0.8868 - val_loss: 0.2520 - val_accuracy: 0.9252\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3837 - accuracy: 0.8880 - val_loss: 0.2532 - val_accuracy: 0.9235\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3831 - accuracy: 0.8907 - val_loss: 0.2481 - val_accuracy: 0.9261\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3761 - accuracy: 0.8909 - val_loss: 0.2477 - val_accuracy: 0.9252\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3614 - accuracy: 0.8956 - val_loss: 0.2449 - val_accuracy: 0.9257\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3699 - accuracy: 0.8937 - val_loss: 0.2422 - val_accuracy: 0.9263\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3676 - accuracy: 0.8938 - val_loss: 0.2453 - val_accuracy: 0.9266\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3664 - accuracy: 0.8952 - val_loss: 0.2415 - val_accuracy: 0.9272\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3531 - accuracy: 0.8970 - val_loss: 0.2411 - val_accuracy: 0.9277\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3491 - accuracy: 0.8996 - val_loss: 0.2385 - val_accuracy: 0.9287\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.9023 - val_loss: 0.2351 - val_accuracy: 0.9298\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.9041 - val_loss: 0.2337 - val_accuracy: 0.9297\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3433 - accuracy: 0.9037 - val_loss: 0.2338 - val_accuracy: 0.9293\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3483 - accuracy: 0.9020 - val_loss: 0.2309 - val_accuracy: 0.9298\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.9032 - val_loss: 0.2302 - val_accuracy: 0.9312\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.9073 - val_loss: 0.2298 - val_accuracy: 0.9313\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3292 - accuracy: 0.9053 - val_loss: 0.2268 - val_accuracy: 0.9324\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.9071 - val_loss: 0.2249 - val_accuracy: 0.9326\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3165 - accuracy: 0.9093 - val_loss: 0.2242 - val_accuracy: 0.9323\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3245 - accuracy: 0.9095 - val_loss: 0.2211 - val_accuracy: 0.9332\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3088 - accuracy: 0.9111 - val_loss: 0.2214 - val_accuracy: 0.9336\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3087 - accuracy: 0.9123 - val_loss: 0.2208 - val_accuracy: 0.9341\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3072 - accuracy: 0.9124 - val_loss: 0.2191 - val_accuracy: 0.9348\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3033 - accuracy: 0.9140 - val_loss: 0.2180 - val_accuracy: 0.9351\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2993 - accuracy: 0.9152 - val_loss: 0.2148 - val_accuracy: 0.9366\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2983 - accuracy: 0.1240 - val_loss: 2.2833 - val_accuracy: 0.2585\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2786 - accuracy: 0.2155 - val_loss: 2.2521 - val_accuracy: 0.3374\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2378 - accuracy: 0.2927 - val_loss: 2.1019 - val_accuracy: 0.4033\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0391 - accuracy: 0.3570 - val_loss: 1.5360 - val_accuracy: 0.5598\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6357 - accuracy: 0.4659 - val_loss: 1.0170 - val_accuracy: 0.7309\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2973 - accuracy: 0.5742 - val_loss: 0.7550 - val_accuracy: 0.8106\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0759 - accuracy: 0.6501 - val_loss: 0.6198 - val_accuracy: 0.8403\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9446 - accuracy: 0.7021 - val_loss: 0.5436 - val_accuracy: 0.8567\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8435 - accuracy: 0.7361 - val_loss: 0.4896 - val_accuracy: 0.8666\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7870 - accuracy: 0.7581 - val_loss: 0.4538 - val_accuracy: 0.8799\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7468 - accuracy: 0.7763 - val_loss: 0.4237 - val_accuracy: 0.8867\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6877 - accuracy: 0.7940 - val_loss: 0.4022 - val_accuracy: 0.8909\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6619 - accuracy: 0.8060 - val_loss: 0.3783 - val_accuracy: 0.8961\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6300 - accuracy: 0.8163 - val_loss: 0.3604 - val_accuracy: 0.9005\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6001 - accuracy: 0.8282 - val_loss: 0.3445 - val_accuracy: 0.9037\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5589 - accuracy: 0.8420 - val_loss: 0.3308 - val_accuracy: 0.9064\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5392 - accuracy: 0.8445 - val_loss: 0.3182 - val_accuracy: 0.9109\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5210 - accuracy: 0.8523 - val_loss: 0.3078 - val_accuracy: 0.9124\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5076 - accuracy: 0.8540 - val_loss: 0.2956 - val_accuracy: 0.9158\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4847 - accuracy: 0.8619 - val_loss: 0.2852 - val_accuracy: 0.9189\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4767 - accuracy: 0.8677 - val_loss: 0.2762 - val_accuracy: 0.9203\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4628 - accuracy: 0.8719 - val_loss: 0.2688 - val_accuracy: 0.9227\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4418 - accuracy: 0.8770 - val_loss: 0.2609 - val_accuracy: 0.9231\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4322 - accuracy: 0.8789 - val_loss: 0.2525 - val_accuracy: 0.9261\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4221 - accuracy: 0.8836 - val_loss: 0.2478 - val_accuracy: 0.9288\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4067 - accuracy: 0.8858 - val_loss: 0.2407 - val_accuracy: 0.9293\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3912 - accuracy: 0.8918 - val_loss: 0.2347 - val_accuracy: 0.9313\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3860 - accuracy: 0.8935 - val_loss: 0.2289 - val_accuracy: 0.9328\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3692 - accuracy: 0.8989 - val_loss: 0.2249 - val_accuracy: 0.9342\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3753 - accuracy: 0.8974 - val_loss: 0.2199 - val_accuracy: 0.9355\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.9046 - val_loss: 0.2159 - val_accuracy: 0.9357\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3495 - accuracy: 0.9052 - val_loss: 0.2122 - val_accuracy: 0.9375\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3421 - accuracy: 0.9045 - val_loss: 0.2069 - val_accuracy: 0.9392\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3319 - accuracy: 0.9119 - val_loss: 0.2052 - val_accuracy: 0.9400\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3243 - accuracy: 0.9157 - val_loss: 0.2023 - val_accuracy: 0.9397\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3193 - accuracy: 0.9141 - val_loss: 0.1990 - val_accuracy: 0.9413\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3057 - accuracy: 0.9173 - val_loss: 0.1941 - val_accuracy: 0.9418\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3111 - accuracy: 0.9177 - val_loss: 0.1925 - val_accuracy: 0.9436\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2975 - accuracy: 0.9186 - val_loss: 0.1882 - val_accuracy: 0.9443\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2927 - accuracy: 0.9221 - val_loss: 0.1862 - val_accuracy: 0.9456\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.9224 - val_loss: 0.1867 - val_accuracy: 0.9463\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2870 - accuracy: 0.9234 - val_loss: 0.1827 - val_accuracy: 0.9471\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2671 - accuracy: 0.9264 - val_loss: 0.1804 - val_accuracy: 0.9475\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2746 - accuracy: 0.9258 - val_loss: 0.1791 - val_accuracy: 0.9487\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2668 - accuracy: 0.9275 - val_loss: 0.1781 - val_accuracy: 0.9492\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2604 - accuracy: 0.9317 - val_loss: 0.1751 - val_accuracy: 0.9500\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2546 - accuracy: 0.9318 - val_loss: 0.1736 - val_accuracy: 0.9507\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2464 - accuracy: 0.9330 - val_loss: 0.1736 - val_accuracy: 0.9506\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2504 - accuracy: 0.9325 - val_loss: 0.1707 - val_accuracy: 0.9518\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2346 - accuracy: 0.9359 - val_loss: 0.1705 - val_accuracy: 0.9517\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.3018 - accuracy: 0.1152 - val_loss: 2.2869 - val_accuracy: 0.1531\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2815 - accuracy: 0.1954 - val_loss: 2.2607 - val_accuracy: 0.3060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2506 - accuracy: 0.2782 - val_loss: 2.1985 - val_accuracy: 0.4590\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1586 - accuracy: 0.3611 - val_loss: 1.8595 - val_accuracy: 0.4469\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8148 - accuracy: 0.4026 - val_loss: 1.3265 - val_accuracy: 0.6177\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4755 - accuracy: 0.4938 - val_loss: 1.0160 - val_accuracy: 0.7018\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2349 - accuracy: 0.5812 - val_loss: 0.7937 - val_accuracy: 0.7862\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0561 - accuracy: 0.6549 - val_loss: 0.6448 - val_accuracy: 0.8276\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9388 - accuracy: 0.6964 - val_loss: 0.5538 - val_accuracy: 0.8504\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8443 - accuracy: 0.7345 - val_loss: 0.4971 - val_accuracy: 0.8645\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7848 - accuracy: 0.7563 - val_loss: 0.4584 - val_accuracy: 0.8723\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7356 - accuracy: 0.7765 - val_loss: 0.4321 - val_accuracy: 0.8808\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.7909 - val_loss: 0.4124 - val_accuracy: 0.8840\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6596 - accuracy: 0.8031 - val_loss: 0.3952 - val_accuracy: 0.8903\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6323 - accuracy: 0.8150 - val_loss: 0.3786 - val_accuracy: 0.8918\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6169 - accuracy: 0.8193 - val_loss: 0.3677 - val_accuracy: 0.8928\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5890 - accuracy: 0.8278 - val_loss: 0.3565 - val_accuracy: 0.8960\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5756 - accuracy: 0.8341 - val_loss: 0.3496 - val_accuracy: 0.8983\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5587 - accuracy: 0.8395 - val_loss: 0.3401 - val_accuracy: 0.9010\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5384 - accuracy: 0.8439 - val_loss: 0.3324 - val_accuracy: 0.9027\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5264 - accuracy: 0.8482 - val_loss: 0.3252 - val_accuracy: 0.9057\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5134 - accuracy: 0.8511 - val_loss: 0.3162 - val_accuracy: 0.9067\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5033 - accuracy: 0.8591 - val_loss: 0.3103 - val_accuracy: 0.9090\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4928 - accuracy: 0.8570 - val_loss: 0.3052 - val_accuracy: 0.9099\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4817 - accuracy: 0.8653 - val_loss: 0.2981 - val_accuracy: 0.9129\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4756 - accuracy: 0.8652 - val_loss: 0.2923 - val_accuracy: 0.9133\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4575 - accuracy: 0.8693 - val_loss: 0.2872 - val_accuracy: 0.9147\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4571 - accuracy: 0.8709 - val_loss: 0.2825 - val_accuracy: 0.9169\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4420 - accuracy: 0.8751 - val_loss: 0.2774 - val_accuracy: 0.9189\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4321 - accuracy: 0.8760 - val_loss: 0.2722 - val_accuracy: 0.9199\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4316 - accuracy: 0.8773 - val_loss: 0.2670 - val_accuracy: 0.9207\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4226 - accuracy: 0.8797 - val_loss: 0.2625 - val_accuracy: 0.9223\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4099 - accuracy: 0.8873 - val_loss: 0.2606 - val_accuracy: 0.9238\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4062 - accuracy: 0.8862 - val_loss: 0.2557 - val_accuracy: 0.9248\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3909 - accuracy: 0.8915 - val_loss: 0.2527 - val_accuracy: 0.9266\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3833 - accuracy: 0.8920 - val_loss: 0.2481 - val_accuracy: 0.9273\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3741 - accuracy: 0.8935 - val_loss: 0.2442 - val_accuracy: 0.9276\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3751 - accuracy: 0.8963 - val_loss: 0.2415 - val_accuracy: 0.9294\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3670 - accuracy: 0.8970 - val_loss: 0.2372 - val_accuracy: 0.9300\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3565 - accuracy: 0.8990 - val_loss: 0.2333 - val_accuracy: 0.9313\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.9017 - val_loss: 0.2313 - val_accuracy: 0.9314\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3556 - accuracy: 0.9019 - val_loss: 0.2274 - val_accuracy: 0.9327\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.9031 - val_loss: 0.2247 - val_accuracy: 0.9336\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3326 - accuracy: 0.9064 - val_loss: 0.2225 - val_accuracy: 0.9339\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3314 - accuracy: 0.9100 - val_loss: 0.2192 - val_accuracy: 0.9355\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3223 - accuracy: 0.9095 - val_loss: 0.2165 - val_accuracy: 0.9363\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3281 - accuracy: 0.9088 - val_loss: 0.2140 - val_accuracy: 0.9379\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3158 - accuracy: 0.9126 - val_loss: 0.2118 - val_accuracy: 0.9371\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.9121 - val_loss: 0.2089 - val_accuracy: 0.9392\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2999 - accuracy: 0.9161 - val_loss: 0.2066 - val_accuracy: 0.9402\n",
      "{'loss': [1.662760615348816, 1.0825426578521729, 0.900113046169281, 0.7961847186088562, 0.7298650741577148, 0.680587649345398, 0.6504083871841431, 0.6242623925209045, 0.5969334244728088, 0.5753170847892761, 0.5654674172401428, 0.5453622341156006, 0.5323063731193542, 0.5220463275909424, 0.5138917565345764, 0.49681633710861206, 0.4932042956352234, 0.4771926999092102, 0.47253382205963135, 0.4653850793838501, 0.45595622062683105, 0.4481584131717682, 0.441282719373703, 0.43862780928611755, 0.4329477548599243, 0.42971888184547424, 0.4201953113079071, 0.4177950322628021, 0.4111347198486328, 0.4088835120201111, 0.40494221448898315, 0.39904963970184326, 0.3908008635044098, 0.38781747221946716, 0.3885575830936432, 0.3802401125431061, 0.3808881342411041, 0.37390759587287903, 0.37205952405929565, 0.3677295744419098, 0.3618599474430084, 0.3556292653083801, 0.35776033997535706, 0.3565997779369354, 0.3464242219924927, 0.34533393383026123, 0.3415943682193756, 0.3414049744606018, 0.33789533376693726, 0.3323599398136139], 'accuracy': [0.4272916615009308, 0.6544791460037231, 0.715708315372467, 0.7512291669845581, 0.7735000252723694, 0.7934791445732117, 0.8038958311080933, 0.8106458187103271, 0.823229193687439, 0.8301666378974915, 0.8340833187103271, 0.8412500023841858, 0.8442708253860474, 0.8477291464805603, 0.8516250252723694, 0.8551041483879089, 0.8588333129882812, 0.8619583249092102, 0.8663125038146973, 0.8681666851043701, 0.8715000152587891, 0.8727499842643738, 0.8739166855812073, 0.8768333196640015, 0.8791249990463257, 0.8789166808128357, 0.8825416564941406, 0.8832291960716248, 0.8851458430290222, 0.8865833282470703, 0.885895848274231, 0.8889791369438171, 0.8920833468437195, 0.8924166560173035, 0.8915833234786987, 0.8955833315849304, 0.8945208191871643, 0.8980208039283752, 0.8962083458900452, 0.898520827293396, 0.9006666541099548, 0.9029374718666077, 0.9013749957084656, 0.9024999737739563, 0.9042291641235352, 0.9051666855812073, 0.9067708253860474, 0.9073749780654907, 0.9079999923706055, 0.9089999794960022], 'val_loss': [0.8788720965385437, 0.6131265163421631, 0.50369793176651, 0.4418611228466034, 0.4097743332386017, 0.38433751463890076, 0.3698095977306366, 0.3545985221862793, 0.3444073498249054, 0.33754676580429077, 0.32907164096832275, 0.3240942656993866, 0.3189517557621002, 0.31335002183914185, 0.3098287880420685, 0.30391189455986023, 0.30209916830062866, 0.2996941804885864, 0.29727092385292053, 0.2940061092376709, 0.2911921739578247, 0.2888130247592926, 0.28710055351257324, 0.2855270504951477, 0.28254052996635437, 0.2810884118080139, 0.2794222831726074, 0.27738288044929504, 0.27400025725364685, 0.27244997024536133, 0.27136358618736267, 0.269507497549057, 0.268303781747818, 0.2682860493659973, 0.26554226875305176, 0.26395004987716675, 0.26155075430870056, 0.26145005226135254, 0.25944289565086365, 0.25719788670539856, 0.255349725484848, 0.25399911403656006, 0.25419509410858154, 0.2518337368965149, 0.2513793408870697, 0.2511090040206909, 0.24911487102508545, 0.24580509960651398, 0.24700331687927246, 0.24509386718273163], 'val_accuracy': [0.7895833253860474, 0.8425833582878113, 0.8650833368301392, 0.878000020980835, 0.8847500085830688, 0.8891666531562805, 0.8917499780654907, 0.8951666951179504, 0.8969166874885559, 0.8983333110809326, 0.9003333449363708, 0.9024166464805603, 0.9055833220481873, 0.9053333401679993, 0.9077500104904175, 0.9085833430290222, 0.9101666808128357, 0.9104999899864197, 0.9130833148956299, 0.9122499823570251, 0.9139999747276306, 0.9140833616256714, 0.9147499799728394, 0.9146666526794434, 0.9169166684150696, 0.9167500138282776, 0.9181666374206543, 0.918666660785675, 0.9198333621025085, 0.9204999804496765, 0.92166668176651, 0.9207500219345093, 0.921833336353302, 0.9212499856948853, 0.9225000143051147, 0.9237499833106995, 0.924916684627533, 0.924916684627533, 0.9255833625793457, 0.9256666898727417, 0.9260833263397217, 0.9269999861717224, 0.9261666536331177, 0.9270833134651184, 0.9283333420753479, 0.9288333058357239, 0.9278333187103271, 0.9295833110809326, 0.9297500252723694, 0.9309166669845581]}\n",
      "{'loss': [2.288398027420044, 2.156951904296875, 1.8412694931030273, 1.5400537252426147, 1.3142532110214233, 1.1461352109909058, 1.0196255445480347, 0.9250281453132629, 0.8570480942726135, 0.8066404461860657, 0.7482709884643555, 0.7041646242141724, 0.6673239469528198, 0.627753496170044, 0.6051150560379028, 0.5758916735649109, 0.5510557293891907, 0.5310711860656738, 0.5074746012687683, 0.49046239256858826, 0.4730249345302582, 0.4480782747268677, 0.43663835525512695, 0.42653191089630127, 0.40558889508247375, 0.39322957396507263, 0.38151782751083374, 0.3720722198486328, 0.3570464551448822, 0.34550753235816956, 0.3282499313354492, 0.3273599147796631, 0.31777939200401306, 0.3041190803050995, 0.29775553941726685, 0.29272162914276123, 0.2811887860298157, 0.2796842157840729, 0.2689940929412842, 0.2563219368457794, 0.2524285316467285, 0.24454207718372345, 0.24288226664066315, 0.23427876830101013, 0.2316618710756302, 0.22409336268901825, 0.21740271151065826, 0.20947833359241486, 0.20671163499355316, 0.19720616936683655], 'accuracy': [0.12793749570846558, 0.22175000607967377, 0.3374166786670685, 0.44333332777023315, 0.5338541865348816, 0.6043750047683716, 0.6563125252723694, 0.6982499957084656, 0.7242708206176758, 0.7486666440963745, 0.7731666564941406, 0.7880625128746033, 0.8042708039283752, 0.8156458139419556, 0.8253541588783264, 0.8363333344459534, 0.8445000052452087, 0.8487916588783264, 0.8566666841506958, 0.8629999756813049, 0.8702916502952576, 0.8764166831970215, 0.8792499899864197, 0.8838124871253967, 0.8885625004768372, 0.893541693687439, 0.8990625143051147, 0.8995833396911621, 0.9046666622161865, 0.9063958525657654, 0.9120416641235352, 0.9122708439826965, 0.9148749709129333, 0.9165208339691162, 0.9210833311080933, 0.9225624799728394, 0.9245833158493042, 0.9235833287239075, 0.9275000095367432, 0.929645836353302, 0.9315624833106995, 0.9344375133514404, 0.9347083568572998, 0.9370416402816772, 0.9382500052452087, 0.9388541579246521, 0.9406874775886536, 0.9436458349227905, 0.9436666369438171, 0.9468333125114441], 'val_loss': [2.2145614624023438, 1.8413269519805908, 1.3805792331695557, 1.0547869205474854, 0.8218513131141663, 0.68316650390625, 0.5782214999198914, 0.5123029947280884, 0.45994532108306885, 0.4231439530849457, 0.3935813307762146, 0.3683529794216156, 0.34342247247695923, 0.32629889249801636, 0.31042638421058655, 0.29329630732536316, 0.2817453444004059, 0.2708590626716614, 0.2624679207801819, 0.25385546684265137, 0.24330206215381622, 0.23689280450344086, 0.23096460103988647, 0.2252684086561203, 0.2199607938528061, 0.21618784964084625, 0.2109607309103012, 0.20864440500736237, 0.20387032628059387, 0.2017728090286255, 0.1983620673418045, 0.19729319214820862, 0.1923999786376953, 0.19030529260635376, 0.18880930542945862, 0.18718326091766357, 0.18630726635456085, 0.1832592785358429, 0.18081393837928772, 0.18430493772029877, 0.18030309677124023, 0.18051736056804657, 0.1755736917257309, 0.1765798181295395, 0.17481136322021484, 0.17619262635707855, 0.174979567527771, 0.1772073358297348, 0.17665646970272064, 0.1747204214334488], 'val_accuracy': [0.3935833275318146, 0.4909999966621399, 0.5569999814033508, 0.7083333134651184, 0.793749988079071, 0.8287500143051147, 0.8553333282470703, 0.874666690826416, 0.8859166502952576, 0.8939999938011169, 0.8989166617393494, 0.903249979019165, 0.9089999794960022, 0.9115833044052124, 0.9156666398048401, 0.9191666841506958, 0.9213333129882812, 0.925000011920929, 0.9285833239555359, 0.9311666488647461, 0.9349166750907898, 0.9355000257492065, 0.9375, 0.9388333559036255, 0.9401666522026062, 0.9417499899864197, 0.9430833458900452, 0.9449166655540466, 0.9447500109672546, 0.9460833072662354, 0.9474999904632568, 0.9481666684150696, 0.9489166736602783, 0.950083315372467, 0.9508333206176758, 0.9509166479110718, 0.9517499804496765, 0.9524166584014893, 0.95291668176651, 0.953000009059906, 0.9545833468437195, 0.9545833468437195, 0.9555000066757202, 0.9554166793823242, 0.956083357334137, 0.956083357334137, 0.9571666717529297, 0.9575833082199097, 0.9582499861717224, 0.9578333497047424]}\n",
      "{'loss': [2.254943609237671, 1.8972675800323486, 1.4730762243270874, 1.1741316318511963, 0.9822481870651245, 0.8490462899208069, 0.7563499212265015, 0.6994575262069702, 0.6511932015419006, 0.6052373647689819, 0.5751098394393921, 0.5432778000831604, 0.5200024247169495, 0.5013258457183838, 0.4729957580566406, 0.4604945480823517, 0.43952086567878723, 0.42716264724731445, 0.41259145736694336, 0.39518070220947266, 0.384456068277359, 0.37291476130485535, 0.3635318875312805, 0.3528903126716614, 0.3473774492740631, 0.3308258354663849, 0.32760417461395264, 0.3175092339515686, 0.30683451890945435, 0.30241620540618896, 0.2980378270149231, 0.2896411418914795, 0.278494268655777, 0.2721542418003082, 0.2713944911956787, 0.26478174328804016, 0.25577446818351746, 0.2513766884803772, 0.24684414267539978, 0.24235504865646362, 0.2373705804347992, 0.22788967192173004, 0.22543536126613617, 0.22241149842739105, 0.2170134037733078, 0.21325460076332092, 0.20852310955524445, 0.20452110469341278, 0.20079512894153595, 0.19692480564117432], 'accuracy': [0.16891667246818542, 0.35104167461395264, 0.49154165387153625, 0.6047916412353516, 0.6827499866485596, 0.731041669845581, 0.7669166922569275, 0.7902708053588867, 0.8068333268165588, 0.8230624794960022, 0.8342499732971191, 0.8459166884422302, 0.8526666760444641, 0.8577916622161865, 0.8662499785423279, 0.8728125095367432, 0.8777499794960022, 0.8812500238418579, 0.885812520980835, 0.8929166793823242, 0.8950833082199097, 0.8992499709129333, 0.901354193687439, 0.9041041731834412, 0.9052083492279053, 0.9101666808128357, 0.909375011920929, 0.9140833616256714, 0.9166458249092102, 0.9191458225250244, 0.9191041588783264, 0.9213958382606506, 0.9238749742507935, 0.9267916679382324, 0.9275624752044678, 0.9281250238418579, 0.929979145526886, 0.9319791793823242, 0.9336041808128357, 0.9353749752044678, 0.9364791512489319, 0.9379374980926514, 0.9398124814033508, 0.9395833611488342, 0.9412708282470703, 0.9416041374206543, 0.9437916874885559, 0.9437291622161865, 0.945604145526886, 0.9472083449363708], 'val_loss': [2.088951587677002, 1.4074541330337524, 0.9385149478912354, 0.6797176003456116, 0.5370451807975769, 0.46276265382766724, 0.41282331943511963, 0.37999874353408813, 0.3620433807373047, 0.3363263010978699, 0.3217581510543823, 0.3084431290626526, 0.29738059639930725, 0.28659534454345703, 0.2762991189956665, 0.26760420203208923, 0.2618701457977295, 0.25583523511886597, 0.24767854809761047, 0.24291718006134033, 0.23923836648464203, 0.23021814227104187, 0.22788260877132416, 0.2233065813779831, 0.21808913350105286, 0.21353039145469666, 0.20982882380485535, 0.20854108035564423, 0.2055421620607376, 0.20070508122444153, 0.19829705357551575, 0.19585178792476654, 0.19403043389320374, 0.1902170479297638, 0.18715250492095947, 0.1861887276172638, 0.18499061465263367, 0.18514801561832428, 0.18209053575992584, 0.18015122413635254, 0.17797881364822388, 0.17693878710269928, 0.17564800381660461, 0.17495645582675934, 0.173148512840271, 0.17325498163700104, 0.1720832884311676, 0.1708090454339981, 0.17050114274024963, 0.17232704162597656], 'val_accuracy': [0.46058332920074463, 0.5707499980926514, 0.731249988079071, 0.8213333487510681, 0.856333315372467, 0.8712499737739563, 0.8825833201408386, 0.8915833234786987, 0.8945000171661377, 0.9023333191871643, 0.9051666855812073, 0.909416675567627, 0.9129166603088379, 0.9147499799728394, 0.9172499775886536, 0.9208333492279053, 0.92166668176651, 0.9241666793823242, 0.9255833625793457, 0.9276666641235352, 0.9283333420753479, 0.9298333525657654, 0.9320833086967468, 0.9332500100135803, 0.934499979019165, 0.9366666674613953, 0.9380000233650208, 0.9369999766349792, 0.9390000104904175, 0.9412500262260437, 0.9421666860580444, 0.9426666498184204, 0.9436666369438171, 0.9443333148956299, 0.9449999928474426, 0.9460833072662354, 0.9451666474342346, 0.9455000162124634, 0.9470000267028809, 0.9470833539962769, 0.9495000243186951, 0.9495000243186951, 0.9502500295639038, 0.950166642665863, 0.9514166712760925, 0.9513333439826965, 0.9514166712760925, 0.9515833258628845, 0.9508333206176758, 0.9514166712760925]}\n",
      "{'loss': [1.6163660287857056, 0.9965621829032898, 0.8287918567657471, 0.7388557195663452, 0.6894800066947937, 0.6490326523780823, 0.6068059802055359, 0.5895620584487915, 0.5666553974151611, 0.545586884021759, 0.5309308767318726, 0.518423318862915, 0.5021827220916748, 0.49260714650154114, 0.4803357720375061, 0.46723294258117676, 0.4615615904331207, 0.45066991448402405, 0.4400990307331085, 0.42895886301994324, 0.42221683263778687, 0.4158310890197754, 0.408376544713974, 0.39813676476478577, 0.39279934763908386, 0.38454023003578186, 0.38373613357543945, 0.37500324845314026, 0.36707088351249695, 0.36184948682785034, 0.3600201904773712, 0.35055211186408997, 0.3435612916946411, 0.3422073423862457, 0.3358578383922577, 0.3324088454246521, 0.3286312520503998, 0.3265496790409088, 0.31944090127944946, 0.31944140791893005, 0.3066413402557373, 0.31316256523132324, 0.3044149577617645, 0.29632067680358887, 0.29908132553100586, 0.2938322424888611, 0.2876493036746979, 0.2909105718135834, 0.28378525376319885, 0.2799251973628998], 'accuracy': [0.4469583332538605, 0.6699583530426025, 0.7302291393280029, 0.7664166688919067, 0.7830208539962769, 0.8014166951179504, 0.8120625019073486, 0.8228541612625122, 0.8303124904632568, 0.835770845413208, 0.840624988079071, 0.8460624814033508, 0.8516666889190674, 0.8557083606719971, 0.859458327293396, 0.8636875152587891, 0.8663958311080933, 0.8680208325386047, 0.8716874718666077, 0.874958336353302, 0.8762291669845581, 0.8801875114440918, 0.8825833201408386, 0.8841458559036255, 0.8870624899864197, 0.8901249766349792, 0.8893749713897705, 0.8929583430290222, 0.8948125243186951, 0.8963541388511658, 0.8981249928474426, 0.8988333344459534, 0.9014166593551636, 0.9010833501815796, 0.903291642665863, 0.9057499766349792, 0.9068333506584167, 0.906166672706604, 0.9093124866485596, 0.9094791412353516, 0.9122916460037231, 0.9113749861717224, 0.9118333458900452, 0.9146875143051147, 0.9148958325386047, 0.9163541793823242, 0.9180416464805603, 0.9180625081062317, 0.9198125004768372, 0.9208333492279053], 'val_loss': [0.792585015296936, 0.5525318384170532, 0.4585859477519989, 0.4106428921222687, 0.3814423084259033, 0.36059826612472534, 0.34661242365837097, 0.3321733772754669, 0.3220885694026947, 0.31445905566215515, 0.30530619621276855, 0.2990233898162842, 0.2917337715625763, 0.2861323952674866, 0.2829819619655609, 0.2779390215873718, 0.2723046541213989, 0.26722192764282227, 0.2638155221939087, 0.2590906023979187, 0.2571698725223541, 0.25156688690185547, 0.24889741837978363, 0.2461308389902115, 0.2427842766046524, 0.2399386167526245, 0.2369387447834015, 0.23310285806655884, 0.2330399602651596, 0.22795844078063965, 0.22560565173625946, 0.2221495509147644, 0.22197923064231873, 0.21792885661125183, 0.21758797764778137, 0.21339741349220276, 0.21379484236240387, 0.2112647294998169, 0.20988735556602478, 0.20864294469356537, 0.2061147689819336, 0.2038586586713791, 0.20503491163253784, 0.20223432779312134, 0.19929762184619904, 0.1992640644311905, 0.1963053196668625, 0.19572953879833221, 0.1951006054878235, 0.19296175241470337], 'val_accuracy': [0.809249997138977, 0.8490833044052124, 0.8694166541099548, 0.8817499876022339, 0.8888333439826965, 0.893750011920929, 0.8994166851043701, 0.9012500047683716, 0.9045000076293945, 0.9056666493415833, 0.9100833535194397, 0.9104166626930237, 0.9133333563804626, 0.9148333072662354, 0.9153333306312561, 0.9164166450500488, 0.918749988079071, 0.921583354473114, 0.9226666688919067, 0.9225833415985107, 0.9227499961853027, 0.925166666507721, 0.9266666769981384, 0.9269166588783264, 0.9282500147819519, 0.9295833110809326, 0.9300000071525574, 0.9304999709129333, 0.9309166669845581, 0.9321666955947876, 0.9331666827201843, 0.9350833296775818, 0.934499979019165, 0.9363333582878113, 0.9361666440963745, 0.937333345413208, 0.9375, 0.937666654586792, 0.9385833144187927, 0.9390000104904175, 0.940500020980835, 0.940833330154419, 0.9409166574478149, 0.9418333172798157, 0.9433333277702332, 0.9424999952316284, 0.9435833096504211, 0.9434166550636292, 0.9433333277702332, 0.9443333148956299]}\n",
      "{'loss': [1.4227508306503296, 0.907420814037323, 0.7734882831573486, 0.7041784524917603, 0.6565449833869934, 0.6171472668647766, 0.5955215096473694, 0.5620104670524597, 0.5473171472549438, 0.5282597541809082, 0.5215269923210144, 0.497038871049881, 0.4924949109554291, 0.47357189655303955, 0.47139033675193787, 0.4582604169845581, 0.45278966426849365, 0.44212621450424194, 0.4396626055240631, 0.423951119184494, 0.4164091944694519, 0.41070035099983215, 0.4077518582344055, 0.40310901403427124, 0.3998532295227051, 0.3883853256702423, 0.3855133354663849, 0.37784358859062195, 0.3727891445159912, 0.3658348321914673, 0.36663639545440674, 0.36398541927337646, 0.35955944657325745, 0.3550679385662079, 0.3532710373401642, 0.34850576519966125, 0.34438806772232056, 0.3428647518157959, 0.3408293128013611, 0.3341648578643799, 0.32609331607818604, 0.32746005058288574, 0.3239692449569702, 0.32235562801361084, 0.31621867418289185, 0.3119725286960602, 0.3093908131122589, 0.3104899823665619, 0.30866265296936035, 0.3075428605079651], 'accuracy': [0.5368124842643738, 0.7044791579246521, 0.7538541555404663, 0.7815625071525574, 0.7989374995231628, 0.8129166960716248, 0.820062518119812, 0.8317916393280029, 0.8364583253860474, 0.8435208201408386, 0.846833348274231, 0.8531041741371155, 0.8558541536331177, 0.859125018119812, 0.8622083067893982, 0.8665624856948853, 0.866895854473114, 0.870520830154419, 0.8742083311080933, 0.8784999847412109, 0.879770815372467, 0.8793333172798157, 0.8816666603088379, 0.8833958506584167, 0.8832291960716248, 0.8885416388511658, 0.8890625238418579, 0.8916875123977661, 0.8923749923706055, 0.895104169845581, 0.8946666717529297, 0.893625020980835, 0.8958333134651184, 0.8982916474342346, 0.8993541598320007, 0.9013333320617676, 0.9011250138282776, 0.9027083516120911, 0.903333306312561, 0.9040208458900452, 0.9067500233650208, 0.905916690826416, 0.9074583053588867, 0.9084166884422302, 0.9104375243186951, 0.9098541736602783, 0.9116041660308838, 0.9112291932106018, 0.9115208387374878, 0.9124166369438171], 'val_loss': [0.4910697937011719, 0.40876612067222595, 0.37611424922943115, 0.3584437668323517, 0.34980320930480957, 0.33885011076927185, 0.32413432002067566, 0.3159380555152893, 0.31044644117355347, 0.30573201179504395, 0.3016831874847412, 0.2950763404369354, 0.2917110323905945, 0.28734228014945984, 0.2823666036128998, 0.27894318103790283, 0.27596932649612427, 0.2745448052883148, 0.2699548006057739, 0.26928335428237915, 0.265065461397171, 0.2605563700199127, 0.26111549139022827, 0.25792980194091797, 0.25292766094207764, 0.2520357370376587, 0.25317829847335815, 0.2480749785900116, 0.24766680598258972, 0.24489428102970123, 0.24220812320709229, 0.24525626003742218, 0.24151967465877533, 0.2410954385995865, 0.2384924739599228, 0.23506827652454376, 0.23367221653461456, 0.23376381397247314, 0.23093003034591675, 0.2301943302154541, 0.22975663840770721, 0.22683319449424744, 0.22485363483428955, 0.22418387234210968, 0.22108592092990875, 0.22135896980762482, 0.22081957757472992, 0.21908485889434814, 0.218047633767128, 0.21477381885051727], 'val_accuracy': [0.8544999957084656, 0.8833333253860474, 0.890666663646698, 0.8958333134651184, 0.8989166617393494, 0.9010000228881836, 0.9042500257492065, 0.906499981880188, 0.9076666831970215, 0.9099166393280029, 0.9102500081062317, 0.9117500185966492, 0.9135833382606506, 0.9144999980926514, 0.9149166941642761, 0.9164999723434448, 0.9171666502952576, 0.9173333048820496, 0.918916642665863, 0.9194166660308838, 0.9207500219345093, 0.922249972820282, 0.92166668176651, 0.9225833415985107, 0.9238333106040955, 0.925166666507721, 0.9235000014305115, 0.9260833263397217, 0.9252499938011169, 0.9256666898727417, 0.9263333082199097, 0.9265833497047424, 0.9271666407585144, 0.9277499914169312, 0.9286666512489319, 0.9298333525657654, 0.9296666383743286, 0.9292500019073486, 0.9298333525657654, 0.9311666488647461, 0.9313333630561829, 0.9324166774749756, 0.9325833320617676, 0.9323333501815796, 0.9331666827201843, 0.9335833191871643, 0.9340833425521851, 0.9348333477973938, 0.9350833296775818, 0.9365833401679993]}\n",
      "{'loss': [2.2937681674957275, 2.2716708183288574, 2.2108442783355713, 1.9400947093963623, 1.5383635759353638, 1.2313529253005981, 1.037609577178955, 0.9197636842727661, 0.8253551721572876, 0.7690098285675049, 0.7290669083595276, 0.6838186979293823, 0.6492999792098999, 0.6177427768707275, 0.592917263507843, 0.5687434673309326, 0.5428081154823303, 0.5198954939842224, 0.5076556205749512, 0.48915112018585205, 0.47155892848968506, 0.45766162872314453, 0.4412468373775482, 0.4308500587940216, 0.41890808939933777, 0.40395262837409973, 0.39827287197113037, 0.38008561730384827, 0.37514254450798035, 0.3639953136444092, 0.3537910282611847, 0.3452221155166626, 0.33686262369155884, 0.330853134393692, 0.32121673226356506, 0.31755971908569336, 0.3090709447860718, 0.30530449748039246, 0.2977389097213745, 0.2913285791873932, 0.2832079529762268, 0.2811647355556488, 0.27247554063796997, 0.26791250705718994, 0.2660643458366394, 0.2584356963634491, 0.2539460361003876, 0.24980725347995758, 0.2479151040315628, 0.23920518159866333], 'accuracy': [0.15279166400432587, 0.23245833814144135, 0.31168749928474426, 0.3799374997615814, 0.4964583218097687, 0.5962916612625122, 0.6631666421890259, 0.7085416913032532, 0.7432916760444641, 0.7639791369438171, 0.78145831823349, 0.7964583039283752, 0.8091458082199097, 0.820354163646698, 0.8305416703224182, 0.8396875262260437, 0.8436458110809326, 0.8533541560173035, 0.8556666374206543, 0.8620208501815796, 0.8691458106040955, 0.8745833039283752, 0.8770416378974915, 0.8799791932106018, 0.8845624923706055, 0.887708306312561, 0.8903124928474426, 0.8958125114440918, 0.8974166512489319, 0.8992916941642761, 0.9036666750907898, 0.9056666493415833, 0.9066666960716248, 0.910979151725769, 0.9151250123977661, 0.9129166603088379, 0.9154583215713501, 0.9180208444595337, 0.9183333516120911, 0.921541690826416, 0.9230208396911621, 0.9230833053588867, 0.9255416393280029, 0.9268125295639038, 0.9278333187103271, 0.9315208196640015, 0.9309583306312561, 0.9314374923706055, 0.9334166646003723, 0.9355208277702332], 'val_loss': [2.283317804336548, 2.2520952224731445, 2.1019270420074463, 1.5359586477279663, 1.0169658660888672, 0.7550494074821472, 0.6198365688323975, 0.543586790561676, 0.48958879709243774, 0.4537806808948517, 0.423706978559494, 0.402152955532074, 0.37828633189201355, 0.36041879653930664, 0.34448790550231934, 0.33083397150039673, 0.3181787431240082, 0.30782410502433777, 0.29562219977378845, 0.28519365191459656, 0.27617955207824707, 0.2687780559062958, 0.2608993351459503, 0.25250881910324097, 0.24784183502197266, 0.24066096544265747, 0.23472516238689423, 0.22886785864830017, 0.22494997084140778, 0.219929501414299, 0.21594512462615967, 0.21215270459651947, 0.20687882602214813, 0.20517481863498688, 0.20226037502288818, 0.1990034431219101, 0.1941205859184265, 0.19250138103961945, 0.18820668756961823, 0.1862451583147049, 0.18666058778762817, 0.18273329734802246, 0.18039652705192566, 0.17911826074123383, 0.17810127139091492, 0.17512744665145874, 0.17363092303276062, 0.17361266911029816, 0.17072172462940216, 0.17045533657073975], 'val_accuracy': [0.25850000977516174, 0.3374166786670685, 0.4032500088214874, 0.5597500205039978, 0.7309166789054871, 0.8105833530426025, 0.8403333425521851, 0.8566666841506958, 0.8665833473205566, 0.8799166679382324, 0.8866666555404663, 0.890916645526886, 0.8960833549499512, 0.9004999995231628, 0.9036666750907898, 0.906416654586792, 0.9109166860580444, 0.9124166369438171, 0.9158333539962769, 0.918916642665863, 0.9203333258628845, 0.9227499961853027, 0.9230833053588867, 0.9260833263397217, 0.9288333058357239, 0.9292500019073486, 0.9313333630561829, 0.9328333139419556, 0.934249997138977, 0.9355000257492065, 0.9356666803359985, 0.9375, 0.9391666650772095, 0.9399999976158142, 0.9396666884422302, 0.9412500262260437, 0.9418333172798157, 0.9435833096504211, 0.9443333148956299, 0.9455833435058594, 0.9462500214576721, 0.9470833539962769, 0.9474999904632568, 0.9486666917800903, 0.9492499828338623, 0.949999988079071, 0.9507499933242798, 0.9505833387374878, 0.9518333077430725, 0.9516666531562805]}\n",
      "{'loss': [2.2971746921539307, 2.275252342224121, 2.237391233444214, 2.0950798988342285, 1.7189723253250122, 1.414182424545288, 1.1976979970932007, 1.0272008180618286, 0.9081761837005615, 0.8276953101158142, 0.7633920907974243, 0.7248029708862305, 0.6855894923210144, 0.6595947742462158, 0.6271055936813354, 0.6104719042778015, 0.5858266353607178, 0.57689368724823, 0.5566782355308533, 0.5417388081550598, 0.5296198129653931, 0.5133413672447205, 0.49923208355903625, 0.4889507591724396, 0.4813864827156067, 0.46989214420318604, 0.45866379141807556, 0.45511141419410706, 0.4418819546699524, 0.4321577548980713, 0.4237574338912964, 0.4177382290363312, 0.40875691175460815, 0.39873725175857544, 0.38975873589515686, 0.3840208351612091, 0.3792051672935486, 0.36841723322868347, 0.3646625280380249, 0.35864704847335815, 0.3546805679798126, 0.3505801856517792, 0.341604620218277, 0.33289867639541626, 0.3329576849937439, 0.32397639751434326, 0.32276976108551025, 0.3181398808956146, 0.3099151849746704, 0.3082892894744873], 'accuracy': [0.13614583015441895, 0.2147083282470703, 0.2994791567325592, 0.3701666593551636, 0.4255833327770233, 0.515708327293396, 0.5978958606719971, 0.6654791831970215, 0.7087083458900452, 0.7396249771118164, 0.7658541798591614, 0.7801666855812073, 0.7927500009536743, 0.8024374842643738, 0.8153749704360962, 0.8208958506584167, 0.8289166688919067, 0.8333541750907898, 0.8383125066757202, 0.8421458601951599, 0.8472499847412109, 0.8533750176429749, 0.859000027179718, 0.859333336353302, 0.8637499809265137, 0.8662291765213013, 0.8696874976158142, 0.8708958625793457, 0.8744166493415833, 0.8776666522026062, 0.8797500133514404, 0.8819583058357239, 0.8865208625793457, 0.8878750205039978, 0.8903124928474426, 0.8925833106040955, 0.8922708630561829, 0.8962916731834412, 0.898479163646698, 0.8994166851043701, 0.9004999995231628, 0.903083324432373, 0.9045624732971191, 0.9077500104904175, 0.9085208177566528, 0.9102500081062317, 0.9100416898727417, 0.9116666913032532, 0.9142500162124634, 0.9150416851043701], 'val_loss': [2.2868545055389404, 2.2606563568115234, 2.198469638824463, 1.8594903945922852, 1.3264782428741455, 1.0160377025604248, 0.7936534285545349, 0.6448266506195068, 0.5537754893302917, 0.4971126616001129, 0.4584454298019409, 0.43211260437965393, 0.41237714886665344, 0.3951936364173889, 0.37863147258758545, 0.3676723539829254, 0.3565216064453125, 0.3495996594429016, 0.34011274576187134, 0.3323845863342285, 0.32520362734794617, 0.3161744475364685, 0.3103165626525879, 0.30522990226745605, 0.29805105924606323, 0.29225724935531616, 0.2872447073459625, 0.2824912369251251, 0.27735134959220886, 0.2722134292125702, 0.26702648401260376, 0.26254019141197205, 0.26056328415870667, 0.2557147741317749, 0.25273001194000244, 0.24812716245651245, 0.24421292543411255, 0.24148832261562347, 0.2372005134820938, 0.23326058685779572, 0.23126305639743805, 0.22736981511116028, 0.22465141117572784, 0.22250531613826752, 0.2192162722349167, 0.21651633083820343, 0.2140262871980667, 0.21183766424655914, 0.20894788205623627, 0.20658338069915771], 'val_accuracy': [0.15308333933353424, 0.3059999942779541, 0.45899999141693115, 0.4469166696071625, 0.6176666617393494, 0.7018333077430725, 0.7861666679382324, 0.8275833129882812, 0.8504166603088379, 0.8644999861717224, 0.8723333477973938, 0.8807500004768372, 0.8840000033378601, 0.890250027179718, 0.8918333053588867, 0.8927500247955322, 0.8960000276565552, 0.8983333110809326, 0.9010000228881836, 0.9026666879653931, 0.9057499766349792, 0.9066666960716248, 0.9089999794960022, 0.9099166393280029, 0.9129166603088379, 0.9132500290870667, 0.9146666526794434, 0.9169166684150696, 0.918916642665863, 0.9199166893959045, 0.9206666946411133, 0.9223333597183228, 0.9238333106040955, 0.924833357334137, 0.9265833497047424, 0.9273333549499512, 0.9275833368301392, 0.9294166564941406, 0.9300000071525574, 0.9313333630561829, 0.9314166903495789, 0.9326666593551636, 0.9335833191871643, 0.9339166879653931, 0.9355000257492065, 0.9363333582878113, 0.9379166960716248, 0.9370833039283752, 0.9391666650772095, 0.9402499794960022]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "noise_5depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
