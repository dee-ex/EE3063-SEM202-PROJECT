{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "56c6b994-aece-4772-9c65-a923b64ce113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 21s 11ms/step - loss: 2.3814 - accuracy: 0.1278 - val_loss: 1.8232 - val_accuracy: 0.4270\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.1109 - accuracy: 0.2228 - val_loss: 1.5422 - val_accuracy: 0.5455\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.9208 - accuracy: 0.2933 - val_loss: 1.3633 - val_accuracy: 0.5778\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.7785 - accuracy: 0.3453 - val_loss: 1.2460 - val_accuracy: 0.5923\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.6642 - accuracy: 0.3826 - val_loss: 1.1707 - val_accuracy: 0.5967\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5896 - accuracy: 0.4079 - val_loss: 1.1252 - val_accuracy: 0.6057\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5168 - accuracy: 0.4332 - val_loss: 1.0898 - val_accuracy: 0.6112\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4565 - accuracy: 0.4550 - val_loss: 1.0666 - val_accuracy: 0.6215\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4176 - accuracy: 0.4712 - val_loss: 1.0394 - val_accuracy: 0.6247\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3805 - accuracy: 0.4879 - val_loss: 1.0216 - val_accuracy: 0.6292\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3531 - accuracy: 0.4971 - val_loss: 1.0075 - val_accuracy: 0.6263\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3069 - accuracy: 0.5120 - val_loss: 0.9915 - val_accuracy: 0.6458\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2973 - accuracy: 0.5201 - val_loss: 0.9747 - val_accuracy: 0.6551\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2595 - accuracy: 0.5298 - val_loss: 0.9634 - val_accuracy: 0.6594\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2401 - accuracy: 0.5363 - val_loss: 0.9497 - val_accuracy: 0.6497\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2193 - accuracy: 0.5497 - val_loss: 0.9350 - val_accuracy: 0.6508\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2023 - accuracy: 0.5520 - val_loss: 0.9208 - val_accuracy: 0.6518\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1869 - accuracy: 0.5601 - val_loss: 0.9020 - val_accuracy: 0.6552\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.1712 - accuracy: 0.5644 - val_loss: 0.8947 - val_accuracy: 0.6538\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1559 - accuracy: 0.5721 - val_loss: 0.8925 - val_accuracy: 0.6513\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1464 - accuracy: 0.5701 - val_loss: 0.8764 - val_accuracy: 0.6559\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1256 - accuracy: 0.5763 - val_loss: 0.8777 - val_accuracy: 0.6482\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1315 - accuracy: 0.5776 - val_loss: 0.8649 - val_accuracy: 0.6629\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1101 - accuracy: 0.5834 - val_loss: 0.8547 - val_accuracy: 0.6600\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0866 - accuracy: 0.5943 - val_loss: 0.8589 - val_accuracy: 0.6552\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0808 - accuracy: 0.5914 - val_loss: 0.8462 - val_accuracy: 0.6637\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0853 - accuracy: 0.5949 - val_loss: 0.8417 - val_accuracy: 0.6646\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0762 - accuracy: 0.5939 - val_loss: 0.8390 - val_accuracy: 0.6645\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0503 - accuracy: 0.6026 - val_loss: 0.8401 - val_accuracy: 0.6653\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0591 - accuracy: 0.6010 - val_loss: 0.8336 - val_accuracy: 0.6652\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0522 - accuracy: 0.6035 - val_loss: 0.8283 - val_accuracy: 0.6639\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0389 - accuracy: 0.6069 - val_loss: 0.8270 - val_accuracy: 0.6713\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0368 - accuracy: 0.6053 - val_loss: 0.8443 - val_accuracy: 0.6533\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0383 - accuracy: 0.6054 - val_loss: 0.8134 - val_accuracy: 0.6685\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0220 - accuracy: 0.6065 - val_loss: 0.8121 - val_accuracy: 0.6679\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0092 - accuracy: 0.6133 - val_loss: 0.8099 - val_accuracy: 0.6689\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0160 - accuracy: 0.6119 - val_loss: 0.8128 - val_accuracy: 0.6572\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0031 - accuracy: 0.6133 - val_loss: 0.7973 - val_accuracy: 0.6591\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0018 - accuracy: 0.6130 - val_loss: 0.8012 - val_accuracy: 0.6607\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9976 - accuracy: 0.6134 - val_loss: 0.8103 - val_accuracy: 0.6588\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9928 - accuracy: 0.6157 - val_loss: 0.8036 - val_accuracy: 0.6613\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0030 - accuracy: 0.6132 - val_loss: 0.7973 - val_accuracy: 0.6709\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9896 - accuracy: 0.6120 - val_loss: 0.7852 - val_accuracy: 0.6743\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9779 - accuracy: 0.6161 - val_loss: 0.7824 - val_accuracy: 0.6632\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9717 - accuracy: 0.6199 - val_loss: 0.7930 - val_accuracy: 0.6636\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9675 - accuracy: 0.6182 - val_loss: 0.7848 - val_accuracy: 0.6746\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9616 - accuracy: 0.6187 - val_loss: 0.7814 - val_accuracy: 0.6727\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9623 - accuracy: 0.6234 - val_loss: 0.7762 - val_accuracy: 0.6678\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9410 - accuracy: 0.6233 - val_loss: 0.7801 - val_accuracy: 0.6770\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9470 - accuracy: 0.6269 - val_loss: 0.7727 - val_accuracy: 0.6780\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 6s 10ms/step - loss: 2.3035 - accuracy: 0.1086 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3011 - accuracy: 0.1246 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3006 - accuracy: 0.1190 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2998 - accuracy: 0.1222 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2996 - accuracy: 0.1188 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2976 - accuracy: 0.1246 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2948 - accuracy: 0.1335 - val_loss: 2.2926 - val_accuracy: 0.1147\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2882 - accuracy: 0.1443 - val_loss: 2.2682 - val_accuracy: 0.1877\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2671 - accuracy: 0.1660 - val_loss: 2.1911 - val_accuracy: 0.2141\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2132 - accuracy: 0.1840 - val_loss: 2.0873 - val_accuracy: 0.2177\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.1525 - accuracy: 0.1988 - val_loss: 2.0305 - val_accuracy: 0.2236\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.0991 - accuracy: 0.2134 - val_loss: 1.9936 - val_accuracy: 0.2358\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.0649 - accuracy: 0.2211 - val_loss: 1.9629 - val_accuracy: 0.2561\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.0226 - accuracy: 0.2295 - val_loss: 1.9165 - val_accuracy: 0.2736\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.9815 - accuracy: 0.2373 - val_loss: 1.8652 - val_accuracy: 0.2837\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.9568 - accuracy: 0.2416 - val_loss: 1.8338 - val_accuracy: 0.2799\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.9085 - accuracy: 0.2447 - val_loss: 1.8082 - val_accuracy: 0.2833\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.8763 - accuracy: 0.2529 - val_loss: 1.7886 - val_accuracy: 0.2943\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.8536 - accuracy: 0.2608 - val_loss: 1.7565 - val_accuracy: 0.2932\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.8337 - accuracy: 0.2650 - val_loss: 1.7389 - val_accuracy: 0.2954\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.8053 - accuracy: 0.2704 - val_loss: 1.7450 - val_accuracy: 0.2871\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.7900 - accuracy: 0.2698 - val_loss: 1.7111 - val_accuracy: 0.2951\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.7746 - accuracy: 0.2774 - val_loss: 1.6943 - val_accuracy: 0.3010\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.7426 - accuracy: 0.2853 - val_loss: 1.6855 - val_accuracy: 0.3053\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.7213 - accuracy: 0.3008 - val_loss: 1.6777 - val_accuracy: 0.3102\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.7218 - accuracy: 0.2991 - val_loss: 1.6950 - val_accuracy: 0.2970\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.7002 - accuracy: 0.3088 - val_loss: 1.6416 - val_accuracy: 0.3204\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6799 - accuracy: 0.3181 - val_loss: 1.6240 - val_accuracy: 0.3458\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6652 - accuracy: 0.3266 - val_loss: 1.6052 - val_accuracy: 0.3527\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6424 - accuracy: 0.3313 - val_loss: 1.6451 - val_accuracy: 0.3603\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6318 - accuracy: 0.3330 - val_loss: 1.5625 - val_accuracy: 0.3772\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.6109 - accuracy: 0.3388 - val_loss: 1.5661 - val_accuracy: 0.3765\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6031 - accuracy: 0.3374 - val_loss: 1.5599 - val_accuracy: 0.3745\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5995 - accuracy: 0.3395 - val_loss: 1.5343 - val_accuracy: 0.4168\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5877 - accuracy: 0.3450 - val_loss: 1.5365 - val_accuracy: 0.4143\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5644 - accuracy: 0.3456 - val_loss: 1.5067 - val_accuracy: 0.3834\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5654 - accuracy: 0.3451 - val_loss: 1.5133 - val_accuracy: 0.3983\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5517 - accuracy: 0.3522 - val_loss: 1.5136 - val_accuracy: 0.3838\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5597 - accuracy: 0.3442 - val_loss: 1.4800 - val_accuracy: 0.4117\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5435 - accuracy: 0.3533 - val_loss: 1.4718 - val_accuracy: 0.4313\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5188 - accuracy: 0.3576 - val_loss: 1.5695 - val_accuracy: 0.4013\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5340 - accuracy: 0.3561 - val_loss: 1.4919 - val_accuracy: 0.4199\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5720 - accuracy: 0.3538 - val_loss: 1.4735 - val_accuracy: 0.4389\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5033 - accuracy: 0.3635 - val_loss: 1.4811 - val_accuracy: 0.4256\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5102 - accuracy: 0.3651 - val_loss: 1.4670 - val_accuracy: 0.4280\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4798 - accuracy: 0.3675 - val_loss: 1.4811 - val_accuracy: 0.4384\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5043 - accuracy: 0.3646 - val_loss: 1.4991 - val_accuracy: 0.4323\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4769 - accuracy: 0.3702 - val_loss: 1.4587 - val_accuracy: 0.4387\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4640 - accuracy: 0.3770 - val_loss: 1.4588 - val_accuracy: 0.4300\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4733 - accuracy: 0.3733 - val_loss: 1.4753 - val_accuracy: 0.4508\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 7s 12ms/step - loss: 2.3034 - accuracy: 0.1117 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3012 - accuracy: 0.1195 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3005 - accuracy: 0.1206 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2996 - accuracy: 0.1258 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2989 - accuracy: 0.1302 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2960 - accuracy: 0.1375 - val_loss: 2.2955 - val_accuracy: 0.1078\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2931 - accuracy: 0.1436 - val_loss: 2.2853 - val_accuracy: 0.1310\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2871 - accuracy: 0.1521 - val_loss: 2.2685 - val_accuracy: 0.1690\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2757 - accuracy: 0.1634 - val_loss: 2.2428 - val_accuracy: 0.1922\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2594 - accuracy: 0.1679 - val_loss: 2.1957 - val_accuracy: 0.2062\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2334 - accuracy: 0.1741 - val_loss: 2.1365 - val_accuracy: 0.2042\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.1950 - accuracy: 0.1757 - val_loss: 2.0587 - val_accuracy: 0.2025\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.1478 - accuracy: 0.1818 - val_loss: 2.0114 - val_accuracy: 0.2100\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.0996 - accuracy: 0.1912 - val_loss: 1.9701 - val_accuracy: 0.2196\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.0671 - accuracy: 0.1978 - val_loss: 1.9169 - val_accuracy: 0.2314\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.0206 - accuracy: 0.2080 - val_loss: 1.8945 - val_accuracy: 0.2488\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.9914 - accuracy: 0.2163 - val_loss: 1.8728 - val_accuracy: 0.2589\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.9546 - accuracy: 0.2256 - val_loss: 1.8277 - val_accuracy: 0.2762\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.9212 - accuracy: 0.2382 - val_loss: 1.7973 - val_accuracy: 0.3013\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.8897 - accuracy: 0.2486 - val_loss: 1.7540 - val_accuracy: 0.3261\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.8498 - accuracy: 0.2579 - val_loss: 1.7216 - val_accuracy: 0.3190\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.8221 - accuracy: 0.2652 - val_loss: 1.7118 - val_accuracy: 0.3140\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.7992 - accuracy: 0.2693 - val_loss: 1.6840 - val_accuracy: 0.3296\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.7714 - accuracy: 0.2745 - val_loss: 1.6552 - val_accuracy: 0.3140\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.7455 - accuracy: 0.2801 - val_loss: 1.6393 - val_accuracy: 0.3272\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.7247 - accuracy: 0.2870 - val_loss: 1.6297 - val_accuracy: 0.3239\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.7064 - accuracy: 0.2933 - val_loss: 1.5879 - val_accuracy: 0.3573\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6703 - accuracy: 0.3029 - val_loss: 1.5646 - val_accuracy: 0.3742\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.6648 - accuracy: 0.3066 - val_loss: 1.5597 - val_accuracy: 0.3646\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6416 - accuracy: 0.3181 - val_loss: 1.5484 - val_accuracy: 0.3583\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6205 - accuracy: 0.3237 - val_loss: 1.5282 - val_accuracy: 0.3897\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6093 - accuracy: 0.3289 - val_loss: 1.5264 - val_accuracy: 0.3670\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5796 - accuracy: 0.3402 - val_loss: 1.4934 - val_accuracy: 0.4050\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5810 - accuracy: 0.3488 - val_loss: 1.4742 - val_accuracy: 0.4199\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5546 - accuracy: 0.3578 - val_loss: 1.4436 - val_accuracy: 0.4589\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5253 - accuracy: 0.3711 - val_loss: 1.3964 - val_accuracy: 0.5032\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5026 - accuracy: 0.3814 - val_loss: 1.3901 - val_accuracy: 0.4701\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4777 - accuracy: 0.3885 - val_loss: 1.3762 - val_accuracy: 0.4501\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4602 - accuracy: 0.3928 - val_loss: 1.3618 - val_accuracy: 0.4559\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4470 - accuracy: 0.3916 - val_loss: 1.3545 - val_accuracy: 0.4412\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4329 - accuracy: 0.4006 - val_loss: 1.3503 - val_accuracy: 0.4268\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4137 - accuracy: 0.4033 - val_loss: 1.3281 - val_accuracy: 0.4680\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4047 - accuracy: 0.4060 - val_loss: 1.3167 - val_accuracy: 0.4772\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3847 - accuracy: 0.4182 - val_loss: 1.2948 - val_accuracy: 0.5056\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3862 - accuracy: 0.4141 - val_loss: 1.3145 - val_accuracy: 0.5207\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3762 - accuracy: 0.4248 - val_loss: 1.3826 - val_accuracy: 0.4637\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3610 - accuracy: 0.4255 - val_loss: 1.2857 - val_accuracy: 0.5052\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3433 - accuracy: 0.4410 - val_loss: 1.2967 - val_accuracy: 0.5270\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3231 - accuracy: 0.4466 - val_loss: 1.2623 - val_accuracy: 0.5030\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3098 - accuracy: 0.4592 - val_loss: 1.2417 - val_accuracy: 0.5434\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 6s 11ms/step - loss: 2.3752 - accuracy: 0.1246 - val_loss: 1.8300 - val_accuracy: 0.4678\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.1008 - accuracy: 0.2100 - val_loss: 1.5312 - val_accuracy: 0.5923\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.9046 - accuracy: 0.2809 - val_loss: 1.3493 - val_accuracy: 0.6326\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.7659 - accuracy: 0.3291 - val_loss: 1.1988 - val_accuracy: 0.6480\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.6524 - accuracy: 0.3705 - val_loss: 1.0734 - val_accuracy: 0.6685\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5576 - accuracy: 0.4006 - val_loss: 0.9991 - val_accuracy: 0.6673\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4869 - accuracy: 0.4324 - val_loss: 0.9526 - val_accuracy: 0.6898\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4225 - accuracy: 0.4558 - val_loss: 0.9206 - val_accuracy: 0.6948\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3972 - accuracy: 0.4724 - val_loss: 0.8885 - val_accuracy: 0.7183\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3526 - accuracy: 0.4918 - val_loss: 0.8508 - val_accuracy: 0.7346\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3189 - accuracy: 0.5057 - val_loss: 0.8150 - val_accuracy: 0.7563\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.2753 - accuracy: 0.5254 - val_loss: 0.7945 - val_accuracy: 0.7515\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.2436 - accuracy: 0.5367 - val_loss: 0.7684 - val_accuracy: 0.7581\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.2185 - accuracy: 0.5460 - val_loss: 0.7497 - val_accuracy: 0.7713\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.1989 - accuracy: 0.5579 - val_loss: 0.7389 - val_accuracy: 0.7865\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.1760 - accuracy: 0.5651 - val_loss: 0.7283 - val_accuracy: 0.7770\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1647 - accuracy: 0.5749 - val_loss: 0.7195 - val_accuracy: 0.7680\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1375 - accuracy: 0.5832 - val_loss: 0.7103 - val_accuracy: 0.7682\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1209 - accuracy: 0.5945 - val_loss: 0.7047 - val_accuracy: 0.7860\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1168 - accuracy: 0.5959 - val_loss: 0.7001 - val_accuracy: 0.7946\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0997 - accuracy: 0.6027 - val_loss: 0.6944 - val_accuracy: 0.8094\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0744 - accuracy: 0.6131 - val_loss: 0.6890 - val_accuracy: 0.7963\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0700 - accuracy: 0.6117 - val_loss: 0.6867 - val_accuracy: 0.7986\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0409 - accuracy: 0.6263 - val_loss: 0.6769 - val_accuracy: 0.8143\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0251 - accuracy: 0.6268 - val_loss: 0.6666 - val_accuracy: 0.8133\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0100 - accuracy: 0.6353 - val_loss: 0.6586 - val_accuracy: 0.8209\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0153 - accuracy: 0.6338 - val_loss: 0.6521 - val_accuracy: 0.8275\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.9946 - accuracy: 0.6440 - val_loss: 0.6403 - val_accuracy: 0.8239\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9776 - accuracy: 0.6478 - val_loss: 0.6399 - val_accuracy: 0.8270\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9781 - accuracy: 0.6495 - val_loss: 0.6242 - val_accuracy: 0.8261\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9680 - accuracy: 0.6593 - val_loss: 0.6168 - val_accuracy: 0.8199\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9576 - accuracy: 0.6701 - val_loss: 0.6048 - val_accuracy: 0.8345\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9551 - accuracy: 0.6656 - val_loss: 0.5974 - val_accuracy: 0.8188\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9399 - accuracy: 0.6713 - val_loss: 0.5910 - val_accuracy: 0.8188\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9355 - accuracy: 0.6740 - val_loss: 0.5811 - val_accuracy: 0.8207\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9215 - accuracy: 0.6803 - val_loss: 0.5710 - val_accuracy: 0.8256\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9000 - accuracy: 0.6870 - val_loss: 0.5666 - val_accuracy: 0.8220\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8832 - accuracy: 0.6888 - val_loss: 0.5618 - val_accuracy: 0.8353\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8890 - accuracy: 0.6977 - val_loss: 0.5514 - val_accuracy: 0.8304\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8776 - accuracy: 0.6971 - val_loss: 0.5452 - val_accuracy: 0.8553\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8661 - accuracy: 0.7058 - val_loss: 0.5475 - val_accuracy: 0.8484\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8639 - accuracy: 0.7034 - val_loss: 0.5339 - val_accuracy: 0.8368\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8436 - accuracy: 0.7094 - val_loss: 0.5251 - val_accuracy: 0.8512\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8253 - accuracy: 0.7202 - val_loss: 0.5234 - val_accuracy: 0.8496\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8318 - accuracy: 0.7197 - val_loss: 0.5162 - val_accuracy: 0.8667\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8363 - accuracy: 0.7211 - val_loss: 0.5143 - val_accuracy: 0.8267\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8267 - accuracy: 0.7196 - val_loss: 0.5112 - val_accuracy: 0.8386\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8180 - accuracy: 0.7247 - val_loss: 0.5086 - val_accuracy: 0.8353\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8149 - accuracy: 0.7292 - val_loss: 0.5006 - val_accuracy: 0.8678\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8126 - accuracy: 0.7309 - val_loss: 0.5062 - val_accuracy: 0.8406\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 6s 11ms/step - loss: 3.3391 - accuracy: 0.1229 - val_loss: 1.5508 - val_accuracy: 0.4926\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.0529 - accuracy: 0.2595 - val_loss: 1.3878 - val_accuracy: 0.5323\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.7905 - accuracy: 0.3271 - val_loss: 1.2082 - val_accuracy: 0.5623\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6215 - accuracy: 0.3748 - val_loss: 1.1054 - val_accuracy: 0.6007\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.5083 - accuracy: 0.4145 - val_loss: 1.0269 - val_accuracy: 0.6058\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4197 - accuracy: 0.4476 - val_loss: 0.9715 - val_accuracy: 0.6143\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3601 - accuracy: 0.4682 - val_loss: 0.9358 - val_accuracy: 0.6226\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3118 - accuracy: 0.4897 - val_loss: 0.9099 - val_accuracy: 0.6162\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.2795 - accuracy: 0.5007 - val_loss: 0.8998 - val_accuracy: 0.5913\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.2381 - accuracy: 0.5076 - val_loss: 0.8934 - val_accuracy: 0.5891\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.2025 - accuracy: 0.5212 - val_loss: 0.8830 - val_accuracy: 0.6005\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1926 - accuracy: 0.5269 - val_loss: 0.8855 - val_accuracy: 0.6060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1786 - accuracy: 0.5306 - val_loss: 0.8800 - val_accuracy: 0.5923\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1479 - accuracy: 0.5338 - val_loss: 0.8718 - val_accuracy: 0.6044\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.1372 - accuracy: 0.5414 - val_loss: 0.8709 - val_accuracy: 0.5962\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1064 - accuracy: 0.5498 - val_loss: 0.8690 - val_accuracy: 0.5922\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.1134 - accuracy: 0.5417 - val_loss: 0.8598 - val_accuracy: 0.5910\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0956 - accuracy: 0.5478 - val_loss: 0.8639 - val_accuracy: 0.5905\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1014 - accuracy: 0.5481 - val_loss: 0.8613 - val_accuracy: 0.5916\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0827 - accuracy: 0.5528 - val_loss: 0.8547 - val_accuracy: 0.6006\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0821 - accuracy: 0.5558 - val_loss: 0.8514 - val_accuracy: 0.6054\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0637 - accuracy: 0.5574 - val_loss: 0.8402 - val_accuracy: 0.5986\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0478 - accuracy: 0.5685 - val_loss: 0.8389 - val_accuracy: 0.6054\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0469 - accuracy: 0.5661 - val_loss: 0.8352 - val_accuracy: 0.6047\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0401 - accuracy: 0.5694 - val_loss: 0.8260 - val_accuracy: 0.6323\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0343 - accuracy: 0.5724 - val_loss: 0.8263 - val_accuracy: 0.6367\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0188 - accuracy: 0.5791 - val_loss: 0.8231 - val_accuracy: 0.6792\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0109 - accuracy: 0.5797 - val_loss: 0.8076 - val_accuracy: 0.6545\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0218 - accuracy: 0.5828 - val_loss: 0.8062 - val_accuracy: 0.6904\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0053 - accuracy: 0.5877 - val_loss: 0.7929 - val_accuracy: 0.6573\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9985 - accuracy: 0.5913 - val_loss: 0.7824 - val_accuracy: 0.6833\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9875 - accuracy: 0.5946 - val_loss: 0.7743 - val_accuracy: 0.6888\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9746 - accuracy: 0.6032 - val_loss: 0.7693 - val_accuracy: 0.6733\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9704 - accuracy: 0.6061 - val_loss: 0.7685 - val_accuracy: 0.6751\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9590 - accuracy: 0.6125 - val_loss: 0.7525 - val_accuracy: 0.6743\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9640 - accuracy: 0.6147 - val_loss: 0.7570 - val_accuracy: 0.6833\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9472 - accuracy: 0.6186 - val_loss: 0.7485 - val_accuracy: 0.7139\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9483 - accuracy: 0.6199 - val_loss: 0.7393 - val_accuracy: 0.6794\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9447 - accuracy: 0.6258 - val_loss: 0.7409 - val_accuracy: 0.7147\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9388 - accuracy: 0.6277 - val_loss: 0.7391 - val_accuracy: 0.6923\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9263 - accuracy: 0.6294 - val_loss: 0.7352 - val_accuracy: 0.6793\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9354 - accuracy: 0.6307 - val_loss: 0.7284 - val_accuracy: 0.6968\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9229 - accuracy: 0.6313 - val_loss: 0.7284 - val_accuracy: 0.6828\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9136 - accuracy: 0.6361 - val_loss: 0.7259 - val_accuracy: 0.6845\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9006 - accuracy: 0.6349 - val_loss: 0.7251 - val_accuracy: 0.6856\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8953 - accuracy: 0.6365 - val_loss: 0.7318 - val_accuracy: 0.6907\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8974 - accuracy: 0.6431 - val_loss: 0.7252 - val_accuracy: 0.7283\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9050 - accuracy: 0.6396 - val_loss: 0.7288 - val_accuracy: 0.6835\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8882 - accuracy: 0.6475 - val_loss: 0.7138 - val_accuracy: 0.6863\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8932 - accuracy: 0.6457 - val_loss: 0.7199 - val_accuracy: 0.6840\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 8s 14ms/step - loss: 2.3022 - accuracy: 0.1155 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3013 - accuracy: 0.1155 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3007 - accuracy: 0.1167 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3009 - accuracy: 0.1150 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3013 - accuracy: 0.1118 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3008 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3009 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3007 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3007 - accuracy: 0.1154 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3005 - accuracy: 0.1168 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3008 - accuracy: 0.1153 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3010 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3009 - accuracy: 0.1118 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3014 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3007 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3012 - accuracy: 0.1117 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3009 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3007 - accuracy: 0.1171 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1135 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3007 - accuracy: 0.1164 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3012 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1156 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3008 - accuracy: 0.1153 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1121 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3006 - accuracy: 0.1158 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3007 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3010 - accuracy: 0.1135 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3007 - accuracy: 0.1148 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3007 - accuracy: 0.1155 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3014 - accuracy: 0.1110 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3017 - accuracy: 0.1102 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3007 - accuracy: 0.1127 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3009 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1129 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3011 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3006 - accuracy: 0.1166 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1115 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.3011 - accuracy: 0.1135 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3006 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 7s 12ms/step - loss: 2.3022 - accuracy: 0.1111 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3015 - accuracy: 0.1129 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3014 - accuracy: 0.1146 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3010 - accuracy: 0.1158 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3005 - accuracy: 0.1171 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3011 - accuracy: 0.1138 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3013 - accuracy: 0.1126 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3013 - accuracy: 0.1127 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3010 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3008 - accuracy: 0.1135 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1145 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1131 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3014 - accuracy: 0.1118 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3006 - accuracy: 0.1148 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3017 - accuracy: 0.1116 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3008 - accuracy: 0.1137 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3011 - accuracy: 0.1120 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3013 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3011 - accuracy: 0.1134 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3008 - accuracy: 0.1153 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3012 - accuracy: 0.1127 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3006 - accuracy: 0.1164 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3007 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3007 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3008 - accuracy: 0.1138 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3007 - accuracy: 0.1158 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3008 - accuracy: 0.1152 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3007 - accuracy: 0.1136 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3010 - accuracy: 0.1128 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3007 - accuracy: 0.1147 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3005 - accuracy: 0.1150 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3008 - accuracy: 0.1132 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3008 - accuracy: 0.1136 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3008 - accuracy: 0.1141 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3003 - accuracy: 0.1183 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3004 - accuracy: 0.1170 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3002 - accuracy: 0.1162 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3006 - accuracy: 0.1142 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3008 - accuracy: 0.1118 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3009 - accuracy: 0.1141 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3009 - accuracy: 0.1137 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3004 - accuracy: 0.1143 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3008 - accuracy: 0.1135 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "{'loss': [2.3033487796783447, 2.0669639110565186, 1.8848525285720825, 1.7506647109985352, 1.6474252939224243, 1.5671672821044922, 1.498957633972168, 1.4481810331344604, 1.4022667407989502, 1.374809741973877, 1.339399814605713, 1.3072565793991089, 1.2838149070739746, 1.2587594985961914, 1.2432416677474976, 1.221805453300476, 1.200258731842041, 1.186879277229309, 1.1740316152572632, 1.1529957056045532, 1.1446326971054077, 1.12614107131958, 1.1209946870803833, 1.1064062118530273, 1.0991986989974976, 1.0858027935028076, 1.0806983709335327, 1.078617811203003, 1.0569380521774292, 1.0588349103927612, 1.0495922565460205, 1.0437053442001343, 1.0399622917175293, 1.0319185256958008, 1.0282361507415771, 1.017703890800476, 1.01711106300354, 1.0131717920303345, 1.0053682327270508, 0.9991080164909363, 0.9882538914680481, 0.9918200969696045, 0.9869112968444824, 0.9818286299705505, 0.9760271906852722, 0.967246413230896, 0.9649107456207275, 0.9619932174682617, 0.9547081589698792, 0.9487779140472412], 'accuracy': [0.15422916412353516, 0.23879165947437286, 0.3077083230018616, 0.3552500009536743, 0.3880000114440918, 0.4154791533946991, 0.43962499499320984, 0.45995834469795227, 0.47964581847190857, 0.49033331871032715, 0.5002708435058594, 0.5133125185966492, 0.5216041803359985, 0.5316458344459534, 0.5379375219345093, 0.5483124852180481, 0.5543749928474426, 0.5603958368301392, 0.562541663646698, 0.570604145526886, 0.573395848274231, 0.5761041641235352, 0.5830416679382324, 0.5852500200271606, 0.5921666622161865, 0.5905208587646484, 0.5965833067893982, 0.5962083339691162, 0.598437488079071, 0.6013749837875366, 0.6032291650772095, 0.6043333411216736, 0.6036249995231628, 0.6068541407585144, 0.6080625057220459, 0.609375, 0.6102708578109741, 0.6122708320617676, 0.6121249794960022, 0.614145815372467, 0.6159583330154419, 0.6170833110809326, 0.6154999732971191, 0.6165624856948853, 0.6185416579246521, 0.6220208406448364, 0.6191458106040955, 0.6224166750907898, 0.6216041445732117, 0.6265416741371155], 'val_loss': [1.823153018951416, 1.5422399044036865, 1.363271951675415, 1.2459934949874878, 1.170695424079895, 1.1251678466796875, 1.0898362398147583, 1.0666428804397583, 1.0393601655960083, 1.021640658378601, 1.007509469985962, 0.9915423393249512, 0.9746949076652527, 0.9633545875549316, 0.9496663212776184, 0.9349749088287354, 0.9207810163497925, 0.9019581079483032, 0.8946956992149353, 0.8924922943115234, 0.8763973712921143, 0.8776810169219971, 0.8649285435676575, 0.8546696901321411, 0.8588617444038391, 0.84615159034729, 0.841742753982544, 0.8389536738395691, 0.8400793671607971, 0.8336315751075745, 0.8282644748687744, 0.8269878625869751, 0.8442726135253906, 0.8134347200393677, 0.8121257424354553, 0.8099247217178345, 0.8128314018249512, 0.7973485589027405, 0.8012181520462036, 0.8102599382400513, 0.8036407828330994, 0.7973027229309082, 0.7851731777191162, 0.7823849320411682, 0.7930240035057068, 0.7848254442214966, 0.7813649773597717, 0.7762159705162048, 0.7801482677459717, 0.7727113366127014], 'val_accuracy': [0.4269999861717224, 0.5454999804496765, 0.577750027179718, 0.5923333168029785, 0.596666693687439, 0.6056666374206543, 0.6112499833106995, 0.6215000152587891, 0.624666690826416, 0.6292499899864197, 0.6262500286102295, 0.6458333134651184, 0.6550833582878113, 0.659416675567627, 0.6497499942779541, 0.6508333086967468, 0.6518333554267883, 0.6551666855812073, 0.6537500023841858, 0.6512500047683716, 0.655916690826416, 0.6481666564941406, 0.6629166603088379, 0.6600000262260437, 0.6551666855812073, 0.6636666655540466, 0.6645833253860474, 0.6644999980926514, 0.6652500033378601, 0.6651666760444641, 0.6639166474342346, 0.6713333129882812, 0.653333306312561, 0.6685000061988831, 0.6679166555404663, 0.668916642665863, 0.6571666598320007, 0.6590833067893982, 0.6607499718666077, 0.6588333249092102, 0.6613333225250244, 0.6709166765213013, 0.6742500066757202, 0.6631666421890259, 0.6635833382606506, 0.6745833158493042, 0.6727499961853027, 0.6678333282470703, 0.6769999861717224, 0.6779999732971191]}\n",
      "{'loss': [2.302629232406616, 2.3011655807495117, 2.300414800643921, 2.2997241020202637, 2.29911208152771, 2.2971038818359375, 2.2936344146728516, 2.2847206592559814, 2.2563936710357666, 2.197634696960449, 2.1407277584075928, 2.093287467956543, 2.056387424468994, 2.0112574100494385, 1.9736137390136719, 1.9394031763076782, 1.9063173532485962, 1.8732852935791016, 1.848199486732483, 1.8236124515533447, 1.8011871576309204, 1.782404899597168, 1.764275074005127, 1.7423992156982422, 1.725763201713562, 1.7148723602294922, 1.691314935684204, 1.674894094467163, 1.6571383476257324, 1.644558310508728, 1.6287999153137207, 1.6132252216339111, 1.6039683818817139, 1.5962759256362915, 1.5861464738845825, 1.5740717649459839, 1.5626293420791626, 1.5542383193969727, 1.5503178834915161, 1.5448896884918213, 1.5251212120056152, 1.5252934694290161, 1.544048547744751, 1.501009464263916, 1.513430118560791, 1.4774296283721924, 1.5117745399475098, 1.4781264066696167, 1.4698141813278198, 1.4800975322723389], 'accuracy': [0.11533333361148834, 0.12075000256299973, 0.11922916769981384, 0.12191666662693024, 0.12089583277702332, 0.12691666185855865, 0.13441666960716248, 0.14912499487400055, 0.1706666648387909, 0.18862499296665192, 0.20229166746139526, 0.21439583599567413, 0.2240625023841858, 0.2316666692495346, 0.2382083386182785, 0.2407708317041397, 0.24522916972637177, 0.2540833353996277, 0.25999999046325684, 0.26737499237060547, 0.2721458375453949, 0.27283334732055664, 0.2800833284854889, 0.28722918033599854, 0.29741665720939636, 0.30370834469795227, 0.3153750002384186, 0.32081249356269836, 0.3294999897480011, 0.33133333921432495, 0.33397915959358215, 0.3386458456516266, 0.3382291793823242, 0.3408125042915344, 0.34443750977516174, 0.34431248903274536, 0.34816667437553406, 0.35081249475479126, 0.3490625023841858, 0.3551875054836273, 0.3566458225250244, 0.3606666624546051, 0.35499998927116394, 0.36252084374427795, 0.3647291660308838, 0.3720416724681854, 0.36393749713897705, 0.37281250953674316, 0.37593749165534973, 0.3739166557788849], 'val_loss': [2.302102565765381, 2.301973581314087, 2.302006244659424, 2.3019611835479736, 2.301870584487915, 2.3005802631378174, 2.292583703994751, 2.26815128326416, 2.19107985496521, 2.0872693061828613, 2.0304713249206543, 1.993619441986084, 1.9629143476486206, 1.9164727926254272, 1.8651883602142334, 1.8338000774383545, 1.8081930875778198, 1.7885905504226685, 1.756482720375061, 1.7388640642166138, 1.7450308799743652, 1.7111414670944214, 1.6942766904830933, 1.6855014562606812, 1.6776988506317139, 1.6950390338897705, 1.6415694952011108, 1.6240061521530151, 1.6052318811416626, 1.6450815200805664, 1.5625085830688477, 1.5660678148269653, 1.5599032640457153, 1.5343133211135864, 1.5365407466888428, 1.5066897869110107, 1.5133060216903687, 1.5135862827301025, 1.4799546003341675, 1.4718085527420044, 1.569464087486267, 1.4918889999389648, 1.4735099077224731, 1.4811040163040161, 1.4670196771621704, 1.4811490774154663, 1.4990965127944946, 1.458710789680481, 1.4588152170181274, 1.4752559661865234], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.11474999785423279, 0.18774999678134918, 0.21408332884311676, 0.21766667068004608, 0.22358334064483643, 0.2357500046491623, 0.25608333945274353, 0.273583322763443, 0.2837499976158142, 0.2799166738986969, 0.28333333134651184, 0.2942500114440918, 0.2931666672229767, 0.2954166531562805, 0.28708332777023315, 0.29508334398269653, 0.3009999990463257, 0.30533334612846375, 0.3101666569709778, 0.296999990940094, 0.320416659116745, 0.34583333134651184, 0.3526666760444641, 0.36033332347869873, 0.37724998593330383, 0.3765000104904175, 0.37450000643730164, 0.4168333411216736, 0.4143333435058594, 0.38341665267944336, 0.398333340883255, 0.3838333189487457, 0.4117499887943268, 0.4313333332538605, 0.4012500047683716, 0.41991665959358215, 0.4389166533946991, 0.4255833327770233, 0.42800000309944153, 0.43841665983200073, 0.4323333203792572, 0.4386666715145111, 0.4300000071525574, 0.4508333206176758]}\n",
      "{'loss': [2.3023178577423096, 2.300842046737671, 2.3001599311828613, 2.2995376586914062, 2.2986488342285156, 2.2956860065460205, 2.291503429412842, 2.2837746143341064, 2.2721495628356934, 2.253237724304199, 2.2238717079162598, 2.183598518371582, 2.137718677520752, 2.0895583629608154, 2.0551114082336426, 2.017153024673462, 1.9825061559677124, 1.947969675064087, 1.9150547981262207, 1.88507878780365, 1.844817042350769, 1.8153237104415894, 1.790289044380188, 1.7642755508422852, 1.7458561658859253, 1.7165906429290771, 1.6949970722198486, 1.6791465282440186, 1.6626516580581665, 1.6452159881591797, 1.6218430995941162, 1.6062936782836914, 1.579976201057434, 1.5713005065917969, 1.547780156135559, 1.5242995023727417, 1.4960895776748657, 1.4841936826705933, 1.4609918594360352, 1.4459456205368042, 1.4232734441757202, 1.4122487306594849, 1.416249394416809, 1.3904075622558594, 1.3773174285888672, 1.367388367652893, 1.3618229627609253, 1.3419346809387207, 1.332134485244751, 1.3135294914245605], 'accuracy': [0.11770833283662796, 0.12200000137090683, 0.12318749725818634, 0.12472916394472122, 0.12993749976158142, 0.13754166662693024, 0.14645832777023315, 0.15725000202655792, 0.16374999284744263, 0.17168749868869781, 0.17629165947437286, 0.17785416543483734, 0.18539583683013916, 0.1941041648387909, 0.20108333230018616, 0.20902083814144135, 0.21904166042804718, 0.22837500274181366, 0.23997916281223297, 0.250083327293396, 0.2603749930858612, 0.2644374966621399, 0.27160418033599854, 0.27910417318344116, 0.2823333442211151, 0.2906666696071625, 0.29762500524520874, 0.3008333444595337, 0.3111041784286499, 0.3164791762828827, 0.3228749930858612, 0.33147916197776794, 0.3396458327770233, 0.3504583239555359, 0.3648749887943268, 0.3736041784286499, 0.38241666555404663, 0.3865833282470703, 0.3917083442211151, 0.3922291696071625, 0.40318751335144043, 0.40297916531562805, 0.406104177236557, 0.41710415482521057, 0.4189791679382324, 0.42504167556762695, 0.4270208477973938, 0.4424166679382324, 0.4442291557788849, 0.45908331871032715], 'val_loss': [2.3019676208496094, 2.3019509315490723, 2.3019309043884277, 2.301851987838745, 2.3014447689056396, 2.2955222129821777, 2.285327911376953, 2.2684500217437744, 2.2428207397460938, 2.195673942565918, 2.136490821838379, 2.058724880218506, 2.011366128921509, 1.9700946807861328, 1.9168665409088135, 1.894502878189087, 1.8727524280548096, 1.827696442604065, 1.7972781658172607, 1.7539725303649902, 1.721592903137207, 1.711799144744873, 1.6840218305587769, 1.6551543474197388, 1.639308214187622, 1.6297041177749634, 1.587936520576477, 1.564611792564392, 1.5596950054168701, 1.5483505725860596, 1.528163194656372, 1.5264108180999756, 1.4934223890304565, 1.474237084388733, 1.4436235427856445, 1.3963912725448608, 1.3901362419128418, 1.3762296438217163, 1.3617583513259888, 1.3544938564300537, 1.3503403663635254, 1.3280624151229858, 1.3167390823364258, 1.2947667837142944, 1.3144763708114624, 1.3826351165771484, 1.2857288122177124, 1.2966535091400146, 1.2623378038406372, 1.2416635751724243], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10783333331346512, 0.13099999725818634, 0.16899999976158142, 0.19224999845027924, 0.20616666972637177, 0.20416666567325592, 0.20250000059604645, 0.20999999344348907, 0.21958333253860474, 0.23141667246818542, 0.2487500011920929, 0.2589166760444641, 0.2761666774749756, 0.30133333802223206, 0.32608333230018616, 0.3190000057220459, 0.3140000104904175, 0.3295833468437195, 0.3140000104904175, 0.32716667652130127, 0.3239166736602783, 0.35733333230018616, 0.37416666746139526, 0.3645833432674408, 0.3583333194255829, 0.38966667652130127, 0.367000013589859, 0.4050000011920929, 0.41991665959358215, 0.45891666412353516, 0.503166675567627, 0.4700833261013031, 0.45008334517478943, 0.4559166729450226, 0.4411666691303253, 0.4268333315849304, 0.46799999475479126, 0.47716665267944336, 0.5055833458900452, 0.5207499861717224, 0.4636666774749756, 0.5052499771118164, 0.5270000100135803, 0.503000020980835, 0.5434166789054871]}\n",
      "{'loss': [2.289118766784668, 2.0520663261413574, 1.8747822046279907, 1.7359507083892822, 1.6276462078094482, 1.5368860960006714, 1.4715933799743652, 1.4144327640533447, 1.38593327999115, 1.3402093648910522, 1.3106790781021118, 1.2714334726333618, 1.2459343671798706, 1.2199435234069824, 1.19545578956604, 1.1721405982971191, 1.1494723558425903, 1.1307134628295898, 1.1149190664291382, 1.1065170764923096, 1.0852930545806885, 1.0736018419265747, 1.0596352815628052, 1.0444799661636353, 1.0324292182922363, 1.0132064819335938, 1.0123201608657837, 1.0015180110931396, 0.9882228970527649, 0.975807785987854, 0.9689654111862183, 0.9573261737823486, 0.9529836177825928, 0.9380317330360413, 0.925649881362915, 0.914065420627594, 0.9052333235740662, 0.8926941156387329, 0.8903696537017822, 0.8746260404586792, 0.8641120791435242, 0.8612139225006104, 0.8424624800682068, 0.8390063643455505, 0.8406365513801575, 0.8393198847770691, 0.8260853886604309, 0.8139398694038391, 0.8095106482505798, 0.7996946573257446], 'accuracy': [0.148499995470047, 0.2264166623353958, 0.28979167342185974, 0.3373749852180481, 0.3800208270549774, 0.40952083468437195, 0.4387708306312561, 0.461041659116745, 0.47577083110809326, 0.4976458251476288, 0.5096458196640015, 0.5298333168029785, 0.5390625, 0.5487499833106995, 0.5607708096504211, 0.5695624947547913, 0.5786666870117188, 0.5878333449363708, 0.5929583311080933, 0.5996458530426025, 0.6066874861717224, 0.6107500195503235, 0.6149791479110718, 0.625041663646698, 0.6275416612625122, 0.6353541612625122, 0.6352083086967468, 0.6423749923706055, 0.6479583382606506, 0.6517916917800903, 0.6599583625793457, 0.6656875014305115, 0.6679375171661377, 0.6736458539962769, 0.6776875257492065, 0.6831250190734863, 0.6848333477973938, 0.6904791593551636, 0.6951249837875366, 0.6977708339691162, 0.7056666612625122, 0.7059999704360962, 0.710979163646698, 0.7164375185966492, 0.7184374928474426, 0.7208750247955322, 0.7228749990463257, 0.7253958582878113, 0.7287291884422302, 0.7340208292007446], 'val_loss': [1.8300138711929321, 1.5311866998672485, 1.3492588996887207, 1.1987699270248413, 1.0734200477600098, 0.9991040229797363, 0.952628493309021, 0.9206159114837646, 0.8885161876678467, 0.8508039712905884, 0.8150231242179871, 0.7944762110710144, 0.7683669328689575, 0.7496604919433594, 0.7388585805892944, 0.7282522916793823, 0.7194654941558838, 0.7103030681610107, 0.7046938538551331, 0.7000823616981506, 0.6943575143814087, 0.6890309453010559, 0.6867327690124512, 0.6768799424171448, 0.6666150093078613, 0.6585593223571777, 0.6520927548408508, 0.6402765512466431, 0.6399443745613098, 0.624155580997467, 0.6168447136878967, 0.6047738194465637, 0.597356379032135, 0.5909976363182068, 0.5811086297035217, 0.571023166179657, 0.5665939450263977, 0.561829686164856, 0.551421582698822, 0.5452238917350769, 0.5475290417671204, 0.5338510870933533, 0.5250511765480042, 0.5234242081642151, 0.5162063837051392, 0.5142543315887451, 0.5112313628196716, 0.508638858795166, 0.5006097555160522, 0.5062323212623596], 'val_accuracy': [0.46775001287460327, 0.5923333168029785, 0.6325833201408386, 0.6480000019073486, 0.6685000061988831, 0.6673333048820496, 0.6897500157356262, 0.6947500109672546, 0.7183333039283752, 0.73458331823349, 0.7562500238418579, 0.7515000104904175, 0.7580833435058594, 0.7713333368301392, 0.7864999771118164, 0.7770000100135803, 0.7680000066757202, 0.7682499885559082, 0.7860000133514404, 0.7945833206176758, 0.809416651725769, 0.7963333129882812, 0.7985833287239075, 0.8143333196640015, 0.8132500052452087, 0.8209166526794434, 0.8274999856948853, 0.8239166736602783, 0.8270000219345093, 0.8260833621025085, 0.8199166655540466, 0.8345000147819519, 0.8187500238418579, 0.8188333511352539, 0.8207499980926514, 0.8255833387374878, 0.8220000267028809, 0.8353333473205566, 0.8304166793823242, 0.8552500009536743, 0.8484166860580444, 0.8368333578109741, 0.8512499928474426, 0.8495833277702332, 0.8666666746139526, 0.8267499804496765, 0.8385833501815796, 0.8353333473205566, 0.8678333163261414, 0.840583324432373]}\n",
      "{'loss': [2.7572593688964844, 1.96930730342865, 1.7384693622589111, 1.5981608629226685, 1.485417127609253, 1.4042555093765259, 1.3451393842697144, 1.298315405845642, 1.2630914449691772, 1.2335561513900757, 1.2096079587936401, 1.1860618591308594, 1.1687685251235962, 1.1467690467834473, 1.1323130130767822, 1.116747260093689, 1.1100873947143555, 1.099178433418274, 1.0945056676864624, 1.0823099613189697, 1.0741589069366455, 1.0623270273208618, 1.0497804880142212, 1.0474119186401367, 1.040245771408081, 1.0300586223602295, 1.0242246389389038, 1.0217185020446777, 1.012107014656067, 1.001515507698059, 0.9973859190940857, 0.9875298142433167, 0.9751938581466675, 0.9614633917808533, 0.9640974402427673, 0.9613738656044006, 0.9485715627670288, 0.9447249174118042, 0.9412379264831543, 0.9333580732345581, 0.9240561723709106, 0.9295126795768738, 0.9213236570358276, 0.9099020957946777, 0.9074795842170715, 0.9021485447883606, 0.9034444093704224, 0.893728494644165, 0.893383800983429, 0.8904407024383545], 'accuracy': [0.16068750619888306, 0.2784791588783264, 0.34193751215934753, 0.3838958442211151, 0.421979159116745, 0.4493125081062317, 0.47210416197776794, 0.49027082324028015, 0.5059999823570251, 0.5113750100135803, 0.5181249976158142, 0.5282708406448364, 0.5304999947547913, 0.5336250066757202, 0.5405208468437195, 0.5455208420753479, 0.5428958535194397, 0.5469791889190674, 0.5478958487510681, 0.5516666769981384, 0.5584375262260437, 0.5613124966621399, 0.5662500262260437, 0.5648750066757202, 0.5719166398048401, 0.5745000243186951, 0.5786458253860474, 0.5801874995231628, 0.5822916626930237, 0.588979184627533, 0.5943958163261414, 0.6004583239555359, 0.6058750152587891, 0.6112291812896729, 0.6147083044052124, 0.616812527179718, 0.6194583177566528, 0.6211249828338623, 0.6245625019073486, 0.6290000081062317, 0.6300208568572998, 0.6311458349227905, 0.6333958506584167, 0.6356666684150696, 0.6353958249092102, 0.6374791860580444, 0.6423333287239075, 0.6415625214576721, 0.6453750133514404, 0.6419583559036255], 'val_loss': [1.5508346557617188, 1.3877532482147217, 1.208239197731018, 1.1054282188415527, 1.026856541633606, 0.971539318561554, 0.9357718229293823, 0.909903883934021, 0.8997520208358765, 0.8934223651885986, 0.8830072283744812, 0.8854997754096985, 0.8799937963485718, 0.8717750906944275, 0.870943009853363, 0.869001567363739, 0.8598311543464661, 0.8639103770256042, 0.8612520098686218, 0.8547070026397705, 0.8513611555099487, 0.840156078338623, 0.8389338254928589, 0.8351516127586365, 0.82600998878479, 0.8263413906097412, 0.82305508852005, 0.807586669921875, 0.8062089681625366, 0.7929404377937317, 0.782364010810852, 0.7743054032325745, 0.7693403959274292, 0.7684711217880249, 0.752474844455719, 0.7570188641548157, 0.7484970092773438, 0.739292562007904, 0.7408641576766968, 0.7390857934951782, 0.735197901725769, 0.7284435033798218, 0.7284050583839417, 0.7258754968643188, 0.7250689268112183, 0.7317514419555664, 0.7251554131507874, 0.7288241386413574, 0.7138282656669617, 0.7198655605316162], 'val_accuracy': [0.49258333444595337, 0.5323333144187927, 0.562250018119812, 0.6006666421890259, 0.6057500243186951, 0.6143333315849304, 0.6225833296775818, 0.6161666512489319, 0.5912500023841858, 0.5890833139419556, 0.6004999876022339, 0.6060000061988831, 0.5923333168029785, 0.6044166684150696, 0.5961666703224182, 0.5921666622161865, 0.5910000205039978, 0.590499997138977, 0.5915833115577698, 0.6005833148956299, 0.6054166555404663, 0.5985833406448364, 0.6054166555404663, 0.6046666502952576, 0.6323333382606506, 0.6366666555404663, 0.6791666746139526, 0.6545000076293945, 0.690416693687439, 0.6573333144187927, 0.6832500100135803, 0.6888333559036255, 0.6732500195503235, 0.675083339214325, 0.6742500066757202, 0.6832500100135803, 0.7139166593551636, 0.6794166564941406, 0.7147499918937683, 0.6923333406448364, 0.6793333292007446, 0.6968333125114441, 0.6828333139419556, 0.684499979019165, 0.6855833530426025, 0.690666675567627, 0.7282500267028809, 0.6834999918937683, 0.6863333582878113, 0.6840000152587891]}\n",
      "{'loss': [2.3019888401031494, 2.3013713359832764, 2.301223039627075, 2.301074266433716, 2.3010621070861816, 2.3010659217834473, 2.30098819732666, 2.3010470867156982, 2.3010079860687256, 2.301016092300415, 2.3010666370391846, 2.30100154876709, 2.301027297973633, 2.301002025604248, 2.3010222911834717, 2.300978422164917, 2.301025867462158, 2.300985813140869, 2.3010241985321045, 2.301018714904785, 2.300994873046875, 2.3010127544403076, 2.3009746074676514, 2.3009836673736572, 2.3009886741638184, 2.3010151386260986, 2.3009543418884277, 2.3009793758392334, 2.300985813140869, 2.300975799560547, 2.3009936809539795, 2.300974130630493, 2.3009867668151855, 2.300971746444702, 2.300985097885132, 2.300938367843628, 2.30100417137146, 2.3009872436523438, 2.3009793758392334, 2.3009419441223145, 2.300956964492798, 2.3009698390960693, 2.300959587097168, 2.3009464740753174, 2.3009703159332275, 2.3009462356567383, 2.3009846210479736, 2.300954818725586, 2.3009536266326904, 2.3009541034698486], 'accuracy': [0.11433333158493042, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.302088975906372, 2.3020007610321045, 2.302003860473633, 2.302004098892212, 2.3020131587982178, 2.3020150661468506, 2.302032232284546, 2.302013635635376, 2.3020238876342773, 2.3020570278167725, 2.3020808696746826, 2.3020882606506348, 2.302055835723877, 2.3020386695861816, 2.302051544189453, 2.3020176887512207, 2.3020670413970947, 2.302049398422241, 2.302065849304199, 2.302065849304199, 2.302058219909668, 2.302049160003662, 2.302069902420044, 2.302065849304199, 2.3020222187042236, 2.3020503520965576, 2.3020737171173096, 2.302107334136963, 2.3020179271698, 2.302016019821167, 2.3020825386047363, 2.3021135330200195, 2.302055835723877, 2.302074432373047, 2.302018404006958, 2.3020496368408203, 2.302061080932617, 2.3020920753479004, 2.3020787239074707, 2.30208420753479, 2.302128314971924, 2.3020472526550293, 2.302055835723877, 2.3020405769348145, 2.302027940750122, 2.302020311355591, 2.302022695541382, 2.302079677581787, 2.3020436763763428, 2.3020379543304443], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [2.30198073387146, 2.3014163970947266, 2.3011534214019775, 2.3010966777801514, 2.3010144233703613, 2.3010759353637695, 2.3010413646698, 2.301007032394409, 2.300926685333252, 2.3010292053222656, 2.3010568618774414, 2.3009917736053467, 2.301011323928833, 2.300985097885132, 2.3009443283081055, 2.3009462356567383, 2.3009440898895264, 2.3009164333343506, 2.3009133338928223, 2.300894021987915, 2.300884246826172, 2.3008830547332764, 2.300916910171509, 2.30090594291687, 2.300880193710327, 2.3009023666381836, 2.3008646965026855, 2.300855875015259, 2.3008313179016113, 2.3008272647857666, 2.3008697032928467, 2.3008337020874023, 2.300816535949707, 2.300812244415283, 2.300776958465576, 2.3008008003234863, 2.300769090652466, 2.300757646560669, 2.3007500171661377, 2.300743579864502, 2.300724983215332, 2.3007051944732666, 2.300715446472168, 2.300711154937744, 2.3006508350372314, 2.3006486892700195, 2.3006391525268555, 2.3006227016448975, 2.300593137741089, 2.3005943298339844], 'accuracy': [0.11343750357627869, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3020079135894775, 2.30192232131958, 2.301919937133789, 2.3019473552703857, 2.3019542694091797, 2.301994562149048, 2.3020224571228027, 2.3020453453063965, 2.302083730697632, 2.3020365238189697, 2.3020293712615967, 2.3020291328430176, 2.302021026611328, 2.3019747734069824, 2.3020095825195312, 2.302002429962158, 2.302021026611328, 2.302023410797119, 2.3020377159118652, 2.30202317237854, 2.302027940750122, 2.3020098209381104, 2.301981210708618, 2.301952838897705, 2.3019537925720215, 2.301927089691162, 2.3019144535064697, 2.301927089691162, 2.3019165992736816, 2.301935911178589, 2.3019015789031982, 2.3018972873687744, 2.3018815517425537, 2.301875591278076, 2.3018484115600586, 2.301830768585205, 2.301818370819092, 2.301819086074829, 2.3018200397491455, 2.301793336868286, 2.3017821311950684, 2.301774024963379, 2.3017449378967285, 2.3017189502716064, 2.3016843795776367, 2.3017055988311768, 2.3017051219940186, 2.3016786575317383, 2.3016653060913086, 2.3016340732574463], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
