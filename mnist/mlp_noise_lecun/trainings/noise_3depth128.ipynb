{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "413a840e-b67e-407e-e8d4-cde794a2c8e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 19s 7ms/step - loss: 1.6394 - accuracy: 0.4530 - val_loss: 0.5806 - val_accuracy: 0.8447\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7141 - accuracy: 0.7837 - val_loss: 0.4354 - val_accuracy: 0.8783\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5737 - accuracy: 0.8243 - val_loss: 0.3869 - val_accuracy: 0.8902\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5238 - accuracy: 0.8402 - val_loss: 0.3628 - val_accuracy: 0.8949\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4810 - accuracy: 0.8519 - val_loss: 0.3475 - val_accuracy: 0.8974\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4649 - accuracy: 0.8580 - val_loss: 0.3376 - val_accuracy: 0.8996\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4539 - accuracy: 0.8617 - val_loss: 0.3294 - val_accuracy: 0.9020\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4333 - accuracy: 0.8674 - val_loss: 0.3230 - val_accuracy: 0.9040\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4218 - accuracy: 0.8723 - val_loss: 0.3187 - val_accuracy: 0.9044\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4150 - accuracy: 0.8749 - val_loss: 0.3145 - val_accuracy: 0.9062\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4087 - accuracy: 0.8788 - val_loss: 0.3099 - val_accuracy: 0.9074\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3989 - accuracy: 0.8808 - val_loss: 0.3064 - val_accuracy: 0.9079\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3867 - accuracy: 0.8825 - val_loss: 0.3040 - val_accuracy: 0.9088\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3875 - accuracy: 0.8821 - val_loss: 0.3001 - val_accuracy: 0.9105\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3815 - accuracy: 0.8860 - val_loss: 0.2962 - val_accuracy: 0.9112\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3773 - accuracy: 0.8873 - val_loss: 0.2944 - val_accuracy: 0.9125\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3690 - accuracy: 0.8895 - val_loss: 0.2913 - val_accuracy: 0.9133\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3641 - accuracy: 0.8906 - val_loss: 0.2897 - val_accuracy: 0.9128\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3731 - accuracy: 0.8884 - val_loss: 0.2880 - val_accuracy: 0.9135\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3552 - accuracy: 0.8935 - val_loss: 0.2861 - val_accuracy: 0.9142\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3584 - accuracy: 0.8917 - val_loss: 0.2837 - val_accuracy: 0.9153\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3563 - accuracy: 0.8934 - val_loss: 0.2812 - val_accuracy: 0.9153\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3443 - accuracy: 0.8969 - val_loss: 0.2797 - val_accuracy: 0.9159\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3358 - accuracy: 0.8991 - val_loss: 0.2769 - val_accuracy: 0.9166\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3451 - accuracy: 0.8973 - val_loss: 0.2751 - val_accuracy: 0.9170\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3368 - accuracy: 0.8974 - val_loss: 0.2743 - val_accuracy: 0.9178\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3365 - accuracy: 0.8973 - val_loss: 0.2724 - val_accuracy: 0.9178\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3260 - accuracy: 0.9012 - val_loss: 0.2696 - val_accuracy: 0.9187\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3236 - accuracy: 0.9025 - val_loss: 0.2681 - val_accuracy: 0.9188\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3242 - accuracy: 0.9028 - val_loss: 0.2672 - val_accuracy: 0.9189\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3152 - accuracy: 0.9049 - val_loss: 0.2635 - val_accuracy: 0.9209\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3164 - accuracy: 0.9044 - val_loss: 0.2624 - val_accuracy: 0.9212\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3168 - accuracy: 0.9061 - val_loss: 0.2609 - val_accuracy: 0.9214\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3102 - accuracy: 0.9054 - val_loss: 0.2598 - val_accuracy: 0.9217\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3035 - accuracy: 0.9087 - val_loss: 0.2569 - val_accuracy: 0.9231\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3086 - accuracy: 0.9075 - val_loss: 0.2557 - val_accuracy: 0.9230\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3087 - accuracy: 0.9068 - val_loss: 0.2549 - val_accuracy: 0.9240\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2894 - accuracy: 0.9103 - val_loss: 0.2531 - val_accuracy: 0.9226\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2982 - accuracy: 0.9118 - val_loss: 0.2514 - val_accuracy: 0.9247\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2963 - accuracy: 0.9086 - val_loss: 0.2492 - val_accuracy: 0.9259\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2904 - accuracy: 0.9139 - val_loss: 0.2472 - val_accuracy: 0.9258\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2937 - accuracy: 0.9115 - val_loss: 0.2457 - val_accuracy: 0.9270\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2868 - accuracy: 0.9125 - val_loss: 0.2446 - val_accuracy: 0.9281\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2812 - accuracy: 0.9133 - val_loss: 0.2433 - val_accuracy: 0.9282\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2854 - accuracy: 0.9135 - val_loss: 0.2414 - val_accuracy: 0.9283\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2781 - accuracy: 0.9145 - val_loss: 0.2398 - val_accuracy: 0.9288\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2845 - accuracy: 0.9153 - val_loss: 0.2379 - val_accuracy: 0.9292\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2772 - accuracy: 0.9165 - val_loss: 0.2375 - val_accuracy: 0.9298\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2767 - accuracy: 0.9166 - val_loss: 0.2354 - val_accuracy: 0.9298\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2648 - accuracy: 0.9200 - val_loss: 0.2343 - val_accuracy: 0.9310\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.1530 - accuracy: 0.2316 - val_loss: 1.1203 - val_accuracy: 0.7589\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2280 - accuracy: 0.5994 - val_loss: 0.6017 - val_accuracy: 0.8510\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8472 - accuracy: 0.7268 - val_loss: 0.4605 - val_accuracy: 0.8772\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6847 - accuracy: 0.7847 - val_loss: 0.3975 - val_accuracy: 0.8890\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6041 - accuracy: 0.8134 - val_loss: 0.3593 - val_accuracy: 0.8967\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5402 - accuracy: 0.8350 - val_loss: 0.3335 - val_accuracy: 0.9027\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5012 - accuracy: 0.8494 - val_loss: 0.3121 - val_accuracy: 0.9057\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4667 - accuracy: 0.8593 - val_loss: 0.2957 - val_accuracy: 0.9103\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4392 - accuracy: 0.8690 - val_loss: 0.2826 - val_accuracy: 0.9141\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4174 - accuracy: 0.8754 - val_loss: 0.2710 - val_accuracy: 0.9174\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4041 - accuracy: 0.8815 - val_loss: 0.2598 - val_accuracy: 0.9213\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3845 - accuracy: 0.8844 - val_loss: 0.2502 - val_accuracy: 0.9237\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3671 - accuracy: 0.8904 - val_loss: 0.2394 - val_accuracy: 0.9277\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3527 - accuracy: 0.8952 - val_loss: 0.2321 - val_accuracy: 0.9300\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3344 - accuracy: 0.9023 - val_loss: 0.2258 - val_accuracy: 0.9322\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3283 - accuracy: 0.9055 - val_loss: 0.2186 - val_accuracy: 0.9342\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3133 - accuracy: 0.9090 - val_loss: 0.2111 - val_accuracy: 0.9367\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2990 - accuracy: 0.9126 - val_loss: 0.2074 - val_accuracy: 0.9387\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2846 - accuracy: 0.9162 - val_loss: 0.2003 - val_accuracy: 0.9408\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2817 - accuracy: 0.9166 - val_loss: 0.1964 - val_accuracy: 0.9413\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2708 - accuracy: 0.9213 - val_loss: 0.1909 - val_accuracy: 0.9431\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2651 - accuracy: 0.9215 - val_loss: 0.1866 - val_accuracy: 0.9442\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2592 - accuracy: 0.9240 - val_loss: 0.1829 - val_accuracy: 0.9448\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2453 - accuracy: 0.9279 - val_loss: 0.1802 - val_accuracy: 0.9458\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2452 - accuracy: 0.9280 - val_loss: 0.1775 - val_accuracy: 0.9461\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2406 - accuracy: 0.9321 - val_loss: 0.1738 - val_accuracy: 0.9472\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2286 - accuracy: 0.9324 - val_loss: 0.1706 - val_accuracy: 0.9478\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2252 - accuracy: 0.9333 - val_loss: 0.1666 - val_accuracy: 0.9492\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2186 - accuracy: 0.9355 - val_loss: 0.1646 - val_accuracy: 0.9492\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2103 - accuracy: 0.9383 - val_loss: 0.1625 - val_accuracy: 0.9507\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2063 - accuracy: 0.9413 - val_loss: 0.1606 - val_accuracy: 0.9513\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2016 - accuracy: 0.9412 - val_loss: 0.1579 - val_accuracy: 0.9517\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1856 - accuracy: 0.9460 - val_loss: 0.1561 - val_accuracy: 0.9528\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1945 - accuracy: 0.9431 - val_loss: 0.1535 - val_accuracy: 0.9532\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1882 - accuracy: 0.9448 - val_loss: 0.1525 - val_accuracy: 0.9532\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1819 - accuracy: 0.9473 - val_loss: 0.1498 - val_accuracy: 0.9535\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1800 - accuracy: 0.9478 - val_loss: 0.1485 - val_accuracy: 0.9541\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1762 - accuracy: 0.9484 - val_loss: 0.1475 - val_accuracy: 0.9545\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1709 - accuracy: 0.9500 - val_loss: 0.1461 - val_accuracy: 0.9553\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1699 - accuracy: 0.9485 - val_loss: 0.1454 - val_accuracy: 0.9557\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1622 - accuracy: 0.9534 - val_loss: 0.1445 - val_accuracy: 0.9559\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1553 - accuracy: 0.9533 - val_loss: 0.1422 - val_accuracy: 0.9558\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1560 - accuracy: 0.9531 - val_loss: 0.1408 - val_accuracy: 0.9567\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1510 - accuracy: 0.9546 - val_loss: 0.1391 - val_accuracy: 0.9568\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1455 - accuracy: 0.9578 - val_loss: 0.1394 - val_accuracy: 0.9567\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1436 - accuracy: 0.9574 - val_loss: 0.1382 - val_accuracy: 0.9571\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1435 - accuracy: 0.9580 - val_loss: 0.1358 - val_accuracy: 0.9581\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1379 - accuracy: 0.9604 - val_loss: 0.1357 - val_accuracy: 0.9579\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1309 - accuracy: 0.9626 - val_loss: 0.1351 - val_accuracy: 0.9582\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1327 - accuracy: 0.9598 - val_loss: 0.1333 - val_accuracy: 0.9588\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.0999 - accuracy: 0.2614 - val_loss: 0.9749 - val_accuracy: 0.7696\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0751 - accuracy: 0.6574 - val_loss: 0.5575 - val_accuracy: 0.8505\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7553 - accuracy: 0.7588 - val_loss: 0.4461 - val_accuracy: 0.8766\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6361 - accuracy: 0.8015 - val_loss: 0.3964 - val_accuracy: 0.8871\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5587 - accuracy: 0.8293 - val_loss: 0.3630 - val_accuracy: 0.8939\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5127 - accuracy: 0.8437 - val_loss: 0.3402 - val_accuracy: 0.8990\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4779 - accuracy: 0.8551 - val_loss: 0.3236 - val_accuracy: 0.9035\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4641 - accuracy: 0.8596 - val_loss: 0.3096 - val_accuracy: 0.9081\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4287 - accuracy: 0.8720 - val_loss: 0.2972 - val_accuracy: 0.9103\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4145 - accuracy: 0.8754 - val_loss: 0.2847 - val_accuracy: 0.9144\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3925 - accuracy: 0.8851 - val_loss: 0.2763 - val_accuracy: 0.9171\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3798 - accuracy: 0.8845 - val_loss: 0.2689 - val_accuracy: 0.9188\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3712 - accuracy: 0.8891 - val_loss: 0.2613 - val_accuracy: 0.9212\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3600 - accuracy: 0.8937 - val_loss: 0.2535 - val_accuracy: 0.9234\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3378 - accuracy: 0.8989 - val_loss: 0.2465 - val_accuracy: 0.9253\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3307 - accuracy: 0.9027 - val_loss: 0.2412 - val_accuracy: 0.9273\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3162 - accuracy: 0.9038 - val_loss: 0.2346 - val_accuracy: 0.9283\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3058 - accuracy: 0.9098 - val_loss: 0.2295 - val_accuracy: 0.9305\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3052 - accuracy: 0.9097 - val_loss: 0.2247 - val_accuracy: 0.9316\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2983 - accuracy: 0.9117 - val_loss: 0.2190 - val_accuracy: 0.9337\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2886 - accuracy: 0.9146 - val_loss: 0.2150 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2771 - accuracy: 0.9177 - val_loss: 0.2112 - val_accuracy: 0.9361\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2725 - accuracy: 0.9198 - val_loss: 0.2069 - val_accuracy: 0.9367\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2619 - accuracy: 0.9220 - val_loss: 0.2036 - val_accuracy: 0.9381\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2617 - accuracy: 0.9257 - val_loss: 0.1992 - val_accuracy: 0.9392\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2523 - accuracy: 0.9240 - val_loss: 0.1959 - val_accuracy: 0.9409\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2474 - accuracy: 0.9251 - val_loss: 0.1934 - val_accuracy: 0.9413\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2421 - accuracy: 0.9281 - val_loss: 0.1897 - val_accuracy: 0.9426\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2381 - accuracy: 0.9287 - val_loss: 0.1875 - val_accuracy: 0.9427\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2334 - accuracy: 0.9297 - val_loss: 0.1841 - val_accuracy: 0.9446\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2291 - accuracy: 0.9313 - val_loss: 0.1813 - val_accuracy: 0.9457\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2224 - accuracy: 0.9336 - val_loss: 0.1790 - val_accuracy: 0.9457\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2181 - accuracy: 0.9340 - val_loss: 0.1776 - val_accuracy: 0.9459\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2110 - accuracy: 0.9357 - val_loss: 0.1751 - val_accuracy: 0.9469\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2050 - accuracy: 0.9381 - val_loss: 0.1726 - val_accuracy: 0.9479\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2089 - accuracy: 0.9391 - val_loss: 0.1706 - val_accuracy: 0.9481\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2015 - accuracy: 0.9396 - val_loss: 0.1691 - val_accuracy: 0.9484\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1981 - accuracy: 0.9404 - val_loss: 0.1662 - val_accuracy: 0.9488\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2004 - accuracy: 0.9392 - val_loss: 0.1654 - val_accuracy: 0.9494\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1923 - accuracy: 0.9431 - val_loss: 0.1645 - val_accuracy: 0.9498\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1868 - accuracy: 0.9427 - val_loss: 0.1626 - val_accuracy: 0.9498\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1846 - accuracy: 0.9435 - val_loss: 0.1601 - val_accuracy: 0.9507\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1776 - accuracy: 0.9482 - val_loss: 0.1595 - val_accuracy: 0.9500\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1817 - accuracy: 0.9443 - val_loss: 0.1582 - val_accuracy: 0.9504\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1775 - accuracy: 0.9476 - val_loss: 0.1566 - val_accuracy: 0.9508\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1700 - accuracy: 0.9491 - val_loss: 0.1553 - val_accuracy: 0.9514\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1670 - accuracy: 0.9487 - val_loss: 0.1553 - val_accuracy: 0.9517\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1660 - accuracy: 0.9484 - val_loss: 0.1525 - val_accuracy: 0.9524\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1696 - accuracy: 0.9489 - val_loss: 0.1523 - val_accuracy: 0.9523\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1622 - accuracy: 0.9510 - val_loss: 0.1502 - val_accuracy: 0.9518\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 1.6842 - accuracy: 0.4388 - val_loss: 0.5534 - val_accuracy: 0.8547\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6987 - accuracy: 0.7824 - val_loss: 0.4204 - val_accuracy: 0.8772\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5713 - accuracy: 0.8262 - val_loss: 0.3739 - val_accuracy: 0.8907\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5225 - accuracy: 0.8403 - val_loss: 0.3525 - val_accuracy: 0.8963\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4857 - accuracy: 0.8505 - val_loss: 0.3404 - val_accuracy: 0.8993\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4587 - accuracy: 0.8573 - val_loss: 0.3278 - val_accuracy: 0.9027\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4419 - accuracy: 0.8644 - val_loss: 0.3189 - val_accuracy: 0.9059\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4272 - accuracy: 0.8695 - val_loss: 0.3129 - val_accuracy: 0.9067\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4163 - accuracy: 0.8773 - val_loss: 0.3083 - val_accuracy: 0.9077\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4083 - accuracy: 0.8783 - val_loss: 0.3018 - val_accuracy: 0.9094\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3985 - accuracy: 0.8798 - val_loss: 0.2959 - val_accuracy: 0.9122\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3859 - accuracy: 0.8827 - val_loss: 0.2932 - val_accuracy: 0.9131\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3761 - accuracy: 0.8866 - val_loss: 0.2883 - val_accuracy: 0.9137\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3682 - accuracy: 0.8892 - val_loss: 0.2837 - val_accuracy: 0.9158\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3566 - accuracy: 0.8923 - val_loss: 0.2796 - val_accuracy: 0.9176\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3592 - accuracy: 0.8918 - val_loss: 0.2761 - val_accuracy: 0.9181\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3471 - accuracy: 0.8954 - val_loss: 0.2730 - val_accuracy: 0.9187\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3524 - accuracy: 0.8934 - val_loss: 0.2696 - val_accuracy: 0.9206\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3341 - accuracy: 0.8987 - val_loss: 0.2656 - val_accuracy: 0.9217\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3356 - accuracy: 0.8974 - val_loss: 0.2617 - val_accuracy: 0.9228\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3342 - accuracy: 0.8979 - val_loss: 0.2593 - val_accuracy: 0.9231\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3279 - accuracy: 0.9014 - val_loss: 0.2561 - val_accuracy: 0.9240\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3214 - accuracy: 0.9025 - val_loss: 0.2521 - val_accuracy: 0.9245\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3173 - accuracy: 0.9025 - val_loss: 0.2516 - val_accuracy: 0.9246\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3062 - accuracy: 0.9065 - val_loss: 0.2466 - val_accuracy: 0.9260\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3018 - accuracy: 0.9105 - val_loss: 0.2438 - val_accuracy: 0.9271\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3069 - accuracy: 0.9065 - val_loss: 0.2420 - val_accuracy: 0.9283\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2976 - accuracy: 0.9094 - val_loss: 0.2379 - val_accuracy: 0.9288\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2926 - accuracy: 0.9092 - val_loss: 0.2354 - val_accuracy: 0.9304\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2958 - accuracy: 0.9098 - val_loss: 0.2334 - val_accuracy: 0.9307\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2845 - accuracy: 0.9136 - val_loss: 0.2305 - val_accuracy: 0.9310\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2756 - accuracy: 0.9154 - val_loss: 0.2277 - val_accuracy: 0.9326\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2723 - accuracy: 0.9170 - val_loss: 0.2256 - val_accuracy: 0.9328\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2706 - accuracy: 0.9181 - val_loss: 0.2235 - val_accuracy: 0.9337\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2696 - accuracy: 0.9188 - val_loss: 0.2208 - val_accuracy: 0.9352\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2657 - accuracy: 0.9196 - val_loss: 0.2180 - val_accuracy: 0.9352\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2642 - accuracy: 0.9189 - val_loss: 0.2165 - val_accuracy: 0.9352\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2550 - accuracy: 0.9207 - val_loss: 0.2139 - val_accuracy: 0.9358\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2554 - accuracy: 0.9214 - val_loss: 0.2125 - val_accuracy: 0.9363\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2439 - accuracy: 0.9249 - val_loss: 0.2104 - val_accuracy: 0.9373\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2518 - accuracy: 0.9210 - val_loss: 0.2104 - val_accuracy: 0.9372\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2492 - accuracy: 0.9253 - val_loss: 0.2079 - val_accuracy: 0.9383\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2459 - accuracy: 0.9242 - val_loss: 0.2051 - val_accuracy: 0.9392\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2536 - accuracy: 0.9218 - val_loss: 0.2040 - val_accuracy: 0.9384\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2477 - accuracy: 0.9232 - val_loss: 0.2017 - val_accuracy: 0.9391\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2485 - accuracy: 0.9238 - val_loss: 0.2004 - val_accuracy: 0.9400\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2362 - accuracy: 0.9273 - val_loss: 0.1987 - val_accuracy: 0.9404\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2352 - accuracy: 0.9272 - val_loss: 0.1975 - val_accuracy: 0.9408\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2229 - accuracy: 0.9307 - val_loss: 0.1951 - val_accuracy: 0.9413\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2370 - accuracy: 0.9271 - val_loss: 0.1947 - val_accuracy: 0.9423\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 1.4499 - accuracy: 0.5194 - val_loss: 0.4173 - val_accuracy: 0.8767\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6376 - accuracy: 0.7987 - val_loss: 0.3713 - val_accuracy: 0.8893\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5610 - accuracy: 0.8265 - val_loss: 0.3539 - val_accuracy: 0.8954\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5137 - accuracy: 0.8419 - val_loss: 0.3402 - val_accuracy: 0.9003\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4834 - accuracy: 0.8531 - val_loss: 0.3335 - val_accuracy: 0.9023\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4694 - accuracy: 0.8562 - val_loss: 0.3286 - val_accuracy: 0.9043\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4601 - accuracy: 0.8638 - val_loss: 0.3246 - val_accuracy: 0.9053\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4416 - accuracy: 0.8653 - val_loss: 0.3189 - val_accuracy: 0.9077\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4395 - accuracy: 0.8670 - val_loss: 0.3155 - val_accuracy: 0.9068\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4172 - accuracy: 0.8735 - val_loss: 0.3131 - val_accuracy: 0.9081\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4148 - accuracy: 0.8766 - val_loss: 0.3098 - val_accuracy: 0.9098\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4069 - accuracy: 0.8787 - val_loss: 0.3084 - val_accuracy: 0.9095\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3943 - accuracy: 0.8805 - val_loss: 0.3036 - val_accuracy: 0.9116\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3930 - accuracy: 0.8828 - val_loss: 0.3014 - val_accuracy: 0.9122\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3854 - accuracy: 0.8830 - val_loss: 0.3011 - val_accuracy: 0.9131\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3824 - accuracy: 0.8834 - val_loss: 0.2983 - val_accuracy: 0.9130\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3799 - accuracy: 0.8845 - val_loss: 0.2953 - val_accuracy: 0.9145\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3579 - accuracy: 0.8922 - val_loss: 0.2932 - val_accuracy: 0.9140\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3613 - accuracy: 0.8914 - val_loss: 0.2917 - val_accuracy: 0.9155\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3602 - accuracy: 0.8895 - val_loss: 0.2892 - val_accuracy: 0.9165\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3560 - accuracy: 0.8914 - val_loss: 0.2897 - val_accuracy: 0.9161\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3419 - accuracy: 0.8954 - val_loss: 0.2860 - val_accuracy: 0.9175\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3461 - accuracy: 0.8953 - val_loss: 0.2821 - val_accuracy: 0.9186\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3427 - accuracy: 0.8964 - val_loss: 0.2831 - val_accuracy: 0.9174\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3405 - accuracy: 0.8958 - val_loss: 0.2809 - val_accuracy: 0.9188\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3427 - accuracy: 0.8947 - val_loss: 0.2786 - val_accuracy: 0.9183\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3251 - accuracy: 0.9020 - val_loss: 0.2754 - val_accuracy: 0.9188\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3357 - accuracy: 0.8999 - val_loss: 0.2737 - val_accuracy: 0.9192\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3271 - accuracy: 0.9009 - val_loss: 0.2725 - val_accuracy: 0.9199\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3252 - accuracy: 0.9013 - val_loss: 0.2716 - val_accuracy: 0.9191\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3236 - accuracy: 0.9015 - val_loss: 0.2711 - val_accuracy: 0.9189\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3170 - accuracy: 0.9049 - val_loss: 0.2673 - val_accuracy: 0.9220\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3146 - accuracy: 0.9040 - val_loss: 0.2652 - val_accuracy: 0.9219\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3104 - accuracy: 0.9054 - val_loss: 0.2629 - val_accuracy: 0.9226\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3100 - accuracy: 0.9070 - val_loss: 0.2618 - val_accuracy: 0.9225\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3089 - accuracy: 0.9055 - val_loss: 0.2604 - val_accuracy: 0.9224\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3148 - accuracy: 0.9054 - val_loss: 0.2579 - val_accuracy: 0.9244\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3130 - accuracy: 0.9057 - val_loss: 0.2575 - val_accuracy: 0.9239\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3038 - accuracy: 0.9070 - val_loss: 0.2541 - val_accuracy: 0.9254\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2939 - accuracy: 0.9112 - val_loss: 0.2516 - val_accuracy: 0.9252\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2975 - accuracy: 0.9093 - val_loss: 0.2503 - val_accuracy: 0.9261\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2962 - accuracy: 0.9090 - val_loss: 0.2470 - val_accuracy: 0.9277\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2854 - accuracy: 0.9112 - val_loss: 0.2476 - val_accuracy: 0.9274\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2839 - accuracy: 0.9141 - val_loss: 0.2449 - val_accuracy: 0.9280\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2838 - accuracy: 0.9138 - val_loss: 0.2429 - val_accuracy: 0.9283\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2847 - accuracy: 0.9125 - val_loss: 0.2433 - val_accuracy: 0.9284\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2822 - accuracy: 0.9132 - val_loss: 0.2415 - val_accuracy: 0.9295\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2717 - accuracy: 0.9159 - val_loss: 0.2381 - val_accuracy: 0.9294\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2752 - accuracy: 0.9158 - val_loss: 0.2384 - val_accuracy: 0.9302\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2689 - accuracy: 0.9161 - val_loss: 0.2353 - val_accuracy: 0.9310\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 7ms/step - loss: 2.2319 - accuracy: 0.1969 - val_loss: 1.6706 - val_accuracy: 0.6712\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.4817 - accuracy: 0.5703 - val_loss: 0.7091 - val_accuracy: 0.8322\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8882 - accuracy: 0.7191 - val_loss: 0.5181 - val_accuracy: 0.8630\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6968 - accuracy: 0.7878 - val_loss: 0.4473 - val_accuracy: 0.8784\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6140 - accuracy: 0.8115 - val_loss: 0.4041 - val_accuracy: 0.8867\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5537 - accuracy: 0.8315 - val_loss: 0.3751 - val_accuracy: 0.8938\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5156 - accuracy: 0.8452 - val_loss: 0.3541 - val_accuracy: 0.8988\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4955 - accuracy: 0.8533 - val_loss: 0.3373 - val_accuracy: 0.9010\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4619 - accuracy: 0.8611 - val_loss: 0.3243 - val_accuracy: 0.9048\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4362 - accuracy: 0.8717 - val_loss: 0.3117 - val_accuracy: 0.9087\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4382 - accuracy: 0.8691 - val_loss: 0.3004 - val_accuracy: 0.9126\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4113 - accuracy: 0.8793 - val_loss: 0.2913 - val_accuracy: 0.9146\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4000 - accuracy: 0.8824 - val_loss: 0.2818 - val_accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3874 - accuracy: 0.8851 - val_loss: 0.2748 - val_accuracy: 0.9180\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3660 - accuracy: 0.8897 - val_loss: 0.2662 - val_accuracy: 0.9212\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3571 - accuracy: 0.8940 - val_loss: 0.2590 - val_accuracy: 0.9239\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3466 - accuracy: 0.8976 - val_loss: 0.2524 - val_accuracy: 0.9245\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3426 - accuracy: 0.8995 - val_loss: 0.2466 - val_accuracy: 0.9268\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3274 - accuracy: 0.9041 - val_loss: 0.2403 - val_accuracy: 0.9277\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3228 - accuracy: 0.9051 - val_loss: 0.2354 - val_accuracy: 0.9289\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3033 - accuracy: 0.9110 - val_loss: 0.2299 - val_accuracy: 0.9314\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3073 - accuracy: 0.9088 - val_loss: 0.2258 - val_accuracy: 0.9323\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2975 - accuracy: 0.9107 - val_loss: 0.2206 - val_accuracy: 0.9334\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2833 - accuracy: 0.9146 - val_loss: 0.2161 - val_accuracy: 0.9349\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2871 - accuracy: 0.9129 - val_loss: 0.2117 - val_accuracy: 0.9368\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2775 - accuracy: 0.9159 - val_loss: 0.2082 - val_accuracy: 0.9383\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2720 - accuracy: 0.9181 - val_loss: 0.2038 - val_accuracy: 0.9390\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2614 - accuracy: 0.9215 - val_loss: 0.2011 - val_accuracy: 0.9405\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2574 - accuracy: 0.9229 - val_loss: 0.1978 - val_accuracy: 0.9406\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2459 - accuracy: 0.9285 - val_loss: 0.1933 - val_accuracy: 0.9426\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2442 - accuracy: 0.9268 - val_loss: 0.1906 - val_accuracy: 0.9436\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2484 - accuracy: 0.9253 - val_loss: 0.1875 - val_accuracy: 0.9440\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2383 - accuracy: 0.9287 - val_loss: 0.1857 - val_accuracy: 0.9449\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2331 - accuracy: 0.9302 - val_loss: 0.1832 - val_accuracy: 0.9456\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2293 - accuracy: 0.9312 - val_loss: 0.1801 - val_accuracy: 0.9463\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2284 - accuracy: 0.9325 - val_loss: 0.1767 - val_accuracy: 0.9475\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2214 - accuracy: 0.9344 - val_loss: 0.1744 - val_accuracy: 0.9482\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2196 - accuracy: 0.9341 - val_loss: 0.1718 - val_accuracy: 0.9483\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2132 - accuracy: 0.9350 - val_loss: 0.1705 - val_accuracy: 0.9490\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2135 - accuracy: 0.9358 - val_loss: 0.1682 - val_accuracy: 0.9497\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2019 - accuracy: 0.9404 - val_loss: 0.1664 - val_accuracy: 0.9501\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2002 - accuracy: 0.9393 - val_loss: 0.1650 - val_accuracy: 0.9504\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1974 - accuracy: 0.9411 - val_loss: 0.1624 - val_accuracy: 0.9517\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1888 - accuracy: 0.9435 - val_loss: 0.1611 - val_accuracy: 0.9515\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1933 - accuracy: 0.9426 - val_loss: 0.1596 - val_accuracy: 0.9520\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1903 - accuracy: 0.9427 - val_loss: 0.1581 - val_accuracy: 0.9528\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1837 - accuracy: 0.9445 - val_loss: 0.1562 - val_accuracy: 0.9517\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1824 - accuracy: 0.9454 - val_loss: 0.1543 - val_accuracy: 0.9536\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1814 - accuracy: 0.9449 - val_loss: 0.1533 - val_accuracy: 0.9532\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1786 - accuracy: 0.9458 - val_loss: 0.1518 - val_accuracy: 0.9538\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2386 - accuracy: 0.2166 - val_loss: 1.9372 - val_accuracy: 0.6720\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7662 - accuracy: 0.5713 - val_loss: 0.9912 - val_accuracy: 0.7788\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0560 - accuracy: 0.6730 - val_loss: 0.6492 - val_accuracy: 0.8346\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8094 - accuracy: 0.7452 - val_loss: 0.5255 - val_accuracy: 0.8615\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7016 - accuracy: 0.7833 - val_loss: 0.4620 - val_accuracy: 0.8732\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6111 - accuracy: 0.8112 - val_loss: 0.4251 - val_accuracy: 0.8824\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5736 - accuracy: 0.8267 - val_loss: 0.3976 - val_accuracy: 0.8882\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5303 - accuracy: 0.8417 - val_loss: 0.3758 - val_accuracy: 0.8913\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5056 - accuracy: 0.8498 - val_loss: 0.3593 - val_accuracy: 0.8963\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4865 - accuracy: 0.8552 - val_loss: 0.3465 - val_accuracy: 0.8997\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4664 - accuracy: 0.8596 - val_loss: 0.3359 - val_accuracy: 0.9034\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4450 - accuracy: 0.8656 - val_loss: 0.3265 - val_accuracy: 0.9043\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4425 - accuracy: 0.8669 - val_loss: 0.3169 - val_accuracy: 0.9083\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4234 - accuracy: 0.8736 - val_loss: 0.3095 - val_accuracy: 0.9097\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4182 - accuracy: 0.8745 - val_loss: 0.3028 - val_accuracy: 0.9118\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4007 - accuracy: 0.8827 - val_loss: 0.2958 - val_accuracy: 0.9130\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3951 - accuracy: 0.8806 - val_loss: 0.2904 - val_accuracy: 0.9147\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3868 - accuracy: 0.8840 - val_loss: 0.2854 - val_accuracy: 0.9147\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3770 - accuracy: 0.8861 - val_loss: 0.2797 - val_accuracy: 0.9168\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3663 - accuracy: 0.8929 - val_loss: 0.2746 - val_accuracy: 0.9180\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3603 - accuracy: 0.8915 - val_loss: 0.2691 - val_accuracy: 0.9197\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3492 - accuracy: 0.8953 - val_loss: 0.2643 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3392 - accuracy: 0.8960 - val_loss: 0.2604 - val_accuracy: 0.9225\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3471 - accuracy: 0.8967 - val_loss: 0.2554 - val_accuracy: 0.9236\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3367 - accuracy: 0.8962 - val_loss: 0.2519 - val_accuracy: 0.9241\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3192 - accuracy: 0.9035 - val_loss: 0.2484 - val_accuracy: 0.9252\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3122 - accuracy: 0.9057 - val_loss: 0.2439 - val_accuracy: 0.9262\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3165 - accuracy: 0.9067 - val_loss: 0.2409 - val_accuracy: 0.9267\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3129 - accuracy: 0.9053 - val_loss: 0.2372 - val_accuracy: 0.9283\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3020 - accuracy: 0.9096 - val_loss: 0.2337 - val_accuracy: 0.9295\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2971 - accuracy: 0.9112 - val_loss: 0.2307 - val_accuracy: 0.9300\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2972 - accuracy: 0.9106 - val_loss: 0.2272 - val_accuracy: 0.9309\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2865 - accuracy: 0.9118 - val_loss: 0.2237 - val_accuracy: 0.9321\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2806 - accuracy: 0.9153 - val_loss: 0.2214 - val_accuracy: 0.9333\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2838 - accuracy: 0.9136 - val_loss: 0.2183 - val_accuracy: 0.9341\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2721 - accuracy: 0.9183 - val_loss: 0.2154 - val_accuracy: 0.9350\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2715 - accuracy: 0.9200 - val_loss: 0.2124 - val_accuracy: 0.9352\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2684 - accuracy: 0.9176 - val_loss: 0.2102 - val_accuracy: 0.9365\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2607 - accuracy: 0.9222 - val_loss: 0.2070 - val_accuracy: 0.9368\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2593 - accuracy: 0.9211 - val_loss: 0.2049 - val_accuracy: 0.9377\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2561 - accuracy: 0.9219 - val_loss: 0.2026 - val_accuracy: 0.9382\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2501 - accuracy: 0.9250 - val_loss: 0.2006 - val_accuracy: 0.9387\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2441 - accuracy: 0.9259 - val_loss: 0.1979 - val_accuracy: 0.9394\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2446 - accuracy: 0.9250 - val_loss: 0.1962 - val_accuracy: 0.9405\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2385 - accuracy: 0.9289 - val_loss: 0.1942 - val_accuracy: 0.9414\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2428 - accuracy: 0.9248 - val_loss: 0.1924 - val_accuracy: 0.9417\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2331 - accuracy: 0.9305 - val_loss: 0.1902 - val_accuracy: 0.9427\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2296 - accuracy: 0.9294 - val_loss: 0.1886 - val_accuracy: 0.9433\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2262 - accuracy: 0.9301 - val_loss: 0.1865 - val_accuracy: 0.9442\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2242 - accuracy: 0.9314 - val_loss: 0.1845 - val_accuracy: 0.9442\n",
      "{'loss': [1.217867374420166, 0.6720628142356873, 0.5657859444618225, 0.5154266953468323, 0.48272380232810974, 0.4651433825492859, 0.4457036852836609, 0.4334961473941803, 0.4240007996559143, 0.4135788083076477, 0.407753050327301, 0.39664340019226074, 0.3917679786682129, 0.38706403970718384, 0.3813188970088959, 0.37675532698631287, 0.3712889552116394, 0.36749911308288574, 0.36354753375053406, 0.3548840880393982, 0.35593634843826294, 0.35267385840415955, 0.34440457820892334, 0.34085240960121155, 0.33855339884757996, 0.3368573486804962, 0.3325895071029663, 0.3271952271461487, 0.3242872655391693, 0.3221801519393921, 0.32091742753982544, 0.31637969613075256, 0.31416815519332886, 0.3102000057697296, 0.30630847811698914, 0.30507394671440125, 0.30370110273361206, 0.2977628707885742, 0.29714950919151306, 0.2945445477962494, 0.28990453481674194, 0.2932324707508087, 0.28718405961990356, 0.28328025341033936, 0.28133344650268555, 0.2798652648925781, 0.2789328992366791, 0.27505922317504883, 0.27249881625175476, 0.27135226130485535], 'accuracy': [0.6164791584014893, 0.7947083115577698, 0.8273125290870667, 0.8428541421890259, 0.8530625104904175, 0.8583958148956299, 0.864229142665863, 0.8682500123977661, 0.8706041574478149, 0.8754166960716248, 0.8774166703224182, 0.8803750276565552, 0.8819375038146973, 0.8830416798591614, 0.8859166502952576, 0.8871458172798157, 0.8894791603088379, 0.8891666531562805, 0.8916666507720947, 0.893666684627533, 0.8920416831970215, 0.8943333625793457, 0.8964999914169312, 0.8975416421890259, 0.89822918176651, 0.898145854473114, 0.8990416526794434, 0.9008749723434448, 0.9018333554267883, 0.9029791951179504, 0.9033750295639038, 0.9039999842643738, 0.9056666493415833, 0.9053333401679993, 0.9077291488647461, 0.9079375267028809, 0.9074583053588867, 0.9083750247955322, 0.910729169845581, 0.9101874828338623, 0.9135000109672546, 0.9106666445732117, 0.9120208621025085, 0.9134374856948853, 0.9143333435058594, 0.9163541793823242, 0.9160624742507935, 0.9163125157356262, 0.9176666736602783, 0.9172916412353516], 'val_loss': [0.580624520778656, 0.43541887402534485, 0.3868768811225891, 0.36284810304641724, 0.34752869606018066, 0.33758068084716797, 0.3293655216693878, 0.3230322599411011, 0.3187415599822998, 0.3145354688167572, 0.3098606765270233, 0.30642080307006836, 0.3039674162864685, 0.3000602424144745, 0.2961522042751312, 0.29439276456832886, 0.2913151979446411, 0.28967365622520447, 0.28802725672721863, 0.28611528873443604, 0.2837073802947998, 0.28124871850013733, 0.2796953618526459, 0.27693605422973633, 0.27514517307281494, 0.27427956461906433, 0.27243372797966003, 0.26960495114326477, 0.268112450838089, 0.2672194540500641, 0.2634544372558594, 0.26241573691368103, 0.2609390616416931, 0.25982990860939026, 0.2569386959075928, 0.2556911110877991, 0.25489988923072815, 0.25310856103897095, 0.25139299035072327, 0.24923846125602722, 0.24719907343387604, 0.24569250643253326, 0.24456597864627838, 0.24327410757541656, 0.24135443568229675, 0.2397942692041397, 0.23786331713199615, 0.23745766282081604, 0.23537708818912506, 0.2342575639486313], 'val_accuracy': [0.8446666598320007, 0.878333330154419, 0.8901666402816772, 0.8949166536331177, 0.8974166512489319, 0.8995833396911621, 0.9020000100135803, 0.9039999842643738, 0.9044166803359985, 0.90625, 0.9074166417121887, 0.9079166650772095, 0.9088333249092102, 0.9104999899864197, 0.9112499952316284, 0.9125000238418579, 0.9132500290870667, 0.9127500057220459, 0.9135000109672546, 0.9141666889190674, 0.9153333306312561, 0.9152500033378601, 0.9159166812896729, 0.9165833592414856, 0.9169999957084656, 0.9177500009536743, 0.9178333282470703, 0.918749988079071, 0.918833315372467, 0.918916642665863, 0.9209166765213013, 0.9212499856948853, 0.9214166402816772, 0.92166668176651, 0.9230833053588867, 0.9229999780654907, 0.9240000247955322, 0.9225833415985107, 0.9247499704360962, 0.9259166717529297, 0.9257500171661377, 0.9269999861717224, 0.9280833601951599, 0.9281666874885559, 0.9283333420753479, 0.9288333058357239, 0.9291666746139526, 0.9297500252723694, 0.9298333525657654, 0.9309999942779541]}\n",
      "{'loss': [1.9165716171264648, 1.1009128093719482, 0.7992805242538452, 0.6655044555664062, 0.5900879502296448, 0.5362127423286438, 0.49507594108581543, 0.4638938009738922, 0.43669697642326355, 0.4172534644603729, 0.3975365459918976, 0.3819592595100403, 0.36242422461509705, 0.351279616355896, 0.33754080533981323, 0.32252585887908936, 0.30739206075668335, 0.30177462100982666, 0.2892928123474121, 0.2815782427787781, 0.26948031783103943, 0.26188427209854126, 0.2569293677806854, 0.24640919268131256, 0.24345704913139343, 0.2357511818408966, 0.22712062299251556, 0.22552280128002167, 0.2171909660100937, 0.2087508589029312, 0.20399317145347595, 0.20008420944213867, 0.19180645048618317, 0.1910644769668579, 0.1891879141330719, 0.18436798453330994, 0.18142984807491302, 0.1722269505262375, 0.17187638580799103, 0.16426873207092285, 0.16088932752609253, 0.15831920504570007, 0.15361611545085907, 0.15369313955307007, 0.14821523427963257, 0.14286260306835175, 0.1433997005224228, 0.13779258728027344, 0.13302843272686005, 0.13431204855442047], 'accuracy': [0.3476458191871643, 0.6381250023841858, 0.7440000176429749, 0.7911041378974915, 0.8193749785423279, 0.8377291560173035, 0.851687490940094, 0.859375, 0.8705000281333923, 0.8756250143051147, 0.883187472820282, 0.8871874809265137, 0.8920416831970215, 0.8962708115577698, 0.9002500176429749, 0.9064791798591614, 0.9100208282470703, 0.9118541479110718, 0.9149583578109741, 0.9164375066757202, 0.9209583401679993, 0.9231458306312561, 0.9236875176429749, 0.9274583458900452, 0.9287083148956299, 0.9318125247955322, 0.9332916736602783, 0.9337291717529297, 0.9359791874885559, 0.9385416507720947, 0.9408541917800903, 0.9412916898727417, 0.9437916874885559, 0.9439791440963745, 0.9438541531562805, 0.945562481880188, 0.9471874833106995, 0.9491249918937683, 0.9494583606719971, 0.9514791369438171, 0.9531875252723694, 0.9525625109672546, 0.9547708630561829, 0.9541041851043701, 0.9565208554267883, 0.9583333134651184, 0.957645833492279, 0.9594374895095825, 0.960645854473114, 0.9600625038146973], 'val_loss': [1.1202715635299683, 0.6016620397567749, 0.46047258377075195, 0.3975202143192291, 0.35932469367980957, 0.33345741033554077, 0.3121391832828522, 0.29569724202156067, 0.28264492750167847, 0.2710007429122925, 0.2597690522670746, 0.25019800662994385, 0.23940405249595642, 0.23206400871276855, 0.2258177250623703, 0.2186218798160553, 0.21114493906497955, 0.20740780234336853, 0.2002871334552765, 0.19637133181095123, 0.19085313379764557, 0.1866273432970047, 0.1828923523426056, 0.18022730946540833, 0.1775093525648117, 0.1738019585609436, 0.17061981558799744, 0.16656342148780823, 0.16461420059204102, 0.16252689063549042, 0.16062787175178528, 0.15792451798915863, 0.15613408386707306, 0.15351170301437378, 0.15249410271644592, 0.14984987676143646, 0.14854243397712708, 0.14749890565872192, 0.14613460004329681, 0.14540161192417145, 0.14446651935577393, 0.14223624765872955, 0.1408415585756302, 0.13914494216442108, 0.139383926987648, 0.13819122314453125, 0.13584423065185547, 0.13565616309642792, 0.13509412109851837, 0.13332538306713104], 'val_accuracy': [0.7589166760444641, 0.8510000109672546, 0.8771666884422302, 0.8889999985694885, 0.8967499732971191, 0.9026666879653931, 0.9056666493415833, 0.9102500081062317, 0.9140833616256714, 0.9174166917800903, 0.9213333129882812, 0.9236666560173035, 0.9276666641235352, 0.9300000071525574, 0.9321666955947876, 0.934166669845581, 0.9366666674613953, 0.9386666417121887, 0.940750002861023, 0.9412500262260437, 0.9430833458900452, 0.9441666603088379, 0.9447500109672546, 0.9458333253860474, 0.9460833072662354, 0.9471666812896729, 0.9478333592414856, 0.9492499828338623, 0.9491666555404663, 0.9506666660308838, 0.9513333439826965, 0.9516666531562805, 0.952833354473114, 0.953166663646698, 0.953166663646698, 0.953499972820282, 0.9540833234786987, 0.9545000195503235, 0.9553333520889282, 0.9556666612625122, 0.9559166431427002, 0.9558333158493042, 0.9567499756813049, 0.9568333625793457, 0.9567499756813049, 0.9570833444595337, 0.9580833315849304, 0.9579166769981384, 0.9582499861717224, 0.9587500095367432]}\n",
      "{'loss': [1.8097267150878906, 0.9659101366996765, 0.7185887694358826, 0.6169509887695312, 0.5482062697410583, 0.5038790702819824, 0.4741886258125305, 0.4530239403247833, 0.42691126465797424, 0.4077396094799042, 0.39393168687820435, 0.37898117303848267, 0.36326903104782104, 0.35253602266311646, 0.34176382422447205, 0.3296716511249542, 0.3218161165714264, 0.3079191744327545, 0.3031907379627228, 0.29601016640663147, 0.28856709599494934, 0.2798823118209839, 0.27051323652267456, 0.26639819145202637, 0.26066264510154724, 0.2532273232936859, 0.24925309419631958, 0.24386391043663025, 0.23757195472717285, 0.23292136192321777, 0.22903819382190704, 0.22346369922161102, 0.21928627789020538, 0.2136988788843155, 0.2080421894788742, 0.20689864456653595, 0.20236870646476746, 0.19889378547668457, 0.1938810646533966, 0.18907323479652405, 0.18968601524829865, 0.1841401755809784, 0.18049582839012146, 0.17895497381687164, 0.17528310418128967, 0.16942636668682098, 0.16911795735359192, 0.16615964472293854, 0.16369971632957458, 0.16185910999774933], 'accuracy': [0.4036458432674408, 0.6930208206176758, 0.7736250162124634, 0.8088958263397217, 0.8340416550636292, 0.8463333249092102, 0.8554999828338623, 0.864270806312561, 0.8732916712760925, 0.878208339214325, 0.883062481880188, 0.8853124976158142, 0.8918541669845581, 0.8947499990463257, 0.8979374766349792, 0.9024375081062317, 0.9043333530426025, 0.9080416560173035, 0.9098333120346069, 0.9118333458900452, 0.9146875143051147, 0.9159583449363708, 0.9197708368301392, 0.9197916388511658, 0.9235000014305115, 0.9245833158493042, 0.9247291684150696, 0.9276458621025085, 0.9290833473205566, 0.9298750162124634, 0.9322916865348816, 0.9332708120346069, 0.9346250295639038, 0.9354375004768372, 0.9365208148956299, 0.9388541579246521, 0.9387500286102295, 0.9401875138282776, 0.9415833353996277, 0.9439166784286499, 0.9426041841506958, 0.9446874856948853, 0.9466875195503235, 0.9458749890327454, 0.9474166631698608, 0.9486874938011169, 0.948562502861023, 0.9491458535194397, 0.950124979019165, 0.9506458044052124], 'val_loss': [0.9749402403831482, 0.5575345754623413, 0.4460846483707428, 0.3963543772697449, 0.3630363345146179, 0.3402137756347656, 0.323583722114563, 0.30956894159317017, 0.29716455936431885, 0.2847186028957367, 0.27634769678115845, 0.26887452602386475, 0.26125943660736084, 0.25354838371276855, 0.24654817581176758, 0.2411821335554123, 0.23463165760040283, 0.2295149266719818, 0.22468750178813934, 0.2189655900001526, 0.21500352025032043, 0.21123532950878143, 0.20688273012638092, 0.20355434715747833, 0.19923706352710724, 0.19590270519256592, 0.19336503744125366, 0.18967364728450775, 0.18754471838474274, 0.18409986793994904, 0.18128088116645813, 0.1790398508310318, 0.17760182917118073, 0.1750527322292328, 0.1726054698228836, 0.17055156826972961, 0.16913767158985138, 0.166243776679039, 0.16539335250854492, 0.16447803378105164, 0.16259869933128357, 0.160091370344162, 0.15948086977005005, 0.158197820186615, 0.15662218630313873, 0.1553235501050949, 0.15530803799629211, 0.15249648690223694, 0.1522889882326126, 0.1501753181219101], 'val_accuracy': [0.7695833444595337, 0.8504999876022339, 0.8765833377838135, 0.8870833516120911, 0.893916666507721, 0.8989999890327454, 0.9035000205039978, 0.9080833196640015, 0.9103333353996277, 0.9144166707992554, 0.9170833230018616, 0.918833315372467, 0.9212499856948853, 0.9234166741371155, 0.9253333210945129, 0.9273333549499512, 0.9282500147819519, 0.9304999709129333, 0.9315833449363708, 0.9337499737739563, 0.934583306312561, 0.9360833168029785, 0.9366666674613953, 0.9380833506584167, 0.9392499923706055, 0.9409166574478149, 0.9413333535194397, 0.9425833225250244, 0.9427499771118164, 0.9445833563804626, 0.9456666707992554, 0.9456666707992554, 0.9459166526794434, 0.9469166398048401, 0.9479166865348816, 0.9480833411216736, 0.9484166502952576, 0.9487500190734863, 0.9494166374206543, 0.9497500061988831, 0.9497500061988831, 0.9506666660308838, 0.949999988079071, 0.9504166841506958, 0.9508333206176758, 0.9514166712760925, 0.9516666531562805, 0.9524166584014893, 0.9523333311080933, 0.9518333077430725]}\n",
      "{'loss': [1.223059058189392, 0.6524124145507812, 0.5542826652526855, 0.5089156627655029, 0.4764721989631653, 0.4534669518470764, 0.4391753673553467, 0.42673996090888977, 0.41609805822372437, 0.403046578168869, 0.3932713270187378, 0.38584935665130615, 0.3798234462738037, 0.37316790223121643, 0.3635331988334656, 0.35928046703338623, 0.34874019026756287, 0.34885433316230774, 0.3380816876888275, 0.3365287184715271, 0.33166706562042236, 0.3245174288749695, 0.3240908086299896, 0.31863218545913696, 0.3118654191493988, 0.30772995948791504, 0.3010671138763428, 0.3002168536186218, 0.29638469219207764, 0.29259151220321655, 0.2876359224319458, 0.2800261974334717, 0.2791321873664856, 0.27602043747901917, 0.27334681153297424, 0.2686302363872528, 0.2645881175994873, 0.2583020031452179, 0.2570708990097046, 0.25227129459381104, 0.2508959472179413, 0.2509709298610687, 0.25060969591140747, 0.24625302851200104, 0.24294696748256683, 0.23976953327655792, 0.23713691532611847, 0.23665118217468262, 0.23033878207206726, 0.23198850452899933], 'accuracy': [0.6101458072662354, 0.7977499961853027, 0.8297083377838135, 0.8442708253860474, 0.854729175567627, 0.8603333234786987, 0.8657500147819519, 0.8701666593551636, 0.8770833611488342, 0.8791458606719971, 0.882437527179718, 0.882520854473114, 0.8861250281333923, 0.8882708549499512, 0.8909375071525574, 0.8920208215713501, 0.8946666717529297, 0.8949999809265137, 0.8976041674613953, 0.8978333473205566, 0.8991875052452087, 0.9012291431427002, 0.9023749828338623, 0.9022708535194397, 0.9052291512489319, 0.9081041812896729, 0.9091249704360962, 0.9078333377838135, 0.909291684627533, 0.9101666808128357, 0.9123125076293945, 0.9139999747276306, 0.9152083396911621, 0.9165624976158142, 0.9171666502952576, 0.9182708263397217, 0.918874979019165, 0.9202499985694885, 0.9215208292007446, 0.9225000143051147, 0.9213958382606506, 0.9240416884422302, 0.9224374890327454, 0.9241666793823242, 0.9253541827201843, 0.926562488079071, 0.9271458387374878, 0.926729142665863, 0.9283750057220459, 0.9279166460037231], 'val_loss': [0.5533503293991089, 0.4204493463039398, 0.37385958433151245, 0.3524848222732544, 0.34036678075790405, 0.327838659286499, 0.3189082741737366, 0.31290480494499207, 0.30834880471229553, 0.3018493950366974, 0.2958584129810333, 0.2931899130344391, 0.2882561981678009, 0.28371307253837585, 0.27963465452194214, 0.27607277035713196, 0.2729584872722626, 0.26962488889694214, 0.26556873321533203, 0.26174336671829224, 0.25932571291923523, 0.2560928463935852, 0.25212663412094116, 0.25164708495140076, 0.24664926528930664, 0.2437966763973236, 0.2419719696044922, 0.23788462579250336, 0.2354343682527542, 0.233429953455925, 0.2304542511701584, 0.2277272790670395, 0.22559432685375214, 0.2234952598810196, 0.22079813480377197, 0.21803657710552216, 0.2164626121520996, 0.2138614058494568, 0.21249939501285553, 0.21042422950267792, 0.21038952469825745, 0.207946315407753, 0.20514807105064392, 0.20402611792087555, 0.20168161392211914, 0.20037105679512024, 0.19867655634880066, 0.1974637806415558, 0.19507792592048645, 0.19471167027950287], 'val_accuracy': [0.8546666502952576, 0.8771666884422302, 0.890666663646698, 0.8963333368301392, 0.8993333578109741, 0.9026666879653931, 0.905916690826416, 0.9066666960716248, 0.9076666831970215, 0.909416675567627, 0.9121666550636292, 0.9130833148956299, 0.9136666655540466, 0.9157500267028809, 0.9175833463668823, 0.9180833101272583, 0.918666660785675, 0.9205833077430725, 0.92166668176651, 0.9228333234786987, 0.9230833053588867, 0.9240000247955322, 0.9244999885559082, 0.9245833158493042, 0.9259999990463257, 0.9270833134651184, 0.9283333420753479, 0.9288333058357239, 0.9304166436195374, 0.9306666851043701, 0.9309999942779541, 0.9325833320617676, 0.9328333139419556, 0.9337499737739563, 0.9351666569709778, 0.9352499842643738, 0.9352499842643738, 0.9358333349227905, 0.9363333582878113, 0.937250018119812, 0.937166690826416, 0.9383333325386047, 0.9392499923706055, 0.9384166598320007, 0.9390833377838135, 0.9399999976158142, 0.940416693687439, 0.940833330154419, 0.9412500262260437, 0.9422500133514404]}\n",
      "{'loss': [1.014638066291809, 0.616888165473938, 0.5522247552871704, 0.5114588737487793, 0.483358234167099, 0.4713401794433594, 0.4551270604133606, 0.4413147270679474, 0.4295746684074402, 0.4190705120563507, 0.41392552852630615, 0.40328019857406616, 0.3941780924797058, 0.392560213804245, 0.38559773564338684, 0.38310644030570984, 0.37547680735588074, 0.3658694922924042, 0.3672720491886139, 0.36120203137397766, 0.3554028868675232, 0.35053136944770813, 0.34992143511772156, 0.34523335099220276, 0.34036973118782043, 0.3375038206577301, 0.3360871374607086, 0.3324262201786041, 0.3273203372955322, 0.324343740940094, 0.32113951444625854, 0.31702086329460144, 0.31371667981147766, 0.31334373354911804, 0.30887988209724426, 0.30613595247268677, 0.30446526408195496, 0.2990666627883911, 0.29811206459999084, 0.29518160223960876, 0.2957402765750885, 0.29057419300079346, 0.28554224967956543, 0.28488847613334656, 0.28280436992645264, 0.2789306342601776, 0.2785687744617462, 0.27418866753578186, 0.27348437905311584, 0.272161066532135], 'accuracy': [0.664354145526886, 0.8069166541099548, 0.8309999704360962, 0.8433958292007446, 0.8530208468437195, 0.8573333621025085, 0.8633541464805603, 0.867062509059906, 0.8690208196640015, 0.8739583492279053, 0.8754166960716248, 0.8784999847412109, 0.8810625076293945, 0.8819375038146973, 0.8833333253860474, 0.8847291469573975, 0.8853541612625122, 0.8897083401679993, 0.8892499804496765, 0.890500009059906, 0.8918750286102295, 0.8934791684150696, 0.8938958048820496, 0.8960833549499512, 0.8966458439826965, 0.8968541622161865, 0.898520827293396, 0.8992291688919067, 0.9010416865348816, 0.9018124938011169, 0.9015833139419556, 0.9047499895095825, 0.90645831823349, 0.9040625095367432, 0.9058958292007446, 0.9066458344459534, 0.9075624942779541, 0.9093541502952576, 0.909208357334137, 0.9103124737739563, 0.9089375138282776, 0.9105208516120911, 0.9122291803359985, 0.9130208492279053, 0.9131041765213013, 0.9135416746139526, 0.9147499799728394, 0.9165624976158142, 0.9160833358764648, 0.9158541560173035], 'val_loss': [0.4172881543636322, 0.3712646961212158, 0.35389193892478943, 0.3401530086994171, 0.3334606885910034, 0.32858970761299133, 0.3246251344680786, 0.31888821721076965, 0.3155019283294678, 0.31314486265182495, 0.30976128578186035, 0.30838701128959656, 0.3035755455493927, 0.3014335036277771, 0.30105194449424744, 0.29834428429603577, 0.2953255772590637, 0.2932182550430298, 0.29174694418907166, 0.2892041802406311, 0.289664626121521, 0.2860237956047058, 0.2821308374404907, 0.28308552503585815, 0.2808864414691925, 0.2785557210445404, 0.27544182538986206, 0.2736803889274597, 0.272466778755188, 0.27157050371170044, 0.271084725856781, 0.2673483192920685, 0.26517611742019653, 0.2629071772098541, 0.26184219121932983, 0.26041653752326965, 0.25789010524749756, 0.2575494647026062, 0.25406768918037415, 0.25161975622177124, 0.25026148557662964, 0.24696886539459229, 0.24764105677604675, 0.24486172199249268, 0.24293027818202972, 0.24328167736530304, 0.24152269959449768, 0.23806160688400269, 0.23840586841106415, 0.23526611924171448], 'val_accuracy': [0.8766666650772095, 0.8893333077430725, 0.8954166769981384, 0.9002500176429749, 0.9023333191871643, 0.9043333530426025, 0.9052500128746033, 0.9076666831970215, 0.9068333506584167, 0.9080833196640015, 0.9098333120346069, 0.909500002861023, 0.9115833044052124, 0.9122499823570251, 0.9130833148956299, 0.9129999876022339, 0.9144999980926514, 0.9139999747276306, 0.9154999852180481, 0.9164999723434448, 0.9160833358764648, 0.9175000190734863, 0.918583333492279, 0.9174166917800903, 0.918833315372467, 0.9183333516120911, 0.918833315372467, 0.9191666841506958, 0.9199166893959045, 0.9190833568572998, 0.918916642665863, 0.921999990940094, 0.921916663646698, 0.9225833415985107, 0.9225000143051147, 0.9224166870117188, 0.9244166612625122, 0.9239166378974915, 0.9254166483879089, 0.925166666507721, 0.9260833263397217, 0.9276666641235352, 0.9274166822433472, 0.9279999732971191, 0.9283333420753479, 0.9284166693687439, 0.9294999837875366, 0.9294166564941406, 0.9302499890327454, 0.9309999942779541]}\n",
      "{'loss': [2.1051645278930664, 1.2711293697357178, 0.8263124823570251, 0.678521454334259, 0.5988910794258118, 0.553821325302124, 0.5162405371665955, 0.48510921001434326, 0.46120744943618774, 0.4415653347969055, 0.4283285439014435, 0.41014018654823303, 0.39680802822113037, 0.38165536522865295, 0.369331419467926, 0.35877543687820435, 0.34698519110679626, 0.3367612659931183, 0.32607194781303406, 0.32023513317108154, 0.3091687858104706, 0.3050023913383484, 0.2949618995189667, 0.28723740577697754, 0.28231820464134216, 0.27795469760894775, 0.27049675583839417, 0.265338271856308, 0.25586023926734924, 0.25095608830451965, 0.24463830888271332, 0.24050278961658478, 0.234693244099617, 0.23482757806777954, 0.2269258350133896, 0.22176609933376312, 0.22063134610652924, 0.21693216264247894, 0.2094837874174118, 0.20831935107707977, 0.20267876982688904, 0.20046541094779968, 0.19746755063533783, 0.1918180286884308, 0.18913570046424866, 0.1889088749885559, 0.1824718564748764, 0.1801021546125412, 0.17887720465660095, 0.17461806535720825], 'accuracy': [0.3110833466053009, 0.6209791898727417, 0.7414374947547913, 0.7927083373069763, 0.817020833492279, 0.8323749899864197, 0.8453541398048401, 0.8567083477973938, 0.8616458177566528, 0.8694791793823242, 0.872041642665863, 0.8788333535194397, 0.8831250071525574, 0.8874375224113464, 0.8889166712760925, 0.8932291865348816, 0.8974166512489319, 0.8995208144187927, 0.9027708172798157, 0.9048125147819519, 0.9088541865348816, 0.909541666507721, 0.9113125205039978, 0.9136666655540466, 0.9152500033378601, 0.9166250228881836, 0.9194791913032532, 0.9207291603088379, 0.9237083196640015, 0.9255208373069763, 0.926729142665863, 0.9280624985694885, 0.929354190826416, 0.929770827293396, 0.9318125247955322, 0.9337083101272583, 0.9351249933242798, 0.9351875185966492, 0.9370208382606506, 0.9368333220481873, 0.9394166469573975, 0.9396250247955322, 0.9410416483879089, 0.9422500133514404, 0.9431250095367432, 0.9433333277702332, 0.9445624947547913, 0.9460833072662354, 0.9457083344459534, 0.9471458196640015], 'val_loss': [1.6706311702728271, 0.709101140499115, 0.5181486010551453, 0.447339802980423, 0.4041231572628021, 0.3751135766506195, 0.35405102372169495, 0.3373420238494873, 0.32434213161468506, 0.3116711974143982, 0.30044904351234436, 0.2913372814655304, 0.2818233370780945, 0.27482670545578003, 0.2662045359611511, 0.25904035568237305, 0.25243496894836426, 0.24661189317703247, 0.24031633138656616, 0.2354304939508438, 0.22993624210357666, 0.22584323585033417, 0.22057338058948517, 0.21612776815891266, 0.21172381937503815, 0.20815326273441315, 0.20378991961479187, 0.20112605392932892, 0.1977674812078476, 0.1933303028345108, 0.19056221842765808, 0.18754152953624725, 0.1856759488582611, 0.18322384357452393, 0.1800723820924759, 0.17669916152954102, 0.1744416058063507, 0.1718120127916336, 0.17052127420902252, 0.1682378202676773, 0.1663690209388733, 0.16500288248062134, 0.1623813509941101, 0.16111721098423004, 0.15958622097969055, 0.15812982618808746, 0.156212717294693, 0.15426264703273773, 0.15332534909248352, 0.15177373588085175], 'val_accuracy': [0.6711666584014893, 0.8321666717529297, 0.8629999756813049, 0.8784166574478149, 0.8866666555404663, 0.893750011920929, 0.8987500071525574, 0.9010000228881836, 0.9048333168029785, 0.9086666703224182, 0.9125833511352539, 0.9145833253860474, 0.9166666865348816, 0.9179999828338623, 0.9211666584014893, 0.9239166378974915, 0.9244999885559082, 0.9267500042915344, 0.9277499914169312, 0.9289166927337646, 0.9314166903495789, 0.9322500228881836, 0.9334166646003723, 0.9349166750907898, 0.9368333220481873, 0.9383333325386047, 0.9390000104904175, 0.940500020980835, 0.940583348274231, 0.9425833225250244, 0.9435833096504211, 0.9440000057220459, 0.9449166655540466, 0.9455833435058594, 0.9462500214576721, 0.9474999904632568, 0.9482499957084656, 0.9483333230018616, 0.9490000009536743, 0.9496666789054871, 0.950083315372467, 0.9504166841506958, 0.9516666531562805, 0.9514999985694885, 0.9520000219345093, 0.952750027179718, 0.9516666531562805, 0.9535833597183228, 0.953166663646698, 0.9537500143051147]}\n",
      "{'loss': [2.1592037677764893, 1.5559844970703125, 0.9782501459121704, 0.7754307985305786, 0.6706688404083252, 0.6046616435050964, 0.561752200126648, 0.5248557925224304, 0.5016897320747375, 0.4776211380958557, 0.463265597820282, 0.4419994354248047, 0.43283379077911377, 0.42117300629615784, 0.41079697012901306, 0.40012824535369873, 0.39099788665771484, 0.38127923011779785, 0.3749229609966278, 0.364042729139328, 0.3572842478752136, 0.35346436500549316, 0.34113359451293945, 0.33814162015914917, 0.33061811327934265, 0.3221142888069153, 0.31853070855140686, 0.3150692284107208, 0.3093712329864502, 0.3032977879047394, 0.2971060872077942, 0.29282307624816895, 0.2870970368385315, 0.28426188230514526, 0.2819879353046417, 0.27558207511901855, 0.27245840430259705, 0.2682981491088867, 0.26130571961402893, 0.2594068646430969, 0.2563721835613251, 0.25165611505508423, 0.24783320724964142, 0.2465946078300476, 0.24141119420528412, 0.2402554750442505, 0.23497861623764038, 0.23149676620960236, 0.22938932478427887, 0.22337886691093445], 'accuracy': [0.336124986410141, 0.5989791750907898, 0.6926041841506958, 0.7573958039283752, 0.7933750152587891, 0.8159166574478149, 0.8306875228881836, 0.8416666388511658, 0.8502291440963745, 0.8575208187103271, 0.8611458539962769, 0.8676249980926514, 0.8715208172798157, 0.8743333220481873, 0.8772708177566528, 0.882979154586792, 0.8831666707992554, 0.8856250047683716, 0.8869374990463257, 0.8920208215713501, 0.8928124904632568, 0.8932916522026062, 0.8964583277702332, 0.8982916474342346, 0.9000833630561829, 0.9028333425521851, 0.9039166569709778, 0.9068541526794434, 0.906208336353302, 0.9083333611488342, 0.9109166860580444, 0.9118541479110718, 0.9121249914169312, 0.9137916564941406, 0.9152291417121887, 0.9166874885559082, 0.9178333282470703, 0.9189791679382324, 0.9209166765213013, 0.9212499856948853, 0.9213749766349792, 0.9241250157356262, 0.9249374866485596, 0.9238333106040955, 0.9272500276565552, 0.9255416393280029, 0.9282708168029785, 0.9296875, 0.929395854473114, 0.9322708249092102], 'val_loss': [1.9371947050094604, 0.9911845922470093, 0.6492146253585815, 0.525467574596405, 0.4620479345321655, 0.4251426160335541, 0.39761027693748474, 0.37576815485954285, 0.3593081831932068, 0.34647953510284424, 0.3359447717666626, 0.3264535069465637, 0.31694331765174866, 0.30953821539878845, 0.30276069045066833, 0.29580390453338623, 0.2904370129108429, 0.2854209244251251, 0.2797398567199707, 0.2746313810348511, 0.2690589427947998, 0.2642839550971985, 0.26040786504745483, 0.25537168979644775, 0.25192105770111084, 0.24842309951782227, 0.2438947558403015, 0.2409328669309616, 0.23716485500335693, 0.23371034860610962, 0.23067545890808105, 0.22724489867687225, 0.22366735339164734, 0.22140629589557648, 0.21825821697711945, 0.21540769934654236, 0.2123584747314453, 0.21019431948661804, 0.2070169895887375, 0.2048858255147934, 0.20260335505008698, 0.20060458779335022, 0.19790047407150269, 0.19620420038700104, 0.19417670369148254, 0.19236589968204498, 0.1901724487543106, 0.1885548233985901, 0.18654850125312805, 0.18454518914222717], 'val_accuracy': [0.671999990940094, 0.7787500023841858, 0.8345833420753479, 0.8615000247955322, 0.8731666803359985, 0.8824166655540466, 0.8882499933242798, 0.8913333415985107, 0.8962500095367432, 0.8997499942779541, 0.9034166932106018, 0.9042500257492065, 0.9083333611488342, 0.9097499847412109, 0.9117500185966492, 0.9129999876022339, 0.9146666526794434, 0.9146666526794434, 0.9167500138282776, 0.9179999828338623, 0.9196666479110718, 0.9210833311080933, 0.9225000143051147, 0.9235833287239075, 0.9240833520889282, 0.9252499938011169, 0.9262499809265137, 0.9266666769981384, 0.9283333420753479, 0.9294999837875366, 0.9300000071525574, 0.9309166669845581, 0.9320833086967468, 0.9332500100135803, 0.9340833425521851, 0.9350000023841858, 0.9351666569709778, 0.9365000128746033, 0.9368333220481873, 0.937666654586792, 0.9381666779518127, 0.9386666417121887, 0.9394166469573975, 0.940500020980835, 0.9414166808128357, 0.9417499899864197, 0.9426666498184204, 0.9432500004768372, 0.9442499876022339, 0.9441666603088379]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "noise_3depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
