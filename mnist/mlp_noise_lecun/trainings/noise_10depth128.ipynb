{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noise_10depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "6fd67651-c5f4-4e7f-d547-dff2059dd304"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 17s 7ms/step - loss: 2.2306 - accuracy: 0.1763 - val_loss: 1.4685 - val_accuracy: 0.5428\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7522 - accuracy: 0.3649 - val_loss: 1.1029 - val_accuracy: 0.7410\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4867 - accuracy: 0.4861 - val_loss: 0.9130 - val_accuracy: 0.7747\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3268 - accuracy: 0.5490 - val_loss: 0.7923 - val_accuracy: 0.7918\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2190 - accuracy: 0.5880 - val_loss: 0.7208 - val_accuracy: 0.7999\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1437 - accuracy: 0.6227 - val_loss: 0.6714 - val_accuracy: 0.8123\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0844 - accuracy: 0.6412 - val_loss: 0.6381 - val_accuracy: 0.8197\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0189 - accuracy: 0.6699 - val_loss: 0.6147 - val_accuracy: 0.8241\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9944 - accuracy: 0.6797 - val_loss: 0.5952 - val_accuracy: 0.8306\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9503 - accuracy: 0.6963 - val_loss: 0.5767 - val_accuracy: 0.8361\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9239 - accuracy: 0.7122 - val_loss: 0.5606 - val_accuracy: 0.8414\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9080 - accuracy: 0.7210 - val_loss: 0.5479 - val_accuracy: 0.8472\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8721 - accuracy: 0.7319 - val_loss: 0.5388 - val_accuracy: 0.8527\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8459 - accuracy: 0.7441 - val_loss: 0.5207 - val_accuracy: 0.8573\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8271 - accuracy: 0.7560 - val_loss: 0.5100 - val_accuracy: 0.8621\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8107 - accuracy: 0.7652 - val_loss: 0.4989 - val_accuracy: 0.8675\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7829 - accuracy: 0.7776 - val_loss: 0.4829 - val_accuracy: 0.8725\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7722 - accuracy: 0.7800 - val_loss: 0.4690 - val_accuracy: 0.8767\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7603 - accuracy: 0.7884 - val_loss: 0.4620 - val_accuracy: 0.8816\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7467 - accuracy: 0.7955 - val_loss: 0.4516 - val_accuracy: 0.8830\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7381 - accuracy: 0.7991 - val_loss: 0.4351 - val_accuracy: 0.8882\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7155 - accuracy: 0.8105 - val_loss: 0.4295 - val_accuracy: 0.8913\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6961 - accuracy: 0.8182 - val_loss: 0.4290 - val_accuracy: 0.8917\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6825 - accuracy: 0.8202 - val_loss: 0.4169 - val_accuracy: 0.8978\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6729 - accuracy: 0.8231 - val_loss: 0.4115 - val_accuracy: 0.9006\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6556 - accuracy: 0.8320 - val_loss: 0.4033 - val_accuracy: 0.9022\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6468 - accuracy: 0.8332 - val_loss: 0.4032 - val_accuracy: 0.9023\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6369 - accuracy: 0.8392 - val_loss: 0.3978 - val_accuracy: 0.9059\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6375 - accuracy: 0.8374 - val_loss: 0.3960 - val_accuracy: 0.9065\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6315 - accuracy: 0.8429 - val_loss: 0.3885 - val_accuracy: 0.9087\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6167 - accuracy: 0.8418 - val_loss: 0.3833 - val_accuracy: 0.9107\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6098 - accuracy: 0.8460 - val_loss: 0.3815 - val_accuracy: 0.9129\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6008 - accuracy: 0.8520 - val_loss: 0.3756 - val_accuracy: 0.9151\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5925 - accuracy: 0.8571 - val_loss: 0.3723 - val_accuracy: 0.9154\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5771 - accuracy: 0.8579 - val_loss: 0.3781 - val_accuracy: 0.9153\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5629 - accuracy: 0.8653 - val_loss: 0.3682 - val_accuracy: 0.9183\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5679 - accuracy: 0.8615 - val_loss: 0.3680 - val_accuracy: 0.9180\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.8626 - val_loss: 0.3614 - val_accuracy: 0.9186\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5588 - accuracy: 0.8648 - val_loss: 0.3638 - val_accuracy: 0.9181\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5492 - accuracy: 0.8678 - val_loss: 0.3586 - val_accuracy: 0.9212\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5534 - accuracy: 0.8673 - val_loss: 0.3544 - val_accuracy: 0.9233\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5451 - accuracy: 0.8702 - val_loss: 0.3543 - val_accuracy: 0.9222\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5310 - accuracy: 0.8720 - val_loss: 0.3509 - val_accuracy: 0.9239\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5235 - accuracy: 0.8757 - val_loss: 0.3532 - val_accuracy: 0.9250\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5221 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.9235\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5163 - accuracy: 0.8758 - val_loss: 0.3395 - val_accuracy: 0.9271\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5130 - accuracy: 0.8794 - val_loss: 0.3396 - val_accuracy: 0.9272\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5043 - accuracy: 0.8802 - val_loss: 0.3406 - val_accuracy: 0.9269\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5001 - accuracy: 0.8834 - val_loss: 0.3340 - val_accuracy: 0.9287\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5015 - accuracy: 0.8811 - val_loss: 0.3360 - val_accuracy: 0.9286\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3048 - accuracy: 0.1014 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1212 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3005 - accuracy: 0.1203 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2996 - accuracy: 0.1192 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2965 - accuracy: 0.1212 - val_loss: 2.2945 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2902 - accuracy: 0.1313 - val_loss: 2.2659 - val_accuracy: 0.1263\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2616 - accuracy: 0.1448 - val_loss: 2.1773 - val_accuracy: 0.1953\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1993 - accuracy: 0.1669 - val_loss: 2.0847 - val_accuracy: 0.2128\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1427 - accuracy: 0.1935 - val_loss: 2.0219 - val_accuracy: 0.2317\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0826 - accuracy: 0.2201 - val_loss: 1.9596 - val_accuracy: 0.2578\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0315 - accuracy: 0.2388 - val_loss: 1.9026 - val_accuracy: 0.2640\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9710 - accuracy: 0.2364 - val_loss: 1.8652 - val_accuracy: 0.2921\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9276 - accuracy: 0.2517 - val_loss: 1.8151 - val_accuracy: 0.3074\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8797 - accuracy: 0.2634 - val_loss: 1.7783 - val_accuracy: 0.3147\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8504 - accuracy: 0.2734 - val_loss: 1.7525 - val_accuracy: 0.3331\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8170 - accuracy: 0.2802 - val_loss: 1.7204 - val_accuracy: 0.3419\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7939 - accuracy: 0.2865 - val_loss: 1.6909 - val_accuracy: 0.3409\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7621 - accuracy: 0.2899 - val_loss: 1.6780 - val_accuracy: 0.3579\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7433 - accuracy: 0.2986 - val_loss: 1.6369 - val_accuracy: 0.3668\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7181 - accuracy: 0.3048 - val_loss: 1.6467 - val_accuracy: 0.3645\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6997 - accuracy: 0.3073 - val_loss: 1.6203 - val_accuracy: 0.3734\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6799 - accuracy: 0.3085 - val_loss: 1.6051 - val_accuracy: 0.3612\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6532 - accuracy: 0.3190 - val_loss: 1.5536 - val_accuracy: 0.3786\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6414 - accuracy: 0.3177 - val_loss: 1.5996 - val_accuracy: 0.3078\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6153 - accuracy: 0.3294 - val_loss: 1.5230 - val_accuracy: 0.3852\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6204 - accuracy: 0.3236 - val_loss: 1.5274 - val_accuracy: 0.3739\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5986 - accuracy: 0.3326 - val_loss: 1.5570 - val_accuracy: 0.3147\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5796 - accuracy: 0.3381 - val_loss: 1.4862 - val_accuracy: 0.3913\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5701 - accuracy: 0.3406 - val_loss: 1.4734 - val_accuracy: 0.3964\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5602 - accuracy: 0.3448 - val_loss: 1.4640 - val_accuracy: 0.3972\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5566 - accuracy: 0.3453 - val_loss: 1.4729 - val_accuracy: 0.3921\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5552 - accuracy: 0.3456 - val_loss: 1.4566 - val_accuracy: 0.4074\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5409 - accuracy: 0.3523 - val_loss: 1.4507 - val_accuracy: 0.3932\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5170 - accuracy: 0.3610 - val_loss: 1.4506 - val_accuracy: 0.4057\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5183 - accuracy: 0.3600 - val_loss: 1.4235 - val_accuracy: 0.4017\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5156 - accuracy: 0.3573 - val_loss: 1.4238 - val_accuracy: 0.3991\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4936 - accuracy: 0.3677 - val_loss: 1.4318 - val_accuracy: 0.4062\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5102 - accuracy: 0.3638 - val_loss: 1.4155 - val_accuracy: 0.4176\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4684 - accuracy: 0.3764 - val_loss: 1.4232 - val_accuracy: 0.4203\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4795 - accuracy: 0.3769 - val_loss: 1.4163 - val_accuracy: 0.4157\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4496 - accuracy: 0.3848 - val_loss: 1.4025 - val_accuracy: 0.4182\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4574 - accuracy: 0.3821 - val_loss: 1.4127 - val_accuracy: 0.4110\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4453 - accuracy: 0.3810 - val_loss: 1.4056 - val_accuracy: 0.4073\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4570 - accuracy: 0.3839 - val_loss: 1.4113 - val_accuracy: 0.4159\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4176 - accuracy: 0.4004 - val_loss: 1.3759 - val_accuracy: 0.4272\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4199 - accuracy: 0.3955 - val_loss: 1.4090 - val_accuracy: 0.4323\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4111 - accuracy: 0.3959 - val_loss: 1.3814 - val_accuracy: 0.4272\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3977 - accuracy: 0.3983 - val_loss: 1.4365 - val_accuracy: 0.3427\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3947 - accuracy: 0.3956 - val_loss: 1.3903 - val_accuracy: 0.4206\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3838 - accuracy: 0.4062 - val_loss: 1.3518 - val_accuracy: 0.4295\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 7ms/step - loss: 2.3022 - accuracy: 0.1094 - val_loss: 2.2996 - val_accuracy: 0.1061\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2974 - accuracy: 0.1358 - val_loss: 2.2914 - val_accuracy: 0.1494\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2865 - accuracy: 0.1594 - val_loss: 2.2426 - val_accuracy: 0.2007\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2424 - accuracy: 0.1934 - val_loss: 2.1379 - val_accuracy: 0.2107\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1809 - accuracy: 0.2003 - val_loss: 2.0743 - val_accuracy: 0.2193\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1260 - accuracy: 0.2091 - val_loss: 2.0323 - val_accuracy: 0.2274\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0776 - accuracy: 0.2234 - val_loss: 1.9645 - val_accuracy: 0.2668\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0084 - accuracy: 0.2491 - val_loss: 1.8631 - val_accuracy: 0.3079\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.9376 - accuracy: 0.2643 - val_loss: 1.7732 - val_accuracy: 0.3448\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.8657 - accuracy: 0.2863 - val_loss: 1.6717 - val_accuracy: 0.3828\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7752 - accuracy: 0.3059 - val_loss: 1.5770 - val_accuracy: 0.3974\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7011 - accuracy: 0.3329 - val_loss: 1.4789 - val_accuracy: 0.4430\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6181 - accuracy: 0.3709 - val_loss: 1.3592 - val_accuracy: 0.4941\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5384 - accuracy: 0.4048 - val_loss: 1.2536 - val_accuracy: 0.5497\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4572 - accuracy: 0.4372 - val_loss: 1.1787 - val_accuracy: 0.5969\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3873 - accuracy: 0.4713 - val_loss: 1.1129 - val_accuracy: 0.6528\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3334 - accuracy: 0.4940 - val_loss: 1.0657 - val_accuracy: 0.6851\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2710 - accuracy: 0.5242 - val_loss: 1.0232 - val_accuracy: 0.7028\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2324 - accuracy: 0.5500 - val_loss: 0.9664 - val_accuracy: 0.7283\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1992 - accuracy: 0.5591 - val_loss: 0.9172 - val_accuracy: 0.7424\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1533 - accuracy: 0.5834 - val_loss: 0.8820 - val_accuracy: 0.7651\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0966 - accuracy: 0.5992 - val_loss: 0.8478 - val_accuracy: 0.7786\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0562 - accuracy: 0.6183 - val_loss: 0.8137 - val_accuracy: 0.7886\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0322 - accuracy: 0.6314 - val_loss: 0.7884 - val_accuracy: 0.7923\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9897 - accuracy: 0.6475 - val_loss: 0.7628 - val_accuracy: 0.8147\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9546 - accuracy: 0.6649 - val_loss: 0.7331 - val_accuracy: 0.8242\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9249 - accuracy: 0.6738 - val_loss: 0.6979 - val_accuracy: 0.8186\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8976 - accuracy: 0.6850 - val_loss: 0.6741 - val_accuracy: 0.8357\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8738 - accuracy: 0.6943 - val_loss: 0.6554 - val_accuracy: 0.8367\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8335 - accuracy: 0.7115 - val_loss: 0.6168 - val_accuracy: 0.8502\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8148 - accuracy: 0.7224 - val_loss: 0.5990 - val_accuracy: 0.8590\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7721 - accuracy: 0.7305 - val_loss: 0.5797 - val_accuracy: 0.8470\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7380 - accuracy: 0.7416 - val_loss: 0.5605 - val_accuracy: 0.8639\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7282 - accuracy: 0.7486 - val_loss: 0.5321 - val_accuracy: 0.8692\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6940 - accuracy: 0.7632 - val_loss: 0.5224 - val_accuracy: 0.8623\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6875 - accuracy: 0.7684 - val_loss: 0.5063 - val_accuracy: 0.8786\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6610 - accuracy: 0.7792 - val_loss: 0.4902 - val_accuracy: 0.8830\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6296 - accuracy: 0.7894 - val_loss: 0.4847 - val_accuracy: 0.8842\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6259 - accuracy: 0.7925 - val_loss: 0.4799 - val_accuracy: 0.8996\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6117 - accuracy: 0.8011 - val_loss: 0.4581 - val_accuracy: 0.9020\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5928 - accuracy: 0.8109 - val_loss: 0.4366 - val_accuracy: 0.9130\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5596 - accuracy: 0.8275 - val_loss: 0.4341 - val_accuracy: 0.9143\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5603 - accuracy: 0.8285 - val_loss: 0.4175 - val_accuracy: 0.9193\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5475 - accuracy: 0.8354 - val_loss: 0.4118 - val_accuracy: 0.9216\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5302 - accuracy: 0.8438 - val_loss: 0.4042 - val_accuracy: 0.9212\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5124 - accuracy: 0.8494 - val_loss: 0.3947 - val_accuracy: 0.9271\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5037 - accuracy: 0.8586 - val_loss: 0.3992 - val_accuracy: 0.9282\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4734 - accuracy: 0.8632 - val_loss: 0.3874 - val_accuracy: 0.9282\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4543 - accuracy: 0.8725 - val_loss: 0.3789 - val_accuracy: 0.9293\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4547 - accuracy: 0.8700 - val_loss: 0.3786 - val_accuracy: 0.9308\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.2683 - accuracy: 0.1649 - val_loss: 1.3556 - val_accuracy: 0.6908\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7157 - accuracy: 0.3841 - val_loss: 0.8710 - val_accuracy: 0.7770\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3836 - accuracy: 0.5151 - val_loss: 0.6696 - val_accuracy: 0.8242\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2110 - accuracy: 0.5838 - val_loss: 0.5726 - val_accuracy: 0.8420\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0892 - accuracy: 0.6307 - val_loss: 0.5207 - val_accuracy: 0.8529\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0065 - accuracy: 0.6687 - val_loss: 0.4871 - val_accuracy: 0.8618\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9379 - accuracy: 0.6991 - val_loss: 0.4608 - val_accuracy: 0.8683\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8950 - accuracy: 0.7174 - val_loss: 0.4422 - val_accuracy: 0.8760\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8607 - accuracy: 0.7311 - val_loss: 0.4311 - val_accuracy: 0.8749\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8321 - accuracy: 0.7435 - val_loss: 0.4138 - val_accuracy: 0.8855\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8121 - accuracy: 0.7554 - val_loss: 0.4015 - val_accuracy: 0.8917\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7829 - accuracy: 0.7654 - val_loss: 0.3914 - val_accuracy: 0.8918\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7560 - accuracy: 0.7756 - val_loss: 0.3822 - val_accuracy: 0.8959\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7238 - accuracy: 0.7857 - val_loss: 0.3769 - val_accuracy: 0.8953\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7251 - accuracy: 0.7926 - val_loss: 0.3687 - val_accuracy: 0.9010\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6883 - accuracy: 0.8036 - val_loss: 0.3669 - val_accuracy: 0.8973\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6801 - accuracy: 0.8078 - val_loss: 0.3564 - val_accuracy: 0.9032\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6758 - accuracy: 0.8120 - val_loss: 0.3550 - val_accuracy: 0.9019\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6669 - accuracy: 0.8126 - val_loss: 0.3463 - val_accuracy: 0.9053\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6347 - accuracy: 0.8249 - val_loss: 0.3428 - val_accuracy: 0.9062\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6519 - accuracy: 0.8212 - val_loss: 0.3393 - val_accuracy: 0.9096\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6137 - accuracy: 0.8282 - val_loss: 0.3324 - val_accuracy: 0.9126\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6099 - accuracy: 0.8334 - val_loss: 0.3254 - val_accuracy: 0.9136\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6074 - accuracy: 0.8336 - val_loss: 0.3217 - val_accuracy: 0.9154\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5956 - accuracy: 0.8395 - val_loss: 0.3170 - val_accuracy: 0.9162\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5731 - accuracy: 0.8456 - val_loss: 0.3157 - val_accuracy: 0.9173\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5621 - accuracy: 0.8494 - val_loss: 0.3162 - val_accuracy: 0.9181\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5625 - accuracy: 0.8510 - val_loss: 0.3107 - val_accuracy: 0.9202\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5472 - accuracy: 0.8577 - val_loss: 0.3032 - val_accuracy: 0.9222\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5389 - accuracy: 0.8577 - val_loss: 0.3048 - val_accuracy: 0.9214\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5306 - accuracy: 0.8624 - val_loss: 0.2951 - val_accuracy: 0.9229\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5270 - accuracy: 0.8645 - val_loss: 0.2968 - val_accuracy: 0.9245\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5095 - accuracy: 0.8680 - val_loss: 0.2897 - val_accuracy: 0.9262\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5184 - accuracy: 0.8668 - val_loss: 0.2888 - val_accuracy: 0.9264\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4945 - accuracy: 0.8706 - val_loss: 0.2861 - val_accuracy: 0.9269\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5002 - accuracy: 0.8715 - val_loss: 0.2801 - val_accuracy: 0.9277\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5103 - accuracy: 0.8705 - val_loss: 0.2791 - val_accuracy: 0.9309\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4758 - accuracy: 0.8759 - val_loss: 0.2714 - val_accuracy: 0.9307\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4736 - accuracy: 0.8796 - val_loss: 0.2736 - val_accuracy: 0.9311\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4679 - accuracy: 0.8817 - val_loss: 0.2673 - val_accuracy: 0.9311\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4716 - accuracy: 0.8819 - val_loss: 0.2690 - val_accuracy: 0.9322\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4624 - accuracy: 0.8813 - val_loss: 0.2669 - val_accuracy: 0.9327\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4485 - accuracy: 0.8868 - val_loss: 0.2609 - val_accuracy: 0.9345\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4542 - accuracy: 0.8863 - val_loss: 0.2651 - val_accuracy: 0.9353\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4396 - accuracy: 0.8900 - val_loss: 0.2602 - val_accuracy: 0.9355\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4396 - accuracy: 0.8898 - val_loss: 0.2554 - val_accuracy: 0.9367\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4342 - accuracy: 0.8917 - val_loss: 0.2515 - val_accuracy: 0.9373\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4228 - accuracy: 0.8935 - val_loss: 0.2528 - val_accuracy: 0.9384\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4152 - accuracy: 0.8964 - val_loss: 0.2529 - val_accuracy: 0.9383\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4113 - accuracy: 0.8976 - val_loss: 0.2487 - val_accuracy: 0.9398\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.6663 - accuracy: 0.2197 - val_loss: 0.8543 - val_accuracy: 0.7179\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4913 - accuracy: 0.4688 - val_loss: 0.6639 - val_accuracy: 0.7976\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2054 - accuracy: 0.5780 - val_loss: 0.6040 - val_accuracy: 0.8183\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0892 - accuracy: 0.6277 - val_loss: 0.5687 - val_accuracy: 0.8246\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0173 - accuracy: 0.6636 - val_loss: 0.5299 - val_accuracy: 0.8478\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9384 - accuracy: 0.6926 - val_loss: 0.4924 - val_accuracy: 0.8576\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8947 - accuracy: 0.7172 - val_loss: 0.4618 - val_accuracy: 0.8689\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8490 - accuracy: 0.7425 - val_loss: 0.4513 - val_accuracy: 0.8771\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8209 - accuracy: 0.7542 - val_loss: 0.4367 - val_accuracy: 0.8769\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7866 - accuracy: 0.7668 - val_loss: 0.4202 - val_accuracy: 0.8852\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7569 - accuracy: 0.7795 - val_loss: 0.4067 - val_accuracy: 0.8914\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7405 - accuracy: 0.7888 - val_loss: 0.3948 - val_accuracy: 0.8950\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7107 - accuracy: 0.7997 - val_loss: 0.3885 - val_accuracy: 0.8984\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6975 - accuracy: 0.8039 - val_loss: 0.3817 - val_accuracy: 0.9002\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6878 - accuracy: 0.8119 - val_loss: 0.3727 - val_accuracy: 0.9049\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6551 - accuracy: 0.8192 - val_loss: 0.3720 - val_accuracy: 0.9024\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6437 - accuracy: 0.8252 - val_loss: 0.3585 - val_accuracy: 0.9069\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6299 - accuracy: 0.8347 - val_loss: 0.3573 - val_accuracy: 0.9063\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6220 - accuracy: 0.8362 - val_loss: 0.3518 - val_accuracy: 0.9108\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6014 - accuracy: 0.8411 - val_loss: 0.3420 - val_accuracy: 0.9133\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5924 - accuracy: 0.8445 - val_loss: 0.3378 - val_accuracy: 0.9148\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5784 - accuracy: 0.8472 - val_loss: 0.3274 - val_accuracy: 0.9162\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5766 - accuracy: 0.8486 - val_loss: 0.3288 - val_accuracy: 0.9169\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5619 - accuracy: 0.8504 - val_loss: 0.3203 - val_accuracy: 0.9193\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5422 - accuracy: 0.8592 - val_loss: 0.3158 - val_accuracy: 0.9193\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5466 - accuracy: 0.8596 - val_loss: 0.3086 - val_accuracy: 0.9216\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5371 - accuracy: 0.8600 - val_loss: 0.3077 - val_accuracy: 0.9243\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5239 - accuracy: 0.8650 - val_loss: 0.3032 - val_accuracy: 0.9248\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5031 - accuracy: 0.8723 - val_loss: 0.2996 - val_accuracy: 0.9267\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5080 - accuracy: 0.8688 - val_loss: 0.2943 - val_accuracy: 0.9270\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4799 - accuracy: 0.8780 - val_loss: 0.2954 - val_accuracy: 0.9282\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4804 - accuracy: 0.8793 - val_loss: 0.2941 - val_accuracy: 0.9286\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4910 - accuracy: 0.8783 - val_loss: 0.2903 - val_accuracy: 0.9306\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4762 - accuracy: 0.8810 - val_loss: 0.2845 - val_accuracy: 0.9308\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4832 - accuracy: 0.8815 - val_loss: 0.2866 - val_accuracy: 0.9317\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4692 - accuracy: 0.8840 - val_loss: 0.2838 - val_accuracy: 0.9328\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4643 - accuracy: 0.8829 - val_loss: 0.2819 - val_accuracy: 0.9324\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4641 - accuracy: 0.8845 - val_loss: 0.2799 - val_accuracy: 0.9330\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4511 - accuracy: 0.8901 - val_loss: 0.2765 - val_accuracy: 0.9354\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4499 - accuracy: 0.8867 - val_loss: 0.2714 - val_accuracy: 0.9363\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4488 - accuracy: 0.8879 - val_loss: 0.2719 - val_accuracy: 0.9350\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4369 - accuracy: 0.8912 - val_loss: 0.2775 - val_accuracy: 0.9352\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4374 - accuracy: 0.8951 - val_loss: 0.2702 - val_accuracy: 0.9367\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4183 - accuracy: 0.8978 - val_loss: 0.2740 - val_accuracy: 0.9356\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4163 - accuracy: 0.8952 - val_loss: 0.2711 - val_accuracy: 0.9381\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4116 - accuracy: 0.8991 - val_loss: 0.2673 - val_accuracy: 0.9373\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4171 - accuracy: 0.8973 - val_loss: 0.2640 - val_accuracy: 0.9383\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4025 - accuracy: 0.8999 - val_loss: 0.2610 - val_accuracy: 0.9398\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4023 - accuracy: 0.8998 - val_loss: 0.2626 - val_accuracy: 0.9391\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4022 - accuracy: 0.9037 - val_loss: 0.2621 - val_accuracy: 0.9403\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 7ms/step - loss: 2.3022 - accuracy: 0.1182 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3014 - accuracy: 0.1145 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1146 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1130 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1145 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1115 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1145 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1130 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1138 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1135 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1111 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1146 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1135 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1142 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1151 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1135 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1128 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1140 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1163 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1152 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1123 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1148 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1145 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1126 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1123 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1151 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1147 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3002 - accuracy: 0.1160 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1129 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1133 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1131 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3002 - accuracy: 0.1136 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1131 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2998 - accuracy: 0.1160 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2999 - accuracy: 0.1142 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2999 - accuracy: 0.1144 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1124 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2998 - accuracy: 0.1133 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2991 - accuracy: 0.1176 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2998 - accuracy: 0.1136 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1089 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2994 - accuracy: 0.1131 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2996 - accuracy: 0.1136 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2993 - accuracy: 0.1129 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2991 - accuracy: 0.1145 - val_loss: 2.3002 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2987 - accuracy: 0.1157 - val_loss: 2.3000 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2989 - accuracy: 0.1130 - val_loss: 2.2998 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2984 - accuracy: 0.1149 - val_loss: 2.2995 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2988 - accuracy: 0.1115 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.3023 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1137 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1122 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1133 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1129 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1121 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1167 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1142 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1140 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1142 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1135 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1123 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1141 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1127 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1138 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1151 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1129 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1129 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1148 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1127 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1161 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1134 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1138 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1133 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1126 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3003 - accuracy: 0.1118 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.2996 - accuracy: 0.1154 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1113 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2994 - accuracy: 0.1144 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2996 - accuracy: 0.1134 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1116 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2986 - accuracy: 0.1152 - val_loss: 2.3002 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2993 - accuracy: 0.1133 - val_loss: 2.3000 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2988 - accuracy: 0.1141 - val_loss: 2.2997 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2984 - accuracy: 0.1146 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2977 - accuracy: 0.1161 - val_loss: 2.2989 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2972 - accuracy: 0.1154 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2964 - accuracy: 0.1181 - val_loss: 2.2973 - val_accuracy: 0.1061\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2962 - accuracy: 0.1191 - val_loss: 2.2956 - val_accuracy: 0.1098\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2934 - accuracy: 0.1327 - val_loss: 2.2918 - val_accuracy: 0.1399\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2878 - accuracy: 0.1535 - val_loss: 2.2743 - val_accuracy: 0.1937\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2518 - accuracy: 0.1948 - val_loss: 2.1546 - val_accuracy: 0.2005\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1698 - accuracy: 0.2029 - val_loss: 2.0790 - val_accuracy: 0.2023\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1244 - accuracy: 0.2001 - val_loss: 2.0481 - val_accuracy: 0.2058\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0772 - accuracy: 0.2113 - val_loss: 2.0211 - val_accuracy: 0.2184\n",
            "{'loss': [2.0774409770965576, 1.6716196537017822, 1.4454412460327148, 1.2948263883590698, 1.1925491094589233, 1.12443208694458, 1.0612963438034058, 1.0121946334838867, 0.9802438020706177, 0.9445838332176208, 0.921635091304779, 0.8963719010353088, 0.8685013055801392, 0.8490579724311829, 0.8237104415893555, 0.8100231289863586, 0.7902319431304932, 0.7725024223327637, 0.7546407580375671, 0.7463986873626709, 0.7311394810676575, 0.7118848562240601, 0.6989293098449707, 0.6849974989891052, 0.6701565384864807, 0.6587979197502136, 0.6502708792686462, 0.6368367671966553, 0.6376591920852661, 0.6252301335334778, 0.6173474788665771, 0.6016885638237, 0.6001455187797546, 0.5843166708946228, 0.5825455188751221, 0.5736088156700134, 0.5675862431526184, 0.5716966390609741, 0.5558925867080688, 0.5531454086303711, 0.5422494411468506, 0.5321204662322998, 0.5306797027587891, 0.5221431255340576, 0.5233064889907837, 0.5119746923446655, 0.5172644257545471, 0.507649838924408, 0.4986836612224579, 0.5005391240119934], 'accuracy': [0.23464582860469818, 0.40279167890548706, 0.5020624995231628, 0.5629374980926514, 0.598312497138977, 0.6302916407585144, 0.6508541703224182, 0.6732083559036255, 0.6834166646003723, 0.6992708444595337, 0.7144166827201843, 0.7249166369438171, 0.734375, 0.7455000281333923, 0.757562518119812, 0.7654791474342346, 0.7746875286102295, 0.781374990940094, 0.7897083163261414, 0.7946249842643738, 0.8033750057220459, 0.8098958134651184, 0.8168749809265137, 0.8228124976158142, 0.8258541822433472, 0.8311874866485596, 0.8327083587646484, 0.8382708430290222, 0.8379999995231628, 0.8427291512489319, 0.8442708253860474, 0.8496458530426025, 0.8520833253860474, 0.8586875200271606, 0.8574583530426025, 0.8617083430290222, 0.8614374995231628, 0.8617500066757202, 0.8661875128746033, 0.8656874895095825, 0.870312511920929, 0.8725625276565552, 0.8725833296775818, 0.8761666417121887, 0.8763958215713501, 0.8771041631698608, 0.8777291774749756, 0.8797500133514404, 0.882895827293396, 0.8814791440963745], 'val_loss': [1.468475580215454, 1.1028666496276855, 0.9129818677902222, 0.7922561168670654, 0.720797061920166, 0.671395480632782, 0.6381190419197083, 0.6147191524505615, 0.5951820611953735, 0.5767207145690918, 0.5606238842010498, 0.5479448437690735, 0.5387594103813171, 0.5207071304321289, 0.5100045800209045, 0.49886345863342285, 0.48288634419441223, 0.46902787685394287, 0.46197864413261414, 0.45164522528648376, 0.43511852622032166, 0.4295182228088379, 0.4289865791797638, 0.41691333055496216, 0.41149523854255676, 0.4033070504665375, 0.4032346308231354, 0.3978213667869568, 0.396040678024292, 0.38851913809776306, 0.38325971364974976, 0.38151785731315613, 0.3755902051925659, 0.3722774386405945, 0.37813955545425415, 0.3682403862476349, 0.36802008748054504, 0.36141178011894226, 0.3637867569923401, 0.358600378036499, 0.35440516471862793, 0.3542969524860382, 0.3509432375431061, 0.35322245955467224, 0.35181164741516113, 0.33947861194610596, 0.3396000564098358, 0.3405747413635254, 0.33400601148605347, 0.335988312959671], 'val_accuracy': [0.5428333282470703, 0.7409999966621399, 0.7747499942779541, 0.7918333411216736, 0.799916684627533, 0.812250018119812, 0.8196666836738586, 0.8240833282470703, 0.8305833339691162, 0.8360833525657654, 0.8414166569709778, 0.8471666574478149, 0.8526666760444641, 0.8573333621025085, 0.8620833158493042, 0.8675000071525574, 0.8725000023841858, 0.8766666650772095, 0.8815833330154419, 0.8830000162124634, 0.8881666660308838, 0.8913333415985107, 0.8916666507720947, 0.8977500200271606, 0.9005833268165588, 0.9022499918937683, 0.9023333191871643, 0.905916690826416, 0.906499981880188, 0.9086666703224182, 0.9107499718666077, 0.9129166603088379, 0.9150833487510681, 0.9154166579246521, 0.9153333306312561, 0.9182500243186951, 0.9179999828338623, 0.918583333492279, 0.9180833101272583, 0.9211666584014893, 0.9232500195503235, 0.922249972820282, 0.9239166378974915, 0.925000011920929, 0.9235000014305115, 0.9270833134651184, 0.9271666407585144, 0.9269166588783264, 0.9287499785423279, 0.9285833239555359]}\n",
            "{'loss': [2.3033876419067383, 2.3010094165802, 2.300133228302002, 2.298891067504883, 2.2956032752990723, 2.285551071166992, 2.2479681968688965, 2.183345079421997, 2.1255064010620117, 2.068753957748413, 2.01285719871521, 1.960435390472412, 1.9142522811889648, 1.8789883852005005, 1.841576337814331, 1.812762975692749, 1.7839230298995972, 1.7662959098815918, 1.7375268936157227, 1.7147457599639893, 1.6878889799118042, 1.6747174263000488, 1.6535327434539795, 1.6431324481964111, 1.617961049079895, 1.6078135967254639, 1.5960525274276733, 1.5816569328308105, 1.5756371021270752, 1.5550487041473389, 1.5639804601669312, 1.5471351146697998, 1.5390981435775757, 1.5173407793045044, 1.5173276662826538, 1.508500337600708, 1.4990296363830566, 1.510965347290039, 1.4734282493591309, 1.4825735092163086, 1.4542967081069946, 1.4653931856155396, 1.4421823024749756, 1.4453061819076538, 1.4247992038726807, 1.408679723739624, 1.4084500074386597, 1.4018192291259766, 1.393231749534607, 1.3863314390182495], 'accuracy': [0.10887499898672104, 0.12085416913032532, 0.1198333352804184, 0.11935416609048843, 0.12337499856948853, 0.13437500596046448, 0.14631250500679016, 0.1743541657924652, 0.1980416625738144, 0.2228125035762787, 0.2408750057220459, 0.24045833945274353, 0.2566041648387909, 0.265625, 0.27379167079925537, 0.2810416519641876, 0.28806251287460327, 0.2938958406448364, 0.30141666531562805, 0.3049583435058594, 0.31072917580604553, 0.31193751096725464, 0.3177083432674408, 0.3189375102519989, 0.3252291679382324, 0.32758334279060364, 0.3334999978542328, 0.3389583230018616, 0.3401249945163727, 0.34545832872390747, 0.34375, 0.34972918033599854, 0.3512916564941406, 0.35975000262260437, 0.35975000262260437, 0.3610416650772095, 0.36402082443237305, 0.36520832777023315, 0.37302082777023315, 0.3713958263397217, 0.38331249356269836, 0.3793124854564667, 0.38483333587646484, 0.3883124887943268, 0.39539584517478943, 0.39637500047683716, 0.39781248569488525, 0.3972291648387909, 0.4000625014305115, 0.4022499918937683], 'val_loss': [2.3018810749053955, 2.3016483783721924, 2.301598310470581, 2.300344944000244, 2.294450283050537, 2.2659013271331787, 2.1772620677948, 2.084719181060791, 2.0218966007232666, 1.9596357345581055, 1.9025623798370361, 1.8652070760726929, 1.8150508403778076, 1.778326153755188, 1.752450704574585, 1.7203619480133057, 1.690886378288269, 1.6779568195343018, 1.636899709701538, 1.6466749906539917, 1.6203007698059082, 1.6050660610198975, 1.5535959005355835, 1.5995967388153076, 1.522995948791504, 1.5274369716644287, 1.5569835901260376, 1.4861538410186768, 1.47337806224823, 1.4639666080474854, 1.472870945930481, 1.4565777778625488, 1.4506868124008179, 1.4505794048309326, 1.4234881401062012, 1.423804521560669, 1.4318110942840576, 1.4154587984085083, 1.4231904745101929, 1.4163202047348022, 1.4025135040283203, 1.412654995918274, 1.405624508857727, 1.411284327507019, 1.375907063484192, 1.409008264541626, 1.38139808177948, 1.4364597797393799, 1.3902921676635742, 1.3517903089523315], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.1263333261013031, 0.195333331823349, 0.21275000274181366, 0.2316666692495346, 0.257833331823349, 0.2639999985694885, 0.2920833230018616, 0.3074166774749756, 0.31466665863990784, 0.3330833315849304, 0.34191668033599854, 0.3409166634082794, 0.3579166531562805, 0.36683332920074463, 0.3644999861717224, 0.3734166622161865, 0.36116665601730347, 0.3785833418369293, 0.30783334374427795, 0.3851666748523712, 0.3739166557788849, 0.31466665863990784, 0.39125001430511475, 0.39641666412353516, 0.3972499966621399, 0.3920833468437195, 0.4074166715145111, 0.3931666612625122, 0.40566667914390564, 0.40174999833106995, 0.39908334612846375, 0.406166672706604, 0.4175833463668823, 0.4203333258628845, 0.4156666696071625, 0.4181666672229767, 0.41100001335144043, 0.4073333442211151, 0.41591668128967285, 0.4271666705608368, 0.4323333203792572, 0.4272499978542328, 0.3426666557788849, 0.4205833375453949, 0.429500013589859]}\n",
            "{'loss': [2.3011374473571777, 2.29641056060791, 2.279592514038086, 2.2257087230682373, 2.1663973331451416, 2.1129589080810547, 2.061511754989624, 1.9913203716278076, 1.9153233766555786, 1.841829538345337, 1.756117820739746, 1.6863279342651367, 1.5986698865890503, 1.5168834924697876, 1.4406547546386719, 1.3759129047393799, 1.316943883895874, 1.2703096866607666, 1.2298541069030762, 1.1836634874343872, 1.1401671171188354, 1.0944279432296753, 1.055546760559082, 1.0203497409820557, 0.9857639074325562, 0.9522531032562256, 0.9245653748512268, 0.8949068784713745, 0.8651289343833923, 0.8305361270904541, 0.8119882941246033, 0.7711422443389893, 0.7371528148651123, 0.7230274081230164, 0.6978644728660583, 0.679751992225647, 0.6616537570953369, 0.6327067613601685, 0.6214134097099304, 0.6046382784843445, 0.5940426588058472, 0.564726710319519, 0.5544627904891968, 0.5417770743370056, 0.5222058296203613, 0.5081194043159485, 0.4898234009742737, 0.47016242146492004, 0.45815059542655945, 0.4642826020717621], 'accuracy': [0.12039583176374435, 0.1393125057220459, 0.16579166054725647, 0.1978124976158142, 0.2030208259820938, 0.21118749678134918, 0.23000000417232513, 0.25327083468437195, 0.27024999260902405, 0.28945833444595337, 0.312645822763443, 0.33764582872390747, 0.37704166769981384, 0.4155208468437195, 0.4442291557788849, 0.4749999940395355, 0.5029374957084656, 0.5284791588783264, 0.551395833492279, 0.5662083625793457, 0.5882916450500488, 0.6047916412353516, 0.6217291951179504, 0.6364583373069763, 0.6490416526794434, 0.6657500267028809, 0.6780416369438171, 0.6890416741371155, 0.7005208134651184, 0.715791642665863, 0.722083330154419, 0.7335000038146973, 0.7442083358764648, 0.7512500286102295, 0.7627916932106018, 0.7715833187103271, 0.7801874876022339, 0.7878958582878113, 0.796583354473114, 0.805020809173584, 0.8108958601951599, 0.8266666531562805, 0.8276666402816772, 0.8373541831970215, 0.8464166522026062, 0.851229190826416, 0.859000027179718, 0.8648333549499512, 0.8708958625793457, 0.8692916631698608], 'val_loss': [2.299578905105591, 2.2914087772369385, 2.2425858974456787, 2.1378540992736816, 2.0743446350097656, 2.0323145389556885, 1.9644736051559448, 1.863095998764038, 1.773163914680481, 1.6716768741607666, 1.5770379304885864, 1.4789267778396606, 1.3591657876968384, 1.2536399364471436, 1.1786842346191406, 1.1128687858581543, 1.0657445192337036, 1.0232255458831787, 0.9663816094398499, 0.9171512126922607, 0.8820493817329407, 0.8478294014930725, 0.8137416839599609, 0.78838711977005, 0.7627801299095154, 0.7330654859542847, 0.6979240775108337, 0.6741389036178589, 0.655417263507843, 0.6167668104171753, 0.5990089178085327, 0.5797156095504761, 0.5605030059814453, 0.5321164727210999, 0.5223983526229858, 0.5062767863273621, 0.49015650153160095, 0.4846580922603607, 0.4799386262893677, 0.45809102058410645, 0.43656739592552185, 0.434104323387146, 0.41746023297309875, 0.41181424260139465, 0.40416499972343445, 0.39466455578804016, 0.39918252825737, 0.38742759823799133, 0.3788556456565857, 0.37862035632133484], 'val_accuracy': [0.10608333349227905, 0.14941667020320892, 0.2006666660308838, 0.21066667139530182, 0.21933333575725555, 0.22741666436195374, 0.2667500078678131, 0.30791667103767395, 0.3448333442211151, 0.382833331823349, 0.3974166810512543, 0.4429999887943268, 0.49408334493637085, 0.5496666431427002, 0.596916675567627, 0.6528333425521851, 0.6850833296775818, 0.702833354473114, 0.7283333539962769, 0.7424166798591614, 0.7650833129882812, 0.7785833477973938, 0.7885833382606506, 0.7923333048820496, 0.8146666884422302, 0.8242499828338623, 0.8185833096504211, 0.8357499837875366, 0.8366666436195374, 0.8501666784286499, 0.859000027179718, 0.847000002861023, 0.8639166951179504, 0.8692499995231628, 0.862333357334137, 0.8785833120346069, 0.8830000162124634, 0.8841666579246521, 0.8995833396911621, 0.9020000100135803, 0.9129999876022339, 0.9142500162124634, 0.9192500114440918, 0.921583354473114, 0.9211666584014893, 0.9270833134651184, 0.9281666874885559, 0.9281666874885559, 0.9293333292007446, 0.9308333396911621]}\n",
            "{'loss': [2.111177682876587, 1.6117339134216309, 1.3352024555206299, 1.1822980642318726, 1.0685404539108276, 0.9908587336540222, 0.9341508746147156, 0.884932279586792, 0.852862536907196, 0.8197442293167114, 0.8019284605979919, 0.770786464214325, 0.7514625787734985, 0.7306293845176697, 0.7147547006607056, 0.6934617757797241, 0.6821946501731873, 0.6719454526901245, 0.6578795313835144, 0.6371386051177979, 0.640201985836029, 0.6192694902420044, 0.612271249294281, 0.5974105000495911, 0.5887060761451721, 0.5710734724998474, 0.5616777539253235, 0.5564218163490295, 0.5459672808647156, 0.54323410987854, 0.5340666770935059, 0.5278841257095337, 0.5127682089805603, 0.5147877335548401, 0.4988279342651367, 0.4995182752609253, 0.5028480887413025, 0.48406243324279785, 0.47590547800064087, 0.46795421838760376, 0.4653377830982208, 0.4554019868373871, 0.45198705792427063, 0.44638749957084656, 0.4411686658859253, 0.4406028985977173, 0.4316433072090149, 0.420600026845932, 0.41666799783706665, 0.41176652908325195], 'accuracy': [0.23102083802223206, 0.4248333275318146, 0.5338958501815796, 0.5942083597183228, 0.6389583349227905, 0.6748958230018616, 0.698520839214325, 0.7207916378974915, 0.7346041798591614, 0.7479583621025085, 0.757520854473114, 0.7706249952316284, 0.7772708535194397, 0.7844791412353516, 0.7934374809265137, 0.8020625114440918, 0.8069583177566528, 0.8119583129882812, 0.8179791569709778, 0.8241666555404663, 0.8247291445732117, 0.8295416831970215, 0.8346041440963745, 0.8361250162124634, 0.8419374823570251, 0.8463333249092102, 0.8501041531562805, 0.8531875014305115, 0.856374979019165, 0.8582500219345093, 0.8612083196640015, 0.8630625009536743, 0.867020845413208, 0.8683958053588867, 0.8705833554267883, 0.8724583387374878, 0.8734791874885559, 0.8753958344459534, 0.8791458606719971, 0.8822916746139526, 0.8835833072662354, 0.8834166526794434, 0.8848749995231628, 0.8871666789054871, 0.8895208239555359, 0.8897708058357239, 0.8920416831970215, 0.8948749899864197, 0.8963958621025085, 0.898479163646698], 'val_loss': [1.3556283712387085, 0.8710172772407532, 0.6695878505706787, 0.5725676417350769, 0.5207035541534424, 0.48714953660964966, 0.4608323872089386, 0.4422112703323364, 0.4311056435108185, 0.41383999586105347, 0.40148717164993286, 0.391357421875, 0.38221967220306396, 0.3768883943557739, 0.36866891384124756, 0.36694860458374023, 0.35639917850494385, 0.35501524806022644, 0.3463386297225952, 0.34284672141075134, 0.33932965993881226, 0.33235660195350647, 0.3254019320011139, 0.3216969668865204, 0.3170332610607147, 0.31571558117866516, 0.316193550825119, 0.3106832206249237, 0.30322206020355225, 0.30482733249664307, 0.2950846254825592, 0.2967902719974518, 0.28967052698135376, 0.2887820303440094, 0.28609415888786316, 0.28014305233955383, 0.2791249454021454, 0.27136048674583435, 0.27360671758651733, 0.26727503538131714, 0.2689955532550812, 0.26686331629753113, 0.2609393298625946, 0.26506200432777405, 0.26019197702407837, 0.2554461359977722, 0.2514503598213196, 0.2527954876422882, 0.25288087129592896, 0.2487078458070755], 'val_accuracy': [0.690750002861023, 0.7770000100135803, 0.8241666555404663, 0.8420000076293945, 0.8529166579246521, 0.8617500066757202, 0.8682500123977661, 0.8759999871253967, 0.874916672706604, 0.8855000138282776, 0.8916666507720947, 0.8918333053588867, 0.8959166407585144, 0.8953333497047424, 0.9010000228881836, 0.8973333239555359, 0.903166651725769, 0.9019166827201843, 0.9053333401679993, 0.906166672706604, 0.909583330154419, 0.9125833511352539, 0.9135833382606506, 0.9154166579246521, 0.9162499904632568, 0.9173333048820496, 0.9180833101272583, 0.9202499985694885, 0.922166645526886, 0.9214166402816772, 0.9229166507720947, 0.9244999885559082, 0.9261666536331177, 0.9264166951179504, 0.9269166588783264, 0.9277499914169312, 0.9309166669845581, 0.9306666851043701, 0.9310833215713501, 0.9310833215713501, 0.9321666955947876, 0.9327499866485596, 0.934499979019165, 0.9353333115577698, 0.9355000257492065, 0.9366666674613953, 0.937333345413208, 0.9384166598320007, 0.9382500052452087, 0.9397500157356262]}\n",
            "{'loss': [2.172032117843628, 1.4028377532958984, 1.1768817901611328, 1.0669708251953125, 0.9938796162605286, 0.9299953579902649, 0.882517397403717, 0.8467463254928589, 0.8047451376914978, 0.7780699133872986, 0.7522133588790894, 0.7345040440559387, 0.7075816988945007, 0.6899569630622864, 0.6731067895889282, 0.6566268801689148, 0.6504722833633423, 0.6289892196655273, 0.6196697950363159, 0.6024928092956543, 0.5924196243286133, 0.5851732492446899, 0.569568932056427, 0.5587263703346252, 0.5454155802726746, 0.5449406504631042, 0.5273540019989014, 0.5179079174995422, 0.5104008316993713, 0.5086037516593933, 0.48945116996765137, 0.4875201880931854, 0.4870876371860504, 0.47570574283599854, 0.4712351858615875, 0.466613233089447, 0.4615485370159149, 0.4585418403148651, 0.44551700353622437, 0.4465459883213043, 0.43949368596076965, 0.43762752413749695, 0.4347303509712219, 0.4224069118499756, 0.42043909430503845, 0.4145309627056122, 0.4165500998497009, 0.4090454876422882, 0.4059401750564575, 0.3989742696285248], 'accuracy': [0.30156248807907104, 0.5016458630561829, 0.5910833477973938, 0.6373541951179504, 0.6703333258628845, 0.6990625262260437, 0.7240416407585144, 0.7402499914169312, 0.7588124871253967, 0.7692083120346069, 0.7810208201408386, 0.7930416464805603, 0.8002499938011169, 0.8061875104904175, 0.8142083287239075, 0.820395827293396, 0.8236874938011169, 0.8330833315849304, 0.835895836353302, 0.840708315372467, 0.8438958525657654, 0.8463958501815796, 0.8502916693687439, 0.8549791574478149, 0.8601041436195374, 0.8599166870117188, 0.8643749952316284, 0.8666874766349792, 0.8718541860580444, 0.870395839214325, 0.8747708201408386, 0.878333330154419, 0.877958357334137, 0.8812708258628845, 0.8832291960716248, 0.8841458559036255, 0.8840000033378601, 0.885729193687439, 0.8907708525657654, 0.8878958225250244, 0.8911458253860474, 0.8916875123977661, 0.8957083225250244, 0.8963750004768372, 0.8958958387374878, 0.8988958597183228, 0.898312509059906, 0.8994166851043701, 0.8992083072662354, 0.9030625224113464], 'val_loss': [0.8542828559875488, 0.6638547778129578, 0.6040349006652832, 0.5686728358268738, 0.5298774242401123, 0.4924192726612091, 0.46179723739624023, 0.4512970745563507, 0.43670645356178284, 0.42017894983291626, 0.4066767990589142, 0.3948068916797638, 0.3885224461555481, 0.38171327114105225, 0.3727406859397888, 0.37197089195251465, 0.3584567904472351, 0.3572586178779602, 0.3517851233482361, 0.34200528264045715, 0.337822288274765, 0.3273581862449646, 0.32881560921669006, 0.32034048438072205, 0.3157915771007538, 0.3085600733757019, 0.3077086806297302, 0.30322691798210144, 0.2996339499950409, 0.2942977845668793, 0.2954309582710266, 0.2940520644187927, 0.29025548696517944, 0.2844979166984558, 0.28662678599357605, 0.28382742404937744, 0.2818930447101593, 0.27989450097084045, 0.27650749683380127, 0.2714180648326874, 0.27191099524497986, 0.2775362432003021, 0.270212858915329, 0.27402815222740173, 0.2711484432220459, 0.26734572649002075, 0.26403409242630005, 0.2609630227088928, 0.2626061737537384, 0.26211267709732056], 'val_accuracy': [0.7179166674613953, 0.7975833415985107, 0.8182500004768372, 0.8245833516120911, 0.8478333353996277, 0.8575833439826965, 0.8689166903495789, 0.8770833611488342, 0.8769166469573975, 0.8851666450500488, 0.8914166688919067, 0.8949999809265137, 0.8984166383743286, 0.9001666903495789, 0.9049166440963745, 0.9024166464805603, 0.9069166779518127, 0.906333327293396, 0.9108333587646484, 0.9133333563804626, 0.9148333072662354, 0.9162499904632568, 0.9169166684150696, 0.9193333387374878, 0.9192500114440918, 0.921583354473114, 0.9243333339691162, 0.924833357334137, 0.9266666769981384, 0.9269999861717224, 0.9281666874885559, 0.9285833239555359, 0.9305833578109741, 0.9308333396911621, 0.9316666722297668, 0.9328333139419556, 0.9324166774749756, 0.9330000281333923, 0.9354166388511658, 0.9363333582878113, 0.9350000023841858, 0.9352499842643738, 0.9367499947547913, 0.9355833530426025, 0.9380833506584167, 0.937250018119812, 0.9382500052452087, 0.9397500157356262, 0.9390833377838135, 0.9403333067893982]}\n",
            "{'loss': [2.301957130432129, 2.301358461380005, 2.3010809421539307, 2.3009450435638428, 2.3010005950927734, 2.3009252548217773, 2.3007922172546387, 2.30082106590271, 2.3008205890655518, 2.3008878231048584, 2.3008501529693604, 2.3007748126983643, 2.3007848262786865, 2.300710439682007, 2.3006649017333984, 2.300694704055786, 2.300640344619751, 2.3006057739257812, 2.30057954788208, 2.3005926609039307, 2.300557851791382, 2.3006091117858887, 2.30051589012146, 2.3004887104034424, 2.3004539012908936, 2.300431966781616, 2.3004398345947266, 2.300339460372925, 2.300347328186035, 2.3002638816833496, 2.30024790763855, 2.300246000289917, 2.300205707550049, 2.3001530170440674, 2.300076723098755, 2.3000423908233643, 2.2999634742736816, 2.299914836883545, 2.2998459339141846, 2.2997817993164062, 2.29970645904541, 2.2996203899383545, 2.299529790878296, 2.2993695735931396, 2.2992608547210693, 2.2991390228271484, 2.2990288734436035, 2.29886794090271, 2.2986698150634766, 2.298396587371826], 'accuracy': [0.11637499928474426, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3019754886627197, 2.3018555641174316, 2.301851511001587, 2.3019118309020996, 2.3018715381622314, 2.301863193511963, 2.301880359649658, 2.3018898963928223, 2.301893949508667, 2.3018622398376465, 2.301832914352417, 2.301811456680298, 2.301786422729492, 2.3017523288726807, 2.3017418384552, 2.301743745803833, 2.301715135574341, 2.3016934394836426, 2.3016538619995117, 2.30161452293396, 2.301630973815918, 2.3016374111175537, 2.301595449447632, 2.30153751373291, 2.3015267848968506, 2.301518678665161, 2.3014538288116455, 2.3014307022094727, 2.3013994693756104, 2.301382541656494, 2.3013410568237305, 2.3012969493865967, 2.3012447357177734, 2.3012053966522217, 2.3011436462402344, 2.3010549545288086, 2.301039457321167, 2.3009438514709473, 2.300882577896118, 2.3007888793945312, 2.300722122192383, 2.3006644248962402, 2.300551652908325, 2.3004701137542725, 2.3003110885620117, 2.3001582622528076, 2.2999911308288574, 2.2997913360595703, 2.2995312213897705, 2.2992918491363525], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
            "{'loss': [2.3020083904266357, 2.3014001846313477, 2.3011250495910645, 2.301027536392212, 2.3010010719299316, 2.3008759021759033, 2.3009204864501953, 2.3009302616119385, 2.3008768558502197, 2.300832509994507, 2.3007795810699463, 2.3007850646972656, 2.300784111022949, 2.300649881362915, 2.3006436824798584, 2.300670623779297, 2.3005917072296143, 2.3006443977355957, 2.300556182861328, 2.3005378246307373, 2.30045485496521, 2.300435781478882, 2.3004257678985596, 2.300326108932495, 2.3002657890319824, 2.300222396850586, 2.3001770973205566, 2.3001956939697266, 2.3000850677490234, 2.2999846935272217, 2.2998969554901123, 2.299826145172119, 2.2997140884399414, 2.2996106147766113, 2.2994861602783203, 2.2993483543395996, 2.2991585731506348, 2.298978090286255, 2.298715114593506, 2.2983829975128174, 2.2979824542999268, 2.2974278926849365, 2.2966465950012207, 2.2953457832336426, 2.2927143573760986, 2.2848246097564697, 2.2307019233703613, 2.1570780277252197, 2.1080708503723145, 2.0745294094085693], 'accuracy': [0.11385416984558105, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11400000005960464, 0.11427083611488342, 0.11429166793823242, 0.11535416543483734, 0.11752083152532578, 0.12177083641290665, 0.13445833325386047, 0.16068750619888306, 0.19743749499320984, 0.20031249523162842, 0.20366667211055756, 0.21304166316986084], 'val_loss': [2.30206036567688, 2.301952838897705, 2.3019251823425293, 2.3019251823425293, 2.301957607269287, 2.3019518852233887, 2.301908254623413, 2.3018791675567627, 2.3018715381622314, 2.3018524646759033, 2.3017945289611816, 2.3017804622650146, 2.3017585277557373, 2.3017494678497314, 2.3017184734344482, 2.301713228225708, 2.3016390800476074, 2.3015828132629395, 2.301578998565674, 2.301522731781006, 2.3015031814575195, 2.301461935043335, 2.3014211654663086, 2.301377296447754, 2.3013510704040527, 2.301309823989868, 2.30124831199646, 2.3011481761932373, 2.3010365962982178, 2.301008701324463, 2.3009462356567383, 2.3008322715759277, 2.3007731437683105, 2.3006465435028076, 2.30051589012146, 2.3003859519958496, 2.300168991088867, 2.2999532222747803, 2.2997024059295654, 2.2993359565734863, 2.298886299133301, 2.2982373237609863, 2.2972583770751953, 2.2955596446990967, 2.2917706966400146, 2.2743349075317383, 2.1545588970184326, 2.079028367996216, 2.0480778217315674, 2.021068572998047], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10608333349227905, 0.10975000262260437, 0.13991667330265045, 0.19366666674613953, 0.2004999965429306, 0.20233333110809326, 0.2058333307504654, 0.21841666102409363]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}