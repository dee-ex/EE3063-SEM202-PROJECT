{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "0d435ca3-fa5b-4f37-ab28-91c9bb4fd569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 17s 6ms/step - loss: 1.7387 - accuracy: 0.4106 - val_loss: 0.6210 - val_accuracy: 0.8453\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8293 - accuracy: 0.7407 - val_loss: 0.4577 - val_accuracy: 0.8738\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.7922 - val_loss: 0.3993 - val_accuracy: 0.8851\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5978 - accuracy: 0.8180 - val_loss: 0.3704 - val_accuracy: 0.8905\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5584 - accuracy: 0.8321 - val_loss: 0.3520 - val_accuracy: 0.8956\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5258 - accuracy: 0.8405 - val_loss: 0.3406 - val_accuracy: 0.9002\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4960 - accuracy: 0.8486 - val_loss: 0.3294 - val_accuracy: 0.9036\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4867 - accuracy: 0.8544 - val_loss: 0.3205 - val_accuracy: 0.9044\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4842 - accuracy: 0.8543 - val_loss: 0.3154 - val_accuracy: 0.9063\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4604 - accuracy: 0.8601 - val_loss: 0.3092 - val_accuracy: 0.9082\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4454 - accuracy: 0.8658 - val_loss: 0.3049 - val_accuracy: 0.9090\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4452 - accuracy: 0.8685 - val_loss: 0.3007 - val_accuracy: 0.9103\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4281 - accuracy: 0.8702 - val_loss: 0.2962 - val_accuracy: 0.9121\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4220 - accuracy: 0.8738 - val_loss: 0.2922 - val_accuracy: 0.9127\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4088 - accuracy: 0.8755 - val_loss: 0.2890 - val_accuracy: 0.9152\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4120 - accuracy: 0.8784 - val_loss: 0.2876 - val_accuracy: 0.9143\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4092 - accuracy: 0.8779 - val_loss: 0.2845 - val_accuracy: 0.9160\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3977 - accuracy: 0.8823 - val_loss: 0.2793 - val_accuracy: 0.9172\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8815 - val_loss: 0.2782 - val_accuracy: 0.9179\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3850 - accuracy: 0.8854 - val_loss: 0.2744 - val_accuracy: 0.9193\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3849 - accuracy: 0.8869 - val_loss: 0.2745 - val_accuracy: 0.9182\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3769 - accuracy: 0.8876 - val_loss: 0.2723 - val_accuracy: 0.9192\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3757 - accuracy: 0.8898 - val_loss: 0.2690 - val_accuracy: 0.9202\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3712 - accuracy: 0.8909 - val_loss: 0.2668 - val_accuracy: 0.9203\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3731 - accuracy: 0.8896 - val_loss: 0.2644 - val_accuracy: 0.9210\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8970 - val_loss: 0.2615 - val_accuracy: 0.9233\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3557 - accuracy: 0.8944 - val_loss: 0.2588 - val_accuracy: 0.9237\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3592 - accuracy: 0.8938 - val_loss: 0.2564 - val_accuracy: 0.9248\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3472 - accuracy: 0.8986 - val_loss: 0.2577 - val_accuracy: 0.9234\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8983 - val_loss: 0.2540 - val_accuracy: 0.9259\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3390 - accuracy: 0.9013 - val_loss: 0.2530 - val_accuracy: 0.9257\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3406 - accuracy: 0.8983 - val_loss: 0.2509 - val_accuracy: 0.9262\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3401 - accuracy: 0.8993 - val_loss: 0.2501 - val_accuracy: 0.9261\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3297 - accuracy: 0.9022 - val_loss: 0.2473 - val_accuracy: 0.9266\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.9048 - val_loss: 0.2460 - val_accuracy: 0.9277\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3234 - accuracy: 0.9033 - val_loss: 0.2446 - val_accuracy: 0.9284\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.9052 - val_loss: 0.2426 - val_accuracy: 0.9283\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3178 - accuracy: 0.9083 - val_loss: 0.2401 - val_accuracy: 0.9305\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3103 - accuracy: 0.9065 - val_loss: 0.2382 - val_accuracy: 0.9304\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3162 - accuracy: 0.9054 - val_loss: 0.2363 - val_accuracy: 0.9308\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3077 - accuracy: 0.9082 - val_loss: 0.2351 - val_accuracy: 0.9308\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3104 - accuracy: 0.9093 - val_loss: 0.2328 - val_accuracy: 0.9318\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3024 - accuracy: 0.9110 - val_loss: 0.2325 - val_accuracy: 0.9318\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3082 - accuracy: 0.9072 - val_loss: 0.2301 - val_accuracy: 0.9323\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3031 - accuracy: 0.9104 - val_loss: 0.2292 - val_accuracy: 0.9321\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3015 - accuracy: 0.9110 - val_loss: 0.2279 - val_accuracy: 0.9331\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2896 - accuracy: 0.9131 - val_loss: 0.2253 - val_accuracy: 0.9344\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2841 - accuracy: 0.9163 - val_loss: 0.2239 - val_accuracy: 0.9342\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2911 - accuracy: 0.9130 - val_loss: 0.2219 - val_accuracy: 0.9354\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2857 - accuracy: 0.9153 - val_loss: 0.2218 - val_accuracy: 0.9340\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2809 - accuracy: 0.1363 - val_loss: 1.9050 - val_accuracy: 0.5393\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8593 - accuracy: 0.3702 - val_loss: 1.0210 - val_accuracy: 0.7179\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2880 - accuracy: 0.5560 - val_loss: 0.6818 - val_accuracy: 0.8035\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9923 - accuracy: 0.6633 - val_loss: 0.5439 - val_accuracy: 0.8453\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8367 - accuracy: 0.7268 - val_loss: 0.4640 - val_accuracy: 0.8690\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7214 - accuracy: 0.7731 - val_loss: 0.4069 - val_accuracy: 0.8842\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6665 - accuracy: 0.7963 - val_loss: 0.3664 - val_accuracy: 0.8947\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6032 - accuracy: 0.8172 - val_loss: 0.3406 - val_accuracy: 0.9034\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5546 - accuracy: 0.8363 - val_loss: 0.3158 - val_accuracy: 0.9078\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5120 - accuracy: 0.8500 - val_loss: 0.2995 - val_accuracy: 0.9125\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4928 - accuracy: 0.8581 - val_loss: 0.2822 - val_accuracy: 0.9164\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4618 - accuracy: 0.8658 - val_loss: 0.2684 - val_accuracy: 0.9216\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4380 - accuracy: 0.8731 - val_loss: 0.2569 - val_accuracy: 0.9254\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4255 - accuracy: 0.8797 - val_loss: 0.2475 - val_accuracy: 0.9275\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3976 - accuracy: 0.8868 - val_loss: 0.2373 - val_accuracy: 0.9301\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3868 - accuracy: 0.8927 - val_loss: 0.2291 - val_accuracy: 0.9331\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.9017 - val_loss: 0.2214 - val_accuracy: 0.9342\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3493 - accuracy: 0.9019 - val_loss: 0.2139 - val_accuracy: 0.9377\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3307 - accuracy: 0.9072 - val_loss: 0.2087 - val_accuracy: 0.9384\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3253 - accuracy: 0.9100 - val_loss: 0.2037 - val_accuracy: 0.9409\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3089 - accuracy: 0.9154 - val_loss: 0.1992 - val_accuracy: 0.9419\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2997 - accuracy: 0.9178 - val_loss: 0.1938 - val_accuracy: 0.9438\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.9202 - val_loss: 0.1903 - val_accuracy: 0.9460\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2800 - accuracy: 0.9229 - val_loss: 0.1856 - val_accuracy: 0.9468\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2691 - accuracy: 0.9267 - val_loss: 0.1842 - val_accuracy: 0.9477\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2600 - accuracy: 0.9282 - val_loss: 0.1789 - val_accuracy: 0.9497\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2496 - accuracy: 0.9310 - val_loss: 0.1767 - val_accuracy: 0.9504\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2466 - accuracy: 0.9342 - val_loss: 0.1737 - val_accuracy: 0.9508\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2321 - accuracy: 0.9353 - val_loss: 0.1728 - val_accuracy: 0.9506\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2296 - accuracy: 0.9377 - val_loss: 0.1684 - val_accuracy: 0.9515\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2250 - accuracy: 0.9406 - val_loss: 0.1668 - val_accuracy: 0.9524\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2116 - accuracy: 0.9414 - val_loss: 0.1637 - val_accuracy: 0.9529\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9411 - val_loss: 0.1639 - val_accuracy: 0.9532\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2023 - accuracy: 0.9452 - val_loss: 0.1611 - val_accuracy: 0.9546\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9459 - val_loss: 0.1604 - val_accuracy: 0.9551\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1961 - accuracy: 0.9472 - val_loss: 0.1599 - val_accuracy: 0.9544\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1900 - accuracy: 0.9472 - val_loss: 0.1579 - val_accuracy: 0.9559\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1839 - accuracy: 0.9512 - val_loss: 0.1573 - val_accuracy: 0.9555\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1802 - accuracy: 0.9506 - val_loss: 0.1560 - val_accuracy: 0.9559\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9529 - val_loss: 0.1538 - val_accuracy: 0.9561\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1740 - accuracy: 0.9528 - val_loss: 0.1547 - val_accuracy: 0.9569\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1674 - accuracy: 0.9552 - val_loss: 0.1552 - val_accuracy: 0.9580\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1651 - accuracy: 0.9559 - val_loss: 0.1519 - val_accuracy: 0.9584\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9575 - val_loss: 0.1501 - val_accuracy: 0.9589\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1532 - accuracy: 0.9591 - val_loss: 0.1497 - val_accuracy: 0.9581\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1431 - accuracy: 0.9608 - val_loss: 0.1498 - val_accuracy: 0.9588\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1436 - accuracy: 0.9598 - val_loss: 0.1495 - val_accuracy: 0.9596\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1433 - accuracy: 0.9603 - val_loss: 0.1493 - val_accuracy: 0.9598\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1451 - accuracy: 0.9601 - val_loss: 0.1509 - val_accuracy: 0.9587\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1370 - accuracy: 0.9639 - val_loss: 0.1489 - val_accuracy: 0.9597\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.2226 - accuracy: 0.1853 - val_loss: 1.5475 - val_accuracy: 0.6364\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5442 - accuracy: 0.5016 - val_loss: 0.7741 - val_accuracy: 0.7964\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0183 - accuracy: 0.6674 - val_loss: 0.5422 - val_accuracy: 0.8540\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7970 - accuracy: 0.7479 - val_loss: 0.4468 - val_accuracy: 0.8759\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6830 - accuracy: 0.7888 - val_loss: 0.3994 - val_accuracy: 0.8857\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6105 - accuracy: 0.8138 - val_loss: 0.3603 - val_accuracy: 0.8956\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5563 - accuracy: 0.8339 - val_loss: 0.3377 - val_accuracy: 0.9005\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5124 - accuracy: 0.8483 - val_loss: 0.3212 - val_accuracy: 0.9040\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4861 - accuracy: 0.8577 - val_loss: 0.3058 - val_accuracy: 0.9081\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4640 - accuracy: 0.8647 - val_loss: 0.2928 - val_accuracy: 0.9118\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4455 - accuracy: 0.8696 - val_loss: 0.2817 - val_accuracy: 0.9162\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4247 - accuracy: 0.8764 - val_loss: 0.2721 - val_accuracy: 0.9191\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4113 - accuracy: 0.8786 - val_loss: 0.2636 - val_accuracy: 0.9212\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3913 - accuracy: 0.8874 - val_loss: 0.2548 - val_accuracy: 0.9252\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3764 - accuracy: 0.8926 - val_loss: 0.2482 - val_accuracy: 0.9258\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3739 - accuracy: 0.8923 - val_loss: 0.2419 - val_accuracy: 0.9285\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8963 - val_loss: 0.2362 - val_accuracy: 0.9289\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3348 - accuracy: 0.9040 - val_loss: 0.2307 - val_accuracy: 0.9307\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3322 - accuracy: 0.9047 - val_loss: 0.2260 - val_accuracy: 0.9319\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3147 - accuracy: 0.9094 - val_loss: 0.2197 - val_accuracy: 0.9340\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3082 - accuracy: 0.9128 - val_loss: 0.2156 - val_accuracy: 0.9351\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3063 - accuracy: 0.9108 - val_loss: 0.2110 - val_accuracy: 0.9365\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2954 - accuracy: 0.9137 - val_loss: 0.2074 - val_accuracy: 0.9377\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2890 - accuracy: 0.9173 - val_loss: 0.2040 - val_accuracy: 0.9396\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2751 - accuracy: 0.9225 - val_loss: 0.2009 - val_accuracy: 0.9410\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2681 - accuracy: 0.9235 - val_loss: 0.1964 - val_accuracy: 0.9409\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2678 - accuracy: 0.9230 - val_loss: 0.1928 - val_accuracy: 0.9427\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2580 - accuracy: 0.9244 - val_loss: 0.1901 - val_accuracy: 0.9443\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2518 - accuracy: 0.9272 - val_loss: 0.1881 - val_accuracy: 0.9442\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2523 - accuracy: 0.9268 - val_loss: 0.1863 - val_accuracy: 0.9440\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2372 - accuracy: 0.9302 - val_loss: 0.1836 - val_accuracy: 0.9462\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2431 - accuracy: 0.9299 - val_loss: 0.1813 - val_accuracy: 0.9453\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2334 - accuracy: 0.9328 - val_loss: 0.1782 - val_accuracy: 0.9463\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2285 - accuracy: 0.9364 - val_loss: 0.1767 - val_accuracy: 0.9470\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2277 - accuracy: 0.9364 - val_loss: 0.1751 - val_accuracy: 0.9479\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2158 - accuracy: 0.9368 - val_loss: 0.1738 - val_accuracy: 0.9489\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2074 - accuracy: 0.9388 - val_loss: 0.1713 - val_accuracy: 0.9498\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2065 - accuracy: 0.9405 - val_loss: 0.1696 - val_accuracy: 0.9503\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2025 - accuracy: 0.9410 - val_loss: 0.1694 - val_accuracy: 0.9500\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2050 - accuracy: 0.9418 - val_loss: 0.1680 - val_accuracy: 0.9502\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2029 - accuracy: 0.9427 - val_loss: 0.1675 - val_accuracy: 0.9508\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1907 - accuracy: 0.9444 - val_loss: 0.1653 - val_accuracy: 0.9519\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1890 - accuracy: 0.9445 - val_loss: 0.1640 - val_accuracy: 0.9524\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1885 - accuracy: 0.9438 - val_loss: 0.1629 - val_accuracy: 0.9523\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1862 - accuracy: 0.9463 - val_loss: 0.1611 - val_accuracy: 0.9534\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1817 - accuracy: 0.9478 - val_loss: 0.1591 - val_accuracy: 0.9542\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1761 - accuracy: 0.9475 - val_loss: 0.1598 - val_accuracy: 0.9532\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1748 - accuracy: 0.9504 - val_loss: 0.1586 - val_accuracy: 0.9548\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1676 - accuracy: 0.9507 - val_loss: 0.1568 - val_accuracy: 0.9548\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1652 - accuracy: 0.9523 - val_loss: 0.1556 - val_accuracy: 0.9555\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 1.7527 - accuracy: 0.3971 - val_loss: 0.6090 - val_accuracy: 0.8418\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8230 - accuracy: 0.7349 - val_loss: 0.4434 - val_accuracy: 0.8718\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6588 - accuracy: 0.7944 - val_loss: 0.3934 - val_accuracy: 0.8832\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5937 - accuracy: 0.8152 - val_loss: 0.3635 - val_accuracy: 0.8901\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5524 - accuracy: 0.8300 - val_loss: 0.3463 - val_accuracy: 0.8953\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5223 - accuracy: 0.8416 - val_loss: 0.3339 - val_accuracy: 0.9010\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4934 - accuracy: 0.8506 - val_loss: 0.3241 - val_accuracy: 0.9009\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4715 - accuracy: 0.8592 - val_loss: 0.3129 - val_accuracy: 0.9054\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4623 - accuracy: 0.8607 - val_loss: 0.3078 - val_accuracy: 0.9069\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4456 - accuracy: 0.8641 - val_loss: 0.2995 - val_accuracy: 0.9084\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4365 - accuracy: 0.8665 - val_loss: 0.2940 - val_accuracy: 0.9105\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4369 - accuracy: 0.8694 - val_loss: 0.2876 - val_accuracy: 0.9133\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4154 - accuracy: 0.8774 - val_loss: 0.2835 - val_accuracy: 0.9143\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4071 - accuracy: 0.8788 - val_loss: 0.2778 - val_accuracy: 0.9166\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3993 - accuracy: 0.8787 - val_loss: 0.2728 - val_accuracy: 0.9168\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3851 - accuracy: 0.8833 - val_loss: 0.2693 - val_accuracy: 0.9180\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3752 - accuracy: 0.8877 - val_loss: 0.2628 - val_accuracy: 0.9208\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3744 - accuracy: 0.8878 - val_loss: 0.2588 - val_accuracy: 0.9214\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3692 - accuracy: 0.8880 - val_loss: 0.2555 - val_accuracy: 0.9222\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3599 - accuracy: 0.8912 - val_loss: 0.2527 - val_accuracy: 0.9234\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8914 - val_loss: 0.2487 - val_accuracy: 0.9245\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3413 - accuracy: 0.8990 - val_loss: 0.2453 - val_accuracy: 0.9261\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3346 - accuracy: 0.8985 - val_loss: 0.2401 - val_accuracy: 0.9254\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3420 - accuracy: 0.8977 - val_loss: 0.2370 - val_accuracy: 0.9279\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3369 - accuracy: 0.8994 - val_loss: 0.2347 - val_accuracy: 0.9290\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3226 - accuracy: 0.9026 - val_loss: 0.2317 - val_accuracy: 0.9300\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3147 - accuracy: 0.9047 - val_loss: 0.2289 - val_accuracy: 0.9314\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3136 - accuracy: 0.9053 - val_loss: 0.2251 - val_accuracy: 0.9324\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3199 - accuracy: 0.9045 - val_loss: 0.2231 - val_accuracy: 0.9327\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3057 - accuracy: 0.9091 - val_loss: 0.2208 - val_accuracy: 0.9337\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3038 - accuracy: 0.9085 - val_loss: 0.2175 - val_accuracy: 0.9349\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2926 - accuracy: 0.9125 - val_loss: 0.2152 - val_accuracy: 0.9358\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2898 - accuracy: 0.9133 - val_loss: 0.2131 - val_accuracy: 0.9359\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2966 - accuracy: 0.9104 - val_loss: 0.2115 - val_accuracy: 0.9362\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2812 - accuracy: 0.9137 - val_loss: 0.2082 - val_accuracy: 0.9383\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2783 - accuracy: 0.9173 - val_loss: 0.2068 - val_accuracy: 0.9377\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.9128 - val_loss: 0.2056 - val_accuracy: 0.9382\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2653 - accuracy: 0.9195 - val_loss: 0.2033 - val_accuracy: 0.9397\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2773 - accuracy: 0.9172 - val_loss: 0.2011 - val_accuracy: 0.9401\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.9205 - val_loss: 0.1995 - val_accuracy: 0.9412\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2623 - accuracy: 0.9207 - val_loss: 0.1963 - val_accuracy: 0.9419\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2566 - accuracy: 0.9212 - val_loss: 0.1955 - val_accuracy: 0.9426\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2492 - accuracy: 0.9237 - val_loss: 0.1942 - val_accuracy: 0.9438\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2552 - accuracy: 0.9225 - val_loss: 0.1918 - val_accuracy: 0.9431\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2553 - accuracy: 0.9233 - val_loss: 0.1912 - val_accuracy: 0.9437\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2514 - accuracy: 0.9238 - val_loss: 0.1899 - val_accuracy: 0.9434\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2520 - accuracy: 0.9233 - val_loss: 0.1889 - val_accuracy: 0.9447\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2458 - accuracy: 0.9265 - val_loss: 0.1875 - val_accuracy: 0.9450\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2444 - accuracy: 0.9269 - val_loss: 0.1850 - val_accuracy: 0.9454\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2402 - accuracy: 0.9277 - val_loss: 0.1843 - val_accuracy: 0.9452\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 1.6135 - accuracy: 0.4845 - val_loss: 0.4168 - val_accuracy: 0.8797\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7478 - accuracy: 0.7606 - val_loss: 0.3728 - val_accuracy: 0.8923\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6418 - accuracy: 0.8003 - val_loss: 0.3522 - val_accuracy: 0.8982\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5841 - accuracy: 0.8201 - val_loss: 0.3389 - val_accuracy: 0.9015\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5468 - accuracy: 0.8313 - val_loss: 0.3287 - val_accuracy: 0.9045\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5357 - accuracy: 0.8386 - val_loss: 0.3208 - val_accuracy: 0.9071\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5069 - accuracy: 0.8463 - val_loss: 0.3145 - val_accuracy: 0.9083\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4920 - accuracy: 0.8513 - val_loss: 0.3103 - val_accuracy: 0.9087\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4658 - accuracy: 0.8601 - val_loss: 0.3046 - val_accuracy: 0.9091\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4599 - accuracy: 0.8584 - val_loss: 0.3003 - val_accuracy: 0.9103\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4463 - accuracy: 0.8643 - val_loss: 0.2953 - val_accuracy: 0.9110\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4446 - accuracy: 0.8665 - val_loss: 0.2919 - val_accuracy: 0.9145\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4393 - accuracy: 0.8652 - val_loss: 0.2891 - val_accuracy: 0.9153\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4238 - accuracy: 0.8720 - val_loss: 0.2844 - val_accuracy: 0.9158\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4136 - accuracy: 0.8739 - val_loss: 0.2811 - val_accuracy: 0.9160\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4080 - accuracy: 0.8754 - val_loss: 0.2769 - val_accuracy: 0.9185\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4076 - accuracy: 0.8789 - val_loss: 0.2754 - val_accuracy: 0.9187\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3917 - accuracy: 0.8812 - val_loss: 0.2722 - val_accuracy: 0.9191\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3859 - accuracy: 0.8823 - val_loss: 0.2689 - val_accuracy: 0.9207\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3688 - accuracy: 0.8878 - val_loss: 0.2645 - val_accuracy: 0.9218\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3743 - accuracy: 0.8882 - val_loss: 0.2632 - val_accuracy: 0.9207\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3672 - accuracy: 0.8890 - val_loss: 0.2609 - val_accuracy: 0.9219\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3582 - accuracy: 0.8919 - val_loss: 0.2583 - val_accuracy: 0.9233\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3630 - accuracy: 0.8896 - val_loss: 0.2557 - val_accuracy: 0.9243\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8937 - val_loss: 0.2534 - val_accuracy: 0.9247\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3468 - accuracy: 0.8943 - val_loss: 0.2494 - val_accuracy: 0.9254\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3464 - accuracy: 0.8941 - val_loss: 0.2490 - val_accuracy: 0.9266\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3437 - accuracy: 0.8964 - val_loss: 0.2463 - val_accuracy: 0.9255\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3304 - accuracy: 0.9008 - val_loss: 0.2442 - val_accuracy: 0.9268\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3281 - accuracy: 0.9015 - val_loss: 0.2409 - val_accuracy: 0.9273\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3291 - accuracy: 0.8994 - val_loss: 0.2391 - val_accuracy: 0.9302\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3221 - accuracy: 0.9045 - val_loss: 0.2369 - val_accuracy: 0.9292\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3235 - accuracy: 0.9013 - val_loss: 0.2373 - val_accuracy: 0.9298\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3161 - accuracy: 0.9035 - val_loss: 0.2330 - val_accuracy: 0.9296\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3191 - accuracy: 0.9030 - val_loss: 0.2321 - val_accuracy: 0.9316\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3063 - accuracy: 0.9073 - val_loss: 0.2292 - val_accuracy: 0.9315\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3116 - accuracy: 0.9062 - val_loss: 0.2272 - val_accuracy: 0.9318\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3016 - accuracy: 0.9074 - val_loss: 0.2262 - val_accuracy: 0.9327\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3016 - accuracy: 0.9080 - val_loss: 0.2247 - val_accuracy: 0.9334\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3036 - accuracy: 0.9072 - val_loss: 0.2216 - val_accuracy: 0.9337\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2975 - accuracy: 0.9102 - val_loss: 0.2209 - val_accuracy: 0.9339\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2937 - accuracy: 0.9082 - val_loss: 0.2200 - val_accuracy: 0.9343\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2785 - accuracy: 0.9155 - val_loss: 0.2177 - val_accuracy: 0.9362\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2904 - accuracy: 0.9103 - val_loss: 0.2167 - val_accuracy: 0.9358\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2873 - accuracy: 0.9117 - val_loss: 0.2167 - val_accuracy: 0.9362\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2879 - accuracy: 0.9133 - val_loss: 0.2154 - val_accuracy: 0.9358\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2723 - accuracy: 0.9191 - val_loss: 0.2130 - val_accuracy: 0.9367\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2735 - accuracy: 0.9170 - val_loss: 0.2103 - val_accuracy: 0.9368\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2727 - accuracy: 0.9182 - val_loss: 0.2104 - val_accuracy: 0.9379\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2689 - accuracy: 0.9180 - val_loss: 0.2087 - val_accuracy: 0.9376\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.2763 - accuracy: 0.1673 - val_loss: 2.1463 - val_accuracy: 0.4069\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0597 - accuracy: 0.3495 - val_loss: 1.4429 - val_accuracy: 0.6323\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4638 - accuracy: 0.5159 - val_loss: 0.8485 - val_accuracy: 0.7893\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0704 - accuracy: 0.6466 - val_loss: 0.6149 - val_accuracy: 0.8409\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8698 - accuracy: 0.7238 - val_loss: 0.5068 - val_accuracy: 0.8655\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7367 - accuracy: 0.7747 - val_loss: 0.4497 - val_accuracy: 0.8750\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6710 - accuracy: 0.7972 - val_loss: 0.4106 - val_accuracy: 0.8837\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6100 - accuracy: 0.8160 - val_loss: 0.3829 - val_accuracy: 0.8910\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5731 - accuracy: 0.8269 - val_loss: 0.3609 - val_accuracy: 0.8966\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5401 - accuracy: 0.8393 - val_loss: 0.3428 - val_accuracy: 0.9014\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5152 - accuracy: 0.8477 - val_loss: 0.3298 - val_accuracy: 0.9056\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4881 - accuracy: 0.8589 - val_loss: 0.3175 - val_accuracy: 0.9097\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4726 - accuracy: 0.8627 - val_loss: 0.3051 - val_accuracy: 0.9126\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4535 - accuracy: 0.8682 - val_loss: 0.2939 - val_accuracy: 0.9154\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4302 - accuracy: 0.8744 - val_loss: 0.2844 - val_accuracy: 0.9182\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4248 - accuracy: 0.8768 - val_loss: 0.2750 - val_accuracy: 0.9216\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3994 - accuracy: 0.8868 - val_loss: 0.2665 - val_accuracy: 0.9237\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3803 - accuracy: 0.8905 - val_loss: 0.2586 - val_accuracy: 0.9264\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3712 - accuracy: 0.8921 - val_loss: 0.2520 - val_accuracy: 0.9270\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3613 - accuracy: 0.8964 - val_loss: 0.2447 - val_accuracy: 0.9290\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3498 - accuracy: 0.8997 - val_loss: 0.2388 - val_accuracy: 0.9309\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3451 - accuracy: 0.9007 - val_loss: 0.2313 - val_accuracy: 0.9317\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3383 - accuracy: 0.9033 - val_loss: 0.2270 - val_accuracy: 0.9333\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3290 - accuracy: 0.9066 - val_loss: 0.2207 - val_accuracy: 0.9350\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3144 - accuracy: 0.9082 - val_loss: 0.2153 - val_accuracy: 0.9362\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3032 - accuracy: 0.9138 - val_loss: 0.2113 - val_accuracy: 0.9377\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2988 - accuracy: 0.9138 - val_loss: 0.2058 - val_accuracy: 0.9389\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2974 - accuracy: 0.9166 - val_loss: 0.2029 - val_accuracy: 0.9392\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2908 - accuracy: 0.9160 - val_loss: 0.1975 - val_accuracy: 0.9405\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2755 - accuracy: 0.9209 - val_loss: 0.1948 - val_accuracy: 0.9417\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2661 - accuracy: 0.9239 - val_loss: 0.1900 - val_accuracy: 0.9436\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2684 - accuracy: 0.9259 - val_loss: 0.1894 - val_accuracy: 0.9433\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2593 - accuracy: 0.9286 - val_loss: 0.1857 - val_accuracy: 0.9445\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2496 - accuracy: 0.9310 - val_loss: 0.1814 - val_accuracy: 0.9452\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2445 - accuracy: 0.9283 - val_loss: 0.1795 - val_accuracy: 0.9463\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2422 - accuracy: 0.9305 - val_loss: 0.1788 - val_accuracy: 0.9462\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2355 - accuracy: 0.9329 - val_loss: 0.1749 - val_accuracy: 0.9480\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2320 - accuracy: 0.9336 - val_loss: 0.1728 - val_accuracy: 0.9481\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2311 - accuracy: 0.9351 - val_loss: 0.1704 - val_accuracy: 0.9481\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2192 - accuracy: 0.9386 - val_loss: 0.1679 - val_accuracy: 0.9497\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2156 - accuracy: 0.9388 - val_loss: 0.1679 - val_accuracy: 0.9497\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2096 - accuracy: 0.9385 - val_loss: 0.1646 - val_accuracy: 0.9509\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2082 - accuracy: 0.9408 - val_loss: 0.1636 - val_accuracy: 0.9508\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2090 - accuracy: 0.9387 - val_loss: 0.1610 - val_accuracy: 0.9513\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2000 - accuracy: 0.9416 - val_loss: 0.1595 - val_accuracy: 0.9521\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1956 - accuracy: 0.9443 - val_loss: 0.1581 - val_accuracy: 0.9527\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1964 - accuracy: 0.9439 - val_loss: 0.1570 - val_accuracy: 0.9531\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1889 - accuracy: 0.9456 - val_loss: 0.1553 - val_accuracy: 0.9538\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1801 - accuracy: 0.9479 - val_loss: 0.1542 - val_accuracy: 0.9537\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1809 - accuracy: 0.9479 - val_loss: 0.1527 - val_accuracy: 0.9548\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.2887 - accuracy: 0.1482 - val_loss: 2.2283 - val_accuracy: 0.5354\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2007 - accuracy: 0.3697 - val_loss: 2.0249 - val_accuracy: 0.6136\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9105 - accuracy: 0.4773 - val_loss: 1.2291 - val_accuracy: 0.7117\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3086 - accuracy: 0.5771 - val_loss: 0.7858 - val_accuracy: 0.7967\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9953 - accuracy: 0.6772 - val_loss: 0.5993 - val_accuracy: 0.8401\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8235 - accuracy: 0.7365 - val_loss: 0.5064 - val_accuracy: 0.8628\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7265 - accuracy: 0.7751 - val_loss: 0.4579 - val_accuracy: 0.8718\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6553 - accuracy: 0.8011 - val_loss: 0.4217 - val_accuracy: 0.8796\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6098 - accuracy: 0.8182 - val_loss: 0.4007 - val_accuracy: 0.8841\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5687 - accuracy: 0.8310 - val_loss: 0.3788 - val_accuracy: 0.8898\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5349 - accuracy: 0.8409 - val_loss: 0.3643 - val_accuracy: 0.8930\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5324 - accuracy: 0.8437 - val_loss: 0.3508 - val_accuracy: 0.8966\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5011 - accuracy: 0.8498 - val_loss: 0.3395 - val_accuracy: 0.9008\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4840 - accuracy: 0.8566 - val_loss: 0.3284 - val_accuracy: 0.9050\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4617 - accuracy: 0.8609 - val_loss: 0.3215 - val_accuracy: 0.9053\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4516 - accuracy: 0.8683 - val_loss: 0.3132 - val_accuracy: 0.9085\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4502 - accuracy: 0.8714 - val_loss: 0.3059 - val_accuracy: 0.9106\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4345 - accuracy: 0.8727 - val_loss: 0.2985 - val_accuracy: 0.9127\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4202 - accuracy: 0.8764 - val_loss: 0.2931 - val_accuracy: 0.9138\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4119 - accuracy: 0.8804 - val_loss: 0.2864 - val_accuracy: 0.9161\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3992 - accuracy: 0.8833 - val_loss: 0.2812 - val_accuracy: 0.9168\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3958 - accuracy: 0.8837 - val_loss: 0.2751 - val_accuracy: 0.9187\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3863 - accuracy: 0.8873 - val_loss: 0.2722 - val_accuracy: 0.9193\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3717 - accuracy: 0.8925 - val_loss: 0.2659 - val_accuracy: 0.9212\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3650 - accuracy: 0.8938 - val_loss: 0.2607 - val_accuracy: 0.9223\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3595 - accuracy: 0.8936 - val_loss: 0.2562 - val_accuracy: 0.9233\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8963 - val_loss: 0.2529 - val_accuracy: 0.9245\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8975 - val_loss: 0.2490 - val_accuracy: 0.9251\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3454 - accuracy: 0.8963 - val_loss: 0.2448 - val_accuracy: 0.9266\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3348 - accuracy: 0.9020 - val_loss: 0.2400 - val_accuracy: 0.9273\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3229 - accuracy: 0.9052 - val_loss: 0.2364 - val_accuracy: 0.9285\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3260 - accuracy: 0.9043 - val_loss: 0.2333 - val_accuracy: 0.9293\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3183 - accuracy: 0.9059 - val_loss: 0.2295 - val_accuracy: 0.9319\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3054 - accuracy: 0.9115 - val_loss: 0.2271 - val_accuracy: 0.9317\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3086 - accuracy: 0.9114 - val_loss: 0.2225 - val_accuracy: 0.9333\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3002 - accuracy: 0.9122 - val_loss: 0.2196 - val_accuracy: 0.9343\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3012 - accuracy: 0.9104 - val_loss: 0.2176 - val_accuracy: 0.9344\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.9187 - val_loss: 0.2138 - val_accuracy: 0.9361\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2796 - accuracy: 0.9175 - val_loss: 0.2112 - val_accuracy: 0.9369\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2800 - accuracy: 0.9177 - val_loss: 0.2077 - val_accuracy: 0.9372\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2715 - accuracy: 0.9191 - val_loss: 0.2058 - val_accuracy: 0.9377\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2637 - accuracy: 0.9229 - val_loss: 0.2025 - val_accuracy: 0.9388\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2638 - accuracy: 0.9229 - val_loss: 0.2004 - val_accuracy: 0.9398\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2636 - accuracy: 0.9233 - val_loss: 0.1992 - val_accuracy: 0.9392\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2554 - accuracy: 0.9245 - val_loss: 0.1961 - val_accuracy: 0.9407\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2564 - accuracy: 0.9254 - val_loss: 0.1943 - val_accuracy: 0.9412\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2460 - accuracy: 0.9275 - val_loss: 0.1921 - val_accuracy: 0.9419\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2480 - accuracy: 0.9253 - val_loss: 0.1896 - val_accuracy: 0.9432\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2468 - accuracy: 0.9294 - val_loss: 0.1874 - val_accuracy: 0.9441\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2448 - accuracy: 0.9288 - val_loss: 0.1863 - val_accuracy: 0.9442\n",
      "{'loss': [1.3394345045089722, 0.7755186557769775, 0.6468174457550049, 0.5863093733787537, 0.5511513948440552, 0.5211102962493896, 0.49845197796821594, 0.48520874977111816, 0.47294530272483826, 0.45692044496536255, 0.4507775604724884, 0.4427759647369385, 0.4333522617816925, 0.4215356707572937, 0.4195832908153534, 0.40905097126960754, 0.4039314389228821, 0.39773938059806824, 0.3932642936706543, 0.3929515480995178, 0.3860929012298584, 0.3749382793903351, 0.3732697069644928, 0.3716096878051758, 0.3703920841217041, 0.36180323362350464, 0.3566819727420807, 0.35223332047462463, 0.34855327010154724, 0.3442977964878082, 0.3418445289134979, 0.3392949104309082, 0.33937492966651917, 0.3325856029987335, 0.32796046137809753, 0.32469847798347473, 0.3235306143760681, 0.31933170557022095, 0.31601718068122864, 0.3130165934562683, 0.31043297052383423, 0.30639544129371643, 0.3019469678401947, 0.3031361401081085, 0.3019298315048218, 0.2938232123851776, 0.2925245463848114, 0.2878357768058777, 0.287604421377182, 0.2835230827331543], 'accuracy': [0.5675416588783264, 0.7603541612625122, 0.8021249771118164, 0.8215208053588867, 0.8323749899864197, 0.8419791460037231, 0.848437488079071, 0.8540416955947876, 0.8578749895095825, 0.8610416650772095, 0.8649166822433472, 0.8690000176429749, 0.8691250085830688, 0.8728958368301392, 0.8731458187103271, 0.878333330154419, 0.8793333172798157, 0.883062481880188, 0.8818333148956299, 0.88302081823349, 0.8854583501815796, 0.8887500166893005, 0.8897500038146973, 0.8911458253860474, 0.890291690826416, 0.8934583067893982, 0.8942083120346069, 0.895104169845581, 0.8969166874885559, 0.898270845413208, 0.8997291922569275, 0.898270845413208, 0.8992916941642761, 0.9015833139419556, 0.9036250114440918, 0.9041666388511658, 0.9048749804496765, 0.9071666598320007, 0.9048958420753479, 0.9068750143051147, 0.9081458449363708, 0.9100416898727417, 0.9113333225250244, 0.9104791879653931, 0.9117916822433472, 0.9128541946411133, 0.9128541946411133, 0.9152083396911621, 0.9154166579246521, 0.9162708520889282], 'val_loss': [0.6209685206413269, 0.45772120356559753, 0.39934542775154114, 0.37036511301994324, 0.35198071599006653, 0.3406314253807068, 0.3293541371822357, 0.3204995095729828, 0.31543874740600586, 0.30921828746795654, 0.30492597818374634, 0.3006928265094757, 0.29622209072113037, 0.29222309589385986, 0.2890022397041321, 0.28763237595558167, 0.2844711244106293, 0.27926498651504517, 0.27816054224967957, 0.27439457178115845, 0.2745392620563507, 0.27225261926651, 0.2689892649650574, 0.2668071389198303, 0.2643769383430481, 0.2615213692188263, 0.2588171064853668, 0.2564311623573303, 0.2577090561389923, 0.25396597385406494, 0.2529517114162445, 0.25090548396110535, 0.25014230608940125, 0.24729789793491364, 0.2460126280784607, 0.24463574588298798, 0.2425806224346161, 0.24011850357055664, 0.23824633657932281, 0.23634696006774902, 0.23505651950836182, 0.23277394473552704, 0.23245148360729218, 0.23012830317020416, 0.22923195362091064, 0.22786684334278107, 0.22534218430519104, 0.22388796508312225, 0.22191688418388367, 0.22183473408222198], 'val_accuracy': [0.8453333377838135, 0.8738333582878113, 0.8850833177566528, 0.890500009059906, 0.8955833315849304, 0.9001666903495789, 0.9035833477973938, 0.9044166803359985, 0.906333327293396, 0.9081666469573975, 0.9089999794960022, 0.9103333353996277, 0.9120833277702332, 0.9126666784286499, 0.9151666760444641, 0.9142500162124634, 0.9160000085830688, 0.9172499775886536, 0.9179166555404663, 0.9192500114440918, 0.9181666374206543, 0.9191666841506958, 0.9201666712760925, 0.9203333258628845, 0.9210000038146973, 0.9232500195503235, 0.9236666560173035, 0.924833357334137, 0.9234166741371155, 0.9259166717529297, 0.9256666898727417, 0.9262499809265137, 0.9260833263397217, 0.9265833497047424, 0.9277499914169312, 0.9284166693687439, 0.9282500147819519, 0.9304999709129333, 0.9304166436195374, 0.9308333396911621, 0.9307500123977661, 0.9318333268165588, 0.9318333268165588, 0.9323333501815796, 0.9320833086967468, 0.9330833554267883, 0.934416651725769, 0.934166669845581, 0.9354166388511658, 0.9340000152587891]}\n",
      "{'loss': [2.220512866973877, 1.6982569694519043, 1.2010599374771118, 0.9522047638893127, 0.8092555999755859, 0.7081717252731323, 0.6464861631393433, 0.5980541706085205, 0.5454772710800171, 0.5129560828208923, 0.48305439949035645, 0.46131283044815063, 0.43743807077407837, 0.41149914264678955, 0.3951549828052521, 0.3779287040233612, 0.3572438657283783, 0.3500192165374756, 0.3274044394493103, 0.32475823163986206, 0.3101085424423218, 0.2965807616710663, 0.2874393165111542, 0.27884000539779663, 0.26793724298477173, 0.25945475697517395, 0.2518344819545746, 0.24629324674606323, 0.2364261895418167, 0.23105372488498688, 0.2230711132287979, 0.21509847044944763, 0.21078218519687653, 0.20378358662128448, 0.2013368457555771, 0.19614142179489136, 0.18732403218746185, 0.18529783189296722, 0.1777273714542389, 0.1760135143995285, 0.17126765847206116, 0.16391469538211823, 0.1648830622434616, 0.15782305598258972, 0.15292373299598694, 0.14950938522815704, 0.1445004642009735, 0.14551055431365967, 0.14081713557243347, 0.1364736258983612], 'accuracy': [0.18727083504199982, 0.42225000262260437, 0.5865625143051147, 0.6797500252723694, 0.7382083535194397, 0.7794166803359985, 0.8026041388511658, 0.8212083578109741, 0.8386666774749756, 0.8503958582878113, 0.8614583611488342, 0.867479145526886, 0.8745833039283752, 0.8824999928474426, 0.8880208134651184, 0.895270824432373, 0.9010208249092102, 0.9015416502952576, 0.9088125228881836, 0.910812497138977, 0.9153541922569275, 0.9184791445732117, 0.9202083349227905, 0.9231041669845581, 0.926562488079071, 0.9279166460037231, 0.9309999942779541, 0.9339374899864197, 0.934499979019165, 0.9367708563804626, 0.9404374957084656, 0.9410833120346069, 0.942020833492279, 0.9447291493415833, 0.9455416798591614, 0.9470000267028809, 0.9488750100135803, 0.9506041407585144, 0.9514583349227905, 0.9528541564941406, 0.953166663646698, 0.9556249976158142, 0.9558958411216736, 0.9582499861717224, 0.9583541750907898, 0.9592916369438171, 0.9604791402816772, 0.9602916836738586, 0.9611250162124634, 0.963895857334137], 'val_loss': [1.9050229787826538, 1.0209639072418213, 0.6818349361419678, 0.5439152717590332, 0.4639701843261719, 0.4069289565086365, 0.36643579602241516, 0.3405771255493164, 0.3158027231693268, 0.29949212074279785, 0.28220778703689575, 0.268397718667984, 0.25688284635543823, 0.24751533567905426, 0.23732595145702362, 0.2290785163640976, 0.221375972032547, 0.21393923461437225, 0.2086554914712906, 0.20374001562595367, 0.1992136836051941, 0.19379965960979462, 0.1902548372745514, 0.18561436235904694, 0.18415549397468567, 0.17891925573349, 0.17674633860588074, 0.17367081344127655, 0.1728430986404419, 0.16837741434574127, 0.16681183874607086, 0.16367317736148834, 0.1639406979084015, 0.16112308204174042, 0.16038207709789276, 0.15989212691783905, 0.15792213380336761, 0.15733519196510315, 0.15602442622184753, 0.15383456647396088, 0.15467502176761627, 0.15518958866596222, 0.15194685757160187, 0.15009984374046326, 0.14966531097888947, 0.14982306957244873, 0.1494760811328888, 0.14934778213500977, 0.15086232125759125, 0.14889784157276154], 'val_accuracy': [0.5393333435058594, 0.7179166674613953, 0.8034999966621399, 0.8453333377838135, 0.8690000176429749, 0.8841666579246521, 0.8947499990463257, 0.9034166932106018, 0.9078333377838135, 0.9125000238418579, 0.9164166450500488, 0.921583354473114, 0.9254166483879089, 0.9275000095367432, 0.9300833344459534, 0.9330833554267883, 0.934249997138977, 0.937666654586792, 0.9384166598320007, 0.9409166574478149, 0.9419166445732117, 0.9437500238418579, 0.9459999799728394, 0.9468333125114441, 0.9476666450500488, 0.9496666789054871, 0.9504166841506958, 0.9508333206176758, 0.9505833387374878, 0.9514999985694885, 0.9524166584014893, 0.95291668176651, 0.953249990940094, 0.9545833468437195, 0.9550833106040955, 0.9544166922569275, 0.9559166431427002, 0.9555000066757202, 0.9559166431427002, 0.956083357334137, 0.9569166898727417, 0.9580000042915344, 0.9584166407585144, 0.9589166641235352, 0.9580833315849304, 0.9587500095367432, 0.9595833420753479, 0.9598333239555359, 0.9586666822433472, 0.9597499966621399]}\n",
      "{'loss': [2.08899188041687, 1.3766738176345825, 0.9465109705924988, 0.7623050808906555, 0.6622153520584106, 0.5973160862922668, 0.5472389459609985, 0.5098209381103516, 0.4798717498779297, 0.45726144313812256, 0.4381171464920044, 0.41916173696517944, 0.4010242819786072, 0.3857458829879761, 0.37264955043792725, 0.3649281859397888, 0.35227206349372864, 0.33811497688293457, 0.3316718637943268, 0.3178885579109192, 0.31018468737602234, 0.3009744882583618, 0.29244062304496765, 0.2846543490886688, 0.2785654067993164, 0.2700270712375641, 0.26600906252861023, 0.2601371705532074, 0.24951285123825073, 0.24817629158496857, 0.23955200612545013, 0.23716656863689423, 0.23053406178951263, 0.22680236399173737, 0.2223433405160904, 0.21490973234176636, 0.21018554270267487, 0.20804671943187714, 0.20170176029205322, 0.20453308522701263, 0.19512459635734558, 0.19093027710914612, 0.18799088895320892, 0.18643660843372345, 0.18299975991249084, 0.18163588643074036, 0.17375683784484863, 0.1755227893590927, 0.16778123378753662, 0.16632823646068573], 'accuracy': [0.27537500858306885, 0.5534583330154419, 0.6920416951179504, 0.7606041431427002, 0.7959791421890259, 0.8176041841506958, 0.8361666798591614, 0.8500208258628845, 0.8591874837875366, 0.8660625219345093, 0.8727083206176758, 0.8788333535194397, 0.8831666707992554, 0.8882499933242798, 0.8918750286102295, 0.895312488079071, 0.8973125219345093, 0.9029791951179504, 0.9043750166893005, 0.9076458215713501, 0.9113333225250244, 0.9127291440963745, 0.9153749942779541, 0.9176874756813049, 0.9207916855812073, 0.921750009059906, 0.9234166741371155, 0.9252708554267883, 0.9279583096504211, 0.9282916784286499, 0.9306458234786987, 0.9312916398048401, 0.9333333373069763, 0.9359166622161865, 0.9365624785423279, 0.9380833506584167, 0.9386041760444641, 0.9400833249092102, 0.9417083263397217, 0.9410416483879089, 0.9435833096504211, 0.9445833563804626, 0.9450416564941406, 0.9454166889190674, 0.9472291469573975, 0.9477291703224182, 0.9482499957084656, 0.9502916932106018, 0.9504166841506958, 0.9524375200271606], 'val_loss': [1.5474799871444702, 0.7740687131881714, 0.5422025918960571, 0.44683191180229187, 0.3994126319885254, 0.3603133261203766, 0.33770331740379333, 0.3212003707885742, 0.30580252408981323, 0.2928127944469452, 0.2816722095012665, 0.272082656621933, 0.26356515288352966, 0.25477880239486694, 0.24823564291000366, 0.24187025427818298, 0.23617781698703766, 0.2307037115097046, 0.2260150909423828, 0.21973532438278198, 0.21558506786823273, 0.2110065370798111, 0.20739440619945526, 0.20399296283721924, 0.20088446140289307, 0.19640801846981049, 0.1928320676088333, 0.1900755614042282, 0.1881009340286255, 0.1862563043832779, 0.18362575769424438, 0.18127207458019257, 0.1782304048538208, 0.17669904232025146, 0.1750965714454651, 0.17376607656478882, 0.17134985327720642, 0.16963665187358856, 0.16936640441417694, 0.16797253489494324, 0.1675487756729126, 0.16527453064918518, 0.1640491783618927, 0.16289901733398438, 0.16113826632499695, 0.15908373892307281, 0.1597902774810791, 0.1585790067911148, 0.15681666135787964, 0.15556196868419647], 'val_accuracy': [0.6364166736602783, 0.7964166402816772, 0.8539999723434448, 0.8759166598320007, 0.8857499957084656, 0.8955833315849304, 0.9004999995231628, 0.9039999842643738, 0.9080833196640015, 0.9117500185966492, 0.9161666631698608, 0.9190833568572998, 0.9212499856948853, 0.925166666507721, 0.9257500171661377, 0.9284999966621399, 0.9289166927337646, 0.9306666851043701, 0.9319166541099548, 0.9340000152587891, 0.9350833296775818, 0.9365000128746033, 0.937666654586792, 0.9395833611488342, 0.9409999847412109, 0.9409166574478149, 0.9426666498184204, 0.9443333148956299, 0.9441666603088379, 0.9440000057220459, 0.9461666941642761, 0.9453333616256714, 0.9462500214576721, 0.9470000267028809, 0.9479166865348816, 0.9489166736602783, 0.9497500061988831, 0.9503333568572998, 0.949999988079071, 0.950166642665863, 0.9508333206176758, 0.9519166946411133, 0.9524166584014893, 0.9522500038146973, 0.953416645526886, 0.9541666507720947, 0.953249990940094, 0.9548333287239075, 0.9548333287239075, 0.9555000066757202]}\n",
      "{'loss': [1.3555198907852173, 0.7692076563835144, 0.6425847411155701, 0.5824077725410461, 0.5431280732154846, 0.5136048793792725, 0.48455923795700073, 0.47491654753685, 0.4611058235168457, 0.44505077600479126, 0.4338676631450653, 0.42667803168296814, 0.41080936789512634, 0.40590962767601013, 0.3975040018558502, 0.3865143358707428, 0.37670883536338806, 0.37712663412094116, 0.36728838086128235, 0.35798054933547974, 0.3552619218826294, 0.3473935127258301, 0.3410564064979553, 0.340835839509964, 0.3311751186847687, 0.32460638880729675, 0.3139760494232178, 0.3139917254447937, 0.3101594150066376, 0.303179532289505, 0.2987533509731293, 0.29613614082336426, 0.2930876612663269, 0.29136982560157776, 0.2847251892089844, 0.27951353788375854, 0.27787667512893677, 0.27025914192199707, 0.2742707431316376, 0.2666201889514923, 0.2645600438117981, 0.260250985622406, 0.2574746012687683, 0.25662606954574585, 0.2555345594882965, 0.2530389428138733, 0.2508543133735657, 0.248663529753685, 0.24144716560840607, 0.24177616834640503], 'accuracy': [0.549916684627533, 0.7543958425521851, 0.7988958358764648, 0.8208333253860474, 0.8322291374206543, 0.8437708616256714, 0.8534166812896729, 0.8571458458900452, 0.8607083559036255, 0.8660833239555359, 0.8685416579246521, 0.8719791769981384, 0.8757708072662354, 0.8786249756813049, 0.8800625205039978, 0.8832499980926514, 0.8868125081062317, 0.8866249918937683, 0.8900208473205566, 0.8922708630561829, 0.8921041488647461, 0.8960208296775818, 0.8983333110809326, 0.8972916603088379, 0.9010833501815796, 0.9026041626930237, 0.9042291641235352, 0.9054166674613953, 0.9078541398048401, 0.9087291955947876, 0.9102083444595337, 0.9104166626930237, 0.9105208516120911, 0.9129375219345093, 0.9126458168029785, 0.9164166450500488, 0.9156249761581421, 0.9177708625793457, 0.9178333282470703, 0.9198750257492065, 0.9193958044052124, 0.9217291474342346, 0.9216041564941406, 0.9213958382606506, 0.9231874942779541, 0.9233541488647461, 0.9239583611488342, 0.9252916574478149, 0.9276250004768372, 0.926604151725769], 'val_loss': [0.6090388894081116, 0.44336357712745667, 0.393371045589447, 0.36354511976242065, 0.346336305141449, 0.3339221179485321, 0.3240653872489929, 0.31287693977355957, 0.30778250098228455, 0.2995334267616272, 0.2940007448196411, 0.28762102127075195, 0.2835147976875305, 0.27782875299453735, 0.2728430926799774, 0.269347220659256, 0.2628430426120758, 0.2587588131427765, 0.25548282265663147, 0.2526678144931793, 0.24870015680789948, 0.24531865119934082, 0.240144282579422, 0.23700039088726044, 0.23471923172473907, 0.2316880077123642, 0.22890669107437134, 0.2250985950231552, 0.22311416268348694, 0.22084274888038635, 0.2174738496541977, 0.21523383259773254, 0.21307896077632904, 0.21145422756671906, 0.20815743505954742, 0.20678164064884186, 0.20561636984348297, 0.2033202052116394, 0.20110204815864563, 0.199515700340271, 0.19632865488529205, 0.19551008939743042, 0.19416630268096924, 0.19177868962287903, 0.19118520617485046, 0.1899186372756958, 0.18886929750442505, 0.18754549324512482, 0.1850086897611618, 0.18432840704917908], 'val_accuracy': [0.8418333530426025, 0.871833324432373, 0.8832499980926514, 0.8900833129882812, 0.8952500224113464, 0.9010000228881836, 0.9009166955947876, 0.9054166674613953, 0.9069166779518127, 0.9084166884422302, 0.9104999899864197, 0.9133333563804626, 0.9142500162124634, 0.9165833592414856, 0.9168333411216736, 0.9179999828338623, 0.9208333492279053, 0.9214166402816772, 0.922249972820282, 0.9234166741371155, 0.9244999885559082, 0.9260833263397217, 0.9254166483879089, 0.9279166460037231, 0.9290000200271606, 0.9300000071525574, 0.9314166903495789, 0.9324166774749756, 0.9326666593551636, 0.9337499737739563, 0.9349166750907898, 0.9358333349227905, 0.9359166622161865, 0.9362499713897705, 0.9382500052452087, 0.937666654586792, 0.9381666779518127, 0.9396666884422302, 0.9400833249092102, 0.9411666393280029, 0.9419166445732117, 0.9425833225250244, 0.9437500238418579, 0.9430833458900452, 0.9436666369438171, 0.9434166550636292, 0.9446666836738586, 0.9449999928474426, 0.9454166889190674, 0.9451666474342346]}\n",
      "{'loss': [1.1657966375350952, 0.7230002284049988, 0.6291106939315796, 0.5773332715034485, 0.5503250360488892, 0.5249620079994202, 0.5018233060836792, 0.48816022276878357, 0.47103968262672424, 0.4544907510280609, 0.4465286135673523, 0.43698909878730774, 0.4268577992916107, 0.41809919476509094, 0.41475439071655273, 0.40212690830230713, 0.39958906173706055, 0.3906342089176178, 0.3869911730289459, 0.37825244665145874, 0.3736429810523987, 0.36602383852005005, 0.35880663990974426, 0.36348482966423035, 0.35422489047050476, 0.34938347339630127, 0.3441339135169983, 0.34484484791755676, 0.335623174905777, 0.3357991576194763, 0.3310182988643646, 0.3233875036239624, 0.3267844319343567, 0.3218283951282501, 0.31528642773628235, 0.3095713257789612, 0.3128914535045624, 0.3047563135623932, 0.3029920160770416, 0.2997286915779114, 0.29759326577186584, 0.29454857110977173, 0.28526803851127625, 0.28696125745773315, 0.2873237729072571, 0.28330865502357483, 0.2762240469455719, 0.2771240770816803, 0.27470099925994873, 0.27053582668304443], 'accuracy': [0.620354175567627, 0.7713958621025085, 0.8056041598320007, 0.823604166507721, 0.8303958177566528, 0.8398958444595337, 0.8478958606719971, 0.8527083396911621, 0.8582500219345093, 0.8608958125114441, 0.8637499809265137, 0.8686041831970215, 0.8692083358764648, 0.8726875185966492, 0.8736458420753479, 0.8780624866485596, 0.8791041374206543, 0.8809583187103271, 0.882687509059906, 0.8856250047683716, 0.8870208263397217, 0.8900208473205566, 0.8914374709129333, 0.8897708058357239, 0.8919791579246521, 0.8941041827201843, 0.8946874737739563, 0.8958541750907898, 0.8987083435058594, 0.8983749747276306, 0.8991249799728394, 0.902958333492279, 0.9004374742507935, 0.9021458625793457, 0.9046458601951599, 0.906208336353302, 0.90604168176651, 0.906583309173584, 0.9073333144187927, 0.9091249704360962, 0.9101666808128357, 0.9097708463668823, 0.913895845413208, 0.9122291803359985, 0.9118750095367432, 0.9144166707992554, 0.9177291393280029, 0.9160624742507935, 0.917312502861023, 0.9172499775886536], 'val_loss': [0.4167729616165161, 0.37279653549194336, 0.3522043824195862, 0.3388690948486328, 0.3286944031715393, 0.3207949995994568, 0.3144628405570984, 0.3102714419364929, 0.3045898377895355, 0.30032944679260254, 0.29532405734062195, 0.29188767075538635, 0.2891004979610443, 0.284432590007782, 0.28108254075050354, 0.2768830358982086, 0.27539485692977905, 0.27221402525901794, 0.26893413066864014, 0.2644670307636261, 0.2631576359272003, 0.2609180212020874, 0.25832927227020264, 0.2556625306606293, 0.25342825055122375, 0.24939467012882233, 0.24899259209632874, 0.24630320072174072, 0.24415141344070435, 0.240921750664711, 0.23912955820560455, 0.23694057762622833, 0.2372598499059677, 0.23302030563354492, 0.23209263384342194, 0.22919274866580963, 0.22719386219978333, 0.22622351348400116, 0.22473947703838348, 0.2215615212917328, 0.22086051106452942, 0.2200150489807129, 0.21769177913665771, 0.2167433500289917, 0.2167271375656128, 0.21544969081878662, 0.21298648416996002, 0.21029648184776306, 0.2104165107011795, 0.20867569744586945], 'val_accuracy': [0.8796666860580444, 0.8922500014305115, 0.8981666564941406, 0.9014999866485596, 0.9045000076293945, 0.9070833325386047, 0.9083333611488342, 0.9087499976158142, 0.9090833067893982, 0.9102500081062317, 0.9110000133514404, 0.9144999980926514, 0.9153333306312561, 0.9157500267028809, 0.9160000085830688, 0.9185000061988831, 0.918749988079071, 0.9190833568572998, 0.9206666946411133, 0.921833336353302, 0.9206666946411133, 0.921916663646698, 0.9232500195503235, 0.9242500066757202, 0.9247499704360962, 0.9254166483879089, 0.9265833497047424, 0.9254999756813049, 0.9268333315849304, 0.9272500276565552, 0.9301666617393494, 0.9291666746139526, 0.9298333525657654, 0.9295833110809326, 0.9315833449363708, 0.9315000176429749, 0.9318333268165588, 0.9326666593551636, 0.9334166646003723, 0.9336666464805603, 0.9339166879653931, 0.934333324432373, 0.9361666440963745, 0.9358333349227905, 0.9362499713897705, 0.9358333349227905, 0.9366666674613953, 0.9368333220481873, 0.9379166960716248, 0.937583327293396]}\n",
      "{'loss': [2.2469136714935303, 1.931951642036438, 1.3387449979782104, 1.0077335834503174, 0.8311333060264587, 0.7211430072784424, 0.6564292311668396, 0.6023527383804321, 0.563486635684967, 0.5322154760360718, 0.5036717057228088, 0.4831993281841278, 0.46551114320755005, 0.4462709426879883, 0.429633229970932, 0.4149080812931061, 0.40363609790802, 0.384186714887619, 0.3741873502731323, 0.36093270778656006, 0.35384008288383484, 0.3428633511066437, 0.3363112509250641, 0.322942852973938, 0.31083059310913086, 0.3004607856273651, 0.29520347714424133, 0.29103127121925354, 0.28300970792770386, 0.2722665071487427, 0.2663658559322357, 0.2607646584510803, 0.2595665752887726, 0.25036585330963135, 0.2453620880842209, 0.23630422353744507, 0.2331065535545349, 0.2298734486103058, 0.22762291133403778, 0.22015728056430817, 0.21577727794647217, 0.21225392818450928, 0.20976613461971283, 0.20368444919586182, 0.20075060427188873, 0.19608190655708313, 0.19656871259212494, 0.1880892515182495, 0.18574374914169312, 0.18032701313495636], 'accuracy': [0.21772916615009308, 0.39377084374427795, 0.5534583330154419, 0.6702916622161865, 0.7368124723434448, 0.7814375162124634, 0.8025833368301392, 0.8188750147819519, 0.8309375047683716, 0.8431458473205566, 0.8513749837875366, 0.8595208525657654, 0.8645625114440918, 0.8701666593551636, 0.8751041889190674, 0.8809583187103271, 0.8837708234786987, 0.8894583582878113, 0.8918541669845581, 0.8962291479110718, 0.8983333110809326, 0.9020000100135803, 0.9041875004768372, 0.9072499871253967, 0.9100416898727417, 0.9145208597183228, 0.9144791960716248, 0.9176250100135803, 0.9183124899864197, 0.92208331823349, 0.9245416522026062, 0.926520824432373, 0.9253749847412109, 0.9298750162124634, 0.9289374947547913, 0.9318333268165588, 0.9334999918937683, 0.934416651725769, 0.9354375004768372, 0.9379583597183228, 0.9382291436195374, 0.9387916922569275, 0.9394999742507935, 0.9404374957084656, 0.9419583082199097, 0.9441666603088379, 0.9429791569709778, 0.9466666579246521, 0.9471041560173035, 0.9488750100135803], 'val_loss': [2.1463143825531006, 1.4428644180297852, 0.8484513163566589, 0.6149473190307617, 0.506756067276001, 0.44974422454833984, 0.4106180965900421, 0.38291338086128235, 0.3608885109424591, 0.34283995628356934, 0.32977530360221863, 0.31749585270881653, 0.3050942122936249, 0.2939116060733795, 0.2844337224960327, 0.2749813497066498, 0.2665462791919708, 0.25855186581611633, 0.2519628703594208, 0.2447226345539093, 0.23884083330631256, 0.23131048679351807, 0.22697196900844574, 0.2207433134317398, 0.21533186733722687, 0.21126186847686768, 0.20578688383102417, 0.20290403068065643, 0.1975238025188446, 0.1947978138923645, 0.1900133490562439, 0.18935894966125488, 0.18571026623249054, 0.18144315481185913, 0.17947545647621155, 0.1787741482257843, 0.17486311495304108, 0.17278015613555908, 0.17042291164398193, 0.16788865625858307, 0.16785234212875366, 0.16462568938732147, 0.16357724368572235, 0.16097372770309448, 0.15949004888534546, 0.15812940895557404, 0.15703026950359344, 0.15534672141075134, 0.15420962870121002, 0.15265172719955444], 'val_accuracy': [0.40691667795181274, 0.6323333382606506, 0.7892500162124634, 0.8409166932106018, 0.8654999732971191, 0.875, 0.8836666941642761, 0.890999972820282, 0.8965833187103271, 0.9014166593551636, 0.9055833220481873, 0.9096666574478149, 0.9125833511352539, 0.9154166579246521, 0.9181666374206543, 0.921583354473114, 0.9236666560173035, 0.9264166951179504, 0.9269999861717224, 0.9290000200271606, 0.9309166669845581, 0.9317499995231628, 0.9333333373069763, 0.9350000023841858, 0.9362499713897705, 0.937666654586792, 0.9389166831970215, 0.9391666650772095, 0.940500020980835, 0.9417499899864197, 0.9435833096504211, 0.9432500004768372, 0.9445000290870667, 0.9451666474342346, 0.9462500214576721, 0.9461666941642761, 0.9480000138282776, 0.9480833411216736, 0.9480833411216736, 0.9496666789054871, 0.9496666789054871, 0.9509166479110718, 0.9508333206176758, 0.9512500166893005, 0.9520833492279053, 0.9526666402816772, 0.953083336353302, 0.9537500143051147, 0.9536666870117188, 0.9548333287239075]}\n",
      "{'loss': [2.27116060256958, 2.1591970920562744, 1.7502048015594482, 1.2155029773712158, 0.9425980448722839, 0.7964633107185364, 0.7087901830673218, 0.6415793299674988, 0.6068262457847595, 0.5681397914886475, 0.5374720692634583, 0.517048180103302, 0.4990122616291046, 0.4835570454597473, 0.46432414650917053, 0.4538642466068268, 0.44164782762527466, 0.4265700578689575, 0.4223988354206085, 0.41202616691589355, 0.398642897605896, 0.3905774652957916, 0.38568851351737976, 0.3776252567768097, 0.3651944100856781, 0.3586914539337158, 0.35231664776802063, 0.34585556387901306, 0.3394794464111328, 0.3341100811958313, 0.3233679533004761, 0.3247999846935272, 0.3161735236644745, 0.3102632164955139, 0.30274078249931335, 0.2975864112377167, 0.29560643434524536, 0.2870236039161682, 0.2823109030723572, 0.2792418897151947, 0.2745843231678009, 0.2692321836948395, 0.2644628584384918, 0.2629246115684509, 0.2595088481903076, 0.258131742477417, 0.2514438033103943, 0.24633382260799408, 0.24549643695354462, 0.239772230386734], 'accuracy': [0.20595833659172058, 0.40799999237060547, 0.49918749928474426, 0.6060000061988831, 0.6964791417121887, 0.7456458210945129, 0.7817291617393494, 0.8056666851043701, 0.8175208568572998, 0.8305208086967468, 0.8385624885559082, 0.8475000262260437, 0.8523125052452087, 0.8580416440963745, 0.8624374866485596, 0.8664583563804626, 0.8715208172798157, 0.8742499947547913, 0.8770624995231628, 0.8805208206176758, 0.8836458325386047, 0.8855624794960022, 0.8879374861717224, 0.890541672706604, 0.8928124904632568, 0.8939375281333923, 0.8969374895095825, 0.8988333344459534, 0.9009166955947876, 0.9027291536331177, 0.9053958058357239, 0.9047708511352539, 0.9074583053588867, 0.9109166860580444, 0.9113749861717224, 0.9127291440963745, 0.9125208258628845, 0.9160208106040955, 0.9170416593551636, 0.9177500009536743, 0.9184166789054871, 0.9215624928474426, 0.9230625033378601, 0.9231250286102295, 0.9228125214576721, 0.9243333339691162, 0.9258958101272583, 0.9271458387374878, 0.9279166460037231, 0.9292083382606506], 'val_loss': [2.22829270362854, 2.0249178409576416, 1.229116678237915, 0.7858457565307617, 0.5992655158042908, 0.5063512921333313, 0.4578913450241089, 0.4216955602169037, 0.40069714188575745, 0.3788468539714813, 0.3642708361148834, 0.35078853368759155, 0.33948031067848206, 0.3284117877483368, 0.3214948773384094, 0.31320688128471375, 0.305947482585907, 0.2984847128391266, 0.2931176722049713, 0.28641197085380554, 0.28117817640304565, 0.27506765723228455, 0.2722229063510895, 0.26585128903388977, 0.26072609424591064, 0.2562399208545685, 0.25294843316078186, 0.2489742785692215, 0.24484647810459137, 0.23998849093914032, 0.23636597394943237, 0.23325660824775696, 0.22950516641139984, 0.22708585858345032, 0.22247304022312164, 0.21961642801761627, 0.21755348145961761, 0.21382102370262146, 0.21118029952049255, 0.2076624482870102, 0.20577950775623322, 0.20254960656166077, 0.20044709742069244, 0.19915513694286346, 0.19605855643749237, 0.1942795366048813, 0.1920633167028427, 0.1896214783191681, 0.18742895126342773, 0.18632055819034576], 'val_accuracy': [0.5354166626930237, 0.6135833263397217, 0.7117499709129333, 0.79666668176651, 0.8400833606719971, 0.8628333210945129, 0.871833324432373, 0.8795833587646484, 0.8840833306312561, 0.8898333311080933, 0.8930000066757202, 0.8965833187103271, 0.9008333086967468, 0.9049999713897705, 0.9053333401679993, 0.9085000157356262, 0.9105833172798157, 0.9126666784286499, 0.9138333201408386, 0.9160833358764648, 0.9168333411216736, 0.918666660785675, 0.9192500114440918, 0.9211666584014893, 0.9223333597183228, 0.9233333468437195, 0.9244999885559082, 0.925083339214325, 0.9265833497047424, 0.9273333549499512, 0.9284999966621399, 0.9292500019073486, 0.9319166541099548, 0.9317499995231628, 0.9333333373069763, 0.934333324432373, 0.934416651725769, 0.9360833168029785, 0.9369166493415833, 0.937166690826416, 0.937666654586792, 0.9388333559036255, 0.9398333430290222, 0.9392499923706055, 0.940666675567627, 0.9411666393280029, 0.9419166445732117, 0.9431666731834412, 0.9440833330154419, 0.9442499876022339]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "noise_4depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
