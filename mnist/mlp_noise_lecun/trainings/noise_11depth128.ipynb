{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "f11b5116-6844-435e-e803-c19fa9d8dfd3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 17s 6ms/step - loss: 2.2860 - accuracy: 0.1582 - val_loss: 1.5097 - val_accuracy: 0.5300\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8216 - accuracy: 0.3406 - val_loss: 1.1760 - val_accuracy: 0.6798\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5913 - accuracy: 0.4387 - val_loss: 0.9905 - val_accuracy: 0.7201\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4227 - accuracy: 0.4996 - val_loss: 0.8888 - val_accuracy: 0.7453\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3114 - accuracy: 0.5400 - val_loss: 0.8248 - val_accuracy: 0.7523\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2242 - accuracy: 0.5819 - val_loss: 0.7840 - val_accuracy: 0.7689\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1608 - accuracy: 0.6068 - val_loss: 0.7407 - val_accuracy: 0.7768\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1135 - accuracy: 0.6264 - val_loss: 0.7155 - val_accuracy: 0.7908\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0727 - accuracy: 0.6426 - val_loss: 0.6814 - val_accuracy: 0.7990\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0358 - accuracy: 0.6611 - val_loss: 0.6605 - val_accuracy: 0.8026\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9853 - accuracy: 0.6832 - val_loss: 0.6358 - val_accuracy: 0.8150\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9735 - accuracy: 0.6958 - val_loss: 0.6190 - val_accuracy: 0.8148\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9418 - accuracy: 0.7074 - val_loss: 0.6000 - val_accuracy: 0.8213\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9242 - accuracy: 0.7151 - val_loss: 0.5865 - val_accuracy: 0.8271\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9079 - accuracy: 0.7242 - val_loss: 0.5779 - val_accuracy: 0.8327\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8769 - accuracy: 0.7347 - val_loss: 0.5720 - val_accuracy: 0.8314\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8567 - accuracy: 0.7419 - val_loss: 0.5593 - val_accuracy: 0.8437\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8443 - accuracy: 0.7502 - val_loss: 0.5494 - val_accuracy: 0.8508\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8341 - accuracy: 0.7499 - val_loss: 0.5478 - val_accuracy: 0.8493\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8042 - accuracy: 0.7612 - val_loss: 0.5413 - val_accuracy: 0.8477\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8125 - accuracy: 0.7587 - val_loss: 0.5291 - val_accuracy: 0.8578\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7910 - accuracy: 0.7686 - val_loss: 0.5224 - val_accuracy: 0.8667\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7769 - accuracy: 0.7769 - val_loss: 0.5175 - val_accuracy: 0.8607\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7616 - accuracy: 0.7809 - val_loss: 0.5125 - val_accuracy: 0.8668\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7676 - accuracy: 0.7803 - val_loss: 0.4995 - val_accuracy: 0.8753\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7494 - accuracy: 0.7861 - val_loss: 0.4897 - val_accuracy: 0.8765\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7397 - accuracy: 0.7893 - val_loss: 0.4869 - val_accuracy: 0.8774\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7369 - accuracy: 0.7948 - val_loss: 0.4791 - val_accuracy: 0.8798\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7295 - accuracy: 0.7971 - val_loss: 0.4701 - val_accuracy: 0.8833\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7203 - accuracy: 0.8028 - val_loss: 0.4655 - val_accuracy: 0.8867\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7121 - accuracy: 0.8054 - val_loss: 0.4569 - val_accuracy: 0.8917\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6945 - accuracy: 0.8104 - val_loss: 0.4606 - val_accuracy: 0.8900\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.8144 - val_loss: 0.4436 - val_accuracy: 0.8952\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6891 - accuracy: 0.8191 - val_loss: 0.4473 - val_accuracy: 0.8939\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6758 - accuracy: 0.8216 - val_loss: 0.4326 - val_accuracy: 0.8975\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6528 - accuracy: 0.8318 - val_loss: 0.4271 - val_accuracy: 0.9017\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6532 - accuracy: 0.8315 - val_loss: 0.4223 - val_accuracy: 0.9032\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6279 - accuracy: 0.8404 - val_loss: 0.4162 - val_accuracy: 0.9043\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6475 - accuracy: 0.8394 - val_loss: 0.4106 - val_accuracy: 0.9062\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6183 - accuracy: 0.8420 - val_loss: 0.4013 - val_accuracy: 0.9082\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6311 - accuracy: 0.8448 - val_loss: 0.4014 - val_accuracy: 0.9096\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6246 - accuracy: 0.8475 - val_loss: 0.3908 - val_accuracy: 0.9109\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6081 - accuracy: 0.8494 - val_loss: 0.3932 - val_accuracy: 0.9112\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5991 - accuracy: 0.8538 - val_loss: 0.3867 - val_accuracy: 0.9135\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5992 - accuracy: 0.8551 - val_loss: 0.3895 - val_accuracy: 0.9143\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6015 - accuracy: 0.8557 - val_loss: 0.3805 - val_accuracy: 0.9166\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5772 - accuracy: 0.8630 - val_loss: 0.3747 - val_accuracy: 0.9180\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5782 - accuracy: 0.8640 - val_loss: 0.3705 - val_accuracy: 0.9183\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5753 - accuracy: 0.8622 - val_loss: 0.3667 - val_accuracy: 0.9203\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5660 - accuracy: 0.8675 - val_loss: 0.3676 - val_accuracy: 0.9213\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.3033 - accuracy: 0.1029 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1235 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3009 - accuracy: 0.1188 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.3002 - accuracy: 0.1218 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2999 - accuracy: 0.1229 - val_loss: 2.2996 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2984 - accuracy: 0.1275 - val_loss: 2.2944 - val_accuracy: 0.1068\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2956 - accuracy: 0.1362 - val_loss: 2.2827 - val_accuracy: 0.1567\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2838 - accuracy: 0.1525 - val_loss: 2.2286 - val_accuracy: 0.2009\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2439 - accuracy: 0.1731 - val_loss: 2.1082 - val_accuracy: 0.2058\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.1642 - accuracy: 0.1912 - val_loss: 1.9957 - val_accuracy: 0.2083\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0764 - accuracy: 0.2009 - val_loss: 1.9448 - val_accuracy: 0.1952\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.0170 - accuracy: 0.1977 - val_loss: 1.9032 - val_accuracy: 0.2074\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9745 - accuracy: 0.2033 - val_loss: 1.8772 - val_accuracy: 0.2074\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9449 - accuracy: 0.2063 - val_loss: 1.8586 - val_accuracy: 0.1959\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9187 - accuracy: 0.2021 - val_loss: 1.8484 - val_accuracy: 0.2049\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9071 - accuracy: 0.2047 - val_loss: 1.8318 - val_accuracy: 0.2102\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8918 - accuracy: 0.2089 - val_loss: 1.8211 - val_accuracy: 0.2109\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8763 - accuracy: 0.2109 - val_loss: 1.8134 - val_accuracy: 0.2158\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8623 - accuracy: 0.2222 - val_loss: 1.8037 - val_accuracy: 0.2437\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8492 - accuracy: 0.2275 - val_loss: 1.7926 - val_accuracy: 0.2377\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8379 - accuracy: 0.2376 - val_loss: 1.7706 - val_accuracy: 0.2406\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8136 - accuracy: 0.2523 - val_loss: 1.7465 - val_accuracy: 0.2730\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7999 - accuracy: 0.2608 - val_loss: 1.7225 - val_accuracy: 0.2782\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7815 - accuracy: 0.2692 - val_loss: 1.6877 - val_accuracy: 0.3239\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7619 - accuracy: 0.2691 - val_loss: 1.6745 - val_accuracy: 0.2953\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7319 - accuracy: 0.2878 - val_loss: 1.6240 - val_accuracy: 0.3358\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7253 - accuracy: 0.2915 - val_loss: 1.6313 - val_accuracy: 0.3062\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6924 - accuracy: 0.2992 - val_loss: 1.5668 - val_accuracy: 0.3590\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6814 - accuracy: 0.3018 - val_loss: 1.5393 - val_accuracy: 0.3702\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6569 - accuracy: 0.3058 - val_loss: 1.5048 - val_accuracy: 0.3365\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6362 - accuracy: 0.3102 - val_loss: 1.4842 - val_accuracy: 0.3523\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6205 - accuracy: 0.3118 - val_loss: 1.5055 - val_accuracy: 0.3558\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6138 - accuracy: 0.3136 - val_loss: 1.4431 - val_accuracy: 0.3683\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5969 - accuracy: 0.3235 - val_loss: 1.4336 - val_accuracy: 0.3767\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5769 - accuracy: 0.3268 - val_loss: 1.4211 - val_accuracy: 0.3848\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5640 - accuracy: 0.3280 - val_loss: 1.3952 - val_accuracy: 0.3765\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5430 - accuracy: 0.3299 - val_loss: 1.3873 - val_accuracy: 0.3900\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.5408 - accuracy: 0.3382 - val_loss: 1.4286 - val_accuracy: 0.3893\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5266 - accuracy: 0.3376 - val_loss: 1.3773 - val_accuracy: 0.3786\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5112 - accuracy: 0.3406 - val_loss: 1.3622 - val_accuracy: 0.3893\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5131 - accuracy: 0.3436 - val_loss: 1.3494 - val_accuracy: 0.3908\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4877 - accuracy: 0.3470 - val_loss: 1.3559 - val_accuracy: 0.3917\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4869 - accuracy: 0.3437 - val_loss: 1.4016 - val_accuracy: 0.3473\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4739 - accuracy: 0.3500 - val_loss: 1.4447 - val_accuracy: 0.3537\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4783 - accuracy: 0.3514 - val_loss: 1.3659 - val_accuracy: 0.4039\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4566 - accuracy: 0.3528 - val_loss: 1.3190 - val_accuracy: 0.3817\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4351 - accuracy: 0.3605 - val_loss: 1.3184 - val_accuracy: 0.3848\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4377 - accuracy: 0.3556 - val_loss: 1.3093 - val_accuracy: 0.3977\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4499 - accuracy: 0.3564 - val_loss: 1.3175 - val_accuracy: 0.4013\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4091 - accuracy: 0.3596 - val_loss: 1.2972 - val_accuracy: 0.4026\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 7ms/step - loss: 2.3028 - accuracy: 0.1098 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2989 - accuracy: 0.1279 - val_loss: 2.2965 - val_accuracy: 0.1099\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2920 - accuracy: 0.1458 - val_loss: 2.2704 - val_accuracy: 0.1808\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2695 - accuracy: 0.1718 - val_loss: 2.2008 - val_accuracy: 0.2048\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.2182 - accuracy: 0.1905 - val_loss: 2.0908 - val_accuracy: 0.2128\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1513 - accuracy: 0.2040 - val_loss: 2.0130 - val_accuracy: 0.2250\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0755 - accuracy: 0.2175 - val_loss: 1.9119 - val_accuracy: 0.2386\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0066 - accuracy: 0.2250 - val_loss: 1.8429 - val_accuracy: 0.2671\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.9380 - accuracy: 0.2340 - val_loss: 1.7582 - val_accuracy: 0.2907\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8667 - accuracy: 0.2492 - val_loss: 1.6983 - val_accuracy: 0.3040\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8063 - accuracy: 0.2612 - val_loss: 1.6489 - val_accuracy: 0.3170\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7639 - accuracy: 0.2674 - val_loss: 1.6169 - val_accuracy: 0.3178\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7258 - accuracy: 0.2768 - val_loss: 1.5876 - val_accuracy: 0.3297\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6979 - accuracy: 0.2844 - val_loss: 1.5538 - val_accuracy: 0.3670\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.2924 - val_loss: 1.5223 - val_accuracy: 0.4142\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6392 - accuracy: 0.3075 - val_loss: 1.4909 - val_accuracy: 0.4212\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6006 - accuracy: 0.3323 - val_loss: 1.4456 - val_accuracy: 0.4629\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5620 - accuracy: 0.3593 - val_loss: 1.3948 - val_accuracy: 0.4663\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5198 - accuracy: 0.3837 - val_loss: 1.3488 - val_accuracy: 0.4787\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4754 - accuracy: 0.4034 - val_loss: 1.3199 - val_accuracy: 0.4675\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4308 - accuracy: 0.4204 - val_loss: 1.2721 - val_accuracy: 0.5192\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3914 - accuracy: 0.4305 - val_loss: 1.2478 - val_accuracy: 0.5158\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.3667 - accuracy: 0.4409 - val_loss: 1.2135 - val_accuracy: 0.5154\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3405 - accuracy: 0.4539 - val_loss: 1.1815 - val_accuracy: 0.5256\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3177 - accuracy: 0.4639 - val_loss: 1.1596 - val_accuracy: 0.5425\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2703 - accuracy: 0.4805 - val_loss: 1.1332 - val_accuracy: 0.5517\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2501 - accuracy: 0.4839 - val_loss: 1.1181 - val_accuracy: 0.5450\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2419 - accuracy: 0.4905 - val_loss: 1.0932 - val_accuracy: 0.5622\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2113 - accuracy: 0.5067 - val_loss: 1.0706 - val_accuracy: 0.5822\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1852 - accuracy: 0.5184 - val_loss: 1.0604 - val_accuracy: 0.5918\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1776 - accuracy: 0.5241 - val_loss: 1.0339 - val_accuracy: 0.6178\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1546 - accuracy: 0.5366 - val_loss: 1.0133 - val_accuracy: 0.6235\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1352 - accuracy: 0.5389 - val_loss: 1.0050 - val_accuracy: 0.6260\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1095 - accuracy: 0.5486 - val_loss: 0.9904 - val_accuracy: 0.6184\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0880 - accuracy: 0.5666 - val_loss: 0.9730 - val_accuracy: 0.6132\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0718 - accuracy: 0.5664 - val_loss: 0.9786 - val_accuracy: 0.6280\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0677 - accuracy: 0.5705 - val_loss: 0.9545 - val_accuracy: 0.6561\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0373 - accuracy: 0.5823 - val_loss: 0.9456 - val_accuracy: 0.6550\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0256 - accuracy: 0.5940 - val_loss: 0.9233 - val_accuracy: 0.6745\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0223 - accuracy: 0.5879 - val_loss: 0.9151 - val_accuracy: 0.6899\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9902 - accuracy: 0.6053 - val_loss: 0.8984 - val_accuracy: 0.6906\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9689 - accuracy: 0.6163 - val_loss: 0.9033 - val_accuracy: 0.6947\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9653 - accuracy: 0.6225 - val_loss: 0.8692 - val_accuracy: 0.6973\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9486 - accuracy: 0.6202 - val_loss: 0.9119 - val_accuracy: 0.6803\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9234 - accuracy: 0.6362 - val_loss: 0.8265 - val_accuracy: 0.7121\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9034 - accuracy: 0.6442 - val_loss: 0.8279 - val_accuracy: 0.7213\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8885 - accuracy: 0.6529 - val_loss: 0.8173 - val_accuracy: 0.7261\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8767 - accuracy: 0.6588 - val_loss: 0.7898 - val_accuracy: 0.7185\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8646 - accuracy: 0.6661 - val_loss: 0.7686 - val_accuracy: 0.7297\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8553 - accuracy: 0.6678 - val_loss: 0.7847 - val_accuracy: 0.7342\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.2769 - accuracy: 0.1675 - val_loss: 1.2969 - val_accuracy: 0.6479\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7157 - accuracy: 0.3829 - val_loss: 0.9119 - val_accuracy: 0.7293\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4473 - accuracy: 0.4872 - val_loss: 0.7089 - val_accuracy: 0.8019\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2760 - accuracy: 0.5570 - val_loss: 0.5945 - val_accuracy: 0.8368\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1594 - accuracy: 0.6044 - val_loss: 0.5354 - val_accuracy: 0.8510\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0778 - accuracy: 0.6455 - val_loss: 0.4984 - val_accuracy: 0.8585\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0084 - accuracy: 0.6729 - val_loss: 0.4756 - val_accuracy: 0.8673\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9698 - accuracy: 0.6886 - val_loss: 0.4597 - val_accuracy: 0.8729\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9209 - accuracy: 0.7098 - val_loss: 0.4425 - val_accuracy: 0.8791\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8851 - accuracy: 0.7251 - val_loss: 0.4363 - val_accuracy: 0.8793\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8674 - accuracy: 0.7310 - val_loss: 0.4260 - val_accuracy: 0.8817\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8285 - accuracy: 0.7433 - val_loss: 0.4098 - val_accuracy: 0.8881\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8074 - accuracy: 0.7565 - val_loss: 0.4049 - val_accuracy: 0.8905\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8002 - accuracy: 0.7627 - val_loss: 0.3961 - val_accuracy: 0.8931\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7837 - accuracy: 0.7701 - val_loss: 0.3902 - val_accuracy: 0.8942\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7496 - accuracy: 0.7820 - val_loss: 0.3820 - val_accuracy: 0.8954\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7436 - accuracy: 0.7841 - val_loss: 0.3721 - val_accuracy: 0.8992\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7305 - accuracy: 0.7902 - val_loss: 0.3633 - val_accuracy: 0.9026\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7135 - accuracy: 0.7968 - val_loss: 0.3630 - val_accuracy: 0.9030\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.8053 - val_loss: 0.3579 - val_accuracy: 0.9058\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6863 - accuracy: 0.8082 - val_loss: 0.3476 - val_accuracy: 0.9081\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6702 - accuracy: 0.8198 - val_loss: 0.3465 - val_accuracy: 0.9081\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6539 - accuracy: 0.8190 - val_loss: 0.3349 - val_accuracy: 0.9123\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6501 - accuracy: 0.8235 - val_loss: 0.3335 - val_accuracy: 0.9133\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6292 - accuracy: 0.8291 - val_loss: 0.3248 - val_accuracy: 0.9145\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6237 - accuracy: 0.8350 - val_loss: 0.3246 - val_accuracy: 0.9172\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6003 - accuracy: 0.8401 - val_loss: 0.3193 - val_accuracy: 0.9175\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5989 - accuracy: 0.8417 - val_loss: 0.3180 - val_accuracy: 0.9168\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5915 - accuracy: 0.8471 - val_loss: 0.3068 - val_accuracy: 0.9208\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5822 - accuracy: 0.8511 - val_loss: 0.3176 - val_accuracy: 0.9187\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.8542 - val_loss: 0.2998 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5653 - accuracy: 0.8574 - val_loss: 0.3051 - val_accuracy: 0.9243\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5561 - accuracy: 0.8605 - val_loss: 0.2955 - val_accuracy: 0.9260\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5294 - accuracy: 0.8689 - val_loss: 0.2970 - val_accuracy: 0.9260\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5381 - accuracy: 0.8656 - val_loss: 0.2940 - val_accuracy: 0.9275\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5211 - accuracy: 0.8688 - val_loss: 0.2880 - val_accuracy: 0.9273\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5261 - accuracy: 0.8689 - val_loss: 0.2895 - val_accuracy: 0.9287\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5141 - accuracy: 0.8728 - val_loss: 0.2855 - val_accuracy: 0.9309\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5081 - accuracy: 0.8762 - val_loss: 0.2846 - val_accuracy: 0.9308\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4925 - accuracy: 0.8804 - val_loss: 0.2803 - val_accuracy: 0.9317\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4924 - accuracy: 0.8788 - val_loss: 0.2794 - val_accuracy: 0.9344\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4691 - accuracy: 0.8854 - val_loss: 0.2827 - val_accuracy: 0.9318\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4807 - accuracy: 0.8854 - val_loss: 0.2732 - val_accuracy: 0.9343\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4694 - accuracy: 0.8867 - val_loss: 0.2737 - val_accuracy: 0.9359\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4650 - accuracy: 0.8878 - val_loss: 0.2744 - val_accuracy: 0.9346\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4607 - accuracy: 0.8897 - val_loss: 0.2693 - val_accuracy: 0.9373\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4478 - accuracy: 0.8919 - val_loss: 0.2657 - val_accuracy: 0.9387\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4583 - accuracy: 0.8902 - val_loss: 0.2618 - val_accuracy: 0.9395\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4371 - accuracy: 0.8941 - val_loss: 0.2586 - val_accuracy: 0.9383\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4274 - accuracy: 0.8968 - val_loss: 0.2663 - val_accuracy: 0.9394\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.7066 - accuracy: 0.1731 - val_loss: 1.1457 - val_accuracy: 0.6478\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6650 - accuracy: 0.3870 - val_loss: 0.8533 - val_accuracy: 0.7352\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3464 - accuracy: 0.5141 - val_loss: 0.7369 - val_accuracy: 0.7613\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1868 - accuracy: 0.5789 - val_loss: 0.6902 - val_accuracy: 0.7628\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1087 - accuracy: 0.6139 - val_loss: 0.6581 - val_accuracy: 0.8080\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0560 - accuracy: 0.6313 - val_loss: 0.6278 - val_accuracy: 0.8295\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0054 - accuracy: 0.6569 - val_loss: 0.6085 - val_accuracy: 0.8317\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9740 - accuracy: 0.6713 - val_loss: 0.5826 - val_accuracy: 0.8411\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9388 - accuracy: 0.6886 - val_loss: 0.5527 - val_accuracy: 0.8478\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9214 - accuracy: 0.7017 - val_loss: 0.5263 - val_accuracy: 0.8693\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8780 - accuracy: 0.7238 - val_loss: 0.4885 - val_accuracy: 0.8763\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8473 - accuracy: 0.7401 - val_loss: 0.4687 - val_accuracy: 0.8755\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8240 - accuracy: 0.7519 - val_loss: 0.4448 - val_accuracy: 0.8903\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8007 - accuracy: 0.7662 - val_loss: 0.4216 - val_accuracy: 0.8938\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7745 - accuracy: 0.7802 - val_loss: 0.4115 - val_accuracy: 0.8980\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7504 - accuracy: 0.7857 - val_loss: 0.4012 - val_accuracy: 0.9018\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7522 - accuracy: 0.7913 - val_loss: 0.3919 - val_accuracy: 0.9043\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7227 - accuracy: 0.8034 - val_loss: 0.3933 - val_accuracy: 0.9037\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7074 - accuracy: 0.8086 - val_loss: 0.3844 - val_accuracy: 0.9054\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6880 - accuracy: 0.8145 - val_loss: 0.3742 - val_accuracy: 0.9078\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6759 - accuracy: 0.8223 - val_loss: 0.3673 - val_accuracy: 0.9096\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6557 - accuracy: 0.8273 - val_loss: 0.3654 - val_accuracy: 0.9105\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6467 - accuracy: 0.8345 - val_loss: 0.3612 - val_accuracy: 0.9121\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6449 - accuracy: 0.8354 - val_loss: 0.3521 - val_accuracy: 0.9143\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6281 - accuracy: 0.8414 - val_loss: 0.3520 - val_accuracy: 0.9160\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6245 - accuracy: 0.8440 - val_loss: 0.3480 - val_accuracy: 0.9165\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6082 - accuracy: 0.8479 - val_loss: 0.3491 - val_accuracy: 0.9150\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5964 - accuracy: 0.8506 - val_loss: 0.3461 - val_accuracy: 0.9193\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5953 - accuracy: 0.8527 - val_loss: 0.3339 - val_accuracy: 0.9207\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5718 - accuracy: 0.8617 - val_loss: 0.3335 - val_accuracy: 0.9212\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5786 - accuracy: 0.8581 - val_loss: 0.3266 - val_accuracy: 0.9237\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5644 - accuracy: 0.8620 - val_loss: 0.3266 - val_accuracy: 0.9239\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5582 - accuracy: 0.8627 - val_loss: 0.3182 - val_accuracy: 0.9255\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5568 - accuracy: 0.8660 - val_loss: 0.3249 - val_accuracy: 0.9247\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5411 - accuracy: 0.8696 - val_loss: 0.3175 - val_accuracy: 0.9255\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5393 - accuracy: 0.8688 - val_loss: 0.3134 - val_accuracy: 0.9291\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5287 - accuracy: 0.8704 - val_loss: 0.3124 - val_accuracy: 0.9286\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5261 - accuracy: 0.8740 - val_loss: 0.3053 - val_accuracy: 0.9324\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5077 - accuracy: 0.8799 - val_loss: 0.3058 - val_accuracy: 0.9314\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5108 - accuracy: 0.8779 - val_loss: 0.3051 - val_accuracy: 0.9320\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5083 - accuracy: 0.8806 - val_loss: 0.3040 - val_accuracy: 0.9306\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4823 - accuracy: 0.8877 - val_loss: 0.3026 - val_accuracy: 0.9323\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4872 - accuracy: 0.8828 - val_loss: 0.2971 - val_accuracy: 0.9332\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4724 - accuracy: 0.8885 - val_loss: 0.2954 - val_accuracy: 0.9337\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4775 - accuracy: 0.8880 - val_loss: 0.2933 - val_accuracy: 0.9349\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4634 - accuracy: 0.8907 - val_loss: 0.2965 - val_accuracy: 0.9358\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4661 - accuracy: 0.8934 - val_loss: 0.2853 - val_accuracy: 0.9373\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4572 - accuracy: 0.8925 - val_loss: 0.2880 - val_accuracy: 0.9364\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4571 - accuracy: 0.8933 - val_loss: 0.2812 - val_accuracy: 0.9383\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4409 - accuracy: 0.8981 - val_loss: 0.2833 - val_accuracy: 0.9377\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 8ms/step - loss: 2.3023 - accuracy: 0.1173 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3015 - accuracy: 0.1146 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1134 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1163 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3014 - accuracy: 0.1126 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3014 - accuracy: 0.1117 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1154 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1156 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1150 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1136 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1137 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1159 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1161 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1145 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1150 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1126 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1157 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1121 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1158 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1122 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1168 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1165 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1154 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1129 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1145 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1137 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1132 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1125 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1137 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1157 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1186 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1131 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1151 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1144 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1150 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1132 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1152 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 5s 7ms/step - loss: 2.3023 - accuracy: 0.1146 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1103 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1138 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1153 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1156 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1156 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1132 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1134 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1150 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3008 - accuracy: 0.1123 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1151 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1141 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.3009 - accuracy: 0.1141 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1141 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1116 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1138 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1146 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1145 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1135 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1134 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1148 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1148 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1145 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1135 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1154 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1128 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1115 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1154 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1126 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1110 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1150 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1121 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1129 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1152 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "{'loss': [2.142557144165039, 1.7549446821212769, 1.538994312286377, 1.3965152502059937, 1.2889554500579834, 1.2102090120315552, 1.145815134048462, 1.1041181087493896, 1.0628663301467896, 1.0282390117645264, 0.9878280162811279, 0.9681331515312195, 0.9314455389976501, 0.9187147617340088, 0.8944123387336731, 0.8740514516830444, 0.8550112843513489, 0.8397640585899353, 0.8307700157165527, 0.8186795115470886, 0.8065692782402039, 0.7945266366004944, 0.77847820520401, 0.7620030045509338, 0.7607890367507935, 0.7489155530929565, 0.7434373497962952, 0.7332417964935303, 0.7213323712348938, 0.7113116979598999, 0.7079038619995117, 0.6937493681907654, 0.6870246529579163, 0.6856130957603455, 0.6682928204536438, 0.6633713245391846, 0.6510877013206482, 0.6415265798568726, 0.6395609974861145, 0.6289879679679871, 0.6271914839744568, 0.6215562224388123, 0.6158612966537476, 0.6043516397476196, 0.5989211201667786, 0.5940836071968079, 0.5861737132072449, 0.5838722586631775, 0.5743799805641174, 0.5611542463302612], 'accuracy': [0.2123958319425583, 0.3686666786670685, 0.4547083377838135, 0.5102083086967468, 0.549958348274231, 0.586020827293396, 0.6127916574478149, 0.6310625076293945, 0.6507291793823242, 0.666979193687439, 0.6849374771118164, 0.69552081823349, 0.7108749747276306, 0.7166041731834412, 0.7273125052452087, 0.7365624904632568, 0.7416250109672546, 0.7496041655540466, 0.7522083520889282, 0.7604166865348816, 0.7620833516120911, 0.768541693687439, 0.7758333086967468, 0.7792708277702332, 0.7813541889190674, 0.7874583601951599, 0.7896666526794434, 0.7952499985694885, 0.7984374761581421, 0.8055208325386047, 0.8072500228881836, 0.8114166855812073, 0.8166041374206543, 0.8204166889190674, 0.8256250023841858, 0.8304374814033508, 0.8333333134651184, 0.8377500176429749, 0.8400624990463257, 0.8419166803359985, 0.8443333506584167, 0.8486875295639038, 0.846750020980835, 0.8521875143051147, 0.8552916646003723, 0.8572291731834412, 0.8611249923706055, 0.8608958125114441, 0.8629375100135803, 0.8673333525657654], 'val_loss': [1.5097099542617798, 1.1759504079818726, 0.9905127882957458, 0.8887514472007751, 0.8248093128204346, 0.7839611172676086, 0.7406743764877319, 0.7154543399810791, 0.6814157962799072, 0.6604554653167725, 0.6358320713043213, 0.6190418601036072, 0.6000133752822876, 0.5865369439125061, 0.5778671503067017, 0.5719673037528992, 0.559316873550415, 0.549430787563324, 0.5478073358535767, 0.5412887930870056, 0.5291016697883606, 0.5224026441574097, 0.517541229724884, 0.5125167369842529, 0.49945974349975586, 0.48967444896698, 0.4869038462638855, 0.47910770773887634, 0.4701383113861084, 0.46551513671875, 0.4568611681461334, 0.46055567264556885, 0.44358327984809875, 0.4473499059677124, 0.43257054686546326, 0.42708444595336914, 0.42230460047721863, 0.41621023416519165, 0.410593181848526, 0.40133222937583923, 0.4013683795928955, 0.39082738757133484, 0.3931973874568939, 0.38669872283935547, 0.3894546329975128, 0.38047659397125244, 0.3747020661830902, 0.3704957664012909, 0.36674755811691284, 0.3675552308559418], 'val_accuracy': [0.5299999713897705, 0.6798333525657654, 0.7200833559036255, 0.7453333139419556, 0.7522500157356262, 0.768916666507721, 0.7768333554267883, 0.7908333539962769, 0.7990000247955322, 0.8025833368301392, 0.8149999976158142, 0.8147500157356262, 0.8212500214576721, 0.8270833492279053, 0.8326666951179504, 0.831416666507721, 0.843666672706604, 0.8508333563804626, 0.8493333458900452, 0.8476666808128357, 0.8578333258628845, 0.8666666746139526, 0.8606666922569275, 0.8667500019073486, 0.875333309173584, 0.8765000104904175, 0.8774166703224182, 0.8797500133514404, 0.8833333253860474, 0.8867499828338623, 0.8917499780654907, 0.8899999856948853, 0.8951666951179504, 0.893916666507721, 0.8974999785423279, 0.9016666412353516, 0.903249979019165, 0.9042500257492065, 0.90625, 0.9082499742507935, 0.909583330154419, 0.9109166860580444, 0.9111666679382324, 0.9135000109672546, 0.9143333435058594, 0.9165833592414856, 0.9179999828338623, 0.9182500243186951, 0.9203333258628845, 0.9213333129882812]}\n",
            "{'loss': [2.302541971206665, 2.301222801208496, 2.300856828689575, 2.300323009490967, 2.2997071743011475, 2.2978408336639404, 2.2940382957458496, 2.2771782875061035, 2.2247018814086914, 2.140254259109497, 2.062335729598999, 2.004481792449951, 1.9680484533309937, 1.9399687051773071, 1.9165395498275757, 1.9014904499053955, 1.8845906257629395, 1.8682806491851807, 1.8626168966293335, 1.8473875522613525, 1.8350481986999512, 1.812108039855957, 1.7928204536437988, 1.7782129049301147, 1.754469394683838, 1.7324548959732056, 1.7143707275390625, 1.6877444982528687, 1.6726266145706177, 1.6532480716705322, 1.6329902410507202, 1.6135709285736084, 1.6083459854125977, 1.5860008001327515, 1.5719996690750122, 1.5639728307724, 1.5472177267074585, 1.5373456478118896, 1.5223174095153809, 1.5064581632614136, 1.5049567222595215, 1.4913886785507202, 1.4838863611221313, 1.470184564590454, 1.4695171117782593, 1.4653452634811401, 1.4483931064605713, 1.4392343759536743, 1.4485594034194946, 1.4268962144851685], 'accuracy': [0.11385416984558105, 0.12179166823625565, 0.12018749862909317, 0.12195833027362823, 0.12391666322946548, 0.12785416841506958, 0.1378750056028366, 0.15693749487400055, 0.17922917008399963, 0.19435416162014008, 0.19712500274181366, 0.19602082669734955, 0.2018750011920929, 0.20495833456516266, 0.20389583706855774, 0.2057916671037674, 0.2108333259820938, 0.21318750083446503, 0.2238750010728836, 0.23085416853427887, 0.23908333480358124, 0.25306248664855957, 0.2639583349227905, 0.26774999499320984, 0.2772083282470703, 0.2901250123977661, 0.2954791784286499, 0.3023333251476288, 0.30425000190734863, 0.30687499046325684, 0.31206250190734863, 0.3150208294391632, 0.3167499899864197, 0.3232499957084656, 0.328020840883255, 0.32991665601730347, 0.33402082324028015, 0.3384166657924652, 0.3400000035762787, 0.343895822763443, 0.34304165840148926, 0.3462708294391632, 0.3466458320617676, 0.3503541648387909, 0.3512708246707916, 0.3518333435058594, 0.3570416569709778, 0.3543125092983246, 0.35466668009757996, 0.35631251335144043], 'val_loss': [2.302032709121704, 2.3018836975097656, 2.301499605178833, 2.300610303878784, 2.299638509750366, 2.2944021224975586, 2.2827258110046387, 2.2286365032196045, 2.1082217693328857, 1.9956656694412231, 1.9448350667953491, 1.9031946659088135, 1.877231478691101, 1.8586393594741821, 1.8483995199203491, 1.831779956817627, 1.8210619688034058, 1.813372015953064, 1.8036589622497559, 1.7926443815231323, 1.770602822303772, 1.7464957237243652, 1.722455382347107, 1.6877455711364746, 1.6744879484176636, 1.6239861249923706, 1.6312870979309082, 1.566760540008545, 1.5393472909927368, 1.5048329830169678, 1.4842071533203125, 1.505467176437378, 1.4430917501449585, 1.4336177110671997, 1.421052098274231, 1.3952369689941406, 1.3873305320739746, 1.4286051988601685, 1.3772848844528198, 1.3622353076934814, 1.3493515253067017, 1.3558694124221802, 1.4016250371932983, 1.4446629285812378, 1.3659133911132812, 1.3189975023269653, 1.3183566331863403, 1.3093302249908447, 1.3174983263015747, 1.2971715927124023], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.1068333312869072, 0.15666666626930237, 0.20091666281223297, 0.2057500034570694, 0.2082500010728836, 0.1951666623353958, 0.20741666853427887, 0.20741666853427887, 0.19591666758060455, 0.20491667091846466, 0.21016666293144226, 0.210916668176651, 0.21583333611488342, 0.2436666637659073, 0.23774999380111694, 0.24058333039283752, 0.27300000190734863, 0.27816668152809143, 0.3239166736602783, 0.2953333258628845, 0.335833340883255, 0.3061666786670685, 0.35899999737739563, 0.3701666593551636, 0.33649998903274536, 0.35233333706855774, 0.3558333218097687, 0.3682500123977661, 0.3766666650772095, 0.38483333587646484, 0.3765000104904175, 0.38999998569488525, 0.3893333375453949, 0.3785833418369293, 0.3893333375453949, 0.3908333480358124, 0.3916666805744171, 0.3472500145435333, 0.35374999046325684, 0.4039166569709778, 0.3817499876022339, 0.38483333587646484, 0.39774999022483826, 0.4012500047683716, 0.4025833308696747]}\n",
            "{'loss': [2.30136775970459, 2.297544002532959, 2.2884774208068848, 2.2596535682678223, 2.1995716094970703, 2.131901264190674, 2.059563398361206, 1.9874353408813477, 1.9159331321716309, 1.8492540121078491, 1.7961857318878174, 1.757212519645691, 1.71770441532135, 1.6916117668151855, 1.6575387716293335, 1.6252975463867188, 1.588809847831726, 1.5486254692077637, 1.504033088684082, 1.4568614959716797, 1.4240608215332031, 1.3882147073745728, 1.354662299156189, 1.33318293094635, 1.31150221824646, 1.2759206295013428, 1.251164197921753, 1.2314928770065308, 1.2093161344528198, 1.183924674987793, 1.1737339496612549, 1.1492056846618652, 1.1244113445281982, 1.108575701713562, 1.086635708808899, 1.0782746076583862, 1.069252848625183, 1.0450670719146729, 1.0234891176223755, 1.0101310014724731, 0.9903514981269836, 0.9718186259269714, 0.9698129296302795, 0.9482527375221252, 0.9240577220916748, 0.8986388444900513, 0.8845034837722778, 0.8690976500511169, 0.8760240077972412, 0.849317193031311], 'accuracy': [0.11704166978597641, 0.13179166615009308, 0.15043750405311584, 0.1742916703224182, 0.19477082788944244, 0.2070416659116745, 0.21933333575725555, 0.2277500033378601, 0.23920834064483643, 0.25331249833106995, 0.2645208239555359, 0.2720208466053009, 0.2776458263397217, 0.2879166603088379, 0.296916663646698, 0.3141666650772095, 0.3387708365917206, 0.3656458258628845, 0.3920416533946991, 0.4074999988079071, 0.4230000078678131, 0.4334791600704193, 0.44612500071525574, 0.4581041634082794, 0.46541666984558105, 0.4802916646003723, 0.48897916078567505, 0.49814581871032715, 0.5096874833106995, 0.5195208191871643, 0.5255625247955322, 0.5378958582878113, 0.5445625185966492, 0.5534374713897705, 0.562208354473114, 0.567229151725769, 0.5720624923706055, 0.5838750004768372, 0.5949166417121887, 0.5947708487510681, 0.6071875095367432, 0.6150416731834412, 0.6199583411216736, 0.6262083053588867, 0.6377291679382324, 0.6458541750907898, 0.6556249856948853, 0.6624166369438171, 0.6618333458900452, 0.6690833568572998], 'val_loss': [2.301588535308838, 2.2964835166931152, 2.27040433883667, 2.2007534503936768, 2.0908427238464355, 2.0129635334014893, 1.9119298458099365, 1.8429150581359863, 1.758208990097046, 1.6982669830322266, 1.6489468812942505, 1.6168839931488037, 1.5876166820526123, 1.5537821054458618, 1.522263526916504, 1.4909214973449707, 1.445554494857788, 1.3947675228118896, 1.3487637042999268, 1.319883108139038, 1.2720885276794434, 1.2478302717208862, 1.2135499715805054, 1.181542992591858, 1.1595776081085205, 1.1331636905670166, 1.118073582649231, 1.0931881666183472, 1.0706270933151245, 1.0603959560394287, 1.0339382886886597, 1.0132699012756348, 1.0050112009048462, 0.9903998970985413, 0.9729581475257874, 0.9785563945770264, 0.9545307755470276, 0.9456079006195068, 0.9233139753341675, 0.9150922298431396, 0.8983793258666992, 0.9033492803573608, 0.8691727519035339, 0.9118561744689941, 0.8264906406402588, 0.8278703093528748, 0.8173113465309143, 0.7897691130638123, 0.7686219811439514, 0.7846918702125549], 'val_accuracy': [0.10599999874830246, 0.10991666465997696, 0.1808333396911621, 0.20483332872390747, 0.21275000274181366, 0.22499999403953552, 0.23858332633972168, 0.2670833468437195, 0.2906666696071625, 0.30399999022483826, 0.31700000166893005, 0.3178333342075348, 0.3296666741371155, 0.367000013589859, 0.414166659116745, 0.42116665840148926, 0.46291667222976685, 0.4662500023841858, 0.47866666316986084, 0.4675000011920929, 0.5191666483879089, 0.51583331823349, 0.51541668176651, 0.5255833268165588, 0.5425000190734863, 0.5516666769981384, 0.5450000166893005, 0.562166690826416, 0.5822499990463257, 0.5918333530426025, 0.6178333163261414, 0.6234999895095825, 0.6259999871253967, 0.6184166669845581, 0.6131666898727417, 0.628000020980835, 0.656083345413208, 0.6549999713897705, 0.6744999885559082, 0.6899166703224182, 0.690583348274231, 0.6946666836738586, 0.6972500085830688, 0.6803333163261414, 0.7120833396911621, 0.7213333249092102, 0.7260833382606506, 0.718500018119812, 0.7296666502952576, 0.73416668176651]}\n",
            "{'loss': [2.1017630100250244, 1.6427924633026123, 1.4008431434631348, 1.246374249458313, 1.142166018486023, 1.0585737228393555, 0.9925149083137512, 0.9566824436187744, 0.9168041348457336, 0.8821551203727722, 0.8659284114837646, 0.8298543095588684, 0.8102242946624756, 0.7934718132019043, 0.7739917039871216, 0.7509680390357971, 0.7396987080574036, 0.7293994426727295, 0.7080270051956177, 0.6898187398910522, 0.6795458197593689, 0.6653081178665161, 0.6496456861495972, 0.6475003957748413, 0.6287535429000854, 0.6093540191650391, 0.6065720915794373, 0.6004295945167542, 0.5933606624603271, 0.5794186592102051, 0.5663161873817444, 0.5567745566368103, 0.5497546792030334, 0.5369361639022827, 0.5354951620101929, 0.5217354893684387, 0.5237404704093933, 0.5064581036567688, 0.5012435913085938, 0.497233122587204, 0.48618224263191223, 0.4760069251060486, 0.47775933146476746, 0.4714176058769226, 0.46790412068367004, 0.4619580805301666, 0.44964879751205444, 0.4468728303909302, 0.4392149746417999, 0.4271271526813507], 'accuracy': [0.23216666281223297, 0.41081249713897705, 0.5064583420753479, 0.5680833458900452, 0.613895833492279, 0.653333306312561, 0.6774791479110718, 0.695562481880188, 0.7118750214576721, 0.7251666784286499, 0.73416668176651, 0.7457916736602783, 0.7558541893959045, 0.7646666765213013, 0.7727291584014893, 0.7821041941642761, 0.7871041893959045, 0.7922499775886536, 0.7990416884422302, 0.8069999814033508, 0.8096458315849304, 0.8204166889190674, 0.8229583501815796, 0.8247500061988831, 0.8311458230018616, 0.8379583358764648, 0.8401041626930237, 0.8420624732971191, 0.8472916483879089, 0.85135418176651, 0.8547916412353516, 0.8590624928474426, 0.8611041903495789, 0.8659583330154419, 0.8665416836738586, 0.8683958053588867, 0.8689374923706055, 0.8736875057220459, 0.8784791827201843, 0.8783749938011169, 0.8797916769981384, 0.8832291960716248, 0.8853958249092102, 0.8870833516120911, 0.8870416879653931, 0.8899166584014893, 0.8926041722297668, 0.893666684627533, 0.8957499861717224, 0.8970416784286499], 'val_loss': [1.2969287633895874, 0.911869466304779, 0.7089089155197144, 0.5945093035697937, 0.5354111194610596, 0.4984431266784668, 0.47555723786354065, 0.45967957377433777, 0.44254857301712036, 0.4362829923629761, 0.426026314496994, 0.4098007082939148, 0.4049242436885834, 0.3961392939090729, 0.39017990231513977, 0.3820129334926605, 0.37207162380218506, 0.3632644712924957, 0.36301326751708984, 0.35792577266693115, 0.34756457805633545, 0.34646329283714294, 0.334856778383255, 0.333493173122406, 0.32476696372032166, 0.3245704472064972, 0.31934282183647156, 0.31797364354133606, 0.3068486452102661, 0.31760379672050476, 0.2998081147670746, 0.30514782667160034, 0.2954602837562561, 0.2970450222492218, 0.2939714789390564, 0.28798410296440125, 0.2895021140575409, 0.285546213388443, 0.28460991382598877, 0.2803480923175812, 0.279435932636261, 0.2826843857765198, 0.2731500566005707, 0.27373436093330383, 0.27441608905792236, 0.26928991079330444, 0.26568368077278137, 0.26184773445129395, 0.2586287260055542, 0.2662668228149414], 'val_accuracy': [0.6479166746139526, 0.7293333411216736, 0.8019166588783264, 0.8368333578109741, 0.8510000109672546, 0.8585000038146973, 0.8673333525657654, 0.8729166388511658, 0.8790833353996277, 0.8793333172798157, 0.8816666603088379, 0.8880833387374878, 0.890500009059906, 0.8930833339691162, 0.8941666483879089, 0.8954166769981384, 0.8992499709129333, 0.9025833606719971, 0.902999997138977, 0.9058333039283752, 0.9080833196640015, 0.9080833196640015, 0.9123333096504211, 0.9132500290870667, 0.9144999980926514, 0.9171666502952576, 0.9175000190734863, 0.9168333411216736, 0.9207500219345093, 0.918749988079071, 0.925000011920929, 0.9242500066757202, 0.9259999990463257, 0.9259999990463257, 0.9275000095367432, 0.9273333549499512, 0.9286666512489319, 0.9309166669845581, 0.9308333396911621, 0.9317499995231628, 0.934416651725769, 0.9318333268165588, 0.934333324432373, 0.9359166622161865, 0.934583306312561, 0.937250018119812, 0.9386666417121887, 0.9394999742507935, 0.9382500052452087, 0.9394166469573975]}\n",
            "{'loss': [2.28374981880188, 1.565798282623291, 1.301439642906189, 1.1719655990600586, 1.0960400104522705, 1.0379078388214111, 1.0002293586730957, 0.9657465815544128, 0.9284267425537109, 0.9073220491409302, 0.8699897527694702, 0.8392199873924255, 0.814132571220398, 0.7965506315231323, 0.7689520716667175, 0.748710036277771, 0.7382034659385681, 0.7163556218147278, 0.7026405334472656, 0.691628634929657, 0.680375874042511, 0.6597694754600525, 0.6491257548332214, 0.6445493698120117, 0.6315315365791321, 0.6171841025352478, 0.6026273369789124, 0.593343198299408, 0.5930778384208679, 0.583128035068512, 0.5744687914848328, 0.5593143701553345, 0.5544679760932922, 0.5510488748550415, 0.546471118927002, 0.5332130193710327, 0.5203210711479187, 0.5187249183654785, 0.5081909894943237, 0.5050051212310791, 0.5070682168006897, 0.4894549250602722, 0.4857878088951111, 0.48070138692855835, 0.475267618894577, 0.46697893738746643, 0.46888354420661926, 0.45469847321510315, 0.45750972628593445, 0.4454137682914734], 'accuracy': [0.23906250298023224, 0.42531248927116394, 0.5327083468437195, 0.5865625143051147, 0.6207083463668823, 0.6412708163261414, 0.6616041660308838, 0.6775000095367432, 0.694979190826416, 0.7073125243186951, 0.7273125052452087, 0.742562472820282, 0.7546250224113464, 0.7661874890327454, 0.78104168176651, 0.7894166707992554, 0.7970208525657654, 0.8063125014305115, 0.8118749856948853, 0.817395806312561, 0.8218541741371155, 0.8271458148956299, 0.8345624804496765, 0.8370208144187927, 0.8396875262260437, 0.8457916378974915, 0.8489166498184204, 0.8533541560173035, 0.8546666502952576, 0.8571875095367432, 0.8601874709129333, 0.8637708425521851, 0.8652916550636292, 0.8663541674613953, 0.8691458106040955, 0.870479166507721, 0.8755833506584167, 0.8757708072662354, 0.8792499899864197, 0.8788124918937683, 0.8809999823570251, 0.8852291703224182, 0.8846874833106995, 0.885770857334137, 0.8895624876022339, 0.890500009059906, 0.8918125033378601, 0.8940208554267883, 0.8929791450500488, 0.8974375128746033], 'val_loss': [1.145703673362732, 0.8532825708389282, 0.7369179725646973, 0.690190851688385, 0.6581316590309143, 0.6277887225151062, 0.6085094213485718, 0.5826042294502258, 0.5526964664459229, 0.526317298412323, 0.4885300397872925, 0.46873053908348083, 0.44484826922416687, 0.4216224253177643, 0.41145068407058716, 0.40120431780815125, 0.3918500542640686, 0.3933265507221222, 0.384447306394577, 0.3741840720176697, 0.36729300022125244, 0.365416020154953, 0.36123332381248474, 0.35211890935897827, 0.3519943356513977, 0.347979336977005, 0.3491453528404236, 0.34605589509010315, 0.33388423919677734, 0.33351489901542664, 0.32655274868011475, 0.32657140493392944, 0.3182229697704315, 0.324912965297699, 0.31748703122138977, 0.3134426772594452, 0.3123772442340851, 0.3053266406059265, 0.3058335483074188, 0.30510881543159485, 0.30397653579711914, 0.3025670647621155, 0.29710641503334045, 0.29544880986213684, 0.29327765107154846, 0.2964588403701782, 0.28532642126083374, 0.28798314929008484, 0.28121259808540344, 0.2832852900028229], 'val_accuracy': [0.6478333473205566, 0.7351666688919067, 0.7613333463668823, 0.7627500295639038, 0.8080000281333923, 0.8295000195503235, 0.8316666483879089, 0.8410833477973938, 0.8477500081062317, 0.8693333268165588, 0.8763333559036255, 0.8755000233650208, 0.890333354473114, 0.893750011920929, 0.8980000019073486, 0.9017500281333923, 0.9043333530426025, 0.9036666750907898, 0.9054166674613953, 0.9077500104904175, 0.909583330154419, 0.9104999899864197, 0.9120833277702332, 0.9143333435058594, 0.9160000085830688, 0.9164999723434448, 0.9150000214576721, 0.9192500114440918, 0.9206666946411133, 0.9211666584014893, 0.9237499833106995, 0.9239166378974915, 0.9254999756813049, 0.9247499704360962, 0.9254999756813049, 0.9290833473205566, 0.9285833239555359, 0.9324166774749756, 0.9314166903495789, 0.9319999814033508, 0.9305833578109741, 0.9323333501815796, 0.9331666827201843, 0.9337499737739563, 0.9349166750907898, 0.9358333349227905, 0.937333345413208, 0.9364166855812073, 0.9383333325386047, 0.937749981880188]}\n",
            "{'loss': [2.3020734786987305, 2.301464080810547, 2.30117130279541, 2.3010151386260986, 2.301081657409668, 2.3010144233703613, 2.301011323928833, 2.3010060787200928, 2.3010635375976562, 2.3010082244873047, 2.3009731769561768, 2.3009824752807617, 2.301018714904785, 2.3010172843933105, 2.3009650707244873, 2.3009138107299805, 2.300985813140869, 2.3009748458862305, 2.300931215286255, 2.300910472869873, 2.300900459289551, 2.3009376525878906, 2.30094313621521, 2.300935983657837, 2.3008854389190674, 2.3009045124053955, 2.300893783569336, 2.300936698913574, 2.3009064197540283, 2.3009145259857178, 2.3008697032928467, 2.300924301147461, 2.3008954524993896, 2.3008804321289062, 2.3008768558502197, 2.3008506298065186, 2.300853729248047, 2.3008594512939453, 2.300830364227295, 2.3008663654327393, 2.300839424133301, 2.3008275032043457, 2.300816059112549, 2.300837993621826, 2.3008038997650146, 2.300787925720215, 2.3007779121398926, 2.300776958465576, 2.300776720046997, 2.3007805347442627], 'accuracy': [0.11406250298023224, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3020782470703125, 2.3019492626190186, 2.301942825317383, 2.301989793777466, 2.301999568939209, 2.3020291328430176, 2.302064895629883, 2.302065372467041, 2.3020617961883545, 2.3020331859588623, 2.302063226699829, 2.302027940750122, 2.3020379543304443, 2.3020222187042236, 2.302030563354492, 2.3020570278167725, 2.3020479679107666, 2.3020198345184326, 2.3020074367523193, 2.30204439163208, 2.3020520210266113, 2.302018165588379, 2.3020119667053223, 2.302018880844116, 2.3019888401031494, 2.301983118057251, 2.3019511699676514, 2.301959276199341, 2.3019485473632812, 2.3019371032714844, 2.301952838897705, 2.3019216060638428, 2.3019492626190186, 2.3019237518310547, 2.301917552947998, 2.3019213676452637, 2.301931142807007, 2.301891565322876, 2.3018980026245117, 2.301898717880249, 2.3018980026245117, 2.3018693923950195, 2.3018429279327393, 2.3018369674682617, 2.301881790161133, 2.3018627166748047, 2.3018670082092285, 2.301884412765503, 2.3018548488616943, 2.301828145980835], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
            "{'loss': [2.3020360469818115, 2.3013365268707275, 2.30114483833313, 2.301100969314575, 2.3011040687561035, 2.3010149002075195, 2.3010594844818115, 2.3010830879211426, 2.3010048866271973, 2.3009958267211914, 2.300995349884033, 2.3009562492370605, 2.300992012023926, 2.300999402999878, 2.3009510040283203, 2.3009159564971924, 2.300943613052368, 2.3009307384490967, 2.300887107849121, 2.3009462356567383, 2.300921678543091, 2.3009347915649414, 2.3009181022644043, 2.300935983657837, 2.300900459289551, 2.300884485244751, 2.3008933067321777, 2.3008899688720703, 2.30090594291687, 2.3008995056152344, 2.3008475303649902, 2.30084228515625, 2.3008804321289062, 2.300863742828369, 2.300844430923462, 2.3008460998535156, 2.3008241653442383, 2.3008296489715576, 2.30081844329834, 2.3008413314819336, 2.300797462463379, 2.3007755279541016, 2.300779342651367, 2.300772190093994, 2.3007476329803467, 2.300769805908203, 2.3007636070251465, 2.3007564544677734, 2.300722599029541, 2.3007192611694336], 'accuracy': [0.11400000005960464, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3019771575927734, 2.3018836975097656, 2.301928758621216, 2.3019676208496094, 2.3019826412200928, 2.3019871711730957, 2.302018642425537, 2.302002429962158, 2.3020176887512207, 2.302025556564331, 2.302039861679077, 2.3020381927490234, 2.302029848098755, 2.302025556564331, 2.3020105361938477, 2.3019893169403076, 2.302011251449585, 2.302020788192749, 2.302046775817871, 2.3020288944244385, 2.302004814147949, 2.3019893169403076, 2.3019790649414062, 2.3019602298736572, 2.3019564151763916, 2.3019556999206543, 2.3019509315490723, 2.3019821643829346, 2.3019683361053467, 2.3019602298736572, 2.301943778991699, 2.3019325733184814, 2.301938772201538, 2.3019371032714844, 2.3019325733184814, 2.3019278049468994, 2.301910877227783, 2.3019113540649414, 2.3019328117370605, 2.301907777786255, 2.3018980026245117, 2.3019001483917236, 2.3018851280212402, 2.3018507957458496, 2.3018248081207275, 2.3018360137939453, 2.301841974258423, 2.301830291748047, 2.301828384399414, 2.3018083572387695], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}