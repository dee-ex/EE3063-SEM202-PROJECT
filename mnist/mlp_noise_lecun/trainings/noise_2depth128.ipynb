{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noise_2depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "1cd60833-2924-422b-a801-467875a55ab9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 17s 5ms/step - loss: 1.5698 - accuracy: 0.4885 - val_loss: 0.5984 - val_accuracy: 0.8573\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7029 - accuracy: 0.7944 - val_loss: 0.4560 - val_accuracy: 0.8777\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5634 - accuracy: 0.8343 - val_loss: 0.4050 - val_accuracy: 0.8870\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5101 - accuracy: 0.8455 - val_loss: 0.3774 - val_accuracy: 0.8935\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4764 - accuracy: 0.8565 - val_loss: 0.3616 - val_accuracy: 0.8958\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4662 - accuracy: 0.8588 - val_loss: 0.3495 - val_accuracy: 0.8999\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.8670 - val_loss: 0.3423 - val_accuracy: 0.9001\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4349 - accuracy: 0.8698 - val_loss: 0.3359 - val_accuracy: 0.9015\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4290 - accuracy: 0.8728 - val_loss: 0.3298 - val_accuracy: 0.9028\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4111 - accuracy: 0.8765 - val_loss: 0.3250 - val_accuracy: 0.9045\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - accuracy: 0.8780 - val_loss: 0.3211 - val_accuracy: 0.9047\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3956 - accuracy: 0.8808 - val_loss: 0.3181 - val_accuracy: 0.9058\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3984 - accuracy: 0.8798 - val_loss: 0.3150 - val_accuracy: 0.9071\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3797 - accuracy: 0.8867 - val_loss: 0.3125 - val_accuracy: 0.9078\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3740 - accuracy: 0.8904 - val_loss: 0.3103 - val_accuracy: 0.9083\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3728 - accuracy: 0.8879 - val_loss: 0.3085 - val_accuracy: 0.9089\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3698 - accuracy: 0.8882 - val_loss: 0.3066 - val_accuracy: 0.9091\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3605 - accuracy: 0.8926 - val_loss: 0.3045 - val_accuracy: 0.9095\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3626 - accuracy: 0.8911 - val_loss: 0.3019 - val_accuracy: 0.9114\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.8939 - val_loss: 0.3002 - val_accuracy: 0.9113\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3689 - accuracy: 0.8910 - val_loss: 0.2987 - val_accuracy: 0.9122\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8929 - val_loss: 0.2970 - val_accuracy: 0.9140\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3535 - accuracy: 0.8946 - val_loss: 0.2954 - val_accuracy: 0.9133\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3419 - accuracy: 0.8961 - val_loss: 0.2937 - val_accuracy: 0.9137\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8978 - val_loss: 0.2927 - val_accuracy: 0.9145\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8971 - val_loss: 0.2917 - val_accuracy: 0.9151\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8989 - val_loss: 0.2900 - val_accuracy: 0.9158\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.9027 - val_loss: 0.2884 - val_accuracy: 0.9155\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.9017 - val_loss: 0.2877 - val_accuracy: 0.9168\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.9032 - val_loss: 0.2863 - val_accuracy: 0.9163\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3226 - accuracy: 0.9047 - val_loss: 0.2854 - val_accuracy: 0.9168\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.9032 - val_loss: 0.2835 - val_accuracy: 0.9168\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.9005 - val_loss: 0.2821 - val_accuracy: 0.9176\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.9038 - val_loss: 0.2822 - val_accuracy: 0.9172\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3130 - accuracy: 0.9079 - val_loss: 0.2798 - val_accuracy: 0.9180\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.9079 - val_loss: 0.2783 - val_accuracy: 0.9182\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.9058 - val_loss: 0.2775 - val_accuracy: 0.9188\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3067 - accuracy: 0.9053 - val_loss: 0.2769 - val_accuracy: 0.9179\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.9080 - val_loss: 0.2755 - val_accuracy: 0.9187\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.9085 - val_loss: 0.2736 - val_accuracy: 0.9178\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3101 - accuracy: 0.9074 - val_loss: 0.2735 - val_accuracy: 0.9189\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3085 - accuracy: 0.9077 - val_loss: 0.2714 - val_accuracy: 0.9203\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2990 - accuracy: 0.9114 - val_loss: 0.2704 - val_accuracy: 0.9193\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3031 - accuracy: 0.9101 - val_loss: 0.2692 - val_accuracy: 0.9197\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.9116 - val_loss: 0.2692 - val_accuracy: 0.9191\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2959 - accuracy: 0.9126 - val_loss: 0.2672 - val_accuracy: 0.9208\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.9118 - val_loss: 0.2664 - val_accuracy: 0.9228\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.9110 - val_loss: 0.2648 - val_accuracy: 0.9211\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.9117 - val_loss: 0.2633 - val_accuracy: 0.9225\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2952 - accuracy: 0.9121 - val_loss: 0.2631 - val_accuracy: 0.9214\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9952 - accuracy: 0.3055 - val_loss: 0.8674 - val_accuracy: 0.8109\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0010 - accuracy: 0.6893 - val_loss: 0.5443 - val_accuracy: 0.8645\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7336 - accuracy: 0.7732 - val_loss: 0.4454 - val_accuracy: 0.8815\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6277 - accuracy: 0.8053 - val_loss: 0.3948 - val_accuracy: 0.8915\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5678 - accuracy: 0.8300 - val_loss: 0.3664 - val_accuracy: 0.8963\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.8414 - val_loss: 0.3421 - val_accuracy: 0.9004\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.8541 - val_loss: 0.3241 - val_accuracy: 0.9043\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4625 - accuracy: 0.8614 - val_loss: 0.3108 - val_accuracy: 0.9084\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4488 - accuracy: 0.8664 - val_loss: 0.2986 - val_accuracy: 0.9120\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4236 - accuracy: 0.8736 - val_loss: 0.2873 - val_accuracy: 0.9146\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4039 - accuracy: 0.8805 - val_loss: 0.2778 - val_accuracy: 0.9174\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3880 - accuracy: 0.8854 - val_loss: 0.2692 - val_accuracy: 0.9192\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8870 - val_loss: 0.2610 - val_accuracy: 0.9221\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8934 - val_loss: 0.2541 - val_accuracy: 0.9247\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3484 - accuracy: 0.8946 - val_loss: 0.2472 - val_accuracy: 0.9269\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8974 - val_loss: 0.2410 - val_accuracy: 0.9276\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3293 - accuracy: 0.9017 - val_loss: 0.2345 - val_accuracy: 0.9301\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.9058 - val_loss: 0.2303 - val_accuracy: 0.9310\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3090 - accuracy: 0.9092 - val_loss: 0.2247 - val_accuracy: 0.9317\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.9096 - val_loss: 0.2193 - val_accuracy: 0.9345\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2970 - accuracy: 0.9109 - val_loss: 0.2162 - val_accuracy: 0.9349\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2955 - accuracy: 0.9133 - val_loss: 0.2107 - val_accuracy: 0.9370\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2798 - accuracy: 0.9181 - val_loss: 0.2075 - val_accuracy: 0.9370\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.9192 - val_loss: 0.2030 - val_accuracy: 0.9383\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2582 - accuracy: 0.9229 - val_loss: 0.2004 - val_accuracy: 0.9384\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2618 - accuracy: 0.9235 - val_loss: 0.1968 - val_accuracy: 0.9402\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2488 - accuracy: 0.9259 - val_loss: 0.1936 - val_accuracy: 0.9413\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2596 - accuracy: 0.9234 - val_loss: 0.1907 - val_accuracy: 0.9420\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2496 - accuracy: 0.9273 - val_loss: 0.1872 - val_accuracy: 0.9432\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2448 - accuracy: 0.9297 - val_loss: 0.1846 - val_accuracy: 0.9438\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2389 - accuracy: 0.9288 - val_loss: 0.1817 - val_accuracy: 0.9445\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2275 - accuracy: 0.9319 - val_loss: 0.1794 - val_accuracy: 0.9448\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2272 - accuracy: 0.9323 - val_loss: 0.1772 - val_accuracy: 0.9454\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2241 - accuracy: 0.9337 - val_loss: 0.1749 - val_accuracy: 0.9457\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2184 - accuracy: 0.9364 - val_loss: 0.1731 - val_accuracy: 0.9467\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2182 - accuracy: 0.9343 - val_loss: 0.1708 - val_accuracy: 0.9475\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2140 - accuracy: 0.9385 - val_loss: 0.1688 - val_accuracy: 0.9474\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2096 - accuracy: 0.9375 - val_loss: 0.1662 - val_accuracy: 0.9488\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2102 - accuracy: 0.9360 - val_loss: 0.1642 - val_accuracy: 0.9489\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2047 - accuracy: 0.9376 - val_loss: 0.1624 - val_accuracy: 0.9500\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1978 - accuracy: 0.9402 - val_loss: 0.1614 - val_accuracy: 0.9497\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1897 - accuracy: 0.9440 - val_loss: 0.1596 - val_accuracy: 0.9506\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2013 - accuracy: 0.9405 - val_loss: 0.1584 - val_accuracy: 0.9508\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9458 - val_loss: 0.1567 - val_accuracy: 0.9514\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1856 - accuracy: 0.9451 - val_loss: 0.1552 - val_accuracy: 0.9517\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1824 - accuracy: 0.9468 - val_loss: 0.1531 - val_accuracy: 0.9534\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1772 - accuracy: 0.9469 - val_loss: 0.1517 - val_accuracy: 0.9538\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1779 - accuracy: 0.9468 - val_loss: 0.1505 - val_accuracy: 0.9538\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1722 - accuracy: 0.9512 - val_loss: 0.1493 - val_accuracy: 0.9535\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1692 - accuracy: 0.9498 - val_loss: 0.1475 - val_accuracy: 0.9546\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9213 - accuracy: 0.3546 - val_loss: 0.7890 - val_accuracy: 0.8282\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.9113 - accuracy: 0.7231 - val_loss: 0.5139 - val_accuracy: 0.8698\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6728 - accuracy: 0.7956 - val_loss: 0.4308 - val_accuracy: 0.8825\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5918 - accuracy: 0.8218 - val_loss: 0.3885 - val_accuracy: 0.8912\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5265 - accuracy: 0.8379 - val_loss: 0.3627 - val_accuracy: 0.8982\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4987 - accuracy: 0.8485 - val_loss: 0.3450 - val_accuracy: 0.9006\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4663 - accuracy: 0.8641 - val_loss: 0.3292 - val_accuracy: 0.9032\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.8662 - val_loss: 0.3172 - val_accuracy: 0.9063\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4274 - accuracy: 0.8731 - val_loss: 0.3080 - val_accuracy: 0.9100\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4070 - accuracy: 0.8781 - val_loss: 0.2986 - val_accuracy: 0.9110\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3918 - accuracy: 0.8858 - val_loss: 0.2910 - val_accuracy: 0.9141\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3835 - accuracy: 0.8885 - val_loss: 0.2840 - val_accuracy: 0.9156\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.8882 - val_loss: 0.2774 - val_accuracy: 0.9178\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3680 - accuracy: 0.8912 - val_loss: 0.2708 - val_accuracy: 0.9190\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3534 - accuracy: 0.8957 - val_loss: 0.2650 - val_accuracy: 0.9210\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8983 - val_loss: 0.2602 - val_accuracy: 0.9222\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3358 - accuracy: 0.8994 - val_loss: 0.2550 - val_accuracy: 0.9235\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3209 - accuracy: 0.9040 - val_loss: 0.2503 - val_accuracy: 0.9249\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3214 - accuracy: 0.9039 - val_loss: 0.2458 - val_accuracy: 0.9260\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.9071 - val_loss: 0.2419 - val_accuracy: 0.9270\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3090 - accuracy: 0.9071 - val_loss: 0.2387 - val_accuracy: 0.9277\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2991 - accuracy: 0.9116 - val_loss: 0.2342 - val_accuracy: 0.9294\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2949 - accuracy: 0.9123 - val_loss: 0.2307 - val_accuracy: 0.9303\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9154 - val_loss: 0.2272 - val_accuracy: 0.9314\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.9124 - val_loss: 0.2236 - val_accuracy: 0.9326\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.9155 - val_loss: 0.2204 - val_accuracy: 0.9337\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.9190 - val_loss: 0.2182 - val_accuracy: 0.9336\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.9202 - val_loss: 0.2157 - val_accuracy: 0.9355\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2548 - accuracy: 0.9257 - val_loss: 0.2118 - val_accuracy: 0.9361\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2541 - accuracy: 0.9243 - val_loss: 0.2091 - val_accuracy: 0.9369\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2523 - accuracy: 0.9243 - val_loss: 0.2066 - val_accuracy: 0.9369\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2565 - accuracy: 0.9244 - val_loss: 0.2043 - val_accuracy: 0.9377\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2475 - accuracy: 0.9274 - val_loss: 0.2019 - val_accuracy: 0.9388\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2376 - accuracy: 0.9296 - val_loss: 0.1996 - val_accuracy: 0.9398\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2362 - accuracy: 0.9312 - val_loss: 0.1971 - val_accuracy: 0.9399\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2410 - accuracy: 0.9276 - val_loss: 0.1957 - val_accuracy: 0.9408\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2274 - accuracy: 0.9316 - val_loss: 0.1930 - val_accuracy: 0.9410\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2308 - accuracy: 0.9317 - val_loss: 0.1909 - val_accuracy: 0.9423\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2228 - accuracy: 0.9335 - val_loss: 0.1893 - val_accuracy: 0.9417\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2152 - accuracy: 0.9347 - val_loss: 0.1882 - val_accuracy: 0.9423\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2181 - accuracy: 0.9359 - val_loss: 0.1855 - val_accuracy: 0.9439\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2175 - accuracy: 0.9351 - val_loss: 0.1834 - val_accuracy: 0.9440\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2091 - accuracy: 0.9378 - val_loss: 0.1824 - val_accuracy: 0.9451\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2079 - accuracy: 0.9393 - val_loss: 0.1804 - val_accuracy: 0.9449\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2072 - accuracy: 0.9382 - val_loss: 0.1796 - val_accuracy: 0.9453\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2057 - accuracy: 0.9378 - val_loss: 0.1777 - val_accuracy: 0.9464\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2007 - accuracy: 0.9421 - val_loss: 0.1762 - val_accuracy: 0.9463\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1941 - accuracy: 0.9430 - val_loss: 0.1747 - val_accuracy: 0.9473\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1921 - accuracy: 0.9436 - val_loss: 0.1738 - val_accuracy: 0.9472\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1920 - accuracy: 0.9422 - val_loss: 0.1721 - val_accuracy: 0.9483\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5731 - accuracy: 0.4869 - val_loss: 0.5773 - val_accuracy: 0.8534\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6767 - accuracy: 0.7959 - val_loss: 0.4432 - val_accuracy: 0.8776\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5660 - accuracy: 0.8302 - val_loss: 0.3967 - val_accuracy: 0.8863\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5137 - accuracy: 0.8430 - val_loss: 0.3723 - val_accuracy: 0.8920\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4727 - accuracy: 0.8589 - val_loss: 0.3570 - val_accuracy: 0.8949\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4588 - accuracy: 0.8614 - val_loss: 0.3453 - val_accuracy: 0.8992\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4375 - accuracy: 0.8679 - val_loss: 0.3370 - val_accuracy: 0.9013\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4189 - accuracy: 0.8761 - val_loss: 0.3304 - val_accuracy: 0.9021\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4164 - accuracy: 0.8739 - val_loss: 0.3257 - val_accuracy: 0.9043\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4045 - accuracy: 0.8796 - val_loss: 0.3189 - val_accuracy: 0.9068\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3931 - accuracy: 0.8835 - val_loss: 0.3151 - val_accuracy: 0.9074\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8829 - val_loss: 0.3114 - val_accuracy: 0.9078\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3827 - accuracy: 0.8849 - val_loss: 0.3075 - val_accuracy: 0.9087\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3804 - accuracy: 0.8865 - val_loss: 0.3039 - val_accuracy: 0.9089\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.8905 - val_loss: 0.3007 - val_accuracy: 0.9103\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3708 - accuracy: 0.8903 - val_loss: 0.2977 - val_accuracy: 0.9112\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3593 - accuracy: 0.8912 - val_loss: 0.2943 - val_accuracy: 0.9126\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3552 - accuracy: 0.8936 - val_loss: 0.2924 - val_accuracy: 0.9128\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3466 - accuracy: 0.8960 - val_loss: 0.2909 - val_accuracy: 0.9143\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.8959 - val_loss: 0.2875 - val_accuracy: 0.9145\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8966 - val_loss: 0.2856 - val_accuracy: 0.9158\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8989 - val_loss: 0.2831 - val_accuracy: 0.9162\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8981 - val_loss: 0.2804 - val_accuracy: 0.9169\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3263 - accuracy: 0.9013 - val_loss: 0.2786 - val_accuracy: 0.9174\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3248 - accuracy: 0.9039 - val_loss: 0.2761 - val_accuracy: 0.9188\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.9023 - val_loss: 0.2741 - val_accuracy: 0.9195\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3208 - accuracy: 0.9013 - val_loss: 0.2731 - val_accuracy: 0.9190\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3131 - accuracy: 0.9058 - val_loss: 0.2701 - val_accuracy: 0.9205\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.9061 - val_loss: 0.2685 - val_accuracy: 0.9199\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3114 - accuracy: 0.9075 - val_loss: 0.2666 - val_accuracy: 0.9215\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3094 - accuracy: 0.9062 - val_loss: 0.2650 - val_accuracy: 0.9217\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.9096 - val_loss: 0.2630 - val_accuracy: 0.9215\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.9085 - val_loss: 0.2616 - val_accuracy: 0.9233\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.9077 - val_loss: 0.2590 - val_accuracy: 0.9231\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.9079 - val_loss: 0.2574 - val_accuracy: 0.9242\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2949 - accuracy: 0.9111 - val_loss: 0.2561 - val_accuracy: 0.9241\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2917 - accuracy: 0.9134 - val_loss: 0.2538 - val_accuracy: 0.9239\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.9137 - val_loss: 0.2520 - val_accuracy: 0.9246\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.9131 - val_loss: 0.2512 - val_accuracy: 0.9247\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9136 - val_loss: 0.2493 - val_accuracy: 0.9262\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.9160 - val_loss: 0.2476 - val_accuracy: 0.9260\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.9152 - val_loss: 0.2471 - val_accuracy: 0.9259\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.9164 - val_loss: 0.2439 - val_accuracy: 0.9268\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2765 - accuracy: 0.9172 - val_loss: 0.2432 - val_accuracy: 0.9271\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.9156 - val_loss: 0.2415 - val_accuracy: 0.9275\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.9166 - val_loss: 0.2401 - val_accuracy: 0.9282\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2606 - accuracy: 0.9196 - val_loss: 0.2386 - val_accuracy: 0.9295\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.9190 - val_loss: 0.2365 - val_accuracy: 0.9293\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.9186 - val_loss: 0.2352 - val_accuracy: 0.9302\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.9226 - val_loss: 0.2336 - val_accuracy: 0.9303\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3800 - accuracy: 0.5401 - val_loss: 0.4456 - val_accuracy: 0.8698\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5943 - accuracy: 0.8137 - val_loss: 0.3835 - val_accuracy: 0.8862\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5245 - accuracy: 0.8376 - val_loss: 0.3630 - val_accuracy: 0.8929\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4787 - accuracy: 0.8524 - val_loss: 0.3484 - val_accuracy: 0.8957\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.8612 - val_loss: 0.3416 - val_accuracy: 0.8982\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4469 - accuracy: 0.8638 - val_loss: 0.3352 - val_accuracy: 0.9013\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4379 - accuracy: 0.8688 - val_loss: 0.3328 - val_accuracy: 0.9022\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.8698 - val_loss: 0.3290 - val_accuracy: 0.9032\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4086 - accuracy: 0.8761 - val_loss: 0.3251 - val_accuracy: 0.9057\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4055 - accuracy: 0.8789 - val_loss: 0.3225 - val_accuracy: 0.9050\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - accuracy: 0.8762 - val_loss: 0.3211 - val_accuracy: 0.9061\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3954 - accuracy: 0.8805 - val_loss: 0.3201 - val_accuracy: 0.9066\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3957 - accuracy: 0.8816 - val_loss: 0.3181 - val_accuracy: 0.9067\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8886 - val_loss: 0.3166 - val_accuracy: 0.9070\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3769 - accuracy: 0.8867 - val_loss: 0.3149 - val_accuracy: 0.9075\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3692 - accuracy: 0.8904 - val_loss: 0.3159 - val_accuracy: 0.9077\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3685 - accuracy: 0.8906 - val_loss: 0.3148 - val_accuracy: 0.9080\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3637 - accuracy: 0.8901 - val_loss: 0.3127 - val_accuracy: 0.9072\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3666 - accuracy: 0.8899 - val_loss: 0.3117 - val_accuracy: 0.9084\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3680 - accuracy: 0.8894 - val_loss: 0.3107 - val_accuracy: 0.9077\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3552 - accuracy: 0.8929 - val_loss: 0.3090 - val_accuracy: 0.9086\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8910 - val_loss: 0.3092 - val_accuracy: 0.9084\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3474 - accuracy: 0.8944 - val_loss: 0.3070 - val_accuracy: 0.9096\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.8943 - val_loss: 0.3067 - val_accuracy: 0.9093\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3497 - accuracy: 0.8942 - val_loss: 0.3069 - val_accuracy: 0.9097\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8966 - val_loss: 0.3058 - val_accuracy: 0.9107\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3385 - accuracy: 0.8991 - val_loss: 0.3050 - val_accuracy: 0.9103\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3385 - accuracy: 0.8979 - val_loss: 0.3055 - val_accuracy: 0.9094\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8971 - val_loss: 0.3030 - val_accuracy: 0.9108\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3345 - accuracy: 0.8988 - val_loss: 0.3024 - val_accuracy: 0.9093\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3206 - accuracy: 0.9023 - val_loss: 0.3021 - val_accuracy: 0.9112\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8995 - val_loss: 0.3017 - val_accuracy: 0.9116\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.9026 - val_loss: 0.3010 - val_accuracy: 0.9108\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3264 - accuracy: 0.9021 - val_loss: 0.3009 - val_accuracy: 0.9112\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.9019 - val_loss: 0.2998 - val_accuracy: 0.9122\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3222 - accuracy: 0.9042 - val_loss: 0.3005 - val_accuracy: 0.9114\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.9053 - val_loss: 0.3000 - val_accuracy: 0.9112\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.9044 - val_loss: 0.2979 - val_accuracy: 0.9109\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3206 - accuracy: 0.9058 - val_loss: 0.2972 - val_accuracy: 0.9121\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3195 - accuracy: 0.9045 - val_loss: 0.2969 - val_accuracy: 0.9128\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3112 - accuracy: 0.9064 - val_loss: 0.2966 - val_accuracy: 0.9129\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3144 - accuracy: 0.9066 - val_loss: 0.2959 - val_accuracy: 0.9112\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3157 - accuracy: 0.9058 - val_loss: 0.2939 - val_accuracy: 0.9121\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3111 - accuracy: 0.9076 - val_loss: 0.2942 - val_accuracy: 0.9128\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3147 - accuracy: 0.9056 - val_loss: 0.2939 - val_accuracy: 0.9125\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3114 - accuracy: 0.9072 - val_loss: 0.2933 - val_accuracy: 0.9114\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.9057 - val_loss: 0.2907 - val_accuracy: 0.9134\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3124 - accuracy: 0.9067 - val_loss: 0.2907 - val_accuracy: 0.9143\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2988 - accuracy: 0.9083 - val_loss: 0.2912 - val_accuracy: 0.9148\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.9118 - val_loss: 0.2891 - val_accuracy: 0.9146\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0575 - accuracy: 0.3178 - val_loss: 1.0120 - val_accuracy: 0.8008\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0352 - accuracy: 0.6968 - val_loss: 0.5841 - val_accuracy: 0.8570\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7372 - accuracy: 0.7760 - val_loss: 0.4746 - val_accuracy: 0.8757\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6274 - accuracy: 0.8116 - val_loss: 0.4249 - val_accuracy: 0.8856\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5686 - accuracy: 0.8301 - val_loss: 0.3936 - val_accuracy: 0.8908\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5269 - accuracy: 0.8422 - val_loss: 0.3729 - val_accuracy: 0.8949\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4966 - accuracy: 0.8541 - val_loss: 0.3554 - val_accuracy: 0.8982\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4634 - accuracy: 0.8632 - val_loss: 0.3418 - val_accuracy: 0.9004\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4516 - accuracy: 0.8657 - val_loss: 0.3307 - val_accuracy: 0.9024\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4295 - accuracy: 0.8727 - val_loss: 0.3196 - val_accuracy: 0.9055\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4136 - accuracy: 0.8776 - val_loss: 0.3117 - val_accuracy: 0.9074\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4051 - accuracy: 0.8797 - val_loss: 0.3024 - val_accuracy: 0.9105\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3963 - accuracy: 0.8818 - val_loss: 0.2948 - val_accuracy: 0.9123\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3810 - accuracy: 0.8875 - val_loss: 0.2878 - val_accuracy: 0.9150\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3672 - accuracy: 0.8927 - val_loss: 0.2813 - val_accuracy: 0.9157\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.8936 - val_loss: 0.2744 - val_accuracy: 0.9184\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3542 - accuracy: 0.8923 - val_loss: 0.2679 - val_accuracy: 0.9210\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.8982 - val_loss: 0.2627 - val_accuracy: 0.9223\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.9014 - val_loss: 0.2567 - val_accuracy: 0.9246\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.9025 - val_loss: 0.2528 - val_accuracy: 0.9247\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3208 - accuracy: 0.9055 - val_loss: 0.2469 - val_accuracy: 0.9271\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3103 - accuracy: 0.9082 - val_loss: 0.2428 - val_accuracy: 0.9274\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3090 - accuracy: 0.9078 - val_loss: 0.2379 - val_accuracy: 0.9297\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2916 - accuracy: 0.9136 - val_loss: 0.2334 - val_accuracy: 0.9298\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2869 - accuracy: 0.9149 - val_loss: 0.2290 - val_accuracy: 0.9312\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2914 - accuracy: 0.9141 - val_loss: 0.2257 - val_accuracy: 0.9333\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2796 - accuracy: 0.9183 - val_loss: 0.2221 - val_accuracy: 0.9340\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2745 - accuracy: 0.9189 - val_loss: 0.2184 - val_accuracy: 0.9353\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2706 - accuracy: 0.9210 - val_loss: 0.2142 - val_accuracy: 0.9358\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2659 - accuracy: 0.9220 - val_loss: 0.2110 - val_accuracy: 0.9363\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2657 - accuracy: 0.9238 - val_loss: 0.2075 - val_accuracy: 0.9379\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2602 - accuracy: 0.9220 - val_loss: 0.2044 - val_accuracy: 0.9383\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2521 - accuracy: 0.9248 - val_loss: 0.2011 - val_accuracy: 0.9400\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2482 - accuracy: 0.9254 - val_loss: 0.1987 - val_accuracy: 0.9408\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2476 - accuracy: 0.9274 - val_loss: 0.1963 - val_accuracy: 0.9400\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2361 - accuracy: 0.9298 - val_loss: 0.1938 - val_accuracy: 0.9413\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.9316 - val_loss: 0.1904 - val_accuracy: 0.9426\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2269 - accuracy: 0.9323 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2267 - accuracy: 0.9319 - val_loss: 0.1853 - val_accuracy: 0.9439\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9347 - val_loss: 0.1836 - val_accuracy: 0.9453\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2191 - accuracy: 0.9354 - val_loss: 0.1811 - val_accuracy: 0.9461\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2227 - accuracy: 0.9341 - val_loss: 0.1794 - val_accuracy: 0.9465\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2110 - accuracy: 0.9380 - val_loss: 0.1769 - val_accuracy: 0.9470\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9351 - val_loss: 0.1746 - val_accuracy: 0.9473\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9396 - val_loss: 0.1729 - val_accuracy: 0.9486\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1990 - accuracy: 0.9421 - val_loss: 0.1708 - val_accuracy: 0.9478\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2002 - accuracy: 0.9410 - val_loss: 0.1691 - val_accuracy: 0.9478\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9399 - val_loss: 0.1677 - val_accuracy: 0.9493\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1900 - accuracy: 0.9419 - val_loss: 0.1659 - val_accuracy: 0.9496\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9450 - val_loss: 0.1643 - val_accuracy: 0.9502\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0981 - accuracy: 0.3093 - val_loss: 1.3021 - val_accuracy: 0.7756\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1962 - accuracy: 0.6893 - val_loss: 0.6803 - val_accuracy: 0.8453\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8047 - accuracy: 0.7579 - val_loss: 0.5233 - val_accuracy: 0.8662\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6668 - accuracy: 0.7972 - val_loss: 0.4593 - val_accuracy: 0.8771\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6001 - accuracy: 0.8229 - val_loss: 0.4221 - val_accuracy: 0.8832\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5465 - accuracy: 0.8342 - val_loss: 0.3979 - val_accuracy: 0.8891\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.8471 - val_loss: 0.3808 - val_accuracy: 0.8935\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4872 - accuracy: 0.8559 - val_loss: 0.3663 - val_accuracy: 0.8953\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4727 - accuracy: 0.8590 - val_loss: 0.3542 - val_accuracy: 0.8985\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.8631 - val_loss: 0.3450 - val_accuracy: 0.8999\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4467 - accuracy: 0.8643 - val_loss: 0.3362 - val_accuracy: 0.9023\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4408 - accuracy: 0.8699 - val_loss: 0.3291 - val_accuracy: 0.9045\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4250 - accuracy: 0.8751 - val_loss: 0.3227 - val_accuracy: 0.9055\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4190 - accuracy: 0.8778 - val_loss: 0.3167 - val_accuracy: 0.9068\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4019 - accuracy: 0.8814 - val_loss: 0.3108 - val_accuracy: 0.9098\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8813 - val_loss: 0.3056 - val_accuracy: 0.9099\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3874 - accuracy: 0.8868 - val_loss: 0.3008 - val_accuracy: 0.9118\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8907 - val_loss: 0.2954 - val_accuracy: 0.9126\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3705 - accuracy: 0.8889 - val_loss: 0.2911 - val_accuracy: 0.9144\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3608 - accuracy: 0.8945 - val_loss: 0.2873 - val_accuracy: 0.9156\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3619 - accuracy: 0.8932 - val_loss: 0.2826 - val_accuracy: 0.9165\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3556 - accuracy: 0.8946 - val_loss: 0.2786 - val_accuracy: 0.9181\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3477 - accuracy: 0.8980 - val_loss: 0.2747 - val_accuracy: 0.9186\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.8984 - val_loss: 0.2711 - val_accuracy: 0.9197\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8990 - val_loss: 0.2674 - val_accuracy: 0.9218\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.9024 - val_loss: 0.2638 - val_accuracy: 0.9228\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.9032 - val_loss: 0.2604 - val_accuracy: 0.9237\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3278 - accuracy: 0.9034 - val_loss: 0.2572 - val_accuracy: 0.9249\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3210 - accuracy: 0.9054 - val_loss: 0.2536 - val_accuracy: 0.9252\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3162 - accuracy: 0.9064 - val_loss: 0.2506 - val_accuracy: 0.9270\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3011 - accuracy: 0.9113 - val_loss: 0.2475 - val_accuracy: 0.9276\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2977 - accuracy: 0.9108 - val_loss: 0.2442 - val_accuracy: 0.9285\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3071 - accuracy: 0.9088 - val_loss: 0.2414 - val_accuracy: 0.9290\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2871 - accuracy: 0.9136 - val_loss: 0.2381 - val_accuracy: 0.9305\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.9155 - val_loss: 0.2359 - val_accuracy: 0.9311\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2896 - accuracy: 0.9132 - val_loss: 0.2330 - val_accuracy: 0.9319\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2820 - accuracy: 0.9170 - val_loss: 0.2307 - val_accuracy: 0.9323\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.9167 - val_loss: 0.2277 - val_accuracy: 0.9335\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2782 - accuracy: 0.9176 - val_loss: 0.2253 - val_accuracy: 0.9342\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.9175 - val_loss: 0.2228 - val_accuracy: 0.9349\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2742 - accuracy: 0.9197 - val_loss: 0.2200 - val_accuracy: 0.9354\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.9188 - val_loss: 0.2180 - val_accuracy: 0.9361\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2655 - accuracy: 0.9201 - val_loss: 0.2157 - val_accuracy: 0.9362\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2614 - accuracy: 0.9212 - val_loss: 0.2139 - val_accuracy: 0.9373\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2540 - accuracy: 0.9240 - val_loss: 0.2113 - val_accuracy: 0.9373\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2486 - accuracy: 0.9263 - val_loss: 0.2098 - val_accuracy: 0.9378\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2519 - accuracy: 0.9243 - val_loss: 0.2077 - val_accuracy: 0.9388\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2493 - accuracy: 0.9255 - val_loss: 0.2057 - val_accuracy: 0.9393\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2454 - accuracy: 0.9281 - val_loss: 0.2034 - val_accuracy: 0.9403\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2390 - accuracy: 0.9263 - val_loss: 0.2019 - val_accuracy: 0.9408\n",
            "{'loss': [1.1667499542236328, 0.6550675630569458, 0.5530622005462646, 0.5025996565818787, 0.4756545424461365, 0.4549500346183777, 0.44063282012939453, 0.42529749870300293, 0.41988590359687805, 0.4079841673374176, 0.39858973026275635, 0.3939541280269623, 0.3886641561985016, 0.38080570101737976, 0.37890520691871643, 0.37436261773109436, 0.3670707941055298, 0.3634033203125, 0.36312076449394226, 0.3562461733818054, 0.35607630014419556, 0.3490745425224304, 0.35003870725631714, 0.3462493121623993, 0.33765754103660583, 0.3368412256240845, 0.3370163142681122, 0.3347114324569702, 0.332581490278244, 0.32754647731781006, 0.32323113083839417, 0.3219141960144043, 0.3237491548061371, 0.31844139099121094, 0.31832659244537354, 0.316654771566391, 0.3150905668735504, 0.3138478398323059, 0.31082335114479065, 0.3068717122077942, 0.3029998540878296, 0.30299535393714905, 0.3028762638568878, 0.30047303438186646, 0.3000974655151367, 0.2973889708518982, 0.29185721278190613, 0.29240304231643677, 0.29131975769996643, 0.28845372796058655], 'accuracy': [0.6435208320617676, 0.807979166507721, 0.8348541855812073, 0.8488333225250244, 0.8562291860580444, 0.8631458282470703, 0.8682291507720947, 0.8715416789054871, 0.8747291564941406, 0.8765416741371155, 0.8787708282470703, 0.8804166913032532, 0.883062481880188, 0.8858333230018616, 0.8878124952316284, 0.8879166841506958, 0.8890833258628845, 0.8910416960716248, 0.890541672706604, 0.893541693687439, 0.8941041827201843, 0.8944374918937683, 0.8948749899864197, 0.8961666822433472, 0.898145854473114, 0.8990625143051147, 0.8986666798591614, 0.9020416736602783, 0.9002916812896729, 0.9020208120346069, 0.903124988079071, 0.9037916660308838, 0.9022916555404663, 0.9048958420753479, 0.9052291512489319, 0.9057499766349792, 0.9068541526794434, 0.9045624732971191, 0.9068333506584167, 0.9087708592414856, 0.9083750247955322, 0.9099791646003723, 0.9091041684150696, 0.9106875061988831, 0.9102291464805603, 0.910979151725769, 0.9130416512489319, 0.9116458296775818, 0.9126666784286499, 0.9131875038146973], 'val_loss': [0.5983723998069763, 0.4560118019580841, 0.40502095222473145, 0.3773545026779175, 0.3615920841693878, 0.34951892495155334, 0.34230563044548035, 0.3358862102031708, 0.3298340439796448, 0.32499074935913086, 0.32109466195106506, 0.31807106733322144, 0.3150326609611511, 0.31245583295822144, 0.3102988302707672, 0.30847907066345215, 0.3065868616104126, 0.30452731251716614, 0.3019472360610962, 0.30023393034935, 0.2987242043018341, 0.2970341742038727, 0.29544880986213684, 0.29369109869003296, 0.29274582862854004, 0.2917395830154419, 0.28998062014579773, 0.2883593440055847, 0.2877222001552582, 0.2863081395626068, 0.2853899598121643, 0.28353437781333923, 0.28207406401634216, 0.282220721244812, 0.27981501817703247, 0.27828091382980347, 0.2775234878063202, 0.27693110704421997, 0.27550753951072693, 0.27358490228652954, 0.27345117926597595, 0.27141302824020386, 0.2703767418861389, 0.26919057965278625, 0.2692333161830902, 0.26720941066741943, 0.26637157797813416, 0.26480579376220703, 0.26328691840171814, 0.26310014724731445], 'val_accuracy': [0.8573333621025085, 0.8776666522026062, 0.8870000243186951, 0.8934999704360962, 0.8958333134651184, 0.8999166488647461, 0.9000833630561829, 0.9014999866485596, 0.9027500152587891, 0.9045000076293945, 0.9047499895095825, 0.9058333039283752, 0.9070833325386047, 0.9078333377838135, 0.9083333611488342, 0.9089166522026062, 0.9090833067893982, 0.909500002861023, 0.9114166498184204, 0.9113333225250244, 0.9121666550636292, 0.9139999747276306, 0.9133333563804626, 0.9136666655540466, 0.9144999980926514, 0.9150833487510681, 0.9158333539962769, 0.9154999852180481, 0.9167500138282776, 0.9163333177566528, 0.9167500138282776, 0.9168333411216736, 0.9175833463668823, 0.9172499775886536, 0.9179999828338623, 0.9181666374206543, 0.918833315372467, 0.9179166555404663, 0.918749988079071, 0.9178333282470703, 0.918916642665863, 0.9203333258628845, 0.9192500114440918, 0.9196666479110718, 0.9190833568572998, 0.9208333492279053, 0.9228333234786987, 0.9210833311080933, 0.9225000143051147, 0.9214166402816772]}\n",
            "{'loss': [1.66484534740448, 0.9147781729698181, 0.7063269019126892, 0.6131389737129211, 0.5567420125007629, 0.5133692622184753, 0.4809642434120178, 0.4566963016986847, 0.4396924674510956, 0.4207872748374939, 0.40402689576148987, 0.3891370892524719, 0.37384188175201416, 0.3610849678516388, 0.3489840030670166, 0.3421352505683899, 0.32802438735961914, 0.32058587670326233, 0.31122222542762756, 0.30476516485214233, 0.296852707862854, 0.29144537448883057, 0.28029531240463257, 0.27354076504707336, 0.2664388418197632, 0.2628253102302551, 0.2550518810749054, 0.2531054615974426, 0.24904510378837585, 0.24342301487922668, 0.23678572475910187, 0.23081868886947632, 0.22942203283309937, 0.22412432730197906, 0.21790337562561035, 0.21592660248279572, 0.21289554238319397, 0.20752842724323273, 0.20490358769893646, 0.20345468819141388, 0.1966894567012787, 0.19267524778842926, 0.19209788739681244, 0.18669289350509644, 0.18624289333820343, 0.17961350083351135, 0.1783479005098343, 0.17735712230205536, 0.1740613579750061, 0.1703888177871704], 'accuracy': [0.45754167437553406, 0.7137916684150696, 0.781624972820282, 0.8129374980926514, 0.8322708606719971, 0.8452291488647461, 0.8551458120346069, 0.8627291917800903, 0.8702083230018616, 0.8754166960716248, 0.8792499899864197, 0.8841458559036255, 0.8887916803359985, 0.8935624957084656, 0.8946250081062317, 0.8980208039283752, 0.9019374847412109, 0.9063541889190674, 0.9075208306312561, 0.9100624918937683, 0.9120000004768372, 0.9139583110809326, 0.9172083139419556, 0.9192708134651184, 0.9211249947547913, 0.9235833287239075, 0.9239583611488342, 0.9246875047683716, 0.9271041750907898, 0.9281041622161865, 0.9306874871253967, 0.9320625066757202, 0.9316458106040955, 0.932854175567627, 0.9363958239555359, 0.9356874823570251, 0.9383958578109741, 0.9387916922569275, 0.9385416507720947, 0.9381874799728394, 0.9414583444595337, 0.9430416822433472, 0.9428958296775818, 0.945229172706604, 0.94510418176651, 0.9467916488647461, 0.9473124742507935, 0.9471458196640015, 0.9495624899864197, 0.950124979019165], 'val_loss': [0.8674365282058716, 0.5443155765533447, 0.4454224407672882, 0.3948374390602112, 0.3664368987083435, 0.34206050634384155, 0.32414454221725464, 0.31078773736953735, 0.2985840141773224, 0.28731393814086914, 0.27781224250793457, 0.26915204524993896, 0.2610263526439667, 0.254055917263031, 0.24721111357212067, 0.2409561574459076, 0.23454177379608154, 0.23031286895275116, 0.22474031150341034, 0.21930716931819916, 0.21616089344024658, 0.21068009734153748, 0.20746822655200958, 0.2030288279056549, 0.20038548111915588, 0.19677697122097015, 0.19357694685459137, 0.19068680703639984, 0.18721437454223633, 0.1846088021993637, 0.18165209889411926, 0.1794445961713791, 0.1772107481956482, 0.1748969554901123, 0.1730996072292328, 0.1708417385816574, 0.16879941523075104, 0.16618795692920685, 0.1642349660396576, 0.1623566597700119, 0.1614326387643814, 0.15955452620983124, 0.15840521454811096, 0.1567046344280243, 0.15516488254070282, 0.15313343703746796, 0.15173736214637756, 0.1505422443151474, 0.14932896196842194, 0.14745187759399414], 'val_accuracy': [0.8109166622161865, 0.8644999861717224, 0.8815000057220459, 0.8914999961853027, 0.8963333368301392, 0.9004166722297668, 0.9042500257492065, 0.9084166884422302, 0.9120000004768372, 0.9145833253860474, 0.9174166917800903, 0.9191666841506958, 0.92208331823349, 0.9247499704360962, 0.9269166588783264, 0.9275833368301392, 0.9300833344459534, 0.9309999942779541, 0.9317499995231628, 0.934499979019165, 0.9349166750907898, 0.9369999766349792, 0.9369999766349792, 0.9383333325386047, 0.9384166598320007, 0.9401666522026062, 0.9413333535194397, 0.9419999718666077, 0.9431666731834412, 0.9437500238418579, 0.9445000290870667, 0.9448333382606506, 0.9454166889190674, 0.9456666707992554, 0.9467499852180481, 0.9474999904632568, 0.9474166631698608, 0.9487500190734863, 0.9489166736602783, 0.949999988079071, 0.9496666789054871, 0.9505833387374878, 0.9508333206176758, 0.9514166712760925, 0.9517499804496765, 0.953416645526886, 0.9538333415985107, 0.9538333415985107, 0.953499972820282, 0.9545833468437195]}\n",
            "{'loss': [1.5577749013900757, 0.8348221778869629, 0.6538368463516235, 0.5726245641708374, 0.5222370028495789, 0.48949939012527466, 0.45943769812583923, 0.4403432607650757, 0.42355114221572876, 0.40645280480384827, 0.3925641179084778, 0.38249582052230835, 0.3723726272583008, 0.3630022406578064, 0.3507380485534668, 0.34358492493629456, 0.3310692012310028, 0.323334276676178, 0.3202500641345978, 0.3144184350967407, 0.3064127266407013, 0.29922378063201904, 0.29410433769226074, 0.2885018587112427, 0.2857312560081482, 0.27709683775901794, 0.2719147801399231, 0.2677323818206787, 0.2614317834377289, 0.25510600209236145, 0.25433167815208435, 0.25000765919685364, 0.24711008369922638, 0.24342100322246552, 0.23895882070064545, 0.2354748696088791, 0.23052063584327698, 0.23077666759490967, 0.2228715419769287, 0.22221486270427704, 0.21809349954128265, 0.21441709995269775, 0.2111240029335022, 0.20983676612377167, 0.2087358832359314, 0.20466551184654236, 0.199996218085289, 0.1979045867919922, 0.19648616015911102, 0.19396716356277466], 'accuracy': [0.5146874785423279, 0.7446458339691162, 0.801729142665863, 0.8275833129882812, 0.839187502861023, 0.8528125286102295, 0.8650624752044678, 0.866895854473114, 0.8738333582878113, 0.8787291646003723, 0.8837708234786987, 0.8879374861717224, 0.890250027179718, 0.8924166560173035, 0.8961250185966492, 0.8989999890327454, 0.9012500047683716, 0.902916669845581, 0.9037291407585144, 0.9079999923706055, 0.9086041450500488, 0.911145806312561, 0.9117708206176758, 0.9147291779518127, 0.914229154586792, 0.9166874885559082, 0.9180625081062317, 0.9203749895095825, 0.9236041903495789, 0.9239166378974915, 0.9236666560173035, 0.9259791374206543, 0.9269999861717224, 0.9288333058357239, 0.9292083382606506, 0.9299583435058594, 0.9321041703224182, 0.9316250085830688, 0.9328749775886536, 0.9332708120346069, 0.9359791874885559, 0.9362499713897705, 0.9374791383743286, 0.9372291564941406, 0.9381874799728394, 0.9381666779518127, 0.9412500262260437, 0.9422083497047424, 0.9419999718666077, 0.942270815372467], 'val_loss': [0.7890235185623169, 0.5138696432113647, 0.4308016002178192, 0.38854292035102844, 0.3626849055290222, 0.34503254294395447, 0.32918980717658997, 0.31716832518577576, 0.30804696679115295, 0.2985687851905823, 0.29102155566215515, 0.2839735448360443, 0.27744224667549133, 0.2707935869693756, 0.2650405764579773, 0.2602272629737854, 0.25498712062835693, 0.25032392144203186, 0.2457589954137802, 0.24189230799674988, 0.23872888088226318, 0.23418550193309784, 0.23071248829364777, 0.22715094685554504, 0.22359484434127808, 0.22037538886070251, 0.2181536704301834, 0.21573331952095032, 0.21175344288349152, 0.20907893776893616, 0.20662599802017212, 0.20430994033813477, 0.2018759548664093, 0.19964683055877686, 0.19711486995220184, 0.19565999507904053, 0.19302941858768463, 0.19093617796897888, 0.18926577270030975, 0.18817351758480072, 0.1855304092168808, 0.1834307312965393, 0.18242321908473969, 0.18043562769889832, 0.17963610589504242, 0.17772825062274933, 0.1761687994003296, 0.17474102973937988, 0.17380879819393158, 0.17207308113574982], 'val_accuracy': [0.828166663646698, 0.8697500228881836, 0.8824999928474426, 0.8911666870117188, 0.8981666564941406, 0.9005833268165588, 0.903249979019165, 0.906333327293396, 0.9100000262260437, 0.9110000133514404, 0.9140833616256714, 0.9155833125114441, 0.9177500009536743, 0.9190000295639038, 0.9210000038146973, 0.922166645526886, 0.9235000014305115, 0.924916684627533, 0.9259999990463257, 0.9269999861717224, 0.9277499914169312, 0.9294166564941406, 0.9303333163261414, 0.9314166903495789, 0.9325833320617676, 0.9336666464805603, 0.9335833191871643, 0.9355000257492065, 0.9360833168029785, 0.9369166493415833, 0.9369166493415833, 0.937749981880188, 0.9387500286102295, 0.9398333430290222, 0.9399166703224182, 0.940750002861023, 0.9409999847412109, 0.9423333406448364, 0.9417499899864197, 0.9423333406448364, 0.9439166784286499, 0.9440000057220459, 0.9450833201408386, 0.9449166655540466, 0.9453333616256714, 0.9464166760444641, 0.9463333487510681, 0.9472500085830688, 0.9471666812896729, 0.9483333230018616]}\n",
            "{'loss': [1.1569007635116577, 0.6437385678291321, 0.5491010546684265, 0.4977993667125702, 0.46790164709091187, 0.45466291904449463, 0.4362216293811798, 0.42077016830444336, 0.4116150438785553, 0.4061827063560486, 0.39350804686546326, 0.3912357985973358, 0.3823380470275879, 0.3751230537891388, 0.36680570244789124, 0.36700439453125, 0.36141568422317505, 0.35596123337745667, 0.3499445915222168, 0.3476281762123108, 0.34356242418289185, 0.33884862065315247, 0.3339853286743164, 0.33014947175979614, 0.3289540708065033, 0.32315969467163086, 0.3203183114528656, 0.31495094299316406, 0.3153771162033081, 0.3117619752883911, 0.3070005774497986, 0.30599695444107056, 0.3015458285808563, 0.30007484555244446, 0.2982785999774933, 0.2967100441455841, 0.29293587803840637, 0.2885926365852356, 0.28717780113220215, 0.2813449800014496, 0.28141143918037415, 0.28160178661346436, 0.2771645784378052, 0.2747814655303955, 0.2723678648471832, 0.27138715982437134, 0.2644962668418884, 0.26779940724372864, 0.260672390460968, 0.26354745030403137], 'accuracy': [0.6449166536331177, 0.8057708144187927, 0.8339791893959045, 0.8480416536331177, 0.859416663646698, 0.8627499938011169, 0.8689791560173035, 0.874916672706604, 0.8765208125114441, 0.8785208463668823, 0.883145809173584, 0.8823541402816772, 0.8846250176429749, 0.8879166841506958, 0.8888333439826965, 0.8914583325386047, 0.8915833234786987, 0.8925416469573975, 0.8947083353996277, 0.8961250185966492, 0.8974791765213013, 0.8998541831970215, 0.8983749747276306, 0.9000208377838135, 0.9010208249092102, 0.9038749933242798, 0.9034583568572998, 0.9050833582878113, 0.9049375057220459, 0.9069166779518127, 0.9079375267028809, 0.9073958396911621, 0.9087499976158142, 0.9086250066757202, 0.9096458554267883, 0.9112083315849304, 0.9131875038146973, 0.9135000109672546, 0.913770854473114, 0.913770854473114, 0.9147916436195374, 0.9149791598320007, 0.9166041612625122, 0.9171666502952576, 0.9160833358764648, 0.9167708158493042, 0.9193958044052124, 0.9185000061988831, 0.9205625057220459, 0.9209791421890259], 'val_loss': [0.5773353576660156, 0.44315841794013977, 0.3966929614543915, 0.37226399779319763, 0.35701289772987366, 0.3453347086906433, 0.33703282475471497, 0.3303603231906891, 0.3256567716598511, 0.3188549280166626, 0.3151424825191498, 0.31137216091156006, 0.30748045444488525, 0.3039100766181946, 0.30065324902534485, 0.29767388105392456, 0.29433104395866394, 0.29238924384117126, 0.290914922952652, 0.2874959111213684, 0.2855636775493622, 0.28311753273010254, 0.2804122269153595, 0.27861344814300537, 0.2761000692844391, 0.27410584688186646, 0.2730860114097595, 0.2700830101966858, 0.268490731716156, 0.2665623426437378, 0.26498550176620483, 0.26300951838493347, 0.2616456151008606, 0.2590201497077942, 0.25743067264556885, 0.25608518719673157, 0.25379037857055664, 0.2520330250263214, 0.25121939182281494, 0.24926252663135529, 0.2475670725107193, 0.2470637410879135, 0.24391983449459076, 0.24323728680610657, 0.24152112007141113, 0.24007678031921387, 0.23860882222652435, 0.2365453839302063, 0.23515218496322632, 0.2335904985666275], 'val_accuracy': [0.8534166812896729, 0.8775833249092102, 0.8863333463668823, 0.8920000195503235, 0.8949166536331177, 0.8992499709129333, 0.9012500047683716, 0.9020833373069763, 0.9042500257492065, 0.9068333506584167, 0.9074166417121887, 0.9077500104904175, 0.9086666703224182, 0.9089166522026062, 0.9102500081062317, 0.9112499952316284, 0.9125833511352539, 0.9128333330154419, 0.9142500162124634, 0.9144999980926514, 0.9157500267028809, 0.9161666631698608, 0.9169166684150696, 0.9174166917800903, 0.918833315372467, 0.9194999933242798, 0.9190000295639038, 0.9204999804496765, 0.9199166893959045, 0.921500027179718, 0.92166668176651, 0.921500027179718, 0.9233333468437195, 0.9230833053588867, 0.9241666793823242, 0.9240833520889282, 0.9239166378974915, 0.9245833158493042, 0.9246666431427002, 0.9262499809265137, 0.9259999990463257, 0.9259166717529297, 0.9267500042915344, 0.9270833134651184, 0.9275000095367432, 0.9281666874885559, 0.9294999837875366, 0.9293333292007446, 0.9302499890327454, 0.9303333163261414]}\n",
            "{'loss': [0.9572488069534302, 0.5737304091453552, 0.5107110142707825, 0.4797755479812622, 0.46016645431518555, 0.4431925117969513, 0.43441468477249146, 0.42320477962493896, 0.4144728183746338, 0.4044426679611206, 0.40072301030158997, 0.39486226439476013, 0.38540324568748474, 0.38579583168029785, 0.3817163109779358, 0.3756442964076996, 0.37075838446617126, 0.3711118698120117, 0.3636709451675415, 0.36135104298591614, 0.35733821988105774, 0.3560926616191864, 0.3517647683620453, 0.3500100076198578, 0.3475911021232605, 0.3443179428577423, 0.34125253558158875, 0.33893126249313354, 0.3346730172634125, 0.3358583450317383, 0.33221346139907837, 0.3309142589569092, 0.33313900232315063, 0.3287380039691925, 0.3234919607639313, 0.3254026174545288, 0.3209739923477173, 0.32317784428596497, 0.31700995564460754, 0.31988054513931274, 0.318284273147583, 0.3160414695739746, 0.31435179710388184, 0.3154333233833313, 0.3109201192855835, 0.31025391817092896, 0.3098570704460144, 0.30951768159866333, 0.3019752502441406, 0.3024422228336334], 'accuracy': [0.6884999871253967, 0.8191458582878113, 0.8428333401679993, 0.8522916436195374, 0.8608750104904175, 0.8661041855812073, 0.8698958158493042, 0.871999979019165, 0.8742083311080933, 0.8787500262260437, 0.8793333172798157, 0.8814374804496765, 0.8845208287239075, 0.8858333230018616, 0.8848124742507935, 0.8886041641235352, 0.8890625238418579, 0.8879583477973938, 0.8902708292007446, 0.8911666870117188, 0.8930000066757202, 0.893791675567627, 0.8938541412353516, 0.8946874737739563, 0.8949791789054871, 0.8967499732971191, 0.8970000147819519, 0.8980833292007446, 0.9001874923706055, 0.8999166488647461, 0.9000625014305115, 0.901562511920929, 0.9013333320617676, 0.901770830154419, 0.9026666879653931, 0.9026041626930237, 0.9041249752044678, 0.9043541550636292, 0.9055833220481873, 0.9038749933242798, 0.9046458601951599, 0.9050416946411133, 0.9043541550636292, 0.9062708616256714, 0.9067708253860474, 0.9071458578109741, 0.9069374799728394, 0.9075000286102295, 0.9073333144187927, 0.9090625047683716], 'val_loss': [0.4456031918525696, 0.38350847363471985, 0.36295580863952637, 0.3483966588973999, 0.3416156768798828, 0.3352045714855194, 0.33279094099998474, 0.3290228545665741, 0.3251423239707947, 0.3225184381008148, 0.3211216330528259, 0.3201126158237457, 0.3181186020374298, 0.3165726661682129, 0.3148869276046753, 0.3159286379814148, 0.31476280093193054, 0.3127196133136749, 0.311716765165329, 0.31070104241371155, 0.3089544177055359, 0.3091503977775574, 0.30695781111717224, 0.30669865012168884, 0.3069051206111908, 0.30583879351615906, 0.3049550950527191, 0.30550989508628845, 0.30304333567619324, 0.3023718297481537, 0.3020590841770172, 0.30170872807502747, 0.3010484576225281, 0.3008749485015869, 0.2997806966304779, 0.30053478479385376, 0.29999566078186035, 0.297905296087265, 0.2971797585487366, 0.2969062030315399, 0.2966257631778717, 0.2959040701389313, 0.2938920259475708, 0.29416510462760925, 0.29385140538215637, 0.2933139204978943, 0.29066598415374756, 0.2907496392726898, 0.2912006676197052, 0.2891032099723816], 'val_accuracy': [0.8698333501815796, 0.8861666917800903, 0.8929166793823242, 0.8957499861717224, 0.8981666564941406, 0.9012500047683716, 0.9021666646003723, 0.903249979019165, 0.9057499766349792, 0.9049999713897705, 0.906083345413208, 0.906583309173584, 0.9066666960716248, 0.9070000052452087, 0.9075000286102295, 0.9076666831970215, 0.9079999923706055, 0.9072499871253967, 0.9084166884422302, 0.9076666831970215, 0.9085833430290222, 0.9084166884422302, 0.909583330154419, 0.909333348274231, 0.9096666574478149, 0.9106666445732117, 0.9102500081062317, 0.909416675567627, 0.9108333587646484, 0.909250020980835, 0.9111666679382324, 0.9115833044052124, 0.9108333587646484, 0.9111666679382324, 0.9122499823570251, 0.9114166498184204, 0.9112499952316284, 0.9109166860580444, 0.9120833277702332, 0.9127500057220459, 0.9129166603088379, 0.9112499952316284, 0.9120833277702332, 0.9128333330154419, 0.9125000238418579, 0.9114166498184204, 0.9134166836738586, 0.9142500162124634, 0.9148333072662354, 0.9145833253860474]}\n",
            "{'loss': [1.761629343032837, 0.9296830892562866, 0.7026964426040649, 0.6090731024742126, 0.5536388158798218, 0.520150363445282, 0.48814594745635986, 0.4654960036277771, 0.4488389790058136, 0.4278309643268585, 0.41631725430488586, 0.4023943245410919, 0.3936190605163574, 0.3792998194694519, 0.36839598417282104, 0.3563046455383301, 0.3488500118255615, 0.34246009588241577, 0.33509355783462524, 0.3244747817516327, 0.3168094754219055, 0.31328287720680237, 0.30540731549263, 0.29978325963020325, 0.29114627838134766, 0.28838515281677246, 0.2806370258331299, 0.27539554238319397, 0.27048560976982117, 0.26595252752304077, 0.2608768343925476, 0.2572883665561676, 0.2512780427932739, 0.24597658216953278, 0.24456734955310822, 0.23962046205997467, 0.23443163931369781, 0.22937145829200745, 0.22570472955703735, 0.22439242899417877, 0.2203877568244934, 0.2161778211593628, 0.21342317759990692, 0.2102203220129013, 0.20783869922161102, 0.20156759023666382, 0.20081748068332672, 0.19853544235229492, 0.19293080270290375, 0.19038523733615875], 'accuracy': [0.47747915983200073, 0.7244374752044678, 0.7872499823570251, 0.8169166445732117, 0.8343958258628845, 0.8452083468437195, 0.8564791679382324, 0.8637083172798157, 0.8671249747276306, 0.8739374876022339, 0.8752708435058594, 0.8818541765213013, 0.8834583163261414, 0.887541651725769, 0.890999972820282, 0.8948125243186951, 0.8957708477973938, 0.8987083435058594, 0.9009374976158142, 0.9048541784286499, 0.9060624837875366, 0.9077500104904175, 0.9090625047683716, 0.9124374985694885, 0.9132916927337646, 0.913770854473114, 0.9178125262260437, 0.918624997138977, 0.9212499856948853, 0.9210416674613953, 0.9229375123977661, 0.9235208630561829, 0.9255625009536743, 0.9273958206176758, 0.9278749823570251, 0.9290416836738586, 0.9303125143051147, 0.9323124885559082, 0.9337708353996277, 0.9350000023841858, 0.934583306312561, 0.9351458549499512, 0.9362708330154419, 0.9363541603088379, 0.9379374980926514, 0.940708339214325, 0.9406874775886536, 0.940541684627533, 0.9418749809265137, 0.9443333148956299], 'val_loss': [1.011984944343567, 0.5841258764266968, 0.4745906591415405, 0.42493322491645813, 0.39358851313591003, 0.37294816970825195, 0.3554364740848541, 0.3417944610118866, 0.3307088613510132, 0.3195713460445404, 0.3117123544216156, 0.3024432957172394, 0.294793963432312, 0.28779199719429016, 0.281334787607193, 0.27438443899154663, 0.2679400146007538, 0.26273414492607117, 0.2567083239555359, 0.252817302942276, 0.24694617092609406, 0.24278104305267334, 0.23789198696613312, 0.23344217240810394, 0.22899247705936432, 0.22565416991710663, 0.22206223011016846, 0.2184140980243683, 0.21416421234607697, 0.21102820336818695, 0.2075224220752716, 0.20440596342086792, 0.2010864019393921, 0.1986728310585022, 0.1962745636701584, 0.19376400113105774, 0.19040964543819427, 0.18768033385276794, 0.18534022569656372, 0.1835734099149704, 0.18107058107852936, 0.17940716445446014, 0.17690344154834747, 0.1746038794517517, 0.1728549748659134, 0.17081227898597717, 0.16907764971256256, 0.16769909858703613, 0.1659359484910965, 0.16427172720432281], 'val_accuracy': [0.8007500171661377, 0.8569999933242798, 0.8756666779518127, 0.8855833411216736, 0.89083331823349, 0.8949166536331177, 0.8982499837875366, 0.9004166722297668, 0.9024166464805603, 0.9054999947547913, 0.9074166417121887, 0.9104999899864197, 0.9123333096504211, 0.9150000214576721, 0.9156666398048401, 0.9184166789054871, 0.9210000038146973, 0.9223333597183228, 0.9245833158493042, 0.9246666431427002, 0.9270833134651184, 0.9274166822433472, 0.9296666383743286, 0.9298333525657654, 0.9312499761581421, 0.9332500100135803, 0.9340000152587891, 0.9353333115577698, 0.9358333349227905, 0.9363333582878113, 0.9379166960716248, 0.9382500052452087, 0.9399999976158142, 0.940750002861023, 0.9399999976158142, 0.9413333535194397, 0.9425833225250244, 0.9434999823570251, 0.9439166784286499, 0.9453333616256714, 0.9460833072662354, 0.9465000033378601, 0.9470000267028809, 0.9473333358764648, 0.9485833048820496, 0.9478333592414856, 0.9478333592414856, 0.9493333101272583, 0.9495833516120911, 0.950166642665863]}\n",
            "{'loss': [1.8725101947784424, 1.0611966848373413, 0.7597867250442505, 0.6463309526443481, 0.5838893055915833, 0.5419933795928955, 0.5140787959098816, 0.4903162717819214, 0.4694180190563202, 0.45576658844947815, 0.4424470067024231, 0.4318190813064575, 0.41749101877212524, 0.4115715026855469, 0.39970484375953674, 0.39310359954833984, 0.3847139775753021, 0.3782326579093933, 0.37082353234291077, 0.366993248462677, 0.3561691343784332, 0.35022127628326416, 0.3457406759262085, 0.3428559899330139, 0.33674100041389465, 0.32787778973579407, 0.3240543305873871, 0.3240763247013092, 0.31719669699668884, 0.31145790219306946, 0.30594176054000854, 0.3019596040248871, 0.30032211542129517, 0.2933363914489746, 0.2856024503707886, 0.2850264608860016, 0.28183695673942566, 0.2790951430797577, 0.27263596653938293, 0.271748423576355, 0.26681748032569885, 0.26762545108795166, 0.26215487718582153, 0.25915297865867615, 0.2540375888347626, 0.2503582239151001, 0.24887019395828247, 0.2473180741071701, 0.24159495532512665, 0.2392599731683731], 'accuracy': [0.46439582109451294, 0.7100208401679993, 0.7716249823570251, 0.804729163646698, 0.8269583582878113, 0.8380208611488342, 0.8475416898727417, 0.8542500138282776, 0.8600000143051147, 0.8642083406448364, 0.8684791922569275, 0.871833324432373, 0.8768541812896729, 0.8786249756813049, 0.8814374804496765, 0.8827916383743286, 0.8872500061988831, 0.8893749713897705, 0.8894166946411133, 0.8928333520889282, 0.8949375152587891, 0.8959583044052124, 0.8976250290870667, 0.8985416889190674, 0.8995624780654907, 0.9026041626930237, 0.9039583206176758, 0.9040416479110718, 0.9057916402816772, 0.906624972820282, 0.9084166884422302, 0.9097708463668823, 0.9104166626930237, 0.9131666421890259, 0.9155208468437195, 0.914229154586792, 0.9161458611488342, 0.9167916774749756, 0.9174374938011169, 0.9180625081062317, 0.9209166765213013, 0.9197708368301392, 0.9208124876022339, 0.9223124980926514, 0.9232916831970215, 0.9253749847412109, 0.9256458282470703, 0.926437497138977, 0.9281458258628845, 0.9271875023841858], 'val_loss': [1.3021446466445923, 0.68031907081604, 0.5233104825019836, 0.4592633545398712, 0.4221437871456146, 0.39785000681877136, 0.3807973265647888, 0.36632072925567627, 0.35417720675468445, 0.34501805901527405, 0.33621910214424133, 0.3290604054927826, 0.3227018713951111, 0.3167250454425812, 0.3107636570930481, 0.3055894374847412, 0.3007993996143341, 0.29544103145599365, 0.29107466340065, 0.28725364804267883, 0.28257209062576294, 0.27861088514328003, 0.27469757199287415, 0.27110782265663147, 0.26738953590393066, 0.2638125717639923, 0.26039713621139526, 0.2571580708026886, 0.25363078713417053, 0.2505989670753479, 0.24749016761779785, 0.24422945082187653, 0.24135412275791168, 0.23813694715499878, 0.23588435351848602, 0.2329990267753601, 0.23065835237503052, 0.2277173101902008, 0.22531332075595856, 0.22282160818576813, 0.2200276106595993, 0.21799246966838837, 0.2157476842403412, 0.21394363045692444, 0.21133479475975037, 0.2098032832145691, 0.20765842497348785, 0.20573067665100098, 0.20337821543216705, 0.20193079113960266], 'val_accuracy': [0.7755833268165588, 0.8452500104904175, 0.8662499785423279, 0.8770833611488342, 0.8831666707992554, 0.8890833258628845, 0.8934999704360962, 0.8953333497047424, 0.8985000252723694, 0.8999166488647461, 0.9023333191871643, 0.9045000076293945, 0.9054999947547913, 0.9067500233650208, 0.9098333120346069, 0.9099166393280029, 0.9117500185966492, 0.9125833511352539, 0.9144166707992554, 0.9155833125114441, 0.9164999723434448, 0.9180833101272583, 0.918583333492279, 0.9197499752044678, 0.921833336353302, 0.9228333234786987, 0.9236666560173035, 0.924916684627533, 0.9252499938011169, 0.9269999861717224, 0.9275833368301392, 0.9284999966621399, 0.9290000200271606, 0.9304999709129333, 0.9310833215713501, 0.9319166541099548, 0.9322500228881836, 0.9334999918937683, 0.934249997138977, 0.9349166750907898, 0.9354166388511658, 0.9360833168029785, 0.9361666440963745, 0.937333345413208, 0.937250018119812, 0.937833309173584, 0.9387500286102295, 0.9393333196640015, 0.9403333067893982, 0.940750002861023]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}