{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 919722,
     "status": "ok",
     "timestamp": 1627303291951,
     "user": {
      "displayName": "TRUNG Nguyễn Thành",
      "photoUrl": "",
      "userId": "02848241069421510082"
     },
     "user_tz": -420
    },
    "id": "JnHhSjZec4W6",
    "outputId": "decc2722-5b33-40f0-a0df-2e8573fa4a3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 17s 6ms/step - loss: 2.4523 - accuracy: 0.0975 - val_loss: 2.3041 - val_accuracy: 0.0998\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3646 - accuracy: 0.1007 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3507 - accuracy: 0.1007 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3374 - accuracy: 0.1034 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3315 - accuracy: 0.1050 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3249 - accuracy: 0.1030 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3173 - accuracy: 0.1049 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3176 - accuracy: 0.1039 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3141 - accuracy: 0.1087 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3159 - accuracy: 0.1012 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3126 - accuracy: 0.1021 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3116 - accuracy: 0.1035 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3099 - accuracy: 0.1068 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3088 - accuracy: 0.1038 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3088 - accuracy: 0.1043 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3072 - accuracy: 0.1083 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3068 - accuracy: 0.1059 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3070 - accuracy: 0.1054 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3068 - accuracy: 0.1061 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3066 - accuracy: 0.1034 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3050 - accuracy: 0.1071 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3045 - accuracy: 0.1072 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3051 - accuracy: 0.1084 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3042 - accuracy: 0.1040 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3040 - accuracy: 0.1090 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3044 - accuracy: 0.1086 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3037 - accuracy: 0.1077 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3045 - accuracy: 0.1060 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3044 - accuracy: 0.1049 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3037 - accuracy: 0.1114 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3033 - accuracy: 0.1084 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3043 - accuracy: 0.1072 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3032 - accuracy: 0.1084 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3016 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3031 - accuracy: 0.1100 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3027 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3031 - accuracy: 0.1088 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3031 - accuracy: 0.1083 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3031 - accuracy: 0.1098 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3019 - accuracy: 0.1129 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3025 - accuracy: 0.1117 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.1089 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3021 - accuracy: 0.1119 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3025 - accuracy: 0.1118 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3023 - accuracy: 0.1113 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3025 - accuracy: 0.1116 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3020 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3028 - accuracy: 0.1085 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3021 - accuracy: 0.1100 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3019 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.1596 - accuracy: 0.2130 - val_loss: 1.2509 - val_accuracy: 0.6974\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5836 - accuracy: 0.4562 - val_loss: 0.9649 - val_accuracy: 0.7678\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3536 - accuracy: 0.5412 - val_loss: 0.7843 - val_accuracy: 0.8152\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1981 - accuracy: 0.6034 - val_loss: 0.6617 - val_accuracy: 0.8420\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0871 - accuracy: 0.6475 - val_loss: 0.5844 - val_accuracy: 0.8612\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0166 - accuracy: 0.6806 - val_loss: 0.5362 - val_accuracy: 0.8662\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9595 - accuracy: 0.6962 - val_loss: 0.4953 - val_accuracy: 0.8743\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9151 - accuracy: 0.7217 - val_loss: 0.4669 - val_accuracy: 0.8792\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8720 - accuracy: 0.7356 - val_loss: 0.4405 - val_accuracy: 0.8840\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8420 - accuracy: 0.7536 - val_loss: 0.4293 - val_accuracy: 0.8874\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8048 - accuracy: 0.7639 - val_loss: 0.4142 - val_accuracy: 0.8928\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7801 - accuracy: 0.7733 - val_loss: 0.3961 - val_accuracy: 0.8963\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7428 - accuracy: 0.7909 - val_loss: 0.3917 - val_accuracy: 0.8981\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7360 - accuracy: 0.7959 - val_loss: 0.3744 - val_accuracy: 0.9035\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7166 - accuracy: 0.8027 - val_loss: 0.3673 - val_accuracy: 0.9062\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6976 - accuracy: 0.8096 - val_loss: 0.3626 - val_accuracy: 0.9090\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6993 - accuracy: 0.8111 - val_loss: 0.3518 - val_accuracy: 0.9119\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6688 - accuracy: 0.8207 - val_loss: 0.3471 - val_accuracy: 0.9140\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6593 - accuracy: 0.8252 - val_loss: 0.3426 - val_accuracy: 0.9164\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6497 - accuracy: 0.8288 - val_loss: 0.3407 - val_accuracy: 0.9158\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6308 - accuracy: 0.8341 - val_loss: 0.3355 - val_accuracy: 0.9183\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6235 - accuracy: 0.8368 - val_loss: 0.3287 - val_accuracy: 0.9205\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6118 - accuracy: 0.8438 - val_loss: 0.3293 - val_accuracy: 0.9214\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6029 - accuracy: 0.8465 - val_loss: 0.3287 - val_accuracy: 0.9213\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5902 - accuracy: 0.8528 - val_loss: 0.3263 - val_accuracy: 0.9231\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5855 - accuracy: 0.8546 - val_loss: 0.3157 - val_accuracy: 0.9259\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5900 - accuracy: 0.8523 - val_loss: 0.3238 - val_accuracy: 0.9248\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5756 - accuracy: 0.8575 - val_loss: 0.3090 - val_accuracy: 0.9273\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5600 - accuracy: 0.8607 - val_loss: 0.3079 - val_accuracy: 0.9289\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5597 - accuracy: 0.8614 - val_loss: 0.3085 - val_accuracy: 0.9287\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5518 - accuracy: 0.8636 - val_loss: 0.2976 - val_accuracy: 0.9313\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5444 - accuracy: 0.8673 - val_loss: 0.2988 - val_accuracy: 0.9323\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5440 - accuracy: 0.8662 - val_loss: 0.2981 - val_accuracy: 0.9328\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5344 - accuracy: 0.8693 - val_loss: 0.2944 - val_accuracy: 0.9348\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5216 - accuracy: 0.8749 - val_loss: 0.2905 - val_accuracy: 0.9356\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5389 - accuracy: 0.8700 - val_loss: 0.2864 - val_accuracy: 0.9361\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5205 - accuracy: 0.8735 - val_loss: 0.2868 - val_accuracy: 0.9362\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5065 - accuracy: 0.8798 - val_loss: 0.2912 - val_accuracy: 0.9363\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5050 - accuracy: 0.8787 - val_loss: 0.2751 - val_accuracy: 0.9391\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.8794 - val_loss: 0.2722 - val_accuracy: 0.9391\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4965 - accuracy: 0.8805 - val_loss: 0.2734 - val_accuracy: 0.9403\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5031 - accuracy: 0.8778 - val_loss: 0.2692 - val_accuracy: 0.9405\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4934 - accuracy: 0.8804 - val_loss: 0.2693 - val_accuracy: 0.9408\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4847 - accuracy: 0.8815 - val_loss: 0.2655 - val_accuracy: 0.9416\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4892 - accuracy: 0.8825 - val_loss: 0.2659 - val_accuracy: 0.9424\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4806 - accuracy: 0.8853 - val_loss: 0.2599 - val_accuracy: 0.9443\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4707 - accuracy: 0.8871 - val_loss: 0.2584 - val_accuracy: 0.9438\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4666 - accuracy: 0.8876 - val_loss: 0.2596 - val_accuracy: 0.9435\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4624 - accuracy: 0.8884 - val_loss: 0.2537 - val_accuracy: 0.9445\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4581 - accuracy: 0.8918 - val_loss: 0.2561 - val_accuracy: 0.9466\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.3033 - accuracy: 0.1076 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3008 - accuracy: 0.1281 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2992 - accuracy: 0.1290 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2966 - accuracy: 0.1364 - val_loss: 2.2943 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2919 - accuracy: 0.1493 - val_loss: 2.2785 - val_accuracy: 0.1762\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2759 - accuracy: 0.1715 - val_loss: 2.2359 - val_accuracy: 0.2576\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2418 - accuracy: 0.1823 - val_loss: 2.1560 - val_accuracy: 0.2281\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1866 - accuracy: 0.1998 - val_loss: 2.0603 - val_accuracy: 0.2362\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1278 - accuracy: 0.2129 - val_loss: 1.9816 - val_accuracy: 0.2631\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0590 - accuracy: 0.2287 - val_loss: 1.9087 - val_accuracy: 0.3007\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9848 - accuracy: 0.2525 - val_loss: 1.8436 - val_accuracy: 0.3248\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9204 - accuracy: 0.2827 - val_loss: 1.7172 - val_accuracy: 0.3719\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8259 - accuracy: 0.3226 - val_loss: 1.5711 - val_accuracy: 0.4279\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7443 - accuracy: 0.3537 - val_loss: 1.4669 - val_accuracy: 0.4788\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6545 - accuracy: 0.3801 - val_loss: 1.3745 - val_accuracy: 0.4920\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5695 - accuracy: 0.4033 - val_loss: 1.2822 - val_accuracy: 0.5060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4964 - accuracy: 0.4347 - val_loss: 1.2211 - val_accuracy: 0.5458\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4367 - accuracy: 0.4572 - val_loss: 1.1444 - val_accuracy: 0.5567\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3729 - accuracy: 0.4872 - val_loss: 1.0800 - val_accuracy: 0.6263\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3124 - accuracy: 0.5155 - val_loss: 1.0164 - val_accuracy: 0.6673\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2714 - accuracy: 0.5312 - val_loss: 0.9734 - val_accuracy: 0.6669\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2511 - accuracy: 0.5429 - val_loss: 0.9349 - val_accuracy: 0.6747\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2195 - accuracy: 0.5517 - val_loss: 0.9211 - val_accuracy: 0.6643\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1858 - accuracy: 0.5626 - val_loss: 0.8711 - val_accuracy: 0.6877\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1527 - accuracy: 0.5694 - val_loss: 0.8780 - val_accuracy: 0.6988\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1332 - accuracy: 0.5849 - val_loss: 0.8535 - val_accuracy: 0.6913\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1169 - accuracy: 0.5903 - val_loss: 0.8139 - val_accuracy: 0.7310\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0789 - accuracy: 0.6010 - val_loss: 0.7878 - val_accuracy: 0.7143\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0746 - accuracy: 0.6044 - val_loss: 0.7541 - val_accuracy: 0.7397\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0410 - accuracy: 0.6120 - val_loss: 0.7480 - val_accuracy: 0.7347\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0317 - accuracy: 0.6182 - val_loss: 0.7234 - val_accuracy: 0.7643\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0125 - accuracy: 0.6254 - val_loss: 0.7218 - val_accuracy: 0.7503\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0013 - accuracy: 0.6273 - val_loss: 0.7053 - val_accuracy: 0.7732\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9730 - accuracy: 0.6328 - val_loss: 0.6801 - val_accuracy: 0.7866\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9633 - accuracy: 0.6387 - val_loss: 0.6691 - val_accuracy: 0.7613\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9558 - accuracy: 0.6451 - val_loss: 0.6649 - val_accuracy: 0.7487\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9435 - accuracy: 0.6474 - val_loss: 0.7373 - val_accuracy: 0.7449\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9393 - accuracy: 0.6493 - val_loss: 0.6414 - val_accuracy: 0.7602\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9177 - accuracy: 0.6539 - val_loss: 0.6165 - val_accuracy: 0.7607\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9072 - accuracy: 0.6503 - val_loss: 0.6552 - val_accuracy: 0.7580\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8849 - accuracy: 0.6597 - val_loss: 0.6106 - val_accuracy: 0.7695\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8824 - accuracy: 0.6652 - val_loss: 0.6248 - val_accuracy: 0.7709\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8671 - accuracy: 0.6657 - val_loss: 0.6147 - val_accuracy: 0.7782\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8641 - accuracy: 0.6712 - val_loss: 0.6107 - val_accuracy: 0.7694\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8549 - accuracy: 0.6697 - val_loss: 0.6109 - val_accuracy: 0.7726\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8345 - accuracy: 0.6775 - val_loss: 0.5980 - val_accuracy: 0.7889\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8210 - accuracy: 0.6835 - val_loss: 0.5826 - val_accuracy: 0.7665\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8165 - accuracy: 0.6782 - val_loss: 0.5754 - val_accuracy: 0.8017\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8290 - accuracy: 0.6838 - val_loss: 0.5874 - val_accuracy: 0.7707\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8193 - accuracy: 0.6883 - val_loss: 0.5736 - val_accuracy: 0.7918\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 7ms/step - loss: 2.3039 - accuracy: 0.1065 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3022 - accuracy: 0.1177 - val_loss: 2.2998 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3003 - accuracy: 0.1198 - val_loss: 2.2975 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2987 - accuracy: 0.1177 - val_loss: 2.2937 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2971 - accuracy: 0.1178 - val_loss: 2.2880 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2930 - accuracy: 0.1229 - val_loss: 2.2754 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2863 - accuracy: 0.1264 - val_loss: 2.2477 - val_accuracy: 0.1308\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2647 - accuracy: 0.1519 - val_loss: 2.1683 - val_accuracy: 0.2809\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1913 - accuracy: 0.2016 - val_loss: 1.9357 - val_accuracy: 0.3369\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0269 - accuracy: 0.2645 - val_loss: 1.6696 - val_accuracy: 0.4319\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8404 - accuracy: 0.3309 - val_loss: 1.4124 - val_accuracy: 0.4877\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6741 - accuracy: 0.3888 - val_loss: 1.2497 - val_accuracy: 0.5696\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5232 - accuracy: 0.4327 - val_loss: 1.0915 - val_accuracy: 0.6599\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3842 - accuracy: 0.4862 - val_loss: 0.9461 - val_accuracy: 0.7283\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2561 - accuracy: 0.5390 - val_loss: 0.7910 - val_accuracy: 0.7818\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1476 - accuracy: 0.5851 - val_loss: 0.6962 - val_accuracy: 0.7880\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0574 - accuracy: 0.6283 - val_loss: 0.6315 - val_accuracy: 0.8248\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9572 - accuracy: 0.6645 - val_loss: 0.5828 - val_accuracy: 0.8252\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9085 - accuracy: 0.6899 - val_loss: 0.5492 - val_accuracy: 0.8468\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8496 - accuracy: 0.7141 - val_loss: 0.5197 - val_accuracy: 0.8602\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8077 - accuracy: 0.7291 - val_loss: 0.4907 - val_accuracy: 0.8627\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7631 - accuracy: 0.7468 - val_loss: 0.4646 - val_accuracy: 0.8826\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7277 - accuracy: 0.7589 - val_loss: 0.4412 - val_accuracy: 0.8934\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6842 - accuracy: 0.7794 - val_loss: 0.4229 - val_accuracy: 0.8960\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6566 - accuracy: 0.7903 - val_loss: 0.3985 - val_accuracy: 0.9111\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6364 - accuracy: 0.7977 - val_loss: 0.3805 - val_accuracy: 0.9112\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6017 - accuracy: 0.8144 - val_loss: 0.3670 - val_accuracy: 0.9204\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5810 - accuracy: 0.8215 - val_loss: 0.3503 - val_accuracy: 0.9243\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5635 - accuracy: 0.8297 - val_loss: 0.3357 - val_accuracy: 0.9270\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5330 - accuracy: 0.8411 - val_loss: 0.3176 - val_accuracy: 0.9342\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5331 - accuracy: 0.8482 - val_loss: 0.3062 - val_accuracy: 0.9371\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5104 - accuracy: 0.8536 - val_loss: 0.2917 - val_accuracy: 0.9416\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4817 - accuracy: 0.8641 - val_loss: 0.2839 - val_accuracy: 0.9450\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4692 - accuracy: 0.8746 - val_loss: 0.2750 - val_accuracy: 0.9467\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4542 - accuracy: 0.8743 - val_loss: 0.2644 - val_accuracy: 0.9490\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4308 - accuracy: 0.8853 - val_loss: 0.2518 - val_accuracy: 0.9481\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4254 - accuracy: 0.8855 - val_loss: 0.2513 - val_accuracy: 0.9491\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4215 - accuracy: 0.8901 - val_loss: 0.2377 - val_accuracy: 0.9548\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3984 - accuracy: 0.8939 - val_loss: 0.2283 - val_accuracy: 0.9541\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3770 - accuracy: 0.9024 - val_loss: 0.2276 - val_accuracy: 0.9566\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3656 - accuracy: 0.9059 - val_loss: 0.2220 - val_accuracy: 0.9542\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3619 - accuracy: 0.9085 - val_loss: 0.2102 - val_accuracy: 0.9581\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.9055 - val_loss: 0.2099 - val_accuracy: 0.9578\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3362 - accuracy: 0.9115 - val_loss: 0.2025 - val_accuracy: 0.9588\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3364 - accuracy: 0.9142 - val_loss: 0.1992 - val_accuracy: 0.9593\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3295 - accuracy: 0.9133 - val_loss: 0.1959 - val_accuracy: 0.9607\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3271 - accuracy: 0.9153 - val_loss: 0.1912 - val_accuracy: 0.9608\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3137 - accuracy: 0.9155 - val_loss: 0.1880 - val_accuracy: 0.9624\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3000 - accuracy: 0.9209 - val_loss: 0.1872 - val_accuracy: 0.9632\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2991 - accuracy: 0.9242 - val_loss: 0.1887 - val_accuracy: 0.9641\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.1330 - accuracy: 0.2133 - val_loss: 1.1223 - val_accuracy: 0.7063\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5085 - accuracy: 0.4717 - val_loss: 0.6764 - val_accuracy: 0.8083\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2209 - accuracy: 0.5866 - val_loss: 0.5368 - val_accuracy: 0.8528\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0572 - accuracy: 0.6422 - val_loss: 0.4662 - val_accuracy: 0.8698\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9674 - accuracy: 0.6813 - val_loss: 0.4262 - val_accuracy: 0.8847\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8831 - accuracy: 0.7159 - val_loss: 0.3930 - val_accuracy: 0.8953\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8564 - accuracy: 0.7295 - val_loss: 0.3710 - val_accuracy: 0.9006\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8111 - accuracy: 0.7500 - val_loss: 0.3570 - val_accuracy: 0.9044\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7814 - accuracy: 0.7606 - val_loss: 0.3466 - val_accuracy: 0.9061\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7619 - accuracy: 0.7728 - val_loss: 0.3295 - val_accuracy: 0.9100\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7232 - accuracy: 0.7872 - val_loss: 0.3191 - val_accuracy: 0.9152\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.8005 - val_loss: 0.3045 - val_accuracy: 0.9179\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6781 - accuracy: 0.8034 - val_loss: 0.2982 - val_accuracy: 0.9201\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6611 - accuracy: 0.8128 - val_loss: 0.2872 - val_accuracy: 0.9219\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6425 - accuracy: 0.8196 - val_loss: 0.2784 - val_accuracy: 0.9258\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6136 - accuracy: 0.8283 - val_loss: 0.2835 - val_accuracy: 0.9226\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6110 - accuracy: 0.8323 - val_loss: 0.2733 - val_accuracy: 0.9273\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5868 - accuracy: 0.8393 - val_loss: 0.2693 - val_accuracy: 0.9284\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5705 - accuracy: 0.8457 - val_loss: 0.2623 - val_accuracy: 0.9308\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5641 - accuracy: 0.8498 - val_loss: 0.2588 - val_accuracy: 0.9316\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5555 - accuracy: 0.8522 - val_loss: 0.2575 - val_accuracy: 0.9305\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5497 - accuracy: 0.8556 - val_loss: 0.2497 - val_accuracy: 0.9341\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5394 - accuracy: 0.8591 - val_loss: 0.2493 - val_accuracy: 0.9345\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5299 - accuracy: 0.8621 - val_loss: 0.2476 - val_accuracy: 0.9342\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5226 - accuracy: 0.8651 - val_loss: 0.2374 - val_accuracy: 0.9377\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5042 - accuracy: 0.8706 - val_loss: 0.2362 - val_accuracy: 0.9393\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5034 - accuracy: 0.8684 - val_loss: 0.2358 - val_accuracy: 0.9387\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4858 - accuracy: 0.8768 - val_loss: 0.2281 - val_accuracy: 0.9418\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4774 - accuracy: 0.8754 - val_loss: 0.2288 - val_accuracy: 0.9413\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4743 - accuracy: 0.8802 - val_loss: 0.2215 - val_accuracy: 0.9445\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4697 - accuracy: 0.8808 - val_loss: 0.2189 - val_accuracy: 0.9446\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4546 - accuracy: 0.8846 - val_loss: 0.2177 - val_accuracy: 0.9451\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4616 - accuracy: 0.8841 - val_loss: 0.2161 - val_accuracy: 0.9466\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4503 - accuracy: 0.8866 - val_loss: 0.2141 - val_accuracy: 0.9453\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4489 - accuracy: 0.8886 - val_loss: 0.2097 - val_accuracy: 0.9480\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4287 - accuracy: 0.8935 - val_loss: 0.2126 - val_accuracy: 0.9470\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4323 - accuracy: 0.8935 - val_loss: 0.2060 - val_accuracy: 0.9493\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4206 - accuracy: 0.8958 - val_loss: 0.2032 - val_accuracy: 0.9504\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4206 - accuracy: 0.8970 - val_loss: 0.1979 - val_accuracy: 0.9502\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4139 - accuracy: 0.8983 - val_loss: 0.1986 - val_accuracy: 0.9522\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4003 - accuracy: 0.9006 - val_loss: 0.2020 - val_accuracy: 0.9507\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4092 - accuracy: 0.8997 - val_loss: 0.1911 - val_accuracy: 0.9533\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3976 - accuracy: 0.9018 - val_loss: 0.1932 - val_accuracy: 0.9525\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3803 - accuracy: 0.9063 - val_loss: 0.1896 - val_accuracy: 0.9527\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3935 - accuracy: 0.9009 - val_loss: 0.1861 - val_accuracy: 0.9549\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3864 - accuracy: 0.9043 - val_loss: 0.1853 - val_accuracy: 0.9553\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3742 - accuracy: 0.9083 - val_loss: 0.1841 - val_accuracy: 0.9553\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3780 - accuracy: 0.9074 - val_loss: 0.1840 - val_accuracy: 0.9553\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3727 - accuracy: 0.9096 - val_loss: 0.1807 - val_accuracy: 0.9566\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3793 - accuracy: 0.9086 - val_loss: 0.1822 - val_accuracy: 0.9567\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 6ms/step - loss: 2.7271 - accuracy: 0.1006 - val_loss: 2.3824 - val_accuracy: 0.0786\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.5068 - accuracy: 0.1008 - val_loss: 2.3178 - val_accuracy: 0.0876\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4194 - accuracy: 0.1014 - val_loss: 2.3014 - val_accuracy: 0.0993\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3701 - accuracy: 0.1002 - val_loss: 2.2909 - val_accuracy: 0.1046\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3386 - accuracy: 0.1024 - val_loss: 2.2909 - val_accuracy: 0.1046\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3235 - accuracy: 0.1029 - val_loss: 2.2904 - val_accuracy: 0.1068\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3147 - accuracy: 0.1069 - val_loss: 2.2901 - val_accuracy: 0.1068\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3108 - accuracy: 0.1041 - val_loss: 2.2912 - val_accuracy: 0.1114\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3070 - accuracy: 0.1070 - val_loss: 2.2933 - val_accuracy: 0.1233\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3064 - accuracy: 0.1054 - val_loss: 2.2913 - val_accuracy: 0.1445\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3034 - accuracy: 0.1077 - val_loss: 2.2922 - val_accuracy: 0.1063\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3032 - accuracy: 0.1054 - val_loss: 2.2925 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3021 - accuracy: 0.1086 - val_loss: 2.2935 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3020 - accuracy: 0.1109 - val_loss: 2.2960 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3024 - accuracy: 0.1093 - val_loss: 2.2959 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3020 - accuracy: 0.1106 - val_loss: 2.2971 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3015 - accuracy: 0.1120 - val_loss: 2.2985 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1122 - val_loss: 2.2979 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1121 - val_loss: 2.2973 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3013 - accuracy: 0.1150 - val_loss: 2.2963 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1148 - val_loss: 2.2952 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3015 - accuracy: 0.1116 - val_loss: 2.2952 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1120 - val_loss: 2.2951 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3015 - accuracy: 0.1139 - val_loss: 2.2958 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1131 - val_loss: 2.2961 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.2973 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3017 - accuracy: 0.1129 - val_loss: 2.2965 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3009 - accuracy: 0.1124 - val_loss: 2.2962 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1150 - val_loss: 2.2973 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.2972 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1147 - val_loss: 2.2965 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1156 - val_loss: 2.2962 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.2960 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1141 - val_loss: 2.2963 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3010 - accuracy: 0.1135 - val_loss: 2.2974 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3009 - accuracy: 0.1156 - val_loss: 2.2971 - val_accuracy: 0.1512\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.2968 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1148 - val_loss: 2.2977 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.2992 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1118 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1162 - val_loss: 2.2965 - val_accuracy: 0.1303\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1122 - val_loss: 2.2961 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.2951 - val_accuracy: 0.1720\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1165 - val_loss: 2.2972 - val_accuracy: 0.1787\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1094 - val_loss: 2.2975 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1150 - val_loss: 2.2981 - val_accuracy: 0.1390\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1140 - val_loss: 2.2979 - val_accuracy: 0.1116\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1117 - val_loss: 2.2963 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1163 - val_loss: 2.2949 - val_accuracy: 0.1098\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1138 - val_loss: 2.2970 - val_accuracy: 0.1079\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 7ms/step - loss: 2.3023 - accuracy: 0.1152 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1145 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1132 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1128 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1132 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1144 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1136 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1146 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1141 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1127 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1163 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1146 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1122 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1145 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1173 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1122 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1144 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1148 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1164 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1131 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1132 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1128 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1158 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1137 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1118 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1144 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1131 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1153 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1131 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1143 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1128 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1138 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1119 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1152 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1134 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1137 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1140 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1122 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1140 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2995 - accuracy: 0.1156 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3002 - accuracy: 0.1124 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2994 - accuracy: 0.1157 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2998 - accuracy: 0.1144 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2995 - accuracy: 0.1152 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2993 - accuracy: 0.1146 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2997 - accuracy: 0.1117 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2994 - accuracy: 0.1146 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.3023 - accuracy: 0.1158 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3015 - accuracy: 0.1134 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1156 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1159 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1138 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1117 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1159 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1151 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1135 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1168 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1152 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1129 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1150 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1148 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1153 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1137 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1159 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1141 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1128 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1137 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3009 - accuracy: 0.1108 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3004 - accuracy: 0.1142 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1116 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2998 - accuracy: 0.1165 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1125 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3005 - accuracy: 0.1149 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3003 - accuracy: 0.1135 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1133 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3001 - accuracy: 0.1152 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1139 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1107 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3005 - accuracy: 0.1127 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2996 - accuracy: 0.1146 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2997 - accuracy: 0.1150 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2990 - accuracy: 0.1178 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1110 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2996 - accuracy: 0.1151 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2995 - accuracy: 0.1159 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2996 - accuracy: 0.1129 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2986 - accuracy: 0.1169 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2989 - accuracy: 0.1147 - val_loss: 2.2999 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2990 - accuracy: 0.1141 - val_loss: 2.2996 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2986 - accuracy: 0.1138 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2984 - accuracy: 0.1137 - val_loss: 2.2990 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2977 - accuracy: 0.1129 - val_loss: 2.2985 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2970 - accuracy: 0.1144 - val_loss: 2.2979 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2967 - accuracy: 0.1126 - val_loss: 2.2969 - val_accuracy: 0.1060\n",
      "{'loss': [2.4134509563446045, 2.360013246536255, 2.3454463481903076, 2.3349716663360596, 2.330209493637085, 2.3238706588745117, 2.3196310997009277, 2.3176827430725098, 2.31488037109375, 2.3142926692962646, 2.3125016689300537, 2.310288667678833, 2.3098623752593994, 2.308911085128784, 2.3079750537872314, 2.3065643310546875, 2.307326078414917, 2.307427406311035, 2.306203842163086, 2.3065059185028076, 2.305528402328491, 2.3050668239593506, 2.3048903942108154, 2.304295778274536, 2.304354667663574, 2.3043153285980225, 2.3041934967041016, 2.304806709289551, 2.3042004108428955, 2.30350399017334, 2.3029110431671143, 2.3042168617248535, 2.3030710220336914, 2.3021817207336426, 2.303118944168091, 2.302403211593628, 2.3029661178588867, 2.302997350692749, 2.3030447959899902, 2.3024206161499023, 2.3023428916931152, 2.302435874938965, 2.3025965690612793, 2.30265736579895, 2.3028244972229004, 2.3026325702667236, 2.3027403354644775, 2.302227735519409, 2.3017873764038086, 2.302208662033081], 'accuracy': [0.0989583358168602, 0.1003541648387909, 0.10210416465997696, 0.10352083295583725, 0.1029374971985817, 0.10350000113248825, 0.10218749940395355, 0.10229166597127914, 0.10572917014360428, 0.10310416668653488, 0.1028541699051857, 0.1054999977350235, 0.1055208370089531, 0.10450000315904617, 0.10508333146572113, 0.10766666382551193, 0.10402083396911621, 0.10385416448116302, 0.1066666692495346, 0.10564583539962769, 0.10739583522081375, 0.10577083379030228, 0.10887499898672104, 0.10660416632890701, 0.10791666805744171, 0.1080833300948143, 0.1081250011920929, 0.10560416430234909, 0.10631249845027924, 0.10991666465997696, 0.11010416597127914, 0.10656250268220901, 0.10743749886751175, 0.10997916758060455, 0.10995833575725555, 0.11139583587646484, 0.10918749868869781, 0.1105833351612091, 0.10987500101327896, 0.1118958368897438, 0.11047916859388351, 0.10918749868869781, 0.11004166305065155, 0.11118750274181366, 0.10964583605527878, 0.11085416376590729, 0.1120624989271164, 0.11166666448116302, 0.1120416671037674, 0.11179167032241821], 'val_loss': [2.304070472717285, 2.302107095718384, 2.302138090133667, 2.302018165588379, 2.3020858764648438, 2.3020873069763184, 2.302112579345703, 2.3020033836364746, 2.302048921585083, 2.3020358085632324, 2.3020501136779785, 2.3020949363708496, 2.302100896835327, 2.3020732402801514, 2.3021087646484375, 2.3021204471588135, 2.3021175861358643, 2.302112579345703, 2.302098035812378, 2.302109956741333, 2.302090644836426, 2.3020873069763184, 2.302065372467041, 2.302111864089966, 2.30208420753479, 2.3020880222320557, 2.302058219909668, 2.302060842514038, 2.3020896911621094, 2.302064895629883, 2.3020684719085693, 2.3020901679992676, 2.302097797393799, 2.302100658416748, 2.3020899295806885, 2.302077293395996, 2.30210280418396, 2.3020899295806885, 2.3021059036254883, 2.3021023273468018, 2.3020896911621094, 2.302081823348999, 2.302093029022217, 2.3020741939544678, 2.3020710945129395, 2.3020780086517334, 2.302065849304199, 2.302065849304199, 2.302072763442993, 2.3020730018615723], 'val_accuracy': [0.09983333200216293, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [1.9555854797363281, 1.5136032104492188, 1.3145122528076172, 1.1674203872680664, 1.0740569829940796, 0.9990045428276062, 0.9478099942207336, 0.9032889604568481, 0.8670797348022461, 0.8289913535118103, 0.8020696640014648, 0.7750739455223083, 0.7498661279678345, 0.7357017397880554, 0.7105854749679565, 0.6929820775985718, 0.6835177540779114, 0.6657832264900208, 0.6540506482124329, 0.6433984041213989, 0.6218149662017822, 0.6216349005699158, 0.6151888966560364, 0.5985479354858398, 0.5949978828430176, 0.5852829813957214, 0.5757467746734619, 0.5734450817108154, 0.5694739818572998, 0.5613620281219482, 0.5497415065765381, 0.5449091792106628, 0.5390371680259705, 0.5342940092086792, 0.5253240466117859, 0.5304853320121765, 0.5201848745346069, 0.5137186050415039, 0.5037204623222351, 0.503669023513794, 0.5016112327575684, 0.49422940611839294, 0.49132290482521057, 0.48457983136177063, 0.48644721508026123, 0.47920775413513184, 0.47636982798576355, 0.47045132517814636, 0.4621329605579376, 0.45987629890441895], 'accuracy': [0.30289584398269653, 0.4830208420753479, 0.5555416941642761, 0.6144999861717224, 0.6521250009536743, 0.6851666569709778, 0.7031041383743286, 0.7246249914169312, 0.7398124933242798, 0.7560625076293945, 0.7657708525657654, 0.7773125171661377, 0.7895833253860474, 0.79708331823349, 0.8059583306312561, 0.8119166493415833, 0.8156458139419556, 0.8208541870117188, 0.8269791603088379, 0.8306666612625122, 0.8371041417121887, 0.8385624885559082, 0.8443958163261414, 0.8470625281333923, 0.8504166603088379, 0.8532916903495789, 0.8569375276565552, 0.8573125004768372, 0.8595208525657654, 0.8633541464805603, 0.8649583458900452, 0.8671875, 0.867437481880188, 0.8678958415985107, 0.871999979019165, 0.8713333606719971, 0.8729583621025085, 0.8769166469573975, 0.8786041736602783, 0.8788333535194397, 0.8791458606719971, 0.8790416717529297, 0.8818958401679993, 0.8808958530426025, 0.8828750252723694, 0.8852291703224182, 0.8854791522026062, 0.8878750205039978, 0.8893541693687439, 0.8911041617393494], 'val_loss': [1.2508920431137085, 0.9649465084075928, 0.784258246421814, 0.6617394089698792, 0.5843782424926758, 0.536219596862793, 0.49527546763420105, 0.4669467806816101, 0.44054993987083435, 0.4292984902858734, 0.4141806364059448, 0.39609384536743164, 0.39167794585227966, 0.37439507246017456, 0.367326945066452, 0.36255350708961487, 0.3517540991306305, 0.3471238911151886, 0.3425736129283905, 0.34069427847862244, 0.3354908525943756, 0.32867658138275146, 0.3292554020881653, 0.32871362566947937, 0.32633084058761597, 0.3156501352787018, 0.323792427778244, 0.3090021014213562, 0.30789268016815186, 0.30853471159935, 0.29764798283576965, 0.2987649738788605, 0.29812002182006836, 0.2943553626537323, 0.2904649078845978, 0.2863849997520447, 0.28678184747695923, 0.2912282645702362, 0.27506059408187866, 0.2721964418888092, 0.2734091877937317, 0.26919126510620117, 0.2692927420139313, 0.2655164301395416, 0.2658788859844208, 0.25992223620414734, 0.25835657119750977, 0.2596031129360199, 0.25371021032333374, 0.2560797333717346], 'val_accuracy': [0.6974166631698608, 0.7678333520889282, 0.8151666522026062, 0.8420000076293945, 0.8612499833106995, 0.8662499785423279, 0.8743333220481873, 0.8791666626930237, 0.8840000033378601, 0.887416660785675, 0.8927500247955322, 0.8963333368301392, 0.8980833292007446, 0.9035000205039978, 0.90625, 0.9089999794960022, 0.9119166731834412, 0.9139999747276306, 0.9164166450500488, 0.9158333539962769, 0.9182500243186951, 0.9204999804496765, 0.9214166402816772, 0.9213333129882812, 0.9230833053588867, 0.9259166717529297, 0.924833357334137, 0.9272500276565552, 0.9289166927337646, 0.9287499785423279, 0.9313333630561829, 0.9323333501815796, 0.9328333139419556, 0.9348333477973938, 0.9355833530426025, 0.9360833168029785, 0.9361666440963745, 0.9363333582878113, 0.9390833377838135, 0.9390833377838135, 0.9403333067893982, 0.940500020980835, 0.940750002861023, 0.9415833353996277, 0.9424166679382324, 0.9443333148956299, 0.9438333511352539, 0.9434999823570251, 0.9445000290870667, 0.9465833306312561]}\n",
      "{'loss': [2.302610158920288, 2.3001465797424316, 2.2987754344940186, 2.2954823970794678, 2.289060592651367, 2.269061803817749, 2.2300422191619873, 2.170078992843628, 2.107790470123291, 2.038419008255005, 1.9714453220367432, 1.8985074758529663, 1.8074103593826294, 1.7232295274734497, 1.6320658922195435, 1.5494625568389893, 1.4809199571609497, 1.4244202375411987, 1.3606435060501099, 1.307387351989746, 1.2772787809371948, 1.2384902238845825, 1.2057088613510132, 1.1783989667892456, 1.14433753490448, 1.1304930448532104, 1.1055470705032349, 1.0913664102554321, 1.0651421546936035, 1.0439716577529907, 1.031069278717041, 1.0111078023910522, 1.0005854368209839, 0.9732411503791809, 0.9623310565948486, 0.9503363370895386, 0.9509781002998352, 0.9336580634117126, 0.9162032604217529, 0.903264582157135, 0.890826404094696, 0.882142961025238, 0.8733128905296326, 0.8550359010696411, 0.8595175743103027, 0.840499758720398, 0.8329459428787231, 0.8290572166442871, 0.8371954560279846, 0.8193715810775757], 'accuracy': [0.11554166674613953, 0.1288541704416275, 0.12854166328907013, 0.13893750309944153, 0.15414583683013916, 0.1757708340883255, 0.18787500262260437, 0.20418749749660492, 0.2175416648387909, 0.23483332991600037, 0.2588750123977661, 0.29089581966400146, 0.32754167914390564, 0.3607291579246521, 0.38620832562446594, 0.4138333201408386, 0.4410416781902313, 0.4639583230018616, 0.492000013589859, 0.5177916884422302, 0.5309791564941406, 0.5443333387374878, 0.554812490940094, 0.5649999976158142, 0.5756666660308838, 0.586020827293396, 0.593583345413208, 0.5998541712760925, 0.6068958044052124, 0.6153541803359985, 0.6175416707992554, 0.6268541812896729, 0.6285416483879089, 0.6348333358764648, 0.6401041746139526, 0.6448125243186951, 0.6478333473205566, 0.6492708325386047, 0.6556041836738586, 0.6553124785423279, 0.6586874723434448, 0.6656249761581421, 0.6650000214576721, 0.6714791655540466, 0.6705625057220459, 0.6758124828338623, 0.679520845413208, 0.6775624752044678, 0.6815624833106995, 0.6836249828338623], 'val_loss': [2.3015480041503906, 2.3019168376922607, 2.300398826599121, 2.2943472862243652, 2.278489351272583, 2.23587703704834, 2.1560184955596924, 2.0603249073028564, 1.981648564338684, 1.908748745918274, 1.8435765504837036, 1.717180848121643, 1.5710663795471191, 1.466892957687378, 1.3744734525680542, 1.2822365760803223, 1.2211065292358398, 1.1444171667099, 1.0799853801727295, 1.0164364576339722, 0.9733615517616272, 0.9349305033683777, 0.9210935831069946, 0.8710768222808838, 0.8780110478401184, 0.8535231947898865, 0.8139227032661438, 0.7878480553627014, 0.7540615797042847, 0.7480158805847168, 0.7234417200088501, 0.7218209505081177, 0.7053251266479492, 0.6801354289054871, 0.6690818667411804, 0.6649172902107239, 0.7372605204582214, 0.6413944959640503, 0.6165161728858948, 0.6551769971847534, 0.6106181740760803, 0.6247714757919312, 0.6146723031997681, 0.6107384562492371, 0.6108623147010803, 0.5979654788970947, 0.5826126933097839, 0.5753850340843201, 0.5874314308166504, 0.5736492276191711], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.17616666853427887, 0.2575833201408386, 0.22808332741260529, 0.23616667091846466, 0.2630833387374878, 0.3006666600704193, 0.32483333349227905, 0.37191668152809143, 0.42791667580604553, 0.4788333475589752, 0.492000013589859, 0.5059999823570251, 0.5457500219345093, 0.5567499995231628, 0.6262500286102295, 0.6673333048820496, 0.6669166684150696, 0.6747499704360962, 0.6643333435058594, 0.687666654586792, 0.6988333463668823, 0.6912500262260437, 0.7310000061988831, 0.7143333554267883, 0.7396666407585144, 0.734666645526886, 0.7643333077430725, 0.750333309173584, 0.7731666564941406, 0.7865833044052124, 0.7613333463668823, 0.7486666440963745, 0.7449166774749756, 0.7601666450500488, 0.7606666684150696, 0.7580000162124634, 0.7695000171661377, 0.7709166407585144, 0.778166651725769, 0.7694166898727417, 0.7725833058357239, 0.7889166474342346, 0.7664999961853027, 0.8016666769981384, 0.7707499861717224, 0.7917500138282776]}\n",
      "{'loss': [2.3033058643341064, 2.3013806343078613, 2.300107002258301, 2.2981669902801514, 2.2964565753936768, 2.292160749435425, 2.283154010772705, 2.2544240951538086, 2.155733108520508, 1.9810255765914917, 1.7982176542282104, 1.6325751543045044, 1.4848052263259888, 1.360293984413147, 1.23408043384552, 1.121983289718628, 1.0342925786972046, 0.9514012932777405, 0.8940048217773438, 0.8346219658851624, 0.7931431531906128, 0.7479557991027832, 0.7180556654930115, 0.6794612407684326, 0.6568726897239685, 0.6260917782783508, 0.6020687818527222, 0.5791666507720947, 0.5555052757263184, 0.5390393137931824, 0.5195484757423401, 0.5076214671134949, 0.48124071955680847, 0.46639811992645264, 0.4508048892021179, 0.43276700377464294, 0.423605352640152, 0.412129282951355, 0.39331525564193726, 0.3780231475830078, 0.37284573912620544, 0.358051061630249, 0.3574846088886261, 0.3413129448890686, 0.34060025215148926, 0.3289908468723297, 0.32597780227661133, 0.31533321738243103, 0.30648815631866455, 0.29958784580230713], 'accuracy': [0.11439583450555801, 0.11900000274181366, 0.11699999868869781, 0.11733333021402359, 0.11816667020320892, 0.12081249803304672, 0.1301041692495346, 0.1613541692495346, 0.21554166078567505, 0.27902084589004517, 0.3487291634082794, 0.40318751335144043, 0.44622915983200073, 0.4961458444595337, 0.5516250133514404, 0.597083330154419, 0.635979175567627, 0.671999990940094, 0.6976666450500488, 0.7196041941642761, 0.73416668176651, 0.7510416507720947, 0.7640625238418579, 0.7804999947547913, 0.7905833125114441, 0.8017916679382324, 0.8132708072662354, 0.8223333358764648, 0.8323125243186951, 0.8422499895095825, 0.8517916798591614, 0.8581249713897705, 0.8668749928474426, 0.8746874928474426, 0.8769583106040955, 0.8847708106040955, 0.8874375224113464, 0.8921666741371155, 0.8967708349227905, 0.9011458158493042, 0.9038749933242798, 0.9078333377838135, 0.9072708487510681, 0.9086874723434448, 0.9116041660308838, 0.9136666655540466, 0.9158750176429749, 0.9175833463668823, 0.9211875200271606, 0.9223958253860474], 'val_loss': [2.3010122776031494, 2.299767017364502, 2.2975337505340576, 2.293727159500122, 2.2879507541656494, 2.27536940574646, 2.247715711593628, 2.1682627201080322, 1.9356828927993774, 1.66957426071167, 1.41236412525177, 1.2497044801712036, 1.0915101766586304, 0.9461301565170288, 0.7909877896308899, 0.6961570382118225, 0.6314648389816284, 0.5827631950378418, 0.549173891544342, 0.5197367668151855, 0.49072888493537903, 0.464552640914917, 0.44115740060806274, 0.4228913187980652, 0.3985303044319153, 0.3804985284805298, 0.3670196235179901, 0.35034337639808655, 0.3356878161430359, 0.3175849914550781, 0.30619361996650696, 0.29170385003089905, 0.2839314639568329, 0.27498525381088257, 0.2644166350364685, 0.2518310248851776, 0.25131407380104065, 0.23774220049381256, 0.22834041714668274, 0.22757916152477264, 0.22195082902908325, 0.21015653014183044, 0.20993152260780334, 0.20252451300621033, 0.19915014505386353, 0.1958674043416977, 0.1912185102701187, 0.18796108663082123, 0.1871936172246933, 0.18872904777526855], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.13083332777023315, 0.28091666102409363, 0.33691665530204773, 0.43191665410995483, 0.48766666650772095, 0.5695833563804626, 0.6599166393280029, 0.7283333539962769, 0.7817500233650208, 0.7879999876022339, 0.8247500061988831, 0.825166642665863, 0.846833348274231, 0.8601666688919067, 0.862666666507721, 0.8825833201408386, 0.8934166431427002, 0.8960000276565552, 0.9110833406448364, 0.9111666679382324, 0.9204166531562805, 0.9243333339691162, 0.9269999861717224, 0.934249997138977, 0.9370833039283752, 0.9415833353996277, 0.9449999928474426, 0.9467499852180481, 0.9490000009536743, 0.9480833411216736, 0.9490833282470703, 0.9547500014305115, 0.9540833234786987, 0.9565833210945129, 0.9541666507720947, 0.9580833315849304, 0.9578333497047424, 0.9588333368301392, 0.9593333601951599, 0.9606666564941406, 0.9608333110809326, 0.9624166488647461, 0.9631666541099548, 0.9640833139419556]}\n",
      "{'loss': [1.9316033124923706, 1.4141767024993896, 1.1741652488708496, 1.0329465866088867, 0.9510159492492676, 0.8791334629058838, 0.8464029431343079, 0.8034374117851257, 0.7771202921867371, 0.7515318393707275, 0.7173682451248169, 0.6866740584373474, 0.6719362139701843, 0.6547167897224426, 0.6362105011940002, 0.6205962896347046, 0.6044411063194275, 0.5889226198196411, 0.5787134766578674, 0.5671756863594055, 0.554752767086029, 0.5465102791786194, 0.5372549891471863, 0.524213969707489, 0.5158078074455261, 0.5027011036872864, 0.4970763027667999, 0.48601412773132324, 0.4820554256439209, 0.47652292251586914, 0.4699100852012634, 0.45828160643577576, 0.452588826417923, 0.4483771026134491, 0.44167622923851013, 0.4313849210739136, 0.4268129765987396, 0.4177948534488678, 0.42199036478996277, 0.4103451371192932, 0.40079203248023987, 0.4026147127151489, 0.39704349637031555, 0.38622280955314636, 0.3968231976032257, 0.38151815533638, 0.3782399594783783, 0.3758380115032196, 0.3743830621242523, 0.3725326657295227], 'accuracy': [0.2981041669845581, 0.5069583058357239, 0.5988958477973938, 0.6535624861717224, 0.6899583339691162, 0.7200833559036255, 0.7343124747276306, 0.752958357334137, 0.7634791731834412, 0.7774999737739563, 0.7901458144187927, 0.8007500171661377, 0.8060208559036255, 0.8163750171661377, 0.8217291831970215, 0.828499972820282, 0.8347916603088379, 0.8395000100135803, 0.8445624709129333, 0.8491250276565552, 0.8530625104904175, 0.8566666841506958, 0.8600208163261414, 0.8635416626930237, 0.8669999837875366, 0.870520830154419, 0.8708124756813049, 0.8752291798591614, 0.8770416378974915, 0.879645824432373, 0.8811458349227905, 0.8838750123977661, 0.8863750100135803, 0.887499988079071, 0.8898125290870667, 0.8924791812896729, 0.8944583535194397, 0.8975208401679993, 0.8968124985694885, 0.8991875052452087, 0.9007708430290222, 0.901520848274231, 0.9022291898727417, 0.9052291512489319, 0.9012291431427002, 0.9055625200271606, 0.9077500104904175, 0.9083750247955322, 0.9101041555404663, 0.9098125100135803], 'val_loss': [1.122326135635376, 0.676449716091156, 0.5367590188980103, 0.4661572575569153, 0.42616918683052063, 0.3929624855518341, 0.371002733707428, 0.3570094406604767, 0.34660953283309937, 0.32948872447013855, 0.3190593123435974, 0.30446216464042664, 0.2981945872306824, 0.28720152378082275, 0.27835357189178467, 0.28351929783821106, 0.2733282148838043, 0.2693392038345337, 0.2622549831867218, 0.25877872109413147, 0.2574612498283386, 0.24965912103652954, 0.24928028881549835, 0.24756412208080292, 0.2373739629983902, 0.23619969189167023, 0.235810786485672, 0.22814692556858063, 0.2288210391998291, 0.22146864235401154, 0.21888110041618347, 0.21765738725662231, 0.216053307056427, 0.21412557363510132, 0.2097059190273285, 0.21262644231319427, 0.20601552724838257, 0.20320241153240204, 0.19794735312461853, 0.1986045092344284, 0.20201118290424347, 0.19110295176506042, 0.19322533905506134, 0.18962964415550232, 0.18609777092933655, 0.18531042337417603, 0.1840621531009674, 0.18403279781341553, 0.1807318776845932, 0.18221889436244965], 'val_accuracy': [0.706333339214325, 0.8082500100135803, 0.8527500033378601, 0.8698333501815796, 0.8846666812896729, 0.8952500224113464, 0.9005833268165588, 0.9044166803359985, 0.906083345413208, 0.9100000262260437, 0.9151666760444641, 0.9179166555404663, 0.9200833439826965, 0.921916663646698, 0.9258333444595337, 0.9225833415985107, 0.9272500276565552, 0.9284166693687439, 0.9308333396911621, 0.9315833449363708, 0.9304999709129333, 0.9340833425521851, 0.934499979019165, 0.934166669845581, 0.937749981880188, 0.9393333196640015, 0.9386666417121887, 0.9418333172798157, 0.9412500262260437, 0.9445000290870667, 0.9445833563804626, 0.9450833201408386, 0.9465833306312561, 0.9453333616256714, 0.9480000138282776, 0.9470000267028809, 0.9493333101272583, 0.9504166841506958, 0.950166642665863, 0.9521666765213013, 0.9506666660308838, 0.95333331823349, 0.9524999856948853, 0.9526666402816772, 0.9549166560173035, 0.9552500247955322, 0.9552500247955322, 0.9552500247955322, 0.9565833210945129, 0.9566666483879089]}\n",
      "{'loss': [2.659350633621216, 2.4793453216552734, 2.404311180114746, 2.36011004447937, 2.3359217643737793, 2.3219962120056152, 2.3141496181488037, 2.3098223209381104, 2.306602716445923, 2.304880142211914, 2.303764820098877, 2.3028111457824707, 2.3023157119750977, 2.3017027378082275, 2.3019609451293945, 2.3014800548553467, 2.3013932704925537, 2.30131196975708, 2.3012468814849854, 2.3013296127319336, 2.300877332687378, 2.301032304763794, 2.3010220527648926, 2.3013546466827393, 2.30100679397583, 2.3011369705200195, 2.3013370037078857, 2.300950050354004, 2.301253318786621, 2.3010573387145996, 2.301238536834717, 2.301039695739746, 2.300893545150757, 2.3010339736938477, 2.3011748790740967, 2.3012030124664307, 2.301363706588745, 2.301152229309082, 2.301203489303589, 2.3012545108795166, 2.3009674549102783, 2.3011350631713867, 2.301086664199829, 2.301191568374634, 2.3010683059692383, 2.3011634349823, 2.30116868019104, 2.3011622428894043, 2.300977945327759, 2.301270008087158], 'accuracy': [0.10129166394472122, 0.10104166716337204, 0.10189583152532578, 0.10110417008399963, 0.10216666758060455, 0.10237500071525574, 0.1054375022649765, 0.10445833206176758, 0.10762500017881393, 0.10593750327825546, 0.10781250149011612, 0.10727083683013916, 0.10929166525602341, 0.11077083647251129, 0.11225000023841858, 0.11270833015441895, 0.11387500166893005, 0.11414583027362823, 0.11370833218097687, 0.11383333057165146, 0.11397916823625565, 0.11385416984558105, 0.11389583349227905, 0.11358333379030228, 0.11406250298023224, 0.11339583247900009, 0.11412499845027924, 0.11385416984558105, 0.11410416662693024, 0.11404166370630264, 0.11379166692495346, 0.11387500166893005, 0.11383333057165146, 0.11358333379030228, 0.11389583349227905, 0.11402083188295364, 0.11406250298023224, 0.11393749713897705, 0.11393749713897705, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11400000005960464, 0.11391666531562805, 0.11381249874830246, 0.11397916823625565, 0.11375000327825546, 0.11400000005960464, 0.11416666954755783, 0.11410416662693024], 'val_loss': [2.3823673725128174, 2.31782603263855, 2.3014237880706787, 2.2908713817596436, 2.2909016609191895, 2.2904083728790283, 2.2901031970977783, 2.291231155395508, 2.293276309967041, 2.2912960052490234, 2.292221784591675, 2.2925117015838623, 2.2935240268707275, 2.2959845066070557, 2.295943260192871, 2.2971110343933105, 2.2984724044799805, 2.2979061603546143, 2.2973082065582275, 2.2963130474090576, 2.295161247253418, 2.2952160835266113, 2.2951385974884033, 2.295750141143799, 2.2961199283599854, 2.297309637069702, 2.296463966369629, 2.2962491512298584, 2.2972564697265625, 2.2972168922424316, 2.296538829803467, 2.296210527420044, 2.295954465866089, 2.296267032623291, 2.2973875999450684, 2.297137498855591, 2.2967989444732666, 2.297715902328491, 2.2991576194763184, 2.298158645629883, 2.2965219020843506, 2.296086311340332, 2.2951395511627197, 2.29724383354187, 2.29746413230896, 2.298095703125, 2.29792857170105, 2.2962756156921387, 2.2949273586273193, 2.2970187664031982], 'val_accuracy': [0.07858332991600037, 0.08758333325386047, 0.09933333098888397, 0.10458333045244217, 0.10458333045244217, 0.1068333312869072, 0.1068333312869072, 0.11141666769981384, 0.12333333492279053, 0.1445000022649765, 0.10633333027362823, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.1511666625738144, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.1303333342075348, 0.10599999874830246, 0.1720000058412552, 0.17866666615009308, 0.10599999874830246, 0.13899999856948853, 0.11158332973718643, 0.10599999874830246, 0.10983332991600037, 0.10791666805744171]}\n",
      "{'loss': [2.30197811126709, 2.3014237880706787, 2.3011677265167236, 2.3009955883026123, 2.300934076309204, 2.300917863845825, 2.3009274005889893, 2.3008155822753906, 2.3008856773376465, 2.3008975982666016, 2.300853729248047, 2.3008475303649902, 2.30074405670166, 2.3007872104644775, 2.3007471561431885, 2.3007748126983643, 2.300713062286377, 2.3007242679595947, 2.3007144927978516, 2.3006656169891357, 2.3006339073181152, 2.300611734390259, 2.3006060123443604, 2.3006081581115723, 2.300603151321411, 2.300534248352051, 2.300504446029663, 2.300488233566284, 2.3004746437072754, 2.3004627227783203, 2.300436019897461, 2.300393581390381, 2.300389289855957, 2.3003320693969727, 2.300326108932495, 2.3002657890319824, 2.3002238273620605, 2.3001832962036133, 2.3001480102539062, 2.3000752925872803, 2.3000569343566895, 2.300002336502075, 2.2999558448791504, 2.299846887588501, 2.299776315689087, 2.2998130321502686, 2.299698829650879, 2.2996151447296143, 2.2994847297668457, 2.2994704246520996], 'accuracy': [0.11502083390951157, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.301961898803711, 2.3018288612365723, 2.301815986633301, 2.301875591278076, 2.3019216060638428, 2.3019232749938965, 2.301926851272583, 2.301905870437622, 2.3019044399261475, 2.301873207092285, 2.3018581867218018, 2.30185604095459, 2.3018314838409424, 2.301815986633301, 2.3018016815185547, 2.30178165435791, 2.3017263412475586, 2.3017148971557617, 2.3016960620880127, 2.3017191886901855, 2.3016960620880127, 2.301687002182007, 2.301673650741577, 2.301637649536133, 2.3016138076782227, 2.3016111850738525, 2.3015966415405273, 2.3015706539154053, 2.30153226852417, 2.3015098571777344, 2.3014702796936035, 2.3014602661132812, 2.301424741744995, 2.30138897895813, 2.3013765811920166, 2.3013336658477783, 2.301297664642334, 2.301252841949463, 2.301193952560425, 2.3011748790740967, 2.301114082336426, 2.301056146621704, 2.301002264022827, 2.3009369373321533, 2.300880193710327, 2.3008029460906982, 2.300739049911499, 2.3006463050842285, 2.3005564212799072, 2.3004536628723145], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [2.3020644187927246, 2.3014185428619385, 2.301208734512329, 2.3010568618774414, 2.301011800765991, 2.300987720489502, 2.300983428955078, 2.300950288772583, 2.3009257316589355, 2.3008975982666016, 2.3008763790130615, 2.3008270263671875, 2.3008134365081787, 2.3007421493530273, 2.3007125854492188, 2.3007233142852783, 2.300766944885254, 2.3007171154022217, 2.300708532333374, 2.3006694316864014, 2.3006234169006348, 2.300583600997925, 2.300591230392456, 2.3005003929138184, 2.3005123138427734, 2.3004963397979736, 2.300431728363037, 2.300377130508423, 2.3003225326538086, 2.3002915382385254, 2.300222396850586, 2.300166130065918, 2.3001604080200195, 2.300083875656128, 2.2999985218048096, 2.2999463081359863, 2.299863576889038, 2.2997875213623047, 2.299701452255249, 2.2995824813842773, 2.2994844913482666, 2.2993175983428955, 2.2991349697113037, 2.2989397048950195, 2.2987606525421143, 2.298513889312744, 2.2981374263763428, 2.297713279724121, 2.297178268432617, 2.296431541442871], 'accuracy': [0.11514583230018616, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565], 'val_loss': [2.3020448684692383, 2.3019156455993652, 2.301912307739258, 2.301926612854004, 2.301955461502075, 2.3019702434539795, 2.3019814491271973, 2.3019559383392334, 2.301928997039795, 2.301920175552368, 2.3018956184387207, 2.301859140396118, 2.301851511001587, 2.3018412590026855, 2.301830291748047, 2.301774501800537, 2.3017771244049072, 2.301741600036621, 2.3017306327819824, 2.3017027378082275, 2.301668882369995, 2.30165696144104, 2.3016252517700195, 2.301600694656372, 2.301563262939453, 2.3015248775482178, 2.3014490604400635, 2.301417589187622, 2.301384925842285, 2.3013319969177246, 2.3013010025024414, 2.301248788833618, 2.3011841773986816, 2.3011293411254883, 2.3010611534118652, 2.3009796142578125, 2.3009002208709717, 2.300776243209839, 2.3006815910339355, 2.3005614280700684, 2.3004090785980225, 2.30026912689209, 2.3000998497009277, 2.299877166748047, 2.2996342182159424, 2.299346685409546, 2.298966646194458, 2.2984938621520996, 2.2978594303131104, 2.2969486713409424], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "10depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
