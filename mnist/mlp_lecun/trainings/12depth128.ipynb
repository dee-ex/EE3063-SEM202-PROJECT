{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1081936,
     "status": "ok",
     "timestamp": 1627303594173,
     "user": {
      "displayName": "Trung Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz3Gx8BE3WlqqWlg0FDtKUcK2DEtQ_rPNQD4mLTA=s64",
      "userId": "01683412142186761760"
     },
     "user_tz": -420
    },
    "id": "JnHhSjZec4W6",
    "outputId": "80d86fc6-1d9a-49e3-8ea5-3f048cdfe216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 20s 8ms/step - loss: 2.5126 - accuracy: 0.1014 - val_loss: 2.3034 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4049 - accuracy: 0.1055 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3756 - accuracy: 0.0996 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3614 - accuracy: 0.1004 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3468 - accuracy: 0.1009 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3383 - accuracy: 0.1023 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3332 - accuracy: 0.0985 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3282 - accuracy: 0.1037 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3237 - accuracy: 0.1010 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3189 - accuracy: 0.1032 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3174 - accuracy: 0.1044 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3148 - accuracy: 0.1044 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3120 - accuracy: 0.1060 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3109 - accuracy: 0.1040 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3091 - accuracy: 0.1067 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3099 - accuracy: 0.1020 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3085 - accuracy: 0.1053 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3075 - accuracy: 0.1046 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3057 - accuracy: 0.1068 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3056 - accuracy: 0.1046 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3051 - accuracy: 0.1059 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3048 - accuracy: 0.1079 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3043 - accuracy: 0.1103 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3040 - accuracy: 0.1033 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3040 - accuracy: 0.1105 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3042 - accuracy: 0.1073 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3033 - accuracy: 0.1081 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3037 - accuracy: 0.1091 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3037 - accuracy: 0.1093 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3033 - accuracy: 0.1096 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.1116 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3028 - accuracy: 0.1103 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.1101 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3022 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.1116 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3021 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1116 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3018 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3028 - accuracy: 0.1100 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3018 - accuracy: 0.1115 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3021 - accuracy: 0.1101 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3020 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1104 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3016 - accuracy: 0.1154 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1142 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 7ms/step - loss: 2.3451 - accuracy: 0.1415 - val_loss: 1.7049 - val_accuracy: 0.4747\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0156 - accuracy: 0.2533 - val_loss: 1.4321 - val_accuracy: 0.5327\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8263 - accuracy: 0.3180 - val_loss: 1.2399 - val_accuracy: 0.5891\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6836 - accuracy: 0.3643 - val_loss: 1.1111 - val_accuracy: 0.6361\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5542 - accuracy: 0.4119 - val_loss: 1.0320 - val_accuracy: 0.6728\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4667 - accuracy: 0.4476 - val_loss: 0.9798 - val_accuracy: 0.6990\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4199 - accuracy: 0.4650 - val_loss: 0.9538 - val_accuracy: 0.7048\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3710 - accuracy: 0.4826 - val_loss: 0.9307 - val_accuracy: 0.7180\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3376 - accuracy: 0.4970 - val_loss: 0.9224 - val_accuracy: 0.7207\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3048 - accuracy: 0.5147 - val_loss: 0.8983 - val_accuracy: 0.7236\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2659 - accuracy: 0.5318 - val_loss: 0.8855 - val_accuracy: 0.7087\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2477 - accuracy: 0.5361 - val_loss: 0.8777 - val_accuracy: 0.7117\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2147 - accuracy: 0.5487 - val_loss: 0.8625 - val_accuracy: 0.7143\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2089 - accuracy: 0.5592 - val_loss: 0.8536 - val_accuracy: 0.7282\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1925 - accuracy: 0.5648 - val_loss: 0.8395 - val_accuracy: 0.7129\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1617 - accuracy: 0.5759 - val_loss: 0.8311 - val_accuracy: 0.7175\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1535 - accuracy: 0.5817 - val_loss: 0.8302 - val_accuracy: 0.7295\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1290 - accuracy: 0.5891 - val_loss: 0.8144 - val_accuracy: 0.7194\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1237 - accuracy: 0.5942 - val_loss: 0.8135 - val_accuracy: 0.7149\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1025 - accuracy: 0.6038 - val_loss: 0.8029 - val_accuracy: 0.7207\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1111 - accuracy: 0.6017 - val_loss: 0.7860 - val_accuracy: 0.7262\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0853 - accuracy: 0.6128 - val_loss: 0.7810 - val_accuracy: 0.7245\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0750 - accuracy: 0.6196 - val_loss: 0.7773 - val_accuracy: 0.7203\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0648 - accuracy: 0.6204 - val_loss: 0.7708 - val_accuracy: 0.7273\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0473 - accuracy: 0.6255 - val_loss: 0.7570 - val_accuracy: 0.7326\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0387 - accuracy: 0.6335 - val_loss: 0.7483 - val_accuracy: 0.7335\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0336 - accuracy: 0.6351 - val_loss: 0.7559 - val_accuracy: 0.7306\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0231 - accuracy: 0.6429 - val_loss: 0.7424 - val_accuracy: 0.7408\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0123 - accuracy: 0.6502 - val_loss: 0.7157 - val_accuracy: 0.7434\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9983 - accuracy: 0.6512 - val_loss: 0.7075 - val_accuracy: 0.7460\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9969 - accuracy: 0.6558 - val_loss: 0.6971 - val_accuracy: 0.7514\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9791 - accuracy: 0.6619 - val_loss: 0.6789 - val_accuracy: 0.7542\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9684 - accuracy: 0.6651 - val_loss: 0.6783 - val_accuracy: 0.7526\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9651 - accuracy: 0.6699 - val_loss: 0.6708 - val_accuracy: 0.7547\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9546 - accuracy: 0.6708 - val_loss: 0.6853 - val_accuracy: 0.7502\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9448 - accuracy: 0.6781 - val_loss: 0.6584 - val_accuracy: 0.7566\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9287 - accuracy: 0.6783 - val_loss: 0.6557 - val_accuracy: 0.7580\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9258 - accuracy: 0.6849 - val_loss: 0.6593 - val_accuracy: 0.7571\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9267 - accuracy: 0.6811 - val_loss: 0.6429 - val_accuracy: 0.7588\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9181 - accuracy: 0.6840 - val_loss: 0.6387 - val_accuracy: 0.7613\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9128 - accuracy: 0.6843 - val_loss: 0.6410 - val_accuracy: 0.7606\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9067 - accuracy: 0.6899 - val_loss: 0.6396 - val_accuracy: 0.7624\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9003 - accuracy: 0.6892 - val_loss: 0.6270 - val_accuracy: 0.7644\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8923 - accuracy: 0.6931 - val_loss: 0.6242 - val_accuracy: 0.7642\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8759 - accuracy: 0.6950 - val_loss: 0.6155 - val_accuracy: 0.7662\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8889 - accuracy: 0.6914 - val_loss: 0.6188 - val_accuracy: 0.7647\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8693 - accuracy: 0.6995 - val_loss: 0.6193 - val_accuracy: 0.7683\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8796 - accuracy: 0.6903 - val_loss: 0.6164 - val_accuracy: 0.7664\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8685 - accuracy: 0.6931 - val_loss: 0.6060 - val_accuracy: 0.7687\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8511 - accuracy: 0.7025 - val_loss: 0.6043 - val_accuracy: 0.7697\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 7ms/step - loss: 2.3026 - accuracy: 0.1086 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1265 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1209 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1185 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1214 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2990 - accuracy: 0.1233 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2989 - accuracy: 0.1237 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2994 - accuracy: 0.1227 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2986 - accuracy: 0.1234 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2970 - accuracy: 0.1313 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2960 - accuracy: 0.1335 - val_loss: 2.2968 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2909 - accuracy: 0.1508 - val_loss: 2.2877 - val_accuracy: 0.1268\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2784 - accuracy: 0.1621 - val_loss: 2.2540 - val_accuracy: 0.1978\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2510 - accuracy: 0.1756 - val_loss: 2.1872 - val_accuracy: 0.2022\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2094 - accuracy: 0.1840 - val_loss: 2.1235 - val_accuracy: 0.2066\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1774 - accuracy: 0.1878 - val_loss: 2.0566 - val_accuracy: 0.2133\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1265 - accuracy: 0.2006 - val_loss: 2.0135 - val_accuracy: 0.2244\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0857 - accuracy: 0.2082 - val_loss: 1.9784 - val_accuracy: 0.2373\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0401 - accuracy: 0.2200 - val_loss: 1.9368 - val_accuracy: 0.2507\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9966 - accuracy: 0.2366 - val_loss: 1.9331 - val_accuracy: 0.2623\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9588 - accuracy: 0.2468 - val_loss: 1.8739 - val_accuracy: 0.2822\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9239 - accuracy: 0.2561 - val_loss: 1.8470 - val_accuracy: 0.2848\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8891 - accuracy: 0.2677 - val_loss: 1.8192 - val_accuracy: 0.3020\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8434 - accuracy: 0.2849 - val_loss: 1.7891 - val_accuracy: 0.2977\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8254 - accuracy: 0.2928 - val_loss: 1.7872 - val_accuracy: 0.2873\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7883 - accuracy: 0.3055 - val_loss: 1.7680 - val_accuracy: 0.2867\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7612 - accuracy: 0.3133 - val_loss: 1.7064 - val_accuracy: 0.3324\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7317 - accuracy: 0.3161 - val_loss: 1.6907 - val_accuracy: 0.3184\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6886 - accuracy: 0.3303 - val_loss: 1.6590 - val_accuracy: 0.3183\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6637 - accuracy: 0.3409 - val_loss: 1.6204 - val_accuracy: 0.3503\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6427 - accuracy: 0.3420 - val_loss: 1.6245 - val_accuracy: 0.3016\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6364 - accuracy: 0.3455 - val_loss: 1.5823 - val_accuracy: 0.3306\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6089 - accuracy: 0.3472 - val_loss: 1.5544 - val_accuracy: 0.3607\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5868 - accuracy: 0.3450 - val_loss: 1.5538 - val_accuracy: 0.3429\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5614 - accuracy: 0.3516 - val_loss: 1.5362 - val_accuracy: 0.3583\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5659 - accuracy: 0.3497 - val_loss: 1.4908 - val_accuracy: 0.3636\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5313 - accuracy: 0.3569 - val_loss: 1.4969 - val_accuracy: 0.3592\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5352 - accuracy: 0.3556 - val_loss: 1.4722 - val_accuracy: 0.3669\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5231 - accuracy: 0.3524 - val_loss: 1.4825 - val_accuracy: 0.3660\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4967 - accuracy: 0.3604 - val_loss: 1.4656 - val_accuracy: 0.3519\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4868 - accuracy: 0.3636 - val_loss: 1.4427 - val_accuracy: 0.3695\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4701 - accuracy: 0.3691 - val_loss: 1.4945 - val_accuracy: 0.3545\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4897 - accuracy: 0.3619 - val_loss: 1.4226 - val_accuracy: 0.3983\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4667 - accuracy: 0.3677 - val_loss: 1.4211 - val_accuracy: 0.3779\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4476 - accuracy: 0.3760 - val_loss: 1.4407 - val_accuracy: 0.3733\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4510 - accuracy: 0.3707 - val_loss: 1.3741 - val_accuracy: 0.3898\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4367 - accuracy: 0.3738 - val_loss: 1.3956 - val_accuracy: 0.3968\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4165 - accuracy: 0.3760 - val_loss: 1.4008 - val_accuracy: 0.3853\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4321 - accuracy: 0.3712 - val_loss: 1.4038 - val_accuracy: 0.3805\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4282 - accuracy: 0.3670 - val_loss: 1.3864 - val_accuracy: 0.3799\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 8ms/step - loss: 2.3030 - accuracy: 0.1134 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1273 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2992 - accuracy: 0.1313 - val_loss: 2.2985 - val_accuracy: 0.1063\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2971 - accuracy: 0.1379 - val_loss: 2.2928 - val_accuracy: 0.1417\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2914 - accuracy: 0.1519 - val_loss: 2.2756 - val_accuracy: 0.1945\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2765 - accuracy: 0.1748 - val_loss: 2.2437 - val_accuracy: 0.2001\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2569 - accuracy: 0.1816 - val_loss: 2.1889 - val_accuracy: 0.2562\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2151 - accuracy: 0.1900 - val_loss: 2.1077 - val_accuracy: 0.2152\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1650 - accuracy: 0.1952 - val_loss: 2.0542 - val_accuracy: 0.2165\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1246 - accuracy: 0.2043 - val_loss: 2.0145 - val_accuracy: 0.2272\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0745 - accuracy: 0.2155 - val_loss: 1.9802 - val_accuracy: 0.2569\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0324 - accuracy: 0.2284 - val_loss: 1.9429 - val_accuracy: 0.2702\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0061 - accuracy: 0.2354 - val_loss: 1.9005 - val_accuracy: 0.2914\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9731 - accuracy: 0.2496 - val_loss: 1.8566 - val_accuracy: 0.3038\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9411 - accuracy: 0.2496 - val_loss: 1.8129 - val_accuracy: 0.3169\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9036 - accuracy: 0.2648 - val_loss: 1.7842 - val_accuracy: 0.3222\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8716 - accuracy: 0.2746 - val_loss: 1.7409 - val_accuracy: 0.3471\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8437 - accuracy: 0.2840 - val_loss: 1.7157 - val_accuracy: 0.3537\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8118 - accuracy: 0.2974 - val_loss: 1.6847 - val_accuracy: 0.3866\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7773 - accuracy: 0.3067 - val_loss: 1.6133 - val_accuracy: 0.4157\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7452 - accuracy: 0.3176 - val_loss: 1.5515 - val_accuracy: 0.4217\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7049 - accuracy: 0.3221 - val_loss: 1.5069 - val_accuracy: 0.4236\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6606 - accuracy: 0.3323 - val_loss: 1.4934 - val_accuracy: 0.4055\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6389 - accuracy: 0.3311 - val_loss: 1.4383 - val_accuracy: 0.4485\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5872 - accuracy: 0.3519 - val_loss: 1.3904 - val_accuracy: 0.4714\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5483 - accuracy: 0.3593 - val_loss: 1.3646 - val_accuracy: 0.5056\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5175 - accuracy: 0.3705 - val_loss: 1.3426 - val_accuracy: 0.5368\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5056 - accuracy: 0.3758 - val_loss: 1.3662 - val_accuracy: 0.4956\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4680 - accuracy: 0.3910 - val_loss: 1.2764 - val_accuracy: 0.5393\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4463 - accuracy: 0.3981 - val_loss: 1.2623 - val_accuracy: 0.5247\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4085 - accuracy: 0.4111 - val_loss: 1.2489 - val_accuracy: 0.5345\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3891 - accuracy: 0.4256 - val_loss: 1.2276 - val_accuracy: 0.5491\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3573 - accuracy: 0.4389 - val_loss: 1.1864 - val_accuracy: 0.5553\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3924 - accuracy: 0.4342 - val_loss: 1.1672 - val_accuracy: 0.5298\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3156 - accuracy: 0.4587 - val_loss: 1.1797 - val_accuracy: 0.5730\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3029 - accuracy: 0.4601 - val_loss: 1.1721 - val_accuracy: 0.5861\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2992 - accuracy: 0.4643 - val_loss: 1.1450 - val_accuracy: 0.5805\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3006 - accuracy: 0.4677 - val_loss: 1.1318 - val_accuracy: 0.5746\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2586 - accuracy: 0.4754 - val_loss: 1.1176 - val_accuracy: 0.5823\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2304 - accuracy: 0.4817 - val_loss: 1.1779 - val_accuracy: 0.6136\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2167 - accuracy: 0.4855 - val_loss: 1.1291 - val_accuracy: 0.5623\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2231 - accuracy: 0.4931 - val_loss: 1.2037 - val_accuracy: 0.5422\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2597 - accuracy: 0.4856 - val_loss: 1.0973 - val_accuracy: 0.5773\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1700 - accuracy: 0.5041 - val_loss: 1.1081 - val_accuracy: 0.6007\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2527 - accuracy: 0.4869 - val_loss: 1.1072 - val_accuracy: 0.6014\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1996 - accuracy: 0.4906 - val_loss: 1.0912 - val_accuracy: 0.5698\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1778 - accuracy: 0.5038 - val_loss: 1.1089 - val_accuracy: 0.5798\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1612 - accuracy: 0.5073 - val_loss: 1.0804 - val_accuracy: 0.6222\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1209 - accuracy: 0.5189 - val_loss: 1.0704 - val_accuracy: 0.6313\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1249 - accuracy: 0.5143 - val_loss: 1.0752 - val_accuracy: 0.6284\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 7ms/step - loss: 2.3478 - accuracy: 0.1291 - val_loss: 1.7992 - val_accuracy: 0.4234\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0596 - accuracy: 0.2238 - val_loss: 1.4266 - val_accuracy: 0.5763\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8353 - accuracy: 0.3161 - val_loss: 1.1989 - val_accuracy: 0.6441\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6726 - accuracy: 0.3720 - val_loss: 1.0619 - val_accuracy: 0.6791\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5551 - accuracy: 0.4128 - val_loss: 0.9635 - val_accuracy: 0.7306\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4837 - accuracy: 0.4442 - val_loss: 0.8852 - val_accuracy: 0.7712\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4176 - accuracy: 0.4682 - val_loss: 0.8142 - val_accuracy: 0.7897\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3514 - accuracy: 0.4991 - val_loss: 0.7602 - val_accuracy: 0.8016\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2962 - accuracy: 0.5257 - val_loss: 0.7114 - val_accuracy: 0.8087\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2373 - accuracy: 0.5450 - val_loss: 0.6730 - val_accuracy: 0.8275\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1997 - accuracy: 0.5648 - val_loss: 0.6440 - val_accuracy: 0.8397\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1617 - accuracy: 0.5810 - val_loss: 0.6271 - val_accuracy: 0.8429\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1416 - accuracy: 0.5853 - val_loss: 0.5989 - val_accuracy: 0.8525\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0893 - accuracy: 0.6077 - val_loss: 0.5862 - val_accuracy: 0.8484\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0700 - accuracy: 0.6183 - val_loss: 0.5650 - val_accuracy: 0.8474\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0572 - accuracy: 0.6241 - val_loss: 0.5473 - val_accuracy: 0.8319\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0229 - accuracy: 0.6333 - val_loss: 0.5335 - val_accuracy: 0.8609\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9953 - accuracy: 0.6448 - val_loss: 0.5219 - val_accuracy: 0.8253\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9758 - accuracy: 0.6556 - val_loss: 0.5120 - val_accuracy: 0.8558\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9544 - accuracy: 0.6573 - val_loss: 0.5037 - val_accuracy: 0.8320\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9435 - accuracy: 0.6667 - val_loss: 0.4992 - val_accuracy: 0.8108\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9321 - accuracy: 0.6720 - val_loss: 0.4958 - val_accuracy: 0.8202\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9156 - accuracy: 0.6740 - val_loss: 0.4902 - val_accuracy: 0.8202\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9043 - accuracy: 0.6822 - val_loss: 0.4861 - val_accuracy: 0.8101\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9046 - accuracy: 0.6775 - val_loss: 0.4858 - val_accuracy: 0.7992\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8889 - accuracy: 0.6804 - val_loss: 0.4848 - val_accuracy: 0.8084\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8709 - accuracy: 0.6873 - val_loss: 0.4806 - val_accuracy: 0.7908\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8551 - accuracy: 0.6973 - val_loss: 0.4824 - val_accuracy: 0.7961\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8435 - accuracy: 0.6993 - val_loss: 0.4783 - val_accuracy: 0.7928\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8443 - accuracy: 0.6973 - val_loss: 0.4806 - val_accuracy: 0.7931\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8309 - accuracy: 0.6965 - val_loss: 0.4716 - val_accuracy: 0.8384\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8224 - accuracy: 0.7013 - val_loss: 0.4733 - val_accuracy: 0.7889\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8244 - accuracy: 0.7055 - val_loss: 0.4741 - val_accuracy: 0.8285\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8131 - accuracy: 0.7080 - val_loss: 0.4715 - val_accuracy: 0.7942\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7999 - accuracy: 0.7088 - val_loss: 0.4677 - val_accuracy: 0.8142\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7837 - accuracy: 0.7127 - val_loss: 0.4635 - val_accuracy: 0.8013\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8000 - accuracy: 0.7098 - val_loss: 0.4677 - val_accuracy: 0.7932\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7743 - accuracy: 0.7106 - val_loss: 0.4656 - val_accuracy: 0.7987\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7831 - accuracy: 0.7169 - val_loss: 0.4680 - val_accuracy: 0.7960\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7842 - accuracy: 0.7142 - val_loss: 0.4668 - val_accuracy: 0.8108\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7683 - accuracy: 0.7207 - val_loss: 0.4573 - val_accuracy: 0.8083\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7562 - accuracy: 0.7251 - val_loss: 0.4577 - val_accuracy: 0.8052\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7717 - accuracy: 0.7168 - val_loss: 0.4545 - val_accuracy: 0.8215\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7675 - accuracy: 0.7202 - val_loss: 0.4569 - val_accuracy: 0.7884\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7443 - accuracy: 0.7256 - val_loss: 0.4496 - val_accuracy: 0.7951\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7458 - accuracy: 0.7226 - val_loss: 0.4536 - val_accuracy: 0.8114\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7361 - accuracy: 0.7289 - val_loss: 0.4550 - val_accuracy: 0.8111\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7428 - accuracy: 0.7255 - val_loss: 0.4520 - val_accuracy: 0.7928\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7258 - accuracy: 0.7249 - val_loss: 0.4496 - val_accuracy: 0.8000\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7296 - accuracy: 0.7294 - val_loss: 0.4491 - val_accuracy: 0.7924\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 7ms/step - loss: 2.7498 - accuracy: 0.1002 - val_loss: 2.3613 - val_accuracy: 0.1316\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.5231 - accuracy: 0.0984 - val_loss: 2.2986 - val_accuracy: 0.1291\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.4226 - accuracy: 0.0999 - val_loss: 2.2874 - val_accuracy: 0.1315\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3718 - accuracy: 0.1010 - val_loss: 2.2822 - val_accuracy: 0.1354\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3462 - accuracy: 0.1016 - val_loss: 2.2817 - val_accuracy: 0.1377\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3279 - accuracy: 0.1019 - val_loss: 2.2851 - val_accuracy: 0.1363\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3176 - accuracy: 0.1009 - val_loss: 2.2870 - val_accuracy: 0.1473\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3123 - accuracy: 0.1019 - val_loss: 2.2877 - val_accuracy: 0.1262\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3073 - accuracy: 0.1059 - val_loss: 2.2908 - val_accuracy: 0.1113\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3051 - accuracy: 0.1102 - val_loss: 2.2929 - val_accuracy: 0.1117\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3035 - accuracy: 0.1105 - val_loss: 2.2951 - val_accuracy: 0.1090\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.1079 - val_loss: 2.2973 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3032 - accuracy: 0.1104 - val_loss: 2.2977 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3021 - accuracy: 0.1107 - val_loss: 2.2973 - val_accuracy: 0.1061\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3015 - accuracy: 0.1136 - val_loss: 2.2986 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3015 - accuracy: 0.1134 - val_loss: 2.2999 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1142 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1118 - val_loss: 2.2998 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.2997 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1147 - val_loss: 2.2978 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1179 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1151 - val_loss: 2.3015 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1127 - val_loss: 2.3027 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3013 - accuracy: 0.1135 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1136 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1127 - val_loss: 2.3040 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1151 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1128 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1151 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1150 - val_loss: 2.2969 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3016 - accuracy: 0.1123 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3018 - accuracy: 0.1102 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1133 - val_loss: 2.2991 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1156 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1121 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3018 - accuracy: 0.1108 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1170 - val_loss: 2.2981 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1145 - val_loss: 2.2995 - val_accuracy: 0.1110\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1137 - val_loss: 2.2997 - val_accuracy: 0.1073\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1132 - val_loss: 2.2983 - val_accuracy: 0.1086\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1138 - val_loss: 2.2980 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1157 - val_loss: 2.2994 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1149 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1129 - val_loss: 2.2988 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.2996 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1136 - val_loss: 2.3032 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1141 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3012 - accuracy: 0.1120 - val_loss: 2.2995 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3014 - accuracy: 0.1155 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3017 - accuracy: 0.1122 - val_loss: 2.3038 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 6s 9ms/step - loss: 2.3022 - accuracy: 0.1138 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3015 - accuracy: 0.1128 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3014 - accuracy: 0.1131 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3012 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3011 - accuracy: 0.1150 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3014 - accuracy: 0.1114 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3004 - accuracy: 0.1163 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3007 - accuracy: 0.1149 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3008 - accuracy: 0.1158 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3007 - accuracy: 0.1157 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3009 - accuracy: 0.1128 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3011 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3005 - accuracy: 0.1152 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3008 - accuracy: 0.1125 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3009 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3010 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3012 - accuracy: 0.1123 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3006 - accuracy: 0.1182 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3012 - accuracy: 0.1136 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3005 - accuracy: 0.1167 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3012 - accuracy: 0.1122 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3009 - accuracy: 0.1145 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3010 - accuracy: 0.1131 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3013 - accuracy: 0.1126 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3009 - accuracy: 0.1117 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3005 - accuracy: 0.1148 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3011 - accuracy: 0.1134 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3010 - accuracy: 0.1136 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3007 - accuracy: 0.1161 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3011 - accuracy: 0.1131 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3011 - accuracy: 0.1134 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3013 - accuracy: 0.1138 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3005 - accuracy: 0.1167 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3007 - accuracy: 0.1149 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3008 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3010 - accuracy: 0.1131 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3007 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3005 - accuracy: 0.1155 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3006 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3011 - accuracy: 0.1128 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 8ms/step - loss: 2.3023 - accuracy: 0.1118 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3017 - accuracy: 0.1128 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1144 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1129 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1149 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1146 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1127 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3016 - accuracy: 0.1122 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1129 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1129 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3014 - accuracy: 0.1112 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1157 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1135 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1162 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1138 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1113 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1146 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1103 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1170 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1152 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1135 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1147 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1138 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1114 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3014 - accuracy: 0.1115 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3012 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3006 - accuracy: 0.1163 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3011 - accuracy: 0.1144 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "{'loss': [2.463736057281494, 2.396497964859009, 2.3698911666870117, 2.3577651977539062, 2.3429372310638428, 2.33591890335083, 2.3315415382385254, 2.326409101486206, 2.322098731994629, 2.3177809715270996, 2.3162875175476074, 2.3149144649505615, 2.3118784427642822, 2.309757709503174, 2.3097763061523438, 2.309206008911133, 2.307806968688965, 2.306896209716797, 2.305985689163208, 2.3054041862487793, 2.3053269386291504, 2.304797649383545, 2.3045849800109863, 2.3037898540496826, 2.3040671348571777, 2.304110050201416, 2.303262948989868, 2.3035144805908203, 2.3028976917266846, 2.302898645401001, 2.302720785140991, 2.3026857376098633, 2.3023228645324707, 2.3023531436920166, 2.3025314807891846, 2.3022472858428955, 2.3022890090942383, 2.301926851272583, 2.3021810054779053, 2.302063465118408, 2.3017640113830566, 2.3018293380737305, 2.302117347717285, 2.301591634750366, 2.30171799659729, 2.301785707473755, 2.3016817569732666, 2.3015949726104736, 2.3016116619110107, 2.3016037940979004], 'accuracy': [0.10141666978597641, 0.10337500274181366, 0.10141666978597641, 0.10097916424274445, 0.10297916829586029, 0.10237500071525574, 0.10062500089406967, 0.10366666316986084, 0.10227083414793015, 0.10214583575725555, 0.1041041687130928, 0.10214583575725555, 0.10716667026281357, 0.1042499989271164, 0.10620833188295364, 0.10310416668653488, 0.10750000178813934, 0.10502083599567413, 0.10493750125169754, 0.10627083480358124, 0.10697916895151138, 0.10654166340827942, 0.10770833492279053, 0.10664582997560501, 0.10885416716337204, 0.10754166543483734, 0.10877083241939545, 0.10779166966676712, 0.11133333295583725, 0.11020833253860474, 0.11085416376590729, 0.10987500101327896, 0.10975000262260437, 0.11185416579246521, 0.1120000034570694, 0.1132916659116745, 0.11135416477918625, 0.11214583367109299, 0.11181250214576721, 0.11102083325386047, 0.11170833557844162, 0.11237499862909317, 0.11220833659172058, 0.11285416781902313, 0.1132916659116745, 0.11254166811704636, 0.11364583671092987, 0.11227083206176758, 0.11368750035762787, 0.11362499743700027], 'val_loss': [2.3033947944641113, 2.3021090030670166, 2.3020501136779785, 2.3020687103271484, 2.3022191524505615, 2.3021154403686523, 2.3020894527435303, 2.3019955158233643, 2.3020272254943848, 2.3019518852233887, 2.301992893218994, 2.302061080932617, 2.3019776344299316, 2.3020594120025635, 2.3021581172943115, 2.3021655082702637, 2.302135705947876, 2.3021271228790283, 2.302063465118408, 2.3019893169403076, 2.3020384311676025, 2.302025079727173, 2.301973581314087, 2.3020665645599365, 2.302030324935913, 2.3020195960998535, 2.302116632461548, 2.302122116088867, 2.302154302597046, 2.3020927906036377, 2.302081346511841, 2.3020498752593994, 2.302025318145752, 2.302004098892212, 2.3021135330200195, 2.302112579345703, 2.3021020889282227, 2.3020966053009033, 2.302053928375244, 2.3020427227020264, 2.302103281021118, 2.3021469116210938, 2.3020949363708496, 2.3021140098571777, 2.302100419998169, 2.3021011352539062, 2.3019824028015137, 2.302065134048462, 2.3020613193511963, 2.302100896835327], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [2.2426977157592773, 1.9650678634643555, 1.7799344062805176, 1.6450921297073364, 1.5336326360702515, 1.4581972360610962, 1.4032683372497559, 1.3600122928619385, 1.3242930173873901, 1.2908403873443604, 1.265918493270874, 1.2389248609542847, 1.2186059951782227, 1.2032063007354736, 1.179458498954773, 1.1558928489685059, 1.148587942123413, 1.1328469514846802, 1.1179285049438477, 1.106621503829956, 1.0976804494857788, 1.084683895111084, 1.0742576122283936, 1.0615166425704956, 1.0486918687820435, 1.0403097867965698, 1.0262811183929443, 1.0219782590866089, 1.0066519975662231, 0.9946834444999695, 0.9874425530433655, 0.9761959910392761, 0.9648721814155579, 0.9565114974975586, 0.950130045413971, 0.9430016279220581, 0.9321621060371399, 0.9264512658119202, 0.9234412312507629, 0.9134626388549805, 0.90847247838974, 0.8998003602027893, 0.8961306214332581, 0.8801069259643555, 0.8830342888832092, 0.8775108456611633, 0.8692929148674011, 0.8701676726341248, 0.8660024404525757, 0.8574408888816833], 'accuracy': [0.17552083730697632, 0.27141666412353516, 0.33420833945274353, 0.3785833418369293, 0.4181666672229767, 0.44993749260902405, 0.46806249022483826, 0.48535415530204773, 0.5026875138282776, 0.5207499861717224, 0.5307083129882812, 0.5402500033378601, 0.5483124852180481, 0.5614166855812073, 0.5692291855812073, 0.5797291398048401, 0.5840625166893005, 0.5917083621025085, 0.597041666507721, 0.6030416488647461, 0.6077708601951599, 0.612458348274231, 0.6188541650772095, 0.622041642665863, 0.6278958320617676, 0.6339791417121887, 0.6355416774749756, 0.6417083144187927, 0.651604175567627, 0.6541666388511658, 0.6583541631698608, 0.6634374856948853, 0.6667291522026062, 0.6715208292007446, 0.6727499961853027, 0.6767916679382324, 0.6788333058357239, 0.6850000023841858, 0.682729184627533, 0.6826249957084656, 0.6872708201408386, 0.6914166808128357, 0.6914374828338623, 0.6950833201408386, 0.6929374933242798, 0.6936249732971191, 0.6976875066757202, 0.6935625076293945, 0.6953750252723694, 0.6997291445732117], 'val_loss': [1.7049015760421753, 1.4321290254592896, 1.2399262189865112, 1.1111176013946533, 1.0320029258728027, 0.9798117876052856, 0.9537817239761353, 0.9306500554084778, 0.9223619103431702, 0.8983193635940552, 0.8854697942733765, 0.8777445554733276, 0.8624811172485352, 0.8536437749862671, 0.8395258784294128, 0.8311281800270081, 0.8301770091056824, 0.8144038319587708, 0.8134633898735046, 0.8028940558433533, 0.7860360741615295, 0.7809829711914062, 0.7773427963256836, 0.7707564234733582, 0.7569794058799744, 0.7482950687408447, 0.7559495568275452, 0.7424367070198059, 0.7157481908798218, 0.7075427174568176, 0.6971119046211243, 0.6789473295211792, 0.678322434425354, 0.670782208442688, 0.6852570176124573, 0.6584168076515198, 0.6556820273399353, 0.6592570543289185, 0.6429409384727478, 0.6387208700180054, 0.6410332322120667, 0.6395609378814697, 0.6269997358322144, 0.6241877675056458, 0.6154575347900391, 0.6187888383865356, 0.6192619800567627, 0.6163593530654907, 0.6059578657150269, 0.6042752861976624], 'val_accuracy': [0.47466665506362915, 0.5326666831970215, 0.5890833139419556, 0.6360833048820496, 0.6728333234786987, 0.6990000009536743, 0.7047500014305115, 0.7179999947547913, 0.7207499742507935, 0.7235833406448364, 0.7086666822433472, 0.7116666436195374, 0.7142500281333923, 0.7281666398048401, 0.7129166722297668, 0.7174999713897705, 0.7294999957084656, 0.7194166779518127, 0.7149166464805603, 0.7207499742507935, 0.7261666655540466, 0.7245000004768372, 0.7202500104904175, 0.7273333072662354, 0.7325833439826965, 0.7335000038146973, 0.7305833101272583, 0.7407500147819519, 0.7434166669845581, 0.7459999918937683, 0.7514166831970215, 0.7542499899864197, 0.7525833249092102, 0.7546666860580444, 0.750166654586792, 0.7565833330154419, 0.7580000162124634, 0.7570833563804626, 0.7587500214576721, 0.7612500190734863, 0.7605833411216736, 0.762416660785675, 0.7644166946411133, 0.7642499804496765, 0.7661666870117188, 0.7646666765213013, 0.7683333158493042, 0.7664166688919067, 0.768666684627533, 0.7697499990463257]}\n",
      "{'loss': [2.3021864891052246, 2.300922155380249, 2.300478458404541, 2.3003478050231934, 2.2999236583709717, 2.2995121479034424, 2.299349069595337, 2.2990150451660156, 2.298267364501953, 2.2971179485321045, 2.294304847717285, 2.2885355949401855, 2.2721149921417236, 2.2414393424987793, 2.2021405696868896, 2.163933277130127, 2.1156721115112305, 2.077523708343506, 2.0257527828216553, 1.984649419784546, 1.952052354812622, 1.9111520051956177, 1.8787695169448853, 1.8400667905807495, 1.8183650970458984, 1.7820897102355957, 1.7523951530456543, 1.723252296447754, 1.6892257928848267, 1.6712796688079834, 1.6362959146499634, 1.6243211030960083, 1.6056994199752808, 1.5813695192337036, 1.5628875494003296, 1.5565688610076904, 1.5362801551818848, 1.539400577545166, 1.5210011005401611, 1.4974985122680664, 1.490486979484558, 1.4767780303955078, 1.5140591859817505, 1.469180941581726, 1.4401499032974243, 1.4458461999893188, 1.445340633392334, 1.4197146892547607, 1.4263160228729248, 1.425766110420227], 'accuracy': [0.11749999970197678, 0.12445833534002304, 0.12085416913032532, 0.1198958307504654, 0.12072916328907013, 0.12191666662693024, 0.1211666688323021, 0.12272916734218597, 0.12552084028720856, 0.1301041692495346, 0.13979166746139526, 0.15295833349227905, 0.16591666638851166, 0.17920833826065063, 0.18406249582767487, 0.19374999403953552, 0.20416666567325592, 0.21120832860469818, 0.22472916543483734, 0.23664583265781403, 0.2485833317041397, 0.2619999945163727, 0.27168750762939453, 0.28568750619888306, 0.29368749260902405, 0.304770827293396, 0.31208333373069763, 0.31933334469795227, 0.3297708332538605, 0.3372708261013031, 0.34589582681655884, 0.34695833921432495, 0.3466874957084656, 0.351458340883255, 0.351375013589859, 0.3538541793823242, 0.35614582896232605, 0.3544166684150696, 0.3544999957084656, 0.36149999499320984, 0.3632916808128357, 0.3657708466053009, 0.35733333230018616, 0.367208331823349, 0.37460416555404663, 0.3710833191871643, 0.3713958263397217, 0.37587499618530273, 0.37329167127609253, 0.3734166622161865], 'val_loss': [2.3020436763763428, 2.301913022994995, 2.3019211292266846, 2.301987409591675, 2.3017826080322266, 2.3020832538604736, 2.302020311355591, 2.30182147026062, 2.3012728691101074, 2.3005189895629883, 2.296825647354126, 2.2876718044281006, 2.253972053527832, 2.187192440032959, 2.1235125064849854, 2.0566298961639404, 2.0135436058044434, 1.9783700704574585, 1.9368164539337158, 1.9330848455429077, 1.8738735914230347, 1.8469631671905518, 1.8192050457000732, 1.7890546321868896, 1.7871805429458618, 1.7680383920669556, 1.706390142440796, 1.6906929016113281, 1.6589844226837158, 1.6204363107681274, 1.6244962215423584, 1.582338809967041, 1.5544490814208984, 1.5537693500518799, 1.5361593961715698, 1.4908157587051392, 1.496895670890808, 1.4721680879592896, 1.482529640197754, 1.465647578239441, 1.4427309036254883, 1.4945130348205566, 1.4225739240646362, 1.4211299419403076, 1.4407098293304443, 1.3740804195404053, 1.3955563306808472, 1.400821566581726, 1.4038357734680176, 1.3863564729690552], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.12683333456516266, 0.1977500021457672, 0.20216666162014008, 0.20658333599567413, 0.2133333384990692, 0.22441667318344116, 0.23725000023841858, 0.25066667795181274, 0.26233333349227905, 0.28216665983200073, 0.2847500145435333, 0.3019999861717224, 0.29774999618530273, 0.28725001215934753, 0.2866666615009308, 0.3324166536331177, 0.31841665506362915, 0.31833332777023315, 0.3502500057220459, 0.30158331990242004, 0.3305833339691162, 0.3607499897480011, 0.34291666746139526, 0.3583333194255829, 0.3635833263397217, 0.3591666519641876, 0.3669166564941406, 0.3659999966621399, 0.35191667079925537, 0.3695000112056732, 0.3544999957084656, 0.398333340883255, 0.3779166638851166, 0.37325000762939453, 0.38983333110809326, 0.3968333303928375, 0.3853333294391632, 0.3804999887943268, 0.3799166679382324]}\n",
      "{'loss': [2.3022899627685547, 2.300400733947754, 2.2985849380493164, 2.295457601547241, 2.287975549697876, 2.273136615753174, 2.246370553970337, 2.202486753463745, 2.1559739112854004, 2.111480951309204, 2.0696120262145996, 2.0330662727355957, 1.998661994934082, 1.9616098403930664, 1.9266878366470337, 1.8978896141052246, 1.8651047945022583, 1.8383780717849731, 1.8038471937179565, 1.7669094800949097, 1.7345902919769287, 1.6970205307006836, 1.658643364906311, 1.6250823736190796, 1.5852257013320923, 1.5442531108856201, 1.5151337385177612, 1.5007106065750122, 1.4571750164031982, 1.434793472290039, 1.416269063949585, 1.395851731300354, 1.357702612876892, 1.3504447937011719, 1.3142346143722534, 1.3067736625671387, 1.2922545671463013, 1.3448010683059692, 1.2532570362091064, 1.2315232753753662, 1.2196966409683228, 1.2639015913009644, 1.223846673965454, 1.1835933923721313, 1.226717472076416, 1.221652865409851, 1.1757527589797974, 1.1613000631332397, 1.1274065971374512, 1.1241010427474976], 'accuracy': [0.12077083438634872, 0.12829166650772095, 0.13335417211055756, 0.1433124989271164, 0.15843750536441803, 0.17406250536441803, 0.18449999392032623, 0.1914166659116745, 0.1979166716337204, 0.20733332633972168, 0.218708336353302, 0.22814583778381348, 0.23633334040641785, 0.25077083706855774, 0.2538749873638153, 0.26520833373069763, 0.2758750021457672, 0.28595831990242004, 0.29902082681655884, 0.3102083206176758, 0.31708332896232605, 0.32354167103767395, 0.3316458463668823, 0.335812509059906, 0.351395845413208, 0.3636249899864197, 0.37045833468437195, 0.3779374957084656, 0.39283332228660583, 0.40162500739097595, 0.41231250762939453, 0.4221875071525574, 0.4385208189487457, 0.44495832920074463, 0.4568958282470703, 0.4622708261013031, 0.46672916412353516, 0.45747917890548706, 0.4804374873638153, 0.4827708303928375, 0.4871250092983246, 0.48362499475479126, 0.492229163646698, 0.5007500052452087, 0.49399998784065247, 0.49012500047683716, 0.5063333511352539, 0.5076666474342346, 0.5163124799728394, 0.5166249871253967], 'val_loss': [2.3018314838409424, 2.3011128902435303, 2.2985103130340576, 2.292806386947632, 2.275636672973633, 2.243734121322632, 2.1889498233795166, 2.10774827003479, 2.054194927215576, 2.014465570449829, 1.9801557064056396, 1.9429446458816528, 1.9005473852157593, 1.8565869331359863, 1.8129262924194336, 1.7842377424240112, 1.7408710718154907, 1.7157280445098877, 1.6847141981124878, 1.6132615804672241, 1.5514981746673584, 1.506882667541504, 1.4933826923370361, 1.4383002519607544, 1.390433430671692, 1.3646072149276733, 1.3426077365875244, 1.3662136793136597, 1.2764288187026978, 1.262281060218811, 1.2489138841629028, 1.2275941371917725, 1.186368465423584, 1.1671828031539917, 1.1797150373458862, 1.1720826625823975, 1.1449612379074097, 1.1318148374557495, 1.1175537109375, 1.17792546749115, 1.1291395425796509, 1.2037273645401, 1.0973210334777832, 1.1081188917160034, 1.1071546077728271, 1.0911850929260254, 1.1089351177215576, 1.0804237127304077, 1.0704323053359985, 1.0752378702163696], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10625000298023224, 0.14166666567325592, 0.19449999928474426, 0.20008333027362823, 0.2562499940395355, 0.21516667306423187, 0.21649999916553497, 0.22724999487400055, 0.25691667199134827, 0.27016666531562805, 0.2914166748523712, 0.30375000834465027, 0.31691667437553406, 0.32216668128967285, 0.34708333015441895, 0.35374999046325684, 0.3865833282470703, 0.41574999690055847, 0.4216666519641876, 0.42358332872390747, 0.40549999475479126, 0.44850000739097595, 0.4714166522026062, 0.5055833458900452, 0.5368333458900452, 0.49558332562446594, 0.5392500162124634, 0.5247499942779541, 0.534500002861023, 0.5490833520889282, 0.5553333163261414, 0.5298333168029785, 0.5730000138282776, 0.5860833525657654, 0.5805000066757202, 0.5745833516120911, 0.5823333263397217, 0.6135833263397217, 0.562250018119812, 0.5421666502952576, 0.5773333311080933, 0.6006666421890259, 0.6014166474342346, 0.5698333382606506, 0.5797500014305115, 0.6221666932106018, 0.6312500238418579, 0.6284166574478149]}\n",
      "{'loss': [2.268620014190674, 2.0001165866851807, 1.7932462692260742, 1.6402781009674072, 1.5357435941696167, 1.4654347896575928, 1.3978437185287476, 1.3364098072052002, 1.2794337272644043, 1.2346570491790771, 1.1856257915496826, 1.15218985080719, 1.1324946880340576, 1.0957766771316528, 1.066247582435608, 1.0489318370819092, 1.0142486095428467, 0.9974873065948486, 0.9792099595069885, 0.9575003385543823, 0.9456114768981934, 0.9293239712715149, 0.910851001739502, 0.9093902111053467, 0.8927056193351746, 0.8840690851211548, 0.8685749769210815, 0.8587256669998169, 0.8508303761482239, 0.8442902565002441, 0.8282520174980164, 0.8286736607551575, 0.8221769332885742, 0.8106136322021484, 0.8085857629776001, 0.7955917119979858, 0.7952263951301575, 0.784324049949646, 0.7813898921012878, 0.7779777646064758, 0.7695317268371582, 0.7680354118347168, 0.7623199224472046, 0.7562576532363892, 0.7401003241539001, 0.7450141310691833, 0.7388138771057129, 0.7367483973503113, 0.724850594997406, 0.7255327701568604], 'accuracy': [0.15345832705497742, 0.25179165601730347, 0.3308541774749756, 0.3840416669845581, 0.4234791696071625, 0.4517708420753479, 0.4801041781902313, 0.5050416588783264, 0.5318333506584167, 0.5487499833106995, 0.5699583292007446, 0.5846250057220459, 0.5918124914169312, 0.6060208082199097, 0.6182708144187927, 0.6268125176429749, 0.637374997138977, 0.643916666507721, 0.6559374928474426, 0.6583750247955322, 0.6655416488647461, 0.6730416417121887, 0.6772083044052124, 0.6790624856948853, 0.6807083487510681, 0.6836041808128357, 0.6910208463668823, 0.695395827293396, 0.6952083110809326, 0.6960625052452087, 0.7003958225250244, 0.6987500190734863, 0.7036666870117188, 0.7073541879653931, 0.7084791660308838, 0.7106666564941406, 0.710770845413208, 0.7103958129882812, 0.7158958315849304, 0.7148333191871643, 0.7190625071525574, 0.7198333144187927, 0.7175624966621399, 0.7223541736602783, 0.7262499928474426, 0.7243124842643738, 0.726729154586792, 0.7270416617393494, 0.7269166707992554, 0.7302500009536743], 'val_loss': [1.799175500869751, 1.426620602607727, 1.1988887786865234, 1.0618727207183838, 0.9635000824928284, 0.8852483630180359, 0.8141628503799438, 0.760230302810669, 0.7114471197128296, 0.6729843020439148, 0.6440286040306091, 0.6270639300346375, 0.5988635420799255, 0.5862058997154236, 0.565002977848053, 0.5472771525382996, 0.5335320234298706, 0.5219303369522095, 0.5120200514793396, 0.5037471652030945, 0.4991556704044342, 0.4958041310310364, 0.490242600440979, 0.4860893189907074, 0.48580408096313477, 0.48475000262260437, 0.48062437772750854, 0.48241984844207764, 0.4782809317111969, 0.4805852174758911, 0.47162914276123047, 0.47326236963272095, 0.4740617573261261, 0.47153645753860474, 0.4677134156227112, 0.46350711584091187, 0.4677105247974396, 0.46561044454574585, 0.4679909944534302, 0.46682462096214294, 0.45728743076324463, 0.4577464461326599, 0.45449575781822205, 0.4568541347980499, 0.449607789516449, 0.4536190927028656, 0.4550154209136963, 0.45204129815101624, 0.44960644841194153, 0.4491254389286041], 'val_accuracy': [0.4234166741371155, 0.5762500166893005, 0.6440833210945129, 0.6790833473205566, 0.7305833101272583, 0.7711666822433472, 0.7897499799728394, 0.8015833497047424, 0.8087499737739563, 0.8274999856948853, 0.8396666646003723, 0.8429166674613953, 0.8525000214576721, 0.8484166860580444, 0.8474166393280029, 0.8319166898727417, 0.8609166741371155, 0.8252500295639038, 0.8558333516120911, 0.8320000171661377, 0.8108333349227905, 0.8202499747276306, 0.8202499747276306, 0.8100833296775818, 0.7991666793823242, 0.8084166646003723, 0.7907500267028809, 0.7960833311080933, 0.7928333282470703, 0.7930833101272583, 0.8384166955947876, 0.7889166474342346, 0.828499972820282, 0.7941666841506958, 0.8141666650772095, 0.8013333082199097, 0.7931666374206543, 0.7986666560173035, 0.7960000038146973, 0.8107500076293945, 0.8083333373069763, 0.8051666617393494, 0.8215000033378601, 0.7884166836738586, 0.7950833439826965, 0.8114166855812073, 0.8110833168029785, 0.7927500009536743, 0.800000011920929, 0.7924166917800903]}\n",
      "{'loss': [2.6750829219818115, 2.4909942150115967, 2.404362201690674, 2.3639254570007324, 2.3402342796325684, 2.325176477432251, 2.3162763118743896, 2.3103232383728027, 2.307117462158203, 2.3051371574401855, 2.3037049770355225, 2.303081750869751, 2.3024518489837646, 2.3021905422210693, 2.301893949508667, 2.3017783164978027, 2.301525115966797, 2.301297903060913, 2.301342725753784, 2.3013083934783936, 2.301191806793213, 2.3012046813964844, 2.30143666267395, 2.301255702972412, 2.301206588745117, 2.30112624168396, 2.301121711730957, 2.301239013671875, 2.30130672454834, 2.3012285232543945, 2.301128387451172, 2.301333427429199, 2.3010823726654053, 2.301300525665283, 2.301299571990967, 2.301208972930908, 2.3011250495910645, 2.3013548851013184, 2.3010504245758057, 2.300926685333252, 2.3012049198150635, 2.3011868000030518, 2.3013362884521484, 2.3011422157287598, 2.3010904788970947, 2.3011374473571777, 2.3011727333068848, 2.301180362701416, 2.3012828826904297, 2.3012826442718506], 'accuracy': [0.10047916322946548, 0.10058332979679108, 0.09987500309944153, 0.09872916340827942, 0.10249999910593033, 0.10110417008399963, 0.10195833444595337, 0.1041666641831398, 0.10656250268220901, 0.1080000028014183, 0.10960416495800018, 0.10827083140611649, 0.11164583265781403, 0.11156249791383743, 0.1118958368897438, 0.11258333176374435, 0.11406250298023224, 0.11297916620969772, 0.1132916659116745, 0.1133124977350235, 0.11375000327825546, 0.11381249874830246, 0.11377083510160446, 0.11389583349227905, 0.11391666531562805, 0.11377083510160446, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11422916501760483, 0.11397916823625565, 0.11395833641290665, 0.11393749713897705, 0.11393749713897705, 0.11414583027362823, 0.11381249874830246, 0.11395833641290665, 0.11393749713897705, 0.11408333480358124, 0.11385416984558105, 0.11397916823625565, 0.11393749713897705, 0.11391666531562805, 0.11389583349227905, 0.11395833641290665, 0.11406250298023224, 0.11406250298023224, 0.11339583247900009, 0.11379166692495346, 0.11370833218097687], 'val_loss': [2.361321210861206, 2.298628807067871, 2.287381887435913, 2.2822182178497314, 2.281691789627075, 2.2850584983825684, 2.2870404720306396, 2.2876532077789307, 2.2907533645629883, 2.292865753173828, 2.2950515747070312, 2.2972772121429443, 2.2976880073547363, 2.297316789627075, 2.2986340522766113, 2.2998616695404053, 2.3011722564697266, 2.299833059310913, 2.2996864318847656, 2.2977705001831055, 2.301135540008545, 2.301541805267334, 2.3027234077453613, 2.3023390769958496, 2.3016388416290283, 2.3040294647216797, 2.301693916320801, 2.301292657852173, 2.300722360610962, 2.2969045639038086, 2.299349069595337, 2.3003063201904297, 2.2991294860839844, 2.3007917404174805, 2.30330491065979, 2.3007771968841553, 2.2981343269348145, 2.299470901489258, 2.2996840476989746, 2.298290967941284, 2.2979519367218018, 2.2994213104248047, 2.3010520935058594, 2.298758029937744, 2.2995710372924805, 2.3031580448150635, 2.3016278743743896, 2.2995176315307617, 2.300835371017456, 2.3038394451141357], 'val_accuracy': [0.1315833330154419, 0.12908333539962769, 0.1315000057220459, 0.1354166716337204, 0.13766667246818542, 0.13625000417232513, 0.14733333885669708, 0.1262499988079071, 0.11133333295583725, 0.11174999922513962, 0.10899999737739563, 0.10599999874830246, 0.10599999874830246, 0.10608333349227905, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.11100000143051147, 0.10733333230018616, 0.10858333110809326, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [2.3020310401916504, 2.301405668258667, 2.301135778427124, 2.3011484146118164, 2.3010706901550293, 2.301051378250122, 2.300968647003174, 2.3010032176971436, 2.3010149002075195, 2.300967216491699, 2.3009324073791504, 2.3009369373321533, 2.300971746444702, 2.301013469696045, 2.3009612560272217, 2.3010172843933105, 2.300971746444702, 2.3010051250457764, 2.300995349884033, 2.3009700775146484, 2.3009676933288574, 2.3009698390960693, 2.3009610176086426, 2.3009679317474365, 2.300977945327759, 2.300962209701538, 2.300957679748535, 2.3009281158447266, 2.300978660583496, 2.300952911376953, 2.300973892211914, 2.300962448120117, 2.300950050354004, 2.300950765609741, 2.3009226322174072, 2.3009352684020996, 2.300976276397705, 2.3009371757507324, 2.3009445667266846, 2.3009157180786133, 2.3009939193725586, 2.3009400367736816, 2.3009378910064697, 2.3009488582611084, 2.300938606262207, 2.3009510040283203, 2.3009560108184814, 2.300924777984619, 2.300915479660034, 2.3009331226348877], 'accuracy': [0.11377083510160446, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.302016019821167, 2.301917552947998, 2.3019094467163086, 2.301952838897705, 2.3019537925720215, 2.3020026683807373, 2.301997184753418, 2.302006244659424, 2.30202317237854, 2.302036762237549, 2.302034378051758, 2.3020334243774414, 2.3020477294921875, 2.3020591735839844, 2.3020780086517334, 2.302053689956665, 2.302032470703125, 2.3020381927490234, 2.302034616470337, 2.302060127258301, 2.3020544052124023, 2.302022695541382, 2.3020217418670654, 2.3020405769348145, 2.302018642425537, 2.3020267486572266, 2.3020124435424805, 2.302020311355591, 2.3020050525665283, 2.3020145893096924, 2.3020472526550293, 2.3020453453063965, 2.302050828933716, 2.3020496368408203, 2.3020408153533936, 2.3020293712615967, 2.302050828933716, 2.3020615577697754, 2.30203914642334, 2.302032470703125, 2.3020002841949463, 2.3019888401031494, 2.3020222187042236, 2.3020267486572266, 2.302055597305298, 2.3020458221435547, 2.3020529747009277, 2.3020453453063965, 2.3020288944244385, 2.3020098209381104], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [2.3020925521850586, 2.301461935043335, 2.301208734512329, 2.301147699356079, 2.301023244857788, 2.3010764122009277, 2.3010246753692627, 2.3009870052337646, 2.3010289669036865, 2.301023006439209, 2.3010168075561523, 2.301039934158325, 2.3010029792785645, 2.301034450531006, 2.30100154876709, 2.301013469696045, 2.3010287284851074, 2.300999402999878, 2.3009960651397705, 2.300997734069824, 2.301013231277466, 2.3009908199310303, 2.301002025604248, 2.3009724617004395, 2.3010191917419434, 2.30098557472229, 2.3009936809539795, 2.300964593887329, 2.3009886741638184, 2.3009605407714844, 2.3010153770446777, 2.30096435546875, 2.3010036945343018, 2.300992727279663, 2.3010120391845703, 2.3009815216064453, 2.30100154876709, 2.301010847091675, 2.3009793758392334, 2.300977945327759, 2.300985813140869, 2.300987720489502, 2.300971269607544, 2.300966739654541, 2.300997495651245, 2.300950765609741, 2.300997734069824, 2.3009862899780273, 2.3009865283966064, 2.300992488861084], 'accuracy': [0.11349999904632568, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3020412921905518, 2.301901340484619, 2.30190110206604, 2.3019704818725586, 2.302018404006958, 2.3020620346069336, 2.3020858764648438, 2.302062749862671, 2.302065849304199, 2.302075147628784, 2.3020811080932617, 2.3020944595336914, 2.302095651626587, 2.302067279815674, 2.30208683013916, 2.302111864089966, 2.302083969116211, 2.3020918369293213, 2.302077054977417, 2.3021039962768555, 2.3020923137664795, 2.3020846843719482, 2.3020753860473633, 2.3020966053009033, 2.3020806312561035, 2.3021016120910645, 2.302079916000366, 2.3020880222320557, 2.3020498752593994, 2.302070379257202, 2.3020780086517334, 2.3020517826080322, 2.302067279815674, 2.3020827770233154, 2.3020834922790527, 2.302076578140259, 2.3020832538604736, 2.302109718322754, 2.3020896911621094, 2.302076578140259, 2.302093505859375, 2.302109956741333, 2.3021037578582764, 2.3020620346069336, 2.3021020889282227, 2.3020787239074707, 2.30208420753479, 2.302083730697632, 2.302072525024414, 2.3020920753479004], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
