{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "6fa6cdc7-55bf-485d-f60d-fa5e775caa23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 20s 8ms/step - loss: 2.4382 - accuracy: 0.1003 - val_loss: 2.3031 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3638 - accuracy: 0.1042 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3491 - accuracy: 0.1008 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3387 - accuracy: 0.1036 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3271 - accuracy: 0.1007 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3233 - accuracy: 0.0999 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3213 - accuracy: 0.0997 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3193 - accuracy: 0.1000 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3169 - accuracy: 0.1013 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3126 - accuracy: 0.1061 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3107 - accuracy: 0.1085 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3112 - accuracy: 0.0999 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3094 - accuracy: 0.1064 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3087 - accuracy: 0.1051 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3078 - accuracy: 0.1075 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3076 - accuracy: 0.1028 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3057 - accuracy: 0.1059 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3068 - accuracy: 0.1080 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3054 - accuracy: 0.1070 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3052 - accuracy: 0.1082 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3056 - accuracy: 0.1031 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3057 - accuracy: 0.1068 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3047 - accuracy: 0.1058 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3054 - accuracy: 0.1083 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3054 - accuracy: 0.1064 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3057 - accuracy: 0.1039 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3052 - accuracy: 0.1050 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3047 - accuracy: 0.1053 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3040 - accuracy: 0.1065 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.1086 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3038 - accuracy: 0.1099 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.1119 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3037 - accuracy: 0.1101 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.1088 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3039 - accuracy: 0.1093 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3025 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.1080 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3038 - accuracy: 0.1089 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3030 - accuracy: 0.1100 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3028 - accuracy: 0.1109 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.1109 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3020 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3024 - accuracy: 0.1146 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.1107 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3025 - accuracy: 0.1113 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3029 - accuracy: 0.1088 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3021 - accuracy: 0.1149 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3025 - accuracy: 0.1101 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.1111 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 8ms/step - loss: 2.0650 - accuracy: 0.2546 - val_loss: 1.1635 - val_accuracy: 0.7045\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.4593 - accuracy: 0.5051 - val_loss: 0.8442 - val_accuracy: 0.8063\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2179 - accuracy: 0.6063 - val_loss: 0.6729 - val_accuracy: 0.8499\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0825 - accuracy: 0.6550 - val_loss: 0.5762 - val_accuracy: 0.8640\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9905 - accuracy: 0.6889 - val_loss: 0.5138 - val_accuracy: 0.8732\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9169 - accuracy: 0.7156 - val_loss: 0.4662 - val_accuracy: 0.8818\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8704 - accuracy: 0.7334 - val_loss: 0.4331 - val_accuracy: 0.8867\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8351 - accuracy: 0.7476 - val_loss: 0.4110 - val_accuracy: 0.8909\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7975 - accuracy: 0.7621 - val_loss: 0.3823 - val_accuracy: 0.8965\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7599 - accuracy: 0.7784 - val_loss: 0.3670 - val_accuracy: 0.9002\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7345 - accuracy: 0.7913 - val_loss: 0.3531 - val_accuracy: 0.9043\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7007 - accuracy: 0.8014 - val_loss: 0.3431 - val_accuracy: 0.9071\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6915 - accuracy: 0.8029 - val_loss: 0.3316 - val_accuracy: 0.9101\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6717 - accuracy: 0.8107 - val_loss: 0.3203 - val_accuracy: 0.9128\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6474 - accuracy: 0.8176 - val_loss: 0.3163 - val_accuracy: 0.9131\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6431 - accuracy: 0.8238 - val_loss: 0.3132 - val_accuracy: 0.9153\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6199 - accuracy: 0.8327 - val_loss: 0.3035 - val_accuracy: 0.9183\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6205 - accuracy: 0.8322 - val_loss: 0.2997 - val_accuracy: 0.9178\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5861 - accuracy: 0.8408 - val_loss: 0.2922 - val_accuracy: 0.9202\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5944 - accuracy: 0.8415 - val_loss: 0.2867 - val_accuracy: 0.9233\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5779 - accuracy: 0.8448 - val_loss: 0.2824 - val_accuracy: 0.9237\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5637 - accuracy: 0.8484 - val_loss: 0.2794 - val_accuracy: 0.9260\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5591 - accuracy: 0.8501 - val_loss: 0.2754 - val_accuracy: 0.9271\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5365 - accuracy: 0.8582 - val_loss: 0.2720 - val_accuracy: 0.9268\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5418 - accuracy: 0.8546 - val_loss: 0.2660 - val_accuracy: 0.9305\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5319 - accuracy: 0.8612 - val_loss: 0.2642 - val_accuracy: 0.9307\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5388 - accuracy: 0.8579 - val_loss: 0.2624 - val_accuracy: 0.9317\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5262 - accuracy: 0.8621 - val_loss: 0.2573 - val_accuracy: 0.9342\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5049 - accuracy: 0.8669 - val_loss: 0.2572 - val_accuracy: 0.9321\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5154 - accuracy: 0.8690 - val_loss: 0.2535 - val_accuracy: 0.9355\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5077 - accuracy: 0.8709 - val_loss: 0.2537 - val_accuracy: 0.9348\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4940 - accuracy: 0.8715 - val_loss: 0.2492 - val_accuracy: 0.9358\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4898 - accuracy: 0.8723 - val_loss: 0.2477 - val_accuracy: 0.9367\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4743 - accuracy: 0.8774 - val_loss: 0.2466 - val_accuracy: 0.9372\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4835 - accuracy: 0.8758 - val_loss: 0.2405 - val_accuracy: 0.9383\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4675 - accuracy: 0.8759 - val_loss: 0.2380 - val_accuracy: 0.9393\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4674 - accuracy: 0.8786 - val_loss: 0.2391 - val_accuracy: 0.9401\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4590 - accuracy: 0.8803 - val_loss: 0.2314 - val_accuracy: 0.9426\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4578 - accuracy: 0.8839 - val_loss: 0.2276 - val_accuracy: 0.9421\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4444 - accuracy: 0.8851 - val_loss: 0.2311 - val_accuracy: 0.9411\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4474 - accuracy: 0.8839 - val_loss: 0.2301 - val_accuracy: 0.9418\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4439 - accuracy: 0.8861 - val_loss: 0.2270 - val_accuracy: 0.9438\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4382 - accuracy: 0.8869 - val_loss: 0.2213 - val_accuracy: 0.9438\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4335 - accuracy: 0.8892 - val_loss: 0.2214 - val_accuracy: 0.9441\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4307 - accuracy: 0.8914 - val_loss: 0.2185 - val_accuracy: 0.9454\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4279 - accuracy: 0.8933 - val_loss: 0.2177 - val_accuracy: 0.9458\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4220 - accuracy: 0.8915 - val_loss: 0.2181 - val_accuracy: 0.9457\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4225 - accuracy: 0.8922 - val_loss: 0.2124 - val_accuracy: 0.9477\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4128 - accuracy: 0.8944 - val_loss: 0.2143 - val_accuracy: 0.9477\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4160 - accuracy: 0.8942 - val_loss: 0.2107 - val_accuracy: 0.9487\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 8ms/step - loss: 2.3025 - accuracy: 0.1106 - val_loss: 2.2937 - val_accuracy: 0.1577\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2943 - accuracy: 0.1485 - val_loss: 2.2596 - val_accuracy: 0.2609\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2644 - accuracy: 0.1872 - val_loss: 2.1518 - val_accuracy: 0.2619\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1839 - accuracy: 0.2264 - val_loss: 2.0158 - val_accuracy: 0.3047\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0776 - accuracy: 0.2570 - val_loss: 1.8651 - val_accuracy: 0.3932\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.9575 - accuracy: 0.2987 - val_loss: 1.6609 - val_accuracy: 0.4075\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.8132 - accuracy: 0.3297 - val_loss: 1.5070 - val_accuracy: 0.4026\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7003 - accuracy: 0.3503 - val_loss: 1.3941 - val_accuracy: 0.4198\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.6162 - accuracy: 0.3734 - val_loss: 1.3103 - val_accuracy: 0.4506\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.5320 - accuracy: 0.3965 - val_loss: 1.2426 - val_accuracy: 0.4817\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.4799 - accuracy: 0.4205 - val_loss: 1.1696 - val_accuracy: 0.5280\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.4116 - accuracy: 0.4561 - val_loss: 1.1061 - val_accuracy: 0.5842\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.3512 - accuracy: 0.4941 - val_loss: 1.0473 - val_accuracy: 0.6651\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2986 - accuracy: 0.5296 - val_loss: 0.9894 - val_accuracy: 0.6956\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2536 - accuracy: 0.5551 - val_loss: 0.9371 - val_accuracy: 0.7109\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2039 - accuracy: 0.5747 - val_loss: 0.8862 - val_accuracy: 0.7402\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.1454 - accuracy: 0.5990 - val_loss: 0.8403 - val_accuracy: 0.7436\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.1100 - accuracy: 0.6210 - val_loss: 0.7849 - val_accuracy: 0.7786\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0660 - accuracy: 0.6438 - val_loss: 0.7381 - val_accuracy: 0.7862\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0229 - accuracy: 0.6667 - val_loss: 0.6905 - val_accuracy: 0.8296\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9958 - accuracy: 0.6795 - val_loss: 0.6538 - val_accuracy: 0.8528\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9491 - accuracy: 0.6984 - val_loss: 0.6077 - val_accuracy: 0.8590\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9307 - accuracy: 0.7083 - val_loss: 0.5731 - val_accuracy: 0.8745\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8796 - accuracy: 0.7298 - val_loss: 0.5301 - val_accuracy: 0.8888\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8507 - accuracy: 0.7386 - val_loss: 0.4907 - val_accuracy: 0.9087\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8091 - accuracy: 0.7551 - val_loss: 0.4676 - val_accuracy: 0.9086\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7903 - accuracy: 0.7621 - val_loss: 0.4497 - val_accuracy: 0.9188\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7709 - accuracy: 0.7726 - val_loss: 0.4294 - val_accuracy: 0.9259\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7375 - accuracy: 0.7827 - val_loss: 0.4176 - val_accuracy: 0.9289\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7142 - accuracy: 0.7866 - val_loss: 0.4053 - val_accuracy: 0.9317\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6877 - accuracy: 0.7988 - val_loss: 0.3970 - val_accuracy: 0.9279\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6843 - accuracy: 0.8004 - val_loss: 0.3750 - val_accuracy: 0.9402\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6621 - accuracy: 0.8083 - val_loss: 0.3678 - val_accuracy: 0.9448\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6468 - accuracy: 0.8159 - val_loss: 0.3614 - val_accuracy: 0.9442\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6338 - accuracy: 0.8150 - val_loss: 0.3607 - val_accuracy: 0.9451\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6185 - accuracy: 0.8230 - val_loss: 0.3491 - val_accuracy: 0.9433\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6146 - accuracy: 0.8255 - val_loss: 0.3371 - val_accuracy: 0.9494\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6071 - accuracy: 0.8261 - val_loss: 0.3300 - val_accuracy: 0.9499\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5802 - accuracy: 0.8354 - val_loss: 0.3265 - val_accuracy: 0.9508\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5689 - accuracy: 0.8407 - val_loss: 0.3228 - val_accuracy: 0.9538\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5553 - accuracy: 0.8433 - val_loss: 0.3258 - val_accuracy: 0.9521\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5424 - accuracy: 0.8476 - val_loss: 0.3061 - val_accuracy: 0.9558\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5333 - accuracy: 0.8483 - val_loss: 0.3115 - val_accuracy: 0.9553\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5398 - accuracy: 0.8479 - val_loss: 0.2933 - val_accuracy: 0.9557\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5280 - accuracy: 0.8510 - val_loss: 0.3000 - val_accuracy: 0.9553\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5179 - accuracy: 0.8591 - val_loss: 0.2870 - val_accuracy: 0.9602\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5083 - accuracy: 0.8606 - val_loss: 0.2863 - val_accuracy: 0.9590\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4889 - accuracy: 0.8614 - val_loss: 0.2891 - val_accuracy: 0.9606\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5037 - accuracy: 0.8598 - val_loss: 0.2736 - val_accuracy: 0.9607\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4612 - accuracy: 0.8678 - val_loss: 0.2768 - val_accuracy: 0.9619\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 9ms/step - loss: 2.3008 - accuracy: 0.1128 - val_loss: 2.2645 - val_accuracy: 0.3409\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2648 - accuracy: 0.1673 - val_loss: 2.1033 - val_accuracy: 0.4796\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1169 - accuracy: 0.2456 - val_loss: 1.6198 - val_accuracy: 0.5342\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.8029 - accuracy: 0.3614 - val_loss: 1.2123 - val_accuracy: 0.5962\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.5464 - accuracy: 0.4382 - val_loss: 0.9944 - val_accuracy: 0.6763\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.3611 - accuracy: 0.5119 - val_loss: 0.8416 - val_accuracy: 0.7496\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2289 - accuracy: 0.5637 - val_loss: 0.7351 - val_accuracy: 0.8047\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.1030 - accuracy: 0.6158 - val_loss: 0.6388 - val_accuracy: 0.8343\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0252 - accuracy: 0.6458 - val_loss: 0.5773 - val_accuracy: 0.8420\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9501 - accuracy: 0.6844 - val_loss: 0.5194 - val_accuracy: 0.8633\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8652 - accuracy: 0.7144 - val_loss: 0.4776 - val_accuracy: 0.8792\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8250 - accuracy: 0.7314 - val_loss: 0.4384 - val_accuracy: 0.8939\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7809 - accuracy: 0.7516 - val_loss: 0.4093 - val_accuracy: 0.9079\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7255 - accuracy: 0.7697 - val_loss: 0.3751 - val_accuracy: 0.9129\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7010 - accuracy: 0.7817 - val_loss: 0.3509 - val_accuracy: 0.9194\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.6719 - accuracy: 0.7978 - val_loss: 0.3237 - val_accuracy: 0.9243\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6334 - accuracy: 0.8088 - val_loss: 0.2997 - val_accuracy: 0.9313\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5939 - accuracy: 0.8192 - val_loss: 0.2759 - val_accuracy: 0.9351\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5710 - accuracy: 0.8296 - val_loss: 0.2577 - val_accuracy: 0.9380\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5457 - accuracy: 0.8377 - val_loss: 0.2475 - val_accuracy: 0.9391\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5189 - accuracy: 0.8532 - val_loss: 0.2253 - val_accuracy: 0.9442\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5102 - accuracy: 0.8537 - val_loss: 0.2138 - val_accuracy: 0.9460\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4792 - accuracy: 0.8624 - val_loss: 0.2084 - val_accuracy: 0.9484\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4803 - accuracy: 0.8626 - val_loss: 0.1956 - val_accuracy: 0.9507\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4637 - accuracy: 0.8713 - val_loss: 0.1935 - val_accuracy: 0.9517\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4495 - accuracy: 0.8758 - val_loss: 0.1821 - val_accuracy: 0.9541\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4137 - accuracy: 0.8821 - val_loss: 0.1824 - val_accuracy: 0.9553\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4170 - accuracy: 0.8819 - val_loss: 0.1725 - val_accuracy: 0.9572\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3979 - accuracy: 0.8899 - val_loss: 0.1684 - val_accuracy: 0.9588\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3885 - accuracy: 0.8916 - val_loss: 0.1627 - val_accuracy: 0.9596\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3768 - accuracy: 0.8951 - val_loss: 0.1607 - val_accuracy: 0.9610\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3567 - accuracy: 0.8996 - val_loss: 0.1576 - val_accuracy: 0.9614\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3601 - accuracy: 0.9002 - val_loss: 0.1617 - val_accuracy: 0.9607\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3420 - accuracy: 0.9060 - val_loss: 0.1497 - val_accuracy: 0.9634\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3320 - accuracy: 0.9077 - val_loss: 0.1471 - val_accuracy: 0.9637\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3243 - accuracy: 0.9094 - val_loss: 0.1489 - val_accuracy: 0.9644\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3266 - accuracy: 0.9105 - val_loss: 0.1422 - val_accuracy: 0.9643\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3238 - accuracy: 0.9102 - val_loss: 0.1376 - val_accuracy: 0.9659\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3129 - accuracy: 0.9137 - val_loss: 0.1398 - val_accuracy: 0.9654\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3032 - accuracy: 0.9169 - val_loss: 0.1400 - val_accuracy: 0.9667\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3040 - accuracy: 0.9182 - val_loss: 0.1353 - val_accuracy: 0.9674\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2929 - accuracy: 0.9198 - val_loss: 0.1407 - val_accuracy: 0.9669\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2847 - accuracy: 0.9212 - val_loss: 0.1332 - val_accuracy: 0.9667\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2713 - accuracy: 0.9221 - val_loss: 0.1322 - val_accuracy: 0.9681\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2710 - accuracy: 0.9237 - val_loss: 0.1327 - val_accuracy: 0.9685\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2606 - accuracy: 0.9285 - val_loss: 0.1303 - val_accuracy: 0.9691\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2730 - accuracy: 0.9238 - val_loss: 0.1307 - val_accuracy: 0.9690\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2598 - accuracy: 0.9296 - val_loss: 0.1344 - val_accuracy: 0.9689\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2612 - accuracy: 0.9287 - val_loss: 0.1318 - val_accuracy: 0.9695\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2414 - accuracy: 0.9341 - val_loss: 0.1275 - val_accuracy: 0.9702\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 8ms/step - loss: 2.0582 - accuracy: 0.2501 - val_loss: 1.1084 - val_accuracy: 0.7231\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.4142 - accuracy: 0.5025 - val_loss: 0.7611 - val_accuracy: 0.8143\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.1747 - accuracy: 0.5962 - val_loss: 0.5808 - val_accuracy: 0.8524\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.0173 - accuracy: 0.6622 - val_loss: 0.4671 - val_accuracy: 0.8776\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.9143 - accuracy: 0.7048 - val_loss: 0.4105 - val_accuracy: 0.8890\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.8462 - accuracy: 0.7321 - val_loss: 0.3686 - val_accuracy: 0.8992\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.7905 - accuracy: 0.7521 - val_loss: 0.3403 - val_accuracy: 0.9027\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7585 - accuracy: 0.7625 - val_loss: 0.3217 - val_accuracy: 0.9090\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.7302 - accuracy: 0.7781 - val_loss: 0.3075 - val_accuracy: 0.9124\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.6858 - accuracy: 0.7930 - val_loss: 0.2944 - val_accuracy: 0.9161\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.6652 - accuracy: 0.8009 - val_loss: 0.2837 - val_accuracy: 0.9183\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.6458 - accuracy: 0.8053 - val_loss: 0.2770 - val_accuracy: 0.9212\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.6230 - accuracy: 0.8188 - val_loss: 0.2685 - val_accuracy: 0.9230\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.6190 - accuracy: 0.8229 - val_loss: 0.2597 - val_accuracy: 0.9255\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.5865 - accuracy: 0.8302 - val_loss: 0.2569 - val_accuracy: 0.9272\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5812 - accuracy: 0.8346 - val_loss: 0.2500 - val_accuracy: 0.9287\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.5678 - accuracy: 0.8395 - val_loss: 0.2433 - val_accuracy: 0.9305\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5570 - accuracy: 0.8448 - val_loss: 0.2415 - val_accuracy: 0.9301\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5354 - accuracy: 0.8484 - val_loss: 0.2350 - val_accuracy: 0.9330\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5298 - accuracy: 0.8537 - val_loss: 0.2329 - val_accuracy: 0.9348\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5150 - accuracy: 0.8550 - val_loss: 0.2293 - val_accuracy: 0.9348\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5058 - accuracy: 0.8597 - val_loss: 0.2225 - val_accuracy: 0.9387\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.5049 - accuracy: 0.8644 - val_loss: 0.2200 - val_accuracy: 0.9399\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4917 - accuracy: 0.8628 - val_loss: 0.2149 - val_accuracy: 0.9408\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4798 - accuracy: 0.8708 - val_loss: 0.2143 - val_accuracy: 0.9415\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4703 - accuracy: 0.8712 - val_loss: 0.2111 - val_accuracy: 0.9422\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4558 - accuracy: 0.8735 - val_loss: 0.2051 - val_accuracy: 0.9426\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4600 - accuracy: 0.8765 - val_loss: 0.2037 - val_accuracy: 0.9427\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4346 - accuracy: 0.8813 - val_loss: 0.2015 - val_accuracy: 0.9449\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4482 - accuracy: 0.8775 - val_loss: 0.1965 - val_accuracy: 0.9457\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4446 - accuracy: 0.8790 - val_loss: 0.1964 - val_accuracy: 0.9452\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4300 - accuracy: 0.8822 - val_loss: 0.1930 - val_accuracy: 0.9472\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4146 - accuracy: 0.8877 - val_loss: 0.1900 - val_accuracy: 0.9487\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4246 - accuracy: 0.8830 - val_loss: 0.1861 - val_accuracy: 0.9492\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4195 - accuracy: 0.8876 - val_loss: 0.1851 - val_accuracy: 0.9510\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4034 - accuracy: 0.8896 - val_loss: 0.1833 - val_accuracy: 0.9506\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4029 - accuracy: 0.8901 - val_loss: 0.1807 - val_accuracy: 0.9523\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3919 - accuracy: 0.8961 - val_loss: 0.1820 - val_accuracy: 0.9512\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3881 - accuracy: 0.8943 - val_loss: 0.1752 - val_accuracy: 0.9527\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3889 - accuracy: 0.8935 - val_loss: 0.1765 - val_accuracy: 0.9532\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3768 - accuracy: 0.8986 - val_loss: 0.1734 - val_accuracy: 0.9542\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3730 - accuracy: 0.9005 - val_loss: 0.1673 - val_accuracy: 0.9557\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3760 - accuracy: 0.8997 - val_loss: 0.1699 - val_accuracy: 0.9557\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3700 - accuracy: 0.9018 - val_loss: 0.1677 - val_accuracy: 0.9557\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3673 - accuracy: 0.9023 - val_loss: 0.1666 - val_accuracy: 0.9557\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3702 - accuracy: 0.9025 - val_loss: 0.1654 - val_accuracy: 0.9558\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3597 - accuracy: 0.9019 - val_loss: 0.1651 - val_accuracy: 0.9579\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.3606 - accuracy: 0.9043 - val_loss: 0.1611 - val_accuracy: 0.9581\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.3498 - accuracy: 0.9078 - val_loss: 0.1592 - val_accuracy: 0.9563\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.3470 - accuracy: 0.9046 - val_loss: 0.1571 - val_accuracy: 0.9584\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 8ms/step - loss: 2.7110 - accuracy: 0.1010 - val_loss: 2.2451 - val_accuracy: 0.1737\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.4907 - accuracy: 0.1026 - val_loss: 2.2714 - val_accuracy: 0.1898\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3938 - accuracy: 0.1057 - val_loss: 2.2905 - val_accuracy: 0.2262\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3485 - accuracy: 0.1051 - val_loss: 2.2994 - val_accuracy: 0.1425\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3287 - accuracy: 0.1089 - val_loss: 2.3037 - val_accuracy: 0.0996\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3129 - accuracy: 0.1141 - val_loss: 2.3113 - val_accuracy: 0.0995\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3027 - accuracy: 0.1181 - val_loss: 2.3106 - val_accuracy: 0.0995\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2891 - accuracy: 0.1304 - val_loss: 2.2261 - val_accuracy: 0.1470\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2642 - accuracy: 0.1476 - val_loss: 2.1041 - val_accuracy: 0.2111\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.1976 - accuracy: 0.1821 - val_loss: 3.0288 - val_accuracy: 0.2097\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.1085 - accuracy: 0.2155 - val_loss: 3.5450 - val_accuracy: 0.2102\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0724 - accuracy: 0.2211 - val_loss: 3.7629 - val_accuracy: 0.2083\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0498 - accuracy: 0.2233 - val_loss: 3.6839 - val_accuracy: 0.2100\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0312 - accuracy: 0.2296 - val_loss: 3.9562 - val_accuracy: 0.2136\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0080 - accuracy: 0.2415 - val_loss: 3.7094 - val_accuracy: 0.2270\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.9672 - accuracy: 0.2530 - val_loss: 3.5965 - val_accuracy: 0.2652\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.9164 - accuracy: 0.2668 - val_loss: 3.6432 - val_accuracy: 0.3041\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.8609 - accuracy: 0.2817 - val_loss: 3.3075 - val_accuracy: 0.3176\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.8203 - accuracy: 0.2853 - val_loss: 3.4003 - val_accuracy: 0.3244\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7795 - accuracy: 0.2994 - val_loss: 3.7031 - val_accuracy: 0.3199\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7486 - accuracy: 0.3058 - val_loss: 3.7686 - val_accuracy: 0.3189\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7423 - accuracy: 0.3111 - val_loss: 3.8944 - val_accuracy: 0.3232\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7235 - accuracy: 0.3139 - val_loss: 4.6160 - val_accuracy: 0.3192\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7138 - accuracy: 0.3265 - val_loss: 4.4393 - val_accuracy: 0.3192\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.6902 - accuracy: 0.3346 - val_loss: 4.5681 - val_accuracy: 0.3275\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6665 - accuracy: 0.3461 - val_loss: 4.8920 - val_accuracy: 0.3346\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.6515 - accuracy: 0.3443 - val_loss: 4.8529 - val_accuracy: 0.3427\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.6488 - accuracy: 0.3478 - val_loss: 4.9195 - val_accuracy: 0.3604\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.6130 - accuracy: 0.3692 - val_loss: 4.8264 - val_accuracy: 0.3694\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.6047 - accuracy: 0.3656 - val_loss: 5.3777 - val_accuracy: 0.3767\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.5880 - accuracy: 0.3758 - val_loss: 4.8927 - val_accuracy: 0.3799\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.5686 - accuracy: 0.3780 - val_loss: 5.3293 - val_accuracy: 0.3767\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.5593 - accuracy: 0.3825 - val_loss: 5.1801 - val_accuracy: 0.3892\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.5314 - accuracy: 0.3971 - val_loss: 5.3887 - val_accuracy: 0.3933\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5359 - accuracy: 0.3941 - val_loss: 6.3303 - val_accuracy: 0.3873\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.5142 - accuracy: 0.4002 - val_loss: 5.7612 - val_accuracy: 0.3928\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.5052 - accuracy: 0.4038 - val_loss: 5.9214 - val_accuracy: 0.3822\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4917 - accuracy: 0.4101 - val_loss: 5.9169 - val_accuracy: 0.3902\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4871 - accuracy: 0.4119 - val_loss: 5.7797 - val_accuracy: 0.3901\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4801 - accuracy: 0.4119 - val_loss: 6.0046 - val_accuracy: 0.3878\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4752 - accuracy: 0.4169 - val_loss: 6.3575 - val_accuracy: 0.3878\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4638 - accuracy: 0.4247 - val_loss: 6.9128 - val_accuracy: 0.3619\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4628 - accuracy: 0.4248 - val_loss: 6.4884 - val_accuracy: 0.3610\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4479 - accuracy: 0.4260 - val_loss: 6.9875 - val_accuracy: 0.3830\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4379 - accuracy: 0.4345 - val_loss: 6.3622 - val_accuracy: 0.3586\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4380 - accuracy: 0.4330 - val_loss: 6.7780 - val_accuracy: 0.3658\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4227 - accuracy: 0.4403 - val_loss: 7.1348 - val_accuracy: 0.3539\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4165 - accuracy: 0.4402 - val_loss: 7.1538 - val_accuracy: 0.3620\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4092 - accuracy: 0.4450 - val_loss: 6.6963 - val_accuracy: 0.3514\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.3947 - accuracy: 0.4502 - val_loss: 7.0175 - val_accuracy: 0.3725\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 6s 10ms/step - loss: 2.3023 - accuracy: 0.1158 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3006 - accuracy: 0.1155 - val_loss: 2.3000 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2991 - accuracy: 0.1132 - val_loss: 2.2988 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2977 - accuracy: 0.1157 - val_loss: 2.2973 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2961 - accuracy: 0.1148 - val_loss: 2.2955 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2945 - accuracy: 0.1130 - val_loss: 2.2931 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2915 - accuracy: 0.1157 - val_loss: 2.2893 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2876 - accuracy: 0.1233 - val_loss: 2.2827 - val_accuracy: 0.1141\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.2792 - accuracy: 0.1486 - val_loss: 2.2666 - val_accuracy: 0.1963\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2561 - accuracy: 0.1976 - val_loss: 2.1925 - val_accuracy: 0.2409\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.1677 - accuracy: 0.2263 - val_loss: 1.9665 - val_accuracy: 0.2979\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.0051 - accuracy: 0.2782 - val_loss: 1.6743 - val_accuracy: 0.4508\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.8218 - accuracy: 0.3416 - val_loss: 1.4463 - val_accuracy: 0.5632\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.6438 - accuracy: 0.4127 - val_loss: 1.2373 - val_accuracy: 0.6647\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5059 - accuracy: 0.4686 - val_loss: 1.0921 - val_accuracy: 0.7128\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.3776 - accuracy: 0.5167 - val_loss: 0.9822 - val_accuracy: 0.7380\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2990 - accuracy: 0.5544 - val_loss: 0.8605 - val_accuracy: 0.7677\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2179 - accuracy: 0.5828 - val_loss: 0.7748 - val_accuracy: 0.7896\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.1444 - accuracy: 0.6043 - val_loss: 0.7059 - val_accuracy: 0.8049\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0921 - accuracy: 0.6293 - val_loss: 0.6576 - val_accuracy: 0.8216\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.0425 - accuracy: 0.6468 - val_loss: 0.6149 - val_accuracy: 0.8142\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9795 - accuracy: 0.6660 - val_loss: 0.5764 - val_accuracy: 0.8316\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9537 - accuracy: 0.6779 - val_loss: 0.5475 - val_accuracy: 0.8367\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9226 - accuracy: 0.6851 - val_loss: 0.5205 - val_accuracy: 0.8572\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8954 - accuracy: 0.6963 - val_loss: 0.4986 - val_accuracy: 0.8614\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.8792 - accuracy: 0.7055 - val_loss: 0.4785 - val_accuracy: 0.8413\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8408 - accuracy: 0.7116 - val_loss: 0.4630 - val_accuracy: 0.8585\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8248 - accuracy: 0.7169 - val_loss: 0.4440 - val_accuracy: 0.8767\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8021 - accuracy: 0.7208 - val_loss: 0.4303 - val_accuracy: 0.8677\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7878 - accuracy: 0.7322 - val_loss: 0.4150 - val_accuracy: 0.8808\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7700 - accuracy: 0.7358 - val_loss: 0.4008 - val_accuracy: 0.8988\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7600 - accuracy: 0.7377 - val_loss: 0.3926 - val_accuracy: 0.8835\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7429 - accuracy: 0.7477 - val_loss: 0.3788 - val_accuracy: 0.8980\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7348 - accuracy: 0.7497 - val_loss: 0.3678 - val_accuracy: 0.9109\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7185 - accuracy: 0.7573 - val_loss: 0.3535 - val_accuracy: 0.9165\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7013 - accuracy: 0.7642 - val_loss: 0.3432 - val_accuracy: 0.9177\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6889 - accuracy: 0.7673 - val_loss: 0.3361 - val_accuracy: 0.9190\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6821 - accuracy: 0.7731 - val_loss: 0.3241 - val_accuracy: 0.9221\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6662 - accuracy: 0.7772 - val_loss: 0.3108 - val_accuracy: 0.9268\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6493 - accuracy: 0.7818 - val_loss: 0.3033 - val_accuracy: 0.9286\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6477 - accuracy: 0.7834 - val_loss: 0.2906 - val_accuracy: 0.9341\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6474 - accuracy: 0.7882 - val_loss: 0.2816 - val_accuracy: 0.9350\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6304 - accuracy: 0.7928 - val_loss: 0.2743 - val_accuracy: 0.9373\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6168 - accuracy: 0.7944 - val_loss: 0.2637 - val_accuracy: 0.9400\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6037 - accuracy: 0.8010 - val_loss: 0.2561 - val_accuracy: 0.9406\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5961 - accuracy: 0.8046 - val_loss: 0.2485 - val_accuracy: 0.9417\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5949 - accuracy: 0.8083 - val_loss: 0.2408 - val_accuracy: 0.9439\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5808 - accuracy: 0.8131 - val_loss: 0.2340 - val_accuracy: 0.9446\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.5631 - accuracy: 0.8201 - val_loss: 0.2265 - val_accuracy: 0.9467\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5642 - accuracy: 0.8169 - val_loss: 0.2227 - val_accuracy: 0.9469\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 9ms/step - loss: 2.3024 - accuracy: 0.1085 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3007 - accuracy: 0.1151 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2994 - accuracy: 0.1136 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2986 - accuracy: 0.1127 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2972 - accuracy: 0.1113 - val_loss: 2.2968 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2957 - accuracy: 0.1137 - val_loss: 2.2952 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2942 - accuracy: 0.1120 - val_loss: 2.2930 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.2915 - accuracy: 0.1164 - val_loss: 2.2899 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2879 - accuracy: 0.1209 - val_loss: 2.2850 - val_accuracy: 0.1113\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2827 - accuracy: 0.1363 - val_loss: 2.2751 - val_accuracy: 0.1597\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2694 - accuracy: 0.1694 - val_loss: 2.2402 - val_accuracy: 0.1998\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2147 - accuracy: 0.2095 - val_loss: 2.0842 - val_accuracy: 0.2166\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0929 - accuracy: 0.2166 - val_loss: 1.9571 - val_accuracy: 0.2578\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.9987 - accuracy: 0.2517 - val_loss: 1.8506 - val_accuracy: 0.3002\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.9179 - accuracy: 0.2812 - val_loss: 1.7478 - val_accuracy: 0.3705\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.8301 - accuracy: 0.3172 - val_loss: 1.6242 - val_accuracy: 0.4483\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7253 - accuracy: 0.3611 - val_loss: 1.4502 - val_accuracy: 0.4937\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.6040 - accuracy: 0.4050 - val_loss: 1.3313 - val_accuracy: 0.5328\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.5229 - accuracy: 0.4477 - val_loss: 1.2379 - val_accuracy: 0.5817\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4403 - accuracy: 0.4909 - val_loss: 1.1497 - val_accuracy: 0.6338\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3755 - accuracy: 0.5196 - val_loss: 1.0641 - val_accuracy: 0.6810\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.3039 - accuracy: 0.5571 - val_loss: 0.9734 - val_accuracy: 0.7206\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.2317 - accuracy: 0.5915 - val_loss: 0.8917 - val_accuracy: 0.7648\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.1711 - accuracy: 0.6166 - val_loss: 0.8215 - val_accuracy: 0.7892\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.1205 - accuracy: 0.6405 - val_loss: 0.7579 - val_accuracy: 0.8110\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.0604 - accuracy: 0.6591 - val_loss: 0.7124 - val_accuracy: 0.8277\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.0217 - accuracy: 0.6777 - val_loss: 0.6701 - val_accuracy: 0.8403\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.9818 - accuracy: 0.6889 - val_loss: 0.6383 - val_accuracy: 0.8518\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.9553 - accuracy: 0.7021 - val_loss: 0.6097 - val_accuracy: 0.8583\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9239 - accuracy: 0.7085 - val_loss: 0.5851 - val_accuracy: 0.8645\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.9092 - accuracy: 0.7186 - val_loss: 0.5695 - val_accuracy: 0.8687\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.8867 - accuracy: 0.7282 - val_loss: 0.5462 - val_accuracy: 0.8737\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.8602 - accuracy: 0.7396 - val_loss: 0.5289 - val_accuracy: 0.8752\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.8475 - accuracy: 0.7412 - val_loss: 0.5120 - val_accuracy: 0.8802\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.8255 - accuracy: 0.7519 - val_loss: 0.4991 - val_accuracy: 0.8837\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.8028 - accuracy: 0.7568 - val_loss: 0.4847 - val_accuracy: 0.8855\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7862 - accuracy: 0.7585 - val_loss: 0.4720 - val_accuracy: 0.8882\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7743 - accuracy: 0.7654 - val_loss: 0.4598 - val_accuracy: 0.8900\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7481 - accuracy: 0.7699 - val_loss: 0.4489 - val_accuracy: 0.8945\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7439 - accuracy: 0.7750 - val_loss: 0.4396 - val_accuracy: 0.8954\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7330 - accuracy: 0.7761 - val_loss: 0.4277 - val_accuracy: 0.8993\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7278 - accuracy: 0.7804 - val_loss: 0.4197 - val_accuracy: 0.9012\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7070 - accuracy: 0.7892 - val_loss: 0.4109 - val_accuracy: 0.9032\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7087 - accuracy: 0.7894 - val_loss: 0.3992 - val_accuracy: 0.9075\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6764 - accuracy: 0.7972 - val_loss: 0.3942 - val_accuracy: 0.9071\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6722 - accuracy: 0.7970 - val_loss: 0.3853 - val_accuracy: 0.9108\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6605 - accuracy: 0.8002 - val_loss: 0.3782 - val_accuracy: 0.9106\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6641 - accuracy: 0.8022 - val_loss: 0.3712 - val_accuracy: 0.9153\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6515 - accuracy: 0.8030 - val_loss: 0.3633 - val_accuracy: 0.9183\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6379 - accuracy: 0.8125 - val_loss: 0.3556 - val_accuracy: 0.9203\n",
      "{'loss': [2.40872859954834, 2.36087965965271, 2.345489025115967, 2.332158088684082, 2.325758218765259, 2.322652578353882, 2.319460391998291, 2.3173816204071045, 2.3154919147491455, 2.312619209289551, 2.3108935356140137, 2.3101747035980225, 2.3096017837524414, 2.3092727661132812, 2.3078832626342773, 2.3077523708343506, 2.3067824840545654, 2.3062520027160645, 2.30560302734375, 2.3055527210235596, 2.3051559925079346, 2.3049442768096924, 2.304824113845825, 2.3050315380096436, 2.30513858795166, 2.304584264755249, 2.3041272163391113, 2.3038363456726074, 2.3038582801818848, 2.3032305240631104, 2.3038179874420166, 2.3033218383789062, 2.3039286136627197, 2.3033254146575928, 2.3034019470214844, 2.3031163215637207, 2.303349256515503, 2.3036463260650635, 2.3032259941101074, 2.3027141094207764, 2.3027689456939697, 2.302682876586914, 2.302902936935425, 2.3031325340270996, 2.302670955657959, 2.302676200866699, 2.302471399307251, 2.302053451538086, 2.302736520767212, 2.3024866580963135], 'accuracy': [0.10052083432674408, 0.10045833140611649, 0.10064583271741867, 0.10385416448116302, 0.10335416346788406, 0.10108333081007004, 0.10068749636411667, 0.10060416907072067, 0.1028333306312561, 0.10495833307504654, 0.1053958311676979, 0.101520836353302, 0.10502083599567413, 0.10437499731779099, 0.10689583420753479, 0.10404166579246521, 0.10462500154972076, 0.1081666648387909, 0.10593750327825546, 0.10712499916553497, 0.10385416448116302, 0.10691666603088379, 0.1067708358168602, 0.10858333110809326, 0.10710416734218597, 0.10785416513681412, 0.10583333671092987, 0.10977083444595337, 0.10714583098888397, 0.11112499982118607, 0.10987500101327896, 0.1106458306312561, 0.10960416495800018, 0.11004166305065155, 0.11047916859388351, 0.1120000034570694, 0.10885416716337204, 0.10985416918992996, 0.10970833152532578, 0.11166666448116302, 0.11122916638851166, 0.10987500101327896, 0.11185416579246521, 0.11102083325386047, 0.11185416579246521, 0.10956250131130219, 0.11139583587646484, 0.10981249809265137, 0.1118958368897438, 0.11122916638851166], 'val_loss': [2.3030545711517334, 2.3018271923065186, 2.3018133640289307, 2.3019168376922607, 2.301983118057251, 2.302032709121704, 2.302008867263794, 2.302037239074707, 2.3020167350769043, 2.3020386695861816, 2.3020150661468506, 2.302050828933716, 2.3020238876342773, 2.3020217418670654, 2.3020575046539307, 2.302084445953369, 2.3020429611206055, 2.3020427227020264, 2.302051544189453, 2.3020331859588623, 2.3020801544189453, 2.302058458328247, 2.3020660877227783, 2.302049398422241, 2.302048444747925, 2.302060127258301, 2.3020780086517334, 2.302086353302002, 2.302079677581787, 2.3020875453948975, 2.3021011352539062, 2.3020973205566406, 2.3021016120910645, 2.3020997047424316, 2.302077293395996, 2.302063226699829, 2.302098035812378, 2.3020858764648438, 2.3020920753479004, 2.3020853996276855, 2.302083730697632, 2.302074670791626, 2.302063226699829, 2.302074909210205, 2.3020927906036377, 2.302076578140259, 2.302079200744629, 2.3020894527435303, 2.302091121673584, 2.3020992279052734], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [1.840639591217041, 1.3810274600982666, 1.180989384651184, 1.0585696697235107, 0.9750626683235168, 0.9132329821586609, 0.8641969561576843, 0.8247003555297852, 0.7868253588676453, 0.7511970400810242, 0.7217261791229248, 0.7053382396697998, 0.6872358322143555, 0.6650746464729309, 0.6435994505882263, 0.6361613273620605, 0.619921863079071, 0.6125443577766418, 0.5859629511833191, 0.5831722617149353, 0.5724631547927856, 0.5632182955741882, 0.5586431622505188, 0.5447911620140076, 0.5392330884933472, 0.5304211974143982, 0.5283411741256714, 0.5141967535018921, 0.509215235710144, 0.5125948190689087, 0.4986157715320587, 0.48971113562583923, 0.48599863052368164, 0.47865310311317444, 0.48146483302116394, 0.4718141555786133, 0.4710312783718109, 0.4587322473526001, 0.45983320474624634, 0.4511476159095764, 0.44677025079727173, 0.44711101055145264, 0.4429348409175873, 0.4325982928276062, 0.4368146061897278, 0.42863929271698, 0.42439502477645874, 0.4177888035774231, 0.4166620373725891, 0.4151270389556885], 'accuracy': [0.3503541648387909, 0.539145827293396, 0.6184999942779541, 0.6625833511352539, 0.6956250071525574, 0.7160833477973938, 0.7370208501815796, 0.7521458268165588, 0.7663333415985107, 0.7819791436195374, 0.7929583191871643, 0.8012083172798157, 0.8062083125114441, 0.8132500052452087, 0.8205000162124634, 0.8260833621025085, 0.8320833444595337, 0.8347708582878113, 0.8425416946411133, 0.8441874980926514, 0.846708357334137, 0.8499166369438171, 0.8521249890327454, 0.8567500114440918, 0.8572083115577698, 0.8614374995231628, 0.8615624904632568, 0.8652083277702332, 0.8658750057220459, 0.8689374923706055, 0.8713541626930237, 0.8722083568572998, 0.8736666440963745, 0.8751041889190674, 0.8763124942779541, 0.8761249780654907, 0.8780624866485596, 0.8808958530426025, 0.8823124766349792, 0.8850625157356262, 0.8846458196640015, 0.8850208520889282, 0.887624979019165, 0.8883541822433472, 0.890250027179718, 0.8925416469573975, 0.8922291398048401, 0.8932499885559082, 0.8959583044052124, 0.8942499756813049], 'val_loss': [1.1635138988494873, 0.8442260026931763, 0.6729096174240112, 0.5762454867362976, 0.5137731432914734, 0.466234415769577, 0.43314799666404724, 0.4109570384025574, 0.3823181092739105, 0.36699941754341125, 0.3531215786933899, 0.3431468605995178, 0.3316385746002197, 0.32026174664497375, 0.31626659631729126, 0.31317567825317383, 0.30353665351867676, 0.2996874153614044, 0.2922151982784271, 0.2866826355457306, 0.2824116349220276, 0.2793574035167694, 0.27536866068840027, 0.2719539701938629, 0.26599928736686707, 0.26416251063346863, 0.2623994052410126, 0.25732043385505676, 0.25720641016960144, 0.25346639752388, 0.25373604893684387, 0.24916628003120422, 0.2476641982793808, 0.24659515917301178, 0.2404845654964447, 0.23803932964801788, 0.2390604019165039, 0.23142777383327484, 0.22756630182266235, 0.23107603192329407, 0.23012609779834747, 0.22703836858272552, 0.22127839922904968, 0.22138501703739166, 0.21845746040344238, 0.21772409975528717, 0.21808211505413055, 0.2123510092496872, 0.21431800723075867, 0.21074296534061432], 'val_accuracy': [0.7045000195503235, 0.8063333630561829, 0.8499166369438171, 0.8640000224113464, 0.8731666803359985, 0.8818333148956299, 0.8866666555404663, 0.890916645526886, 0.8964999914169312, 0.9001666903495789, 0.9042500257492065, 0.9070833325386047, 0.9100833535194397, 0.9127500057220459, 0.9130833148956299, 0.9153333306312561, 0.9182500243186951, 0.9177500009536743, 0.9201666712760925, 0.9232500195503235, 0.9236666560173035, 0.9259999990463257, 0.9270833134651184, 0.9267500042915344, 0.9304999709129333, 0.9306666851043701, 0.9317499995231628, 0.934166669845581, 0.9320833086967468, 0.9355000257492065, 0.9348333477973938, 0.9357500076293945, 0.9366666674613953, 0.937166690826416, 0.9382500052452087, 0.9393333196640015, 0.9400833249092102, 0.9425833225250244, 0.9420833587646484, 0.9410833120346069, 0.9418333172798157, 0.9438333511352539, 0.9437500238418579, 0.9440833330154419, 0.9454166889190674, 0.9458333253860474, 0.9457499980926514, 0.9476666450500488, 0.9477499723434448, 0.9486666917800903]}\n",
      "{'loss': [2.3005635738372803, 2.289092540740967, 2.2462422847747803, 2.1559126377105713, 2.051525115966797, 1.923010230064392, 1.7832227945327759, 1.6799023151397705, 1.597041368484497, 1.5239651203155518, 1.4638795852661133, 1.3993521928787231, 1.3418402671813965, 1.2852495908737183, 1.2406468391418457, 1.189703345298767, 1.1363757848739624, 1.098310112953186, 1.050831913948059, 1.0106626749038696, 0.9808451533317566, 0.9459163546562195, 0.9094994068145752, 0.8736451268196106, 0.8385902643203735, 0.8074592351913452, 0.7788613438606262, 0.7618975639343262, 0.7303258180618286, 0.7147831916809082, 0.6911281943321228, 0.6782883405685425, 0.6573356986045837, 0.6472142934799194, 0.638724148273468, 0.6147695779800415, 0.6057483553886414, 0.6001295447349548, 0.5809563994407654, 0.5647364258766174, 0.5526281595230103, 0.5466836094856262, 0.5362333655357361, 0.5362063646316528, 0.5255870819091797, 0.5164017081260681, 0.506665825843811, 0.48260822892189026, 0.49342817068099976, 0.471427857875824], 'accuracy': [0.12222916632890701, 0.1574375033378601, 0.2016250044107437, 0.23506249487400055, 0.26616665720939636, 0.304520845413208, 0.336020827293396, 0.3541041612625122, 0.37704166769981384, 0.40160417556762695, 0.42929166555404663, 0.4659583270549774, 0.502916693687439, 0.5344374775886536, 0.5598124861717224, 0.5815833210945129, 0.604895830154419, 0.6289166808128357, 0.6495416760444641, 0.6709166765213013, 0.6832916736602783, 0.6996874809265137, 0.7138333320617676, 0.7317708134651184, 0.7438125014305115, 0.7573124766349792, 0.7666875123977661, 0.7753541469573975, 0.7828750014305115, 0.7896875143051147, 0.7963541746139526, 0.8013749718666077, 0.8098541498184204, 0.8137708306312561, 0.815708339214325, 0.8249375224113464, 0.8275833129882812, 0.828083336353302, 0.8345208168029785, 0.8392083048820496, 0.8439791798591614, 0.8474166393280029, 0.8493750095367432, 0.8494374752044678, 0.8523125052452087, 0.8581458330154419, 0.8615208268165588, 0.8656874895095825, 0.863979160785675, 0.8672916889190674], 'val_loss': [2.2937076091766357, 2.2596347332000732, 2.151838779449463, 2.015781879425049, 1.865079641342163, 1.6609470844268799, 1.507012963294983, 1.3940833806991577, 1.3103336095809937, 1.242626667022705, 1.1696124076843262, 1.1061259508132935, 1.0472984313964844, 0.9893589615821838, 0.9370560646057129, 0.8862037658691406, 0.8403434157371521, 0.7848649024963379, 0.7381328344345093, 0.6905046105384827, 0.6537997126579285, 0.6077356338500977, 0.5730652809143066, 0.5301312804222107, 0.4907234013080597, 0.4676433801651001, 0.44968628883361816, 0.42940473556518555, 0.41755810379981995, 0.4053414762020111, 0.3969520330429077, 0.37501996755599976, 0.3678441643714905, 0.3613986074924469, 0.36069709062576294, 0.34913793206214905, 0.3370848298072815, 0.32997220754623413, 0.32646510004997253, 0.3228350281715393, 0.3257937729358673, 0.3061027526855469, 0.31154587864875793, 0.2933194637298584, 0.30001693964004517, 0.28699082136154175, 0.28634679317474365, 0.289124459028244, 0.2736261487007141, 0.2768195569515228], 'val_accuracy': [0.1577499955892563, 0.26091668009757996, 0.2619166672229767, 0.304749995470047, 0.3931666612625122, 0.4074999988079071, 0.4025833308696747, 0.41983333230018616, 0.4505833387374878, 0.4816666543483734, 0.527999997138977, 0.5841666460037231, 0.6650833487510681, 0.6955833435058594, 0.7109166383743286, 0.7401666641235352, 0.7435833215713501, 0.7785833477973938, 0.7861666679382324, 0.8295833468437195, 0.8527500033378601, 0.859000027179718, 0.8744999766349792, 0.8887500166893005, 0.9087499976158142, 0.9085833430290222, 0.918833315372467, 0.9259166717529297, 0.9289166927337646, 0.9316666722297668, 0.9279166460037231, 0.9402499794960022, 0.9448333382606506, 0.9442499876022339, 0.9450833201408386, 0.9432500004768372, 0.9494166374206543, 0.949916660785675, 0.9508333206176758, 0.9538333415985107, 0.9520833492279053, 0.9558333158493042, 0.9552500247955322, 0.9556666612625122, 0.9553333520889282, 0.9601666927337646, 0.9589999914169312, 0.9605833292007446, 0.9606666564941406, 0.9619166851043701]}\n",
      "{'loss': [2.2938895225524902, 2.2440428733825684, 2.0424468517303467, 1.7319749593734741, 1.4979162216186523, 1.3220033645629883, 1.1934648752212524, 1.0820175409317017, 1.0069193840026855, 0.9255093336105347, 0.8597081899642944, 0.8107489347457886, 0.7685952186584473, 0.7204182147979736, 0.6864184737205505, 0.6537254452705383, 0.6269530057907104, 0.5962852239608765, 0.5706618428230286, 0.544209361076355, 0.5219780802726746, 0.5079816579818726, 0.4769747257232666, 0.4669780135154724, 0.44672566652297974, 0.44079041481018066, 0.4163953363895416, 0.40850159525871277, 0.40119653940200806, 0.3879270553588867, 0.3739849328994751, 0.36628666520118713, 0.3583049178123474, 0.34391191601753235, 0.33842796087265015, 0.3236386477947235, 0.32098838686943054, 0.31428396701812744, 0.30993783473968506, 0.29965701699256897, 0.29470357298851013, 0.28676196932792664, 0.2874247133731842, 0.2756652534008026, 0.2683098018169403, 0.26772356033325195, 0.26838013529777527, 0.25951239466667175, 0.2538047134876251, 0.24585285782814026], 'accuracy': [0.12862500548362732, 0.18168750405311584, 0.27256250381469727, 0.3814791738986969, 0.4572291672229767, 0.5295833349227905, 0.5746250152587891, 0.6242916584014893, 0.6576041579246521, 0.6900625228881836, 0.718791663646698, 0.739270806312561, 0.7560208439826965, 0.770354151725769, 0.785937488079071, 0.800000011920929, 0.812166690826416, 0.82052081823349, 0.832729160785675, 0.840666651725769, 0.8523541688919067, 0.854770839214325, 0.8614166378974915, 0.8658333420753479, 0.8739374876022339, 0.8754791617393494, 0.8836458325386047, 0.8850208520889282, 0.8887916803359985, 0.8914166688919067, 0.8946874737739563, 0.8976458311080933, 0.9002083539962769, 0.9056666493415833, 0.905958354473114, 0.9095625281333923, 0.9112083315849304, 0.9118124842643738, 0.9152708053588867, 0.9174583554267883, 0.9204166531562805, 0.9207708239555359, 0.9209791421890259, 0.9231250286102295, 0.9247083067893982, 0.926729142665863, 0.9258750081062317, 0.9285833239555359, 0.929520845413208, 0.9320833086967468], 'val_loss': [2.2644846439361572, 2.1032907962799072, 1.6197669506072998, 1.2123445272445679, 0.9943771362304688, 0.8416194915771484, 0.7351071238517761, 0.6388280987739563, 0.5772945284843445, 0.519433856010437, 0.47764161229133606, 0.43841028213500977, 0.4092714786529541, 0.3750647008419037, 0.3509250581264496, 0.323704332113266, 0.2997392416000366, 0.2758743166923523, 0.25771018862724304, 0.24750742316246033, 0.2253430336713791, 0.2137991338968277, 0.20841628313064575, 0.19562403857707977, 0.1935262829065323, 0.18212562799453735, 0.1823829561471939, 0.1724700778722763, 0.168364480137825, 0.1626891940832138, 0.16070978343486786, 0.15762589871883392, 0.16167287528514862, 0.14971761405467987, 0.14712907373905182, 0.14885665476322174, 0.14219972491264343, 0.13757874071598053, 0.13984976708889008, 0.13999709486961365, 0.13525544106960297, 0.14070163667201996, 0.13322557508945465, 0.1321929693222046, 0.1327327936887741, 0.13031929731369019, 0.1307430863380432, 0.13444304466247559, 0.13178078830242157, 0.12752977013587952], 'val_accuracy': [0.3409166634082794, 0.4795833230018616, 0.534166693687439, 0.5962499976158142, 0.6763333082199097, 0.7495833039283752, 0.8046666383743286, 0.8343333601951599, 0.8420000076293945, 0.8633333444595337, 0.8791666626930237, 0.893916666507721, 0.9079166650772095, 0.9129166603088379, 0.9194166660308838, 0.9242500066757202, 0.9313333630561829, 0.9350833296775818, 0.9380000233650208, 0.9390833377838135, 0.9442499876022339, 0.9459999799728394, 0.9484166502952576, 0.9507499933242798, 0.9516666531562805, 0.9540833234786987, 0.9553333520889282, 0.9571666717529297, 0.9588333368301392, 0.9595833420753479, 0.9610000252723694, 0.9614166617393494, 0.9606666564941406, 0.9634166955947876, 0.9636666774749756, 0.9644166827201843, 0.9642500281333923, 0.9659166932106018, 0.965416669845581, 0.9666666388511658, 0.9674166440963745, 0.9669166803359985, 0.9666666388511658, 0.9680833220481873, 0.968500018119812, 0.969083309173584, 0.968999981880188, 0.968916654586792, 0.9695000052452087, 0.9701666831970215]}\n",
      "{'loss': [1.825811505317688, 1.346605896949768, 1.1297305822372437, 0.9934148788452148, 0.9018425345420837, 0.8424381613731384, 0.7845597267150879, 0.7478466033935547, 0.7179743051528931, 0.6889467239379883, 0.6632128953933716, 0.6406874656677246, 0.618237316608429, 0.6083947420120239, 0.5812317728996277, 0.5749039053916931, 0.5600500702857971, 0.5499522686004639, 0.531813383102417, 0.5238488912582397, 0.5138473510742188, 0.5025080442428589, 0.5004596710205078, 0.485487699508667, 0.4761718809604645, 0.4687747359275818, 0.45930010080337524, 0.45366552472114563, 0.44764384627342224, 0.4423459470272064, 0.4402581453323364, 0.4285518527030945, 0.4209882915019989, 0.4216794967651367, 0.41173091530799866, 0.4070313274860382, 0.4013057053089142, 0.3955783247947693, 0.3934752941131592, 0.3902134597301483, 0.3797341585159302, 0.3783016502857208, 0.377372145652771, 0.3732624053955078, 0.3719949424266815, 0.36345407366752625, 0.3583456575870514, 0.35463082790374756, 0.34983402490615845, 0.3504228889942169], 'accuracy': [0.34158334136009216, 0.5274166464805603, 0.6172083616256714, 0.6724166870117188, 0.7099166512489319, 0.7337291836738586, 0.7547916769981384, 0.7679166793823242, 0.7817708253860474, 0.7930833101272583, 0.8027916550636292, 0.8084999918937683, 0.8194166421890259, 0.8243958353996277, 0.8317499756813049, 0.8357916474342346, 0.8419374823570251, 0.8453541398048401, 0.8512916564941406, 0.8548333048820496, 0.8568124771118164, 0.8608333468437195, 0.8632500171661377, 0.8650416731834412, 0.8696249723434448, 0.8721250295639038, 0.8722083568572998, 0.878250002861023, 0.879729151725769, 0.8787083625793457, 0.879729151725769, 0.883104145526886, 0.8862291574478149, 0.8862916827201843, 0.8888124823570251, 0.8901875019073486, 0.8912708163261414, 0.8932083249092102, 0.893833339214325, 0.8949583172798157, 0.8981249928474426, 0.898354172706604, 0.8998958468437195, 0.9005416631698608, 0.9003541469573975, 0.9048749804496765, 0.903208315372467, 0.9055416584014893, 0.9067708253860474, 0.9058125019073486], 'val_loss': [1.1083709001541138, 0.7610596418380737, 0.5808314085006714, 0.4671022891998291, 0.41047513484954834, 0.36856338381767273, 0.3403410017490387, 0.3216712176799774, 0.30748480558395386, 0.2944321036338806, 0.28370919823646545, 0.27699360251426697, 0.2685309648513794, 0.2596680223941803, 0.256916344165802, 0.2499924749135971, 0.24330277740955353, 0.24154669046401978, 0.23499110341072083, 0.2329171746969223, 0.22929567098617554, 0.22250264883041382, 0.22004804015159607, 0.21489886939525604, 0.2142602503299713, 0.2111363261938095, 0.2050832360982895, 0.20374692976474762, 0.2015218436717987, 0.19654835760593414, 0.19643306732177734, 0.1930292397737503, 0.18997421860694885, 0.1861138641834259, 0.18507467210292816, 0.1832602322101593, 0.18074391782283783, 0.18195749819278717, 0.17522074282169342, 0.17649373412132263, 0.17338226735591888, 0.16727061569690704, 0.16985055804252625, 0.16769523918628693, 0.16660283505916595, 0.1654142588376999, 0.16513551771640778, 0.16112001240253448, 0.15922172367572784, 0.1570741832256317], 'val_accuracy': [0.7230833172798157, 0.8143333196640015, 0.8524166941642761, 0.8775833249092102, 0.8889999985694885, 0.8991666436195374, 0.9026666879653931, 0.9089999794960022, 0.9124166369438171, 0.9160833358764648, 0.9182500243186951, 0.9211666584014893, 0.9229999780654907, 0.9254999756813049, 0.9271666407585144, 0.9286666512489319, 0.9304999709129333, 0.9300833344459534, 0.9330000281333923, 0.9348333477973938, 0.9348333477973938, 0.9386666417121887, 0.9399166703224182, 0.940833330154419, 0.9415000081062317, 0.9421666860580444, 0.9425833225250244, 0.9427499771118164, 0.9449166655540466, 0.9457499980926514, 0.9451666474342346, 0.9471666812896729, 0.9486666917800903, 0.9491666555404663, 0.9509999752044678, 0.9505833387374878, 0.9523333311080933, 0.9511666893959045, 0.9526666402816772, 0.953249990940094, 0.9542499780654907, 0.9556666612625122, 0.9556666612625122, 0.9556666612625122, 0.9556666612625122, 0.9558333158493042, 0.9579166769981384, 0.9580833315849304, 0.956250011920929, 0.9584166407585144]}\n",
      "{'loss': [2.634570598602295, 2.4579429626464844, 2.3813042640686035, 2.3421084880828857, 2.32387638092041, 2.309122323989868, 2.2989916801452637, 2.28635311126709, 2.253389596939087, 2.171499013900757, 2.099130630493164, 2.0659971237182617, 2.0455052852630615, 2.0255417823791504, 2.0004281997680664, 1.9571844339370728, 1.8982115983963013, 1.8493269681930542, 1.8109651803970337, 1.7728185653686523, 1.7521902322769165, 1.7397555112838745, 1.7178946733474731, 1.7022184133529663, 1.687018871307373, 1.6583025455474854, 1.6480681896209717, 1.6326993703842163, 1.6143169403076172, 1.5931552648544312, 1.5787674188613892, 1.5606213808059692, 1.5492267608642578, 1.5325512886047363, 1.528511881828308, 1.5113881826400757, 1.5013188123703003, 1.492998719215393, 1.4865976572036743, 1.4777320623397827, 1.4701924324035645, 1.4625908136367798, 1.4561575651168823, 1.4396696090698242, 1.437564492225647, 1.4324389696121216, 1.4258867502212524, 1.4127026796340942, 1.4058423042297363, 1.3990468978881836], 'accuracy': [0.10193750262260437, 0.10366666316986084, 0.10599999874830246, 0.10587500035762787, 0.10914583504199982, 0.11485416442155838, 0.12122916430234909, 0.13122916221618652, 0.15568749606609344, 0.19441667199134827, 0.21708333492279053, 0.22327083349227905, 0.22591666877269745, 0.23522916436195374, 0.24435417354106903, 0.2554374933242798, 0.26995834708213806, 0.28064584732055664, 0.28689584136009216, 0.2981458306312561, 0.304562509059906, 0.3136250078678131, 0.3188541531562805, 0.32866665720939636, 0.33643749356269836, 0.34691667556762695, 0.3467291593551636, 0.35597917437553406, 0.36533331871032715, 0.3709374964237213, 0.3778958320617676, 0.3841666579246521, 0.38729166984558105, 0.39406248927116394, 0.3981666564941406, 0.40152081847190857, 0.4050416648387909, 0.4085416793823242, 0.41079166531562805, 0.41343748569488525, 0.41975000500679016, 0.42395833134651184, 0.4233541786670685, 0.4309583306312561, 0.4345000088214874, 0.4361250102519989, 0.4372291564941406, 0.4441249966621399, 0.44468748569488525, 0.4481666684150696], 'val_loss': [2.245117664337158, 2.271373748779297, 2.2905006408691406, 2.2993946075439453, 2.3037400245666504, 2.3112576007843018, 2.3105661869049072, 2.226140022277832, 2.1040546894073486, 3.028803825378418, 3.544956684112549, 3.7628982067108154, 3.683899402618408, 3.956223249435425, 3.709406614303589, 3.596452474594116, 3.643242120742798, 3.3075006008148193, 3.4002842903137207, 3.7030866146087646, 3.7686314582824707, 3.894404888153076, 4.616006851196289, 4.4393391609191895, 4.5680766105651855, 4.8919677734375, 4.8529181480407715, 4.919465065002441, 4.826391696929932, 5.377729415893555, 4.892704010009766, 5.3293352127075195, 5.180136203765869, 5.388700008392334, 6.330347061157227, 5.761209487915039, 5.921408653259277, 5.916878700256348, 5.7797136306762695, 6.004634857177734, 6.357462406158447, 6.912829399108887, 6.488361835479736, 6.9875102043151855, 6.362171649932861, 6.778046131134033, 7.134799003601074, 7.153769493103027, 6.696315288543701, 7.017524719238281], 'val_accuracy': [0.17366667091846466, 0.18983332812786102, 0.22616666555404663, 0.14249999821186066, 0.09958333522081375, 0.09950000047683716, 0.09950000047683716, 0.1469999998807907, 0.2110833376646042, 0.2097499966621399, 0.21016666293144226, 0.2082500010728836, 0.20999999344348907, 0.2135833352804184, 0.22699999809265137, 0.26516667008399963, 0.30408334732055664, 0.3175833225250244, 0.3244166672229767, 0.31991666555404663, 0.3189166784286499, 0.3232499957084656, 0.3191666603088379, 0.3191666603088379, 0.32749998569488525, 0.3345833420753479, 0.3426666557788849, 0.3604166805744171, 0.36941665410995483, 0.37674999237060547, 0.3799166679382324, 0.37674999237060547, 0.3891666531562805, 0.3933333456516266, 0.38733333349227905, 0.39283332228660583, 0.38216665387153625, 0.39016667008399963, 0.39008334279060364, 0.3878333270549774, 0.3878333270549774, 0.3619166612625122, 0.3610000014305115, 0.382999986410141, 0.35858333110809326, 0.3658333420753479, 0.3539166748523712, 0.3619999885559082, 0.351416677236557, 0.3725000023841858]}\n",
      "{'loss': [2.3017807006835938, 2.300116777420044, 2.2987468242645264, 2.297304630279541, 2.295684337615967, 2.293483018875122, 2.290688991546631, 2.2858684062957764, 2.2758090496063232, 2.24371075630188, 2.1320114135742188, 1.9554551839828491, 1.7765172719955444, 1.6045807600021362, 1.4694690704345703, 1.3596961498260498, 1.271907091140747, 1.1938034296035767, 1.1262456178665161, 1.0752874612808228, 1.0280903577804565, 0.9802917242050171, 0.9470372200012207, 0.918792724609375, 0.8905078172683716, 0.870180070400238, 0.841172993183136, 0.8253574967384338, 0.7991335391998291, 0.7893261909484863, 0.7708332538604736, 0.755506694316864, 0.7389650344848633, 0.7286579608917236, 0.7110829949378967, 0.6979249715805054, 0.686933159828186, 0.6785441040992737, 0.6638672351837158, 0.6533524394035339, 0.6439998745918274, 0.6366605758666992, 0.627044141292572, 0.6160078644752502, 0.6049473285675049, 0.5969990491867065, 0.5882789492607117, 0.5772322416305542, 0.564314067363739, 0.565761923789978], 'accuracy': [0.11902083456516266, 0.11424999684095383, 0.11406250298023224, 0.11402083188295364, 0.11408333480358124, 0.1146666631102562, 0.11745833605527878, 0.12570832669734955, 0.15568749606609344, 0.20531250536441803, 0.23460416495800018, 0.2928333282470703, 0.35839584469795227, 0.4269166588783264, 0.4794999957084656, 0.5247499942779541, 0.565708339214325, 0.590708315372467, 0.6122708320617676, 0.6345624923706055, 0.6508333086967468, 0.6647708415985107, 0.679395854473114, 0.6878958344459534, 0.6966041922569275, 0.7066875100135803, 0.7129791378974915, 0.7183958292007446, 0.7247499823570251, 0.7300833463668823, 0.7356250286102295, 0.7415833473205566, 0.7486666440963745, 0.7528541684150696, 0.7606041431427002, 0.7647083401679993, 0.7681458592414856, 0.7708541750907898, 0.7777291536331177, 0.7808333039283752, 0.7862083315849304, 0.7918333411216736, 0.7948333621025085, 0.7956458330154419, 0.8018749952316284, 0.8062708377838135, 0.8101249933242798, 0.812125027179718, 0.8188958168029785, 0.8170833587646484], 'val_loss': [2.3012051582336426, 2.2999765872955322, 2.2987823486328125, 2.297349214553833, 2.2954976558685303, 2.2930660247802734, 2.2893364429473877, 2.2826650142669678, 2.266646146774292, 2.192521572113037, 1.9665064811706543, 1.6742500066757202, 1.4462745189666748, 1.237341284751892, 1.0921322107315063, 0.9822465181350708, 0.8605480790138245, 0.7747570872306824, 0.7059108018875122, 0.6575573086738586, 0.6149173974990845, 0.5764064788818359, 0.5474717617034912, 0.5204789638519287, 0.49860596656799316, 0.4785253405570984, 0.46300631761550903, 0.444002240896225, 0.4302709698677063, 0.4150450825691223, 0.4007866680622101, 0.392560213804245, 0.3787981867790222, 0.3677586615085602, 0.35352104902267456, 0.34317755699157715, 0.3361450135707855, 0.3241089880466461, 0.3108274042606354, 0.3032536208629608, 0.2906227707862854, 0.2816105782985687, 0.2743401825428009, 0.2636663317680359, 0.2561165690422058, 0.24845056235790253, 0.2407684475183487, 0.23400671780109406, 0.2265356481075287, 0.22266393899917603], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.11408333480358124, 0.19633333384990692, 0.2409166693687439, 0.2979166805744171, 0.4508333206176758, 0.5631666779518127, 0.6647499799728394, 0.7128333449363708, 0.7379999756813049, 0.7676666378974915, 0.7895833253860474, 0.8049166798591614, 0.8215833306312561, 0.8141666650772095, 0.8315833210945129, 0.8366666436195374, 0.8571666479110718, 0.8614166378974915, 0.8412500023841858, 0.8585000038146973, 0.8767499923706055, 0.8676666617393494, 0.8807500004768372, 0.8987500071525574, 0.8834999799728394, 0.8980000019073486, 0.9109166860580444, 0.9164999723434448, 0.9176666736602783, 0.9190000295639038, 0.92208331823349, 0.9268333315849304, 0.9285833239555359, 0.9340833425521851, 0.9350000023841858, 0.937333345413208, 0.9399999976158142, 0.940583348274231, 0.9416666626930237, 0.9439166784286499, 0.9445833563804626, 0.9467499852180481, 0.9469166398048401]}\n",
      "{'loss': [2.301875591278076, 2.300375461578369, 2.2991459369659424, 2.2980892658233643, 2.2966456413269043, 2.2952396869659424, 2.2934584617614746, 2.2907652854919434, 2.2867867946624756, 2.2802116870880127, 2.262218475341797, 2.1854074001312256, 2.0678040981292725, 1.9786739349365234, 1.8962301015853882, 1.8067247867584229, 1.6887165307998657, 1.5787793397903442, 1.4985321760177612, 1.4236494302749634, 1.355151653289795, 1.2796632051467896, 1.2167096138000488, 1.1565877199172974, 1.101666808128357, 1.056949257850647, 1.0121774673461914, 0.9738625288009644, 0.9482399225234985, 0.9152199029922485, 0.9041407704353333, 0.8730927109718323, 0.856232762336731, 0.8417821526527405, 0.8207728862762451, 0.8029083609580994, 0.7838894724845886, 0.7697899341583252, 0.7547531723976135, 0.7409380674362183, 0.730331540107727, 0.7206605672836304, 0.7060180902481079, 0.695584237575531, 0.6792013645172119, 0.6733675003051758, 0.6693413257598877, 0.6624277830123901, 0.6481001377105713, 0.6341087818145752], 'accuracy': [0.11370833218097687, 0.11433333158493042, 0.11400000005960464, 0.11397916823625565, 0.11395833641290665, 0.11404166370630264, 0.11445832997560501, 0.1158749982714653, 0.12304166704416275, 0.14406250417232513, 0.17927083373069763, 0.20931249856948853, 0.22200000286102295, 0.25981250405311584, 0.29093751311302185, 0.32764583826065063, 0.3734999895095825, 0.4176458418369293, 0.45789584517478943, 0.4986250102519989, 0.53104168176651, 0.5643749833106995, 0.5997708439826965, 0.6228333115577698, 0.6450625061988831, 0.6612708568572998, 0.6804375052452087, 0.6913750171661377, 0.7041458487510681, 0.7145833373069763, 0.7213749885559082, 0.7317083477973938, 0.7380625009536743, 0.7427291870117188, 0.7503541707992554, 0.7564166784286499, 0.7603958249092102, 0.7661458253860474, 0.7695416808128357, 0.7751666903495789, 0.7799583077430725, 0.7820208072662354, 0.7882916927337646, 0.7926041483879089, 0.7961875200271606, 0.7982916831970215, 0.7998124957084656, 0.8009999990463257, 0.8046875, 0.8112916946411133], 'val_loss': [2.3013298511505127, 2.3002851009368896, 2.2992613315582275, 2.298161506652832, 2.296844005584717, 2.2951908111572266, 2.293044090270996, 2.2899441719055176, 2.284976005554199, 2.2751219272613525, 2.24015212059021, 2.0841732025146484, 1.957079291343689, 1.850588083267212, 1.7478030920028687, 1.624232530593872, 1.4502032995224, 1.331263542175293, 1.2378915548324585, 1.149742603302002, 1.0641411542892456, 0.973360002040863, 0.8917160630226135, 0.8214786648750305, 0.7579129934310913, 0.7124264240264893, 0.6701168417930603, 0.6383415460586548, 0.6096721291542053, 0.5850788354873657, 0.5695473551750183, 0.5461688041687012, 0.528934895992279, 0.5120471715927124, 0.49907955527305603, 0.48472651839256287, 0.47198253870010376, 0.4598483145236969, 0.44889819622039795, 0.4396054744720459, 0.4277159869670868, 0.41972604393959045, 0.41093769669532776, 0.39915499091148376, 0.39417505264282227, 0.38529500365257263, 0.37824156880378723, 0.37116295099258423, 0.36328378319740295, 0.3556418716907501], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.11133333295583725, 0.15966667234897614, 0.19975000619888306, 0.21658332645893097, 0.257750004529953, 0.30024999380111694, 0.37049999833106995, 0.4483333230018616, 0.4936666786670685, 0.5327500104904175, 0.5816666483879089, 0.6337500214576721, 0.6809999942779541, 0.7205833196640015, 0.7648333311080933, 0.7891666889190674, 0.8109999895095825, 0.8276666402816772, 0.8402500152587891, 0.8518333435058594, 0.8582500219345093, 0.8644999861717224, 0.8687499761581421, 0.8737499713897705, 0.875249981880188, 0.8802499771118164, 0.8836666941642761, 0.8855000138282776, 0.8881666660308838, 0.8899999856948853, 0.8945000171661377, 0.8954166769981384, 0.8993333578109741, 0.9011666774749756, 0.903249979019165, 0.9075000286102295, 0.9070833325386047, 0.9108333587646484, 0.9105833172798157, 0.9152500033378601, 0.9182500243186951, 0.9203333258628845]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
