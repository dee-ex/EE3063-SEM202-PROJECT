{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4depth128.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnHhSjZec4W6","executionInfo":{"status":"ok","timestamp":1627300231866,"user_tz":-420,"elapsed":645696,"user":{"displayName":"Trung Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjz3Gx8BE3WlqqWlg0FDtKUcK2DEtQ_rPNQD4mLTA=s64","userId":"01683412142186761760"}},"outputId":"953d50f9-6d66-4fd7-b2ae-1f263b0971b5"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n","from keras.layers.noise import AlphaDropout\n","from keras.utils.generic_utils import get_custom_objects\n","from keras import backend as K\n","from keras.optimizers import Adam, SGD\n","\n","def preprocess_mnist(x_train, y_train, x_test, y_test):\n","    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n","    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n","    input_shape = (28 * 28,)\n","    \n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    \n","    x_train /= 255\n","    x_test /= 255\n","    \n","    y_train = to_categorical(y_train)\n","    y_test= to_categorical(y_test)\n","    \n","    return x_train, y_train, x_test, y_test, input_shape\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n","\n","def build_cnn(activation,\n","              dropout_rate,\n","              optimizer):\n","    model = Sequential()\n","    \n","    if(activation == 'selu'):\n","        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.5))\n","        model.add(Dense(10, activation='softmax'))\n","    else:\n","        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(10, activation='softmax'))\n","    \n","    model.compile(\n","        loss='categorical_crossentropy', \n","        optimizer=optimizer, \n","        metrics=['accuracy']\n","    )\n","    \n","    return model\n","\n","\n","def gelu(x):\n","    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n","get_custom_objects().update({'gelu': Activation(gelu)})\n","\n","def swish(x):\n","    return x * tf.sigmoid(x)\n","get_custom_objects().update({'swish': Activation(swish)})\n","\n","get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n","\n","act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n","\n","result = []\n","\n","\n","for activation in act_func:\n","    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n","    \n","    model = build_cnn(activation=activation,\n","                      dropout_rate=0.2,\n","                      optimizer=SGD())\n","    \n","    history = model.fit(x_train, y_train,\n","          validation_split=0.20,\n","          batch_size=128,\n","          epochs=50,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","    \n","    result.append(history)\n","    \n","    K.clear_session()\n","    del model\n","\n","for r in result:\n","    print(r.history)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","\n","Training with -->sigmoid<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 17s 5ms/step - loss: 2.5349 - accuracy: 0.1024 - val_loss: 2.3025 - val_accuracy: 0.1060\n","Epoch 2/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.4076 - accuracy: 0.1030 - val_loss: 2.3024 - val_accuracy: 0.1060\n","Epoch 3/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3699 - accuracy: 0.1016 - val_loss: 2.3023 - val_accuracy: 0.1060\n","Epoch 4/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3508 - accuracy: 0.1002 - val_loss: 2.3020 - val_accuracy: 0.1060\n","Epoch 5/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3392 - accuracy: 0.1015 - val_loss: 2.3018 - val_accuracy: 0.1060\n","Epoch 6/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3327 - accuracy: 0.0999 - val_loss: 2.3018 - val_accuracy: 0.1060\n","Epoch 7/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3247 - accuracy: 0.1043 - val_loss: 2.3015 - val_accuracy: 0.1060\n","Epoch 8/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3208 - accuracy: 0.1019 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 9/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3177 - accuracy: 0.1030 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 10/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3145 - accuracy: 0.1047 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 11/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3137 - accuracy: 0.1018 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 12/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3124 - accuracy: 0.1052 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 13/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3083 - accuracy: 0.1089 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 14/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3116 - accuracy: 0.1030 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 15/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3104 - accuracy: 0.1020 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 16/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3075 - accuracy: 0.1063 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 17/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3069 - accuracy: 0.1088 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 18/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3068 - accuracy: 0.1048 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 19/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3055 - accuracy: 0.1098 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 20/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3069 - accuracy: 0.1048 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 21/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3055 - accuracy: 0.1088 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 22/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3051 - accuracy: 0.1058 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 23/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3055 - accuracy: 0.1043 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 24/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3046 - accuracy: 0.1060 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 25/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3059 - accuracy: 0.1070 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 26/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3063 - accuracy: 0.1041 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 27/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3044 - accuracy: 0.1071 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 28/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3042 - accuracy: 0.1090 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 29/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3040 - accuracy: 0.1069 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 30/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3032 - accuracy: 0.1100 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 31/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3034 - accuracy: 0.1069 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 32/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3029 - accuracy: 0.1080 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 33/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3025 - accuracy: 0.1125 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 34/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3033 - accuracy: 0.1088 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 35/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3037 - accuracy: 0.1040 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 36/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3033 - accuracy: 0.1091 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 37/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3028 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 38/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3038 - accuracy: 0.1088 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 39/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3020 - accuracy: 0.1151 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 40/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3033 - accuracy: 0.1087 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 41/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3018 - accuracy: 0.1098 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 42/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3022 - accuracy: 0.1102 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 43/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3029 - accuracy: 0.1117 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 44/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3027 - accuracy: 0.1093 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 45/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3025 - accuracy: 0.1105 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 46/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3028 - accuracy: 0.1098 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 47/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3020 - accuracy: 0.1074 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 48/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3031 - accuracy: 0.1093 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 49/50\n","375/375 [==============================] - 1s 3ms/step - loss: 2.3030 - accuracy: 0.1088 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 50/50\n","375/375 [==============================] - 1s 4ms/step - loss: 2.3025 - accuracy: 0.1110 - val_loss: 2.3017 - val_accuracy: 0.1060\n","\n","Training with -->tanh<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 3s 5ms/step - loss: 1.6654 - accuracy: 0.4434 - val_loss: 0.5964 - val_accuracy: 0.8539\n","Epoch 2/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.7714 - accuracy: 0.7759 - val_loss: 0.4126 - val_accuracy: 0.8898\n","Epoch 3/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6095 - accuracy: 0.8169 - val_loss: 0.3531 - val_accuracy: 0.9001\n","Epoch 4/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5244 - accuracy: 0.8469 - val_loss: 0.3255 - val_accuracy: 0.9048\n","Epoch 5/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.8537 - val_loss: 0.3083 - val_accuracy: 0.9098\n","Epoch 6/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4684 - accuracy: 0.8615 - val_loss: 0.2929 - val_accuracy: 0.9143\n","Epoch 7/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4420 - accuracy: 0.8695 - val_loss: 0.2848 - val_accuracy: 0.9162\n","Epoch 8/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4253 - accuracy: 0.8743 - val_loss: 0.2783 - val_accuracy: 0.9187\n","Epoch 9/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4209 - accuracy: 0.8766 - val_loss: 0.2723 - val_accuracy: 0.9207\n","Epoch 10/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4039 - accuracy: 0.8800 - val_loss: 0.2658 - val_accuracy: 0.9218\n","Epoch 11/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3985 - accuracy: 0.8846 - val_loss: 0.2609 - val_accuracy: 0.9230\n","Epoch 12/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3830 - accuracy: 0.8867 - val_loss: 0.2574 - val_accuracy: 0.9229\n","Epoch 13/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3840 - accuracy: 0.8864 - val_loss: 0.2533 - val_accuracy: 0.9252\n","Epoch 14/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3731 - accuracy: 0.8902 - val_loss: 0.2510 - val_accuracy: 0.9256\n","Epoch 15/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3719 - accuracy: 0.8914 - val_loss: 0.2463 - val_accuracy: 0.9273\n","Epoch 16/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3742 - accuracy: 0.8897 - val_loss: 0.2459 - val_accuracy: 0.9272\n","Epoch 17/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3567 - accuracy: 0.8932 - val_loss: 0.2403 - val_accuracy: 0.9293\n","Epoch 18/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8964 - val_loss: 0.2383 - val_accuracy: 0.9301\n","Epoch 19/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3589 - accuracy: 0.8962 - val_loss: 0.2334 - val_accuracy: 0.9319\n","Epoch 20/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3532 - accuracy: 0.8987 - val_loss: 0.2327 - val_accuracy: 0.9320\n","Epoch 21/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3409 - accuracy: 0.9009 - val_loss: 0.2310 - val_accuracy: 0.9329\n","Epoch 22/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3467 - accuracy: 0.8998 - val_loss: 0.2284 - val_accuracy: 0.9327\n","Epoch 23/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.9015 - val_loss: 0.2254 - val_accuracy: 0.9334\n","Epoch 24/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.9043 - val_loss: 0.2233 - val_accuracy: 0.9352\n","Epoch 25/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.9050 - val_loss: 0.2196 - val_accuracy: 0.9358\n","Epoch 26/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3248 - accuracy: 0.9070 - val_loss: 0.2215 - val_accuracy: 0.9353\n","Epoch 27/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3102 - accuracy: 0.9114 - val_loss: 0.2154 - val_accuracy: 0.9372\n","Epoch 28/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.9092 - val_loss: 0.2146 - val_accuracy: 0.9373\n","Epoch 29/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.9110 - val_loss: 0.2129 - val_accuracy: 0.9379\n","Epoch 30/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.9151 - val_loss: 0.2091 - val_accuracy: 0.9394\n","Epoch 31/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3031 - accuracy: 0.9125 - val_loss: 0.2053 - val_accuracy: 0.9404\n","Epoch 32/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2996 - accuracy: 0.9138 - val_loss: 0.2052 - val_accuracy: 0.9408\n","Epoch 33/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2970 - accuracy: 0.9147 - val_loss: 0.2042 - val_accuracy: 0.9412\n","Epoch 34/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2919 - accuracy: 0.9125 - val_loss: 0.2017 - val_accuracy: 0.9414\n","Epoch 35/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.9174 - val_loss: 0.1987 - val_accuracy: 0.9426\n","Epoch 36/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2908 - accuracy: 0.9152 - val_loss: 0.1970 - val_accuracy: 0.9431\n","Epoch 37/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2834 - accuracy: 0.9172 - val_loss: 0.1957 - val_accuracy: 0.9438\n","Epoch 38/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2778 - accuracy: 0.9190 - val_loss: 0.1952 - val_accuracy: 0.9443\n","Epoch 39/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2866 - accuracy: 0.9178 - val_loss: 0.1914 - val_accuracy: 0.9451\n","Epoch 40/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2725 - accuracy: 0.9212 - val_loss: 0.1893 - val_accuracy: 0.9456\n","Epoch 41/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2777 - accuracy: 0.9207 - val_loss: 0.1876 - val_accuracy: 0.9462\n","Epoch 42/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.9212 - val_loss: 0.1857 - val_accuracy: 0.9474\n","Epoch 43/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.9220 - val_loss: 0.1835 - val_accuracy: 0.9478\n","Epoch 44/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.9224 - val_loss: 0.1827 - val_accuracy: 0.9474\n","Epoch 45/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.9226 - val_loss: 0.1811 - val_accuracy: 0.9489\n","Epoch 46/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2613 - accuracy: 0.9236 - val_loss: 0.1793 - val_accuracy: 0.9498\n","Epoch 47/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2727 - accuracy: 0.9216 - val_loss: 0.1769 - val_accuracy: 0.9502\n","Epoch 48/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2580 - accuracy: 0.9249 - val_loss: 0.1761 - val_accuracy: 0.9502\n","Epoch 49/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2570 - accuracy: 0.9244 - val_loss: 0.1753 - val_accuracy: 0.9503\n","Epoch 50/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2609 - accuracy: 0.9236 - val_loss: 0.1724 - val_accuracy: 0.9515\n","\n","Training with -->relu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 3s 5ms/step - loss: 2.2550 - accuracy: 0.1633 - val_loss: 1.6731 - val_accuracy: 0.6308\n","Epoch 2/50\n","375/375 [==============================] - 1s 4ms/step - loss: 1.6671 - accuracy: 0.4414 - val_loss: 0.7983 - val_accuracy: 0.8179\n","Epoch 3/50\n","375/375 [==============================] - 1s 4ms/step - loss: 1.0880 - accuracy: 0.6410 - val_loss: 0.5143 - val_accuracy: 0.8674\n","Epoch 4/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.8243 - accuracy: 0.7393 - val_loss: 0.4123 - val_accuracy: 0.8858\n","Epoch 5/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.7871 - val_loss: 0.3527 - val_accuracy: 0.8992\n","Epoch 6/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.8211 - val_loss: 0.3157 - val_accuracy: 0.9088\n","Epoch 7/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5467 - accuracy: 0.8390 - val_loss: 0.2877 - val_accuracy: 0.9161\n","Epoch 8/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4871 - accuracy: 0.8608 - val_loss: 0.2638 - val_accuracy: 0.9230\n","Epoch 9/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4535 - accuracy: 0.8702 - val_loss: 0.2441 - val_accuracy: 0.9287\n","Epoch 10/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4251 - accuracy: 0.8796 - val_loss: 0.2272 - val_accuracy: 0.9333\n","Epoch 11/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3915 - accuracy: 0.8910 - val_loss: 0.2139 - val_accuracy: 0.9366\n","Epoch 12/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3744 - accuracy: 0.8949 - val_loss: 0.2024 - val_accuracy: 0.9404\n","Epoch 13/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3554 - accuracy: 0.9024 - val_loss: 0.1888 - val_accuracy: 0.9437\n","Epoch 14/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.9095 - val_loss: 0.1801 - val_accuracy: 0.9458\n","Epoch 15/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3064 - accuracy: 0.9161 - val_loss: 0.1708 - val_accuracy: 0.9476\n","Epoch 16/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.9174 - val_loss: 0.1637 - val_accuracy: 0.9512\n","Epoch 17/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2787 - accuracy: 0.9249 - val_loss: 0.1566 - val_accuracy: 0.9533\n","Epoch 18/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9264 - val_loss: 0.1508 - val_accuracy: 0.9554\n","Epoch 19/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2664 - accuracy: 0.9285 - val_loss: 0.1471 - val_accuracy: 0.9562\n","Epoch 20/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2596 - accuracy: 0.9306 - val_loss: 0.1433 - val_accuracy: 0.9578\n","Epoch 21/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2468 - accuracy: 0.9351 - val_loss: 0.1381 - val_accuracy: 0.9598\n","Epoch 22/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2382 - accuracy: 0.9366 - val_loss: 0.1344 - val_accuracy: 0.9605\n","Epoch 23/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2223 - accuracy: 0.9404 - val_loss: 0.1296 - val_accuracy: 0.9607\n","Epoch 24/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9407 - val_loss: 0.1276 - val_accuracy: 0.9619\n","Epoch 25/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9424 - val_loss: 0.1238 - val_accuracy: 0.9634\n","Epoch 26/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2000 - accuracy: 0.9477 - val_loss: 0.1216 - val_accuracy: 0.9640\n","Epoch 27/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1989 - accuracy: 0.9473 - val_loss: 0.1218 - val_accuracy: 0.9635\n","Epoch 28/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1967 - accuracy: 0.9477 - val_loss: 0.1166 - val_accuracy: 0.9651\n","Epoch 29/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1843 - accuracy: 0.9503 - val_loss: 0.1150 - val_accuracy: 0.9659\n","Epoch 30/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1801 - accuracy: 0.9499 - val_loss: 0.1137 - val_accuracy: 0.9667\n","Epoch 31/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1800 - accuracy: 0.9522 - val_loss: 0.1106 - val_accuracy: 0.9672\n","Epoch 32/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1748 - accuracy: 0.9543 - val_loss: 0.1093 - val_accuracy: 0.9682\n","Epoch 33/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9552 - val_loss: 0.1068 - val_accuracy: 0.9686\n","Epoch 34/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1662 - accuracy: 0.9550 - val_loss: 0.1065 - val_accuracy: 0.9686\n","Epoch 35/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1611 - accuracy: 0.9577 - val_loss: 0.1048 - val_accuracy: 0.9696\n","Epoch 36/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1570 - accuracy: 0.9583 - val_loss: 0.1051 - val_accuracy: 0.9686\n","Epoch 37/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1537 - accuracy: 0.9591 - val_loss: 0.1035 - val_accuracy: 0.9697\n","Epoch 38/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1397 - accuracy: 0.9624 - val_loss: 0.1003 - val_accuracy: 0.9707\n","Epoch 39/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1490 - accuracy: 0.9626 - val_loss: 0.1020 - val_accuracy: 0.9697\n","Epoch 40/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1326 - accuracy: 0.9660 - val_loss: 0.1000 - val_accuracy: 0.9707\n","Epoch 41/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1353 - accuracy: 0.9643 - val_loss: 0.0986 - val_accuracy: 0.9714\n","Epoch 42/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1310 - accuracy: 0.9661 - val_loss: 0.0981 - val_accuracy: 0.9719\n","Epoch 43/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1347 - accuracy: 0.9638 - val_loss: 0.0970 - val_accuracy: 0.9721\n","Epoch 44/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1273 - accuracy: 0.9667 - val_loss: 0.0959 - val_accuracy: 0.9723\n","Epoch 45/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1279 - accuracy: 0.9646 - val_loss: 0.0961 - val_accuracy: 0.9718\n","Epoch 46/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1167 - accuracy: 0.9691 - val_loss: 0.0948 - val_accuracy: 0.9718\n","Epoch 47/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1190 - accuracy: 0.9680 - val_loss: 0.0926 - val_accuracy: 0.9737\n","Epoch 48/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1180 - accuracy: 0.9682 - val_loss: 0.0927 - val_accuracy: 0.9733\n","Epoch 49/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1169 - accuracy: 0.9698 - val_loss: 0.0925 - val_accuracy: 0.9737\n","Epoch 50/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9721 - val_loss: 0.0930 - val_accuracy: 0.9739\n","\n","Training with -->leaky-relu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 3s 5ms/step - loss: 2.1898 - accuracy: 0.2068 - val_loss: 1.3119 - val_accuracy: 0.6892\n","Epoch 2/50\n","375/375 [==============================] - 1s 3ms/step - loss: 1.3705 - accuracy: 0.5417 - val_loss: 0.6275 - val_accuracy: 0.8548\n","Epoch 3/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.8997 - accuracy: 0.7105 - val_loss: 0.4380 - val_accuracy: 0.8877\n","Epoch 4/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.7832 - val_loss: 0.3642 - val_accuracy: 0.8992\n","Epoch 5/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5931 - accuracy: 0.8242 - val_loss: 0.3237 - val_accuracy: 0.9096\n","Epoch 6/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.5345 - accuracy: 0.8441 - val_loss: 0.2960 - val_accuracy: 0.9156\n","Epoch 7/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4772 - accuracy: 0.8618 - val_loss: 0.2749 - val_accuracy: 0.9212\n","Epoch 8/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4444 - accuracy: 0.8724 - val_loss: 0.2577 - val_accuracy: 0.9256\n","Epoch 9/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4177 - accuracy: 0.8813 - val_loss: 0.2422 - val_accuracy: 0.9298\n","Epoch 10/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3896 - accuracy: 0.8899 - val_loss: 0.2326 - val_accuracy: 0.9312\n","Epoch 11/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3778 - accuracy: 0.8937 - val_loss: 0.2196 - val_accuracy: 0.9351\n","Epoch 12/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3579 - accuracy: 0.8999 - val_loss: 0.2102 - val_accuracy: 0.9378\n","Epoch 13/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.9069 - val_loss: 0.2018 - val_accuracy: 0.9399\n","Epoch 14/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.9097 - val_loss: 0.1948 - val_accuracy: 0.9414\n","Epoch 15/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3133 - accuracy: 0.9111 - val_loss: 0.1872 - val_accuracy: 0.9432\n","Epoch 16/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2971 - accuracy: 0.9163 - val_loss: 0.1817 - val_accuracy: 0.9455\n","Epoch 17/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2976 - accuracy: 0.9165 - val_loss: 0.1744 - val_accuracy: 0.9482\n","Epoch 18/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2691 - accuracy: 0.9228 - val_loss: 0.1684 - val_accuracy: 0.9495\n","Epoch 19/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2694 - accuracy: 0.9255 - val_loss: 0.1656 - val_accuracy: 0.9509\n","Epoch 20/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2623 - accuracy: 0.9268 - val_loss: 0.1595 - val_accuracy: 0.9518\n","Epoch 21/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2501 - accuracy: 0.9306 - val_loss: 0.1558 - val_accuracy: 0.9531\n","Epoch 22/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2434 - accuracy: 0.9320 - val_loss: 0.1499 - val_accuracy: 0.9554\n","Epoch 23/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2370 - accuracy: 0.9354 - val_loss: 0.1463 - val_accuracy: 0.9565\n","Epoch 24/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2298 - accuracy: 0.9362 - val_loss: 0.1426 - val_accuracy: 0.9578\n","Epoch 25/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2245 - accuracy: 0.9375 - val_loss: 0.1394 - val_accuracy: 0.9584\n","Epoch 26/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2187 - accuracy: 0.9395 - val_loss: 0.1348 - val_accuracy: 0.9605\n","Epoch 27/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9409 - val_loss: 0.1325 - val_accuracy: 0.9615\n","Epoch 28/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9413 - val_loss: 0.1294 - val_accuracy: 0.9624\n","Epoch 29/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9441 - val_loss: 0.1278 - val_accuracy: 0.9626\n","Epoch 30/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1958 - accuracy: 0.9455 - val_loss: 0.1254 - val_accuracy: 0.9623\n","Epoch 31/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.9455 - val_loss: 0.1250 - val_accuracy: 0.9628\n","Epoch 32/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1917 - accuracy: 0.9453 - val_loss: 0.1220 - val_accuracy: 0.9650\n","Epoch 33/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1803 - accuracy: 0.9492 - val_loss: 0.1199 - val_accuracy: 0.9656\n","Epoch 34/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1811 - accuracy: 0.9505 - val_loss: 0.1183 - val_accuracy: 0.9650\n","Epoch 35/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9512 - val_loss: 0.1153 - val_accuracy: 0.9669\n","Epoch 36/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9505 - val_loss: 0.1140 - val_accuracy: 0.9663\n","Epoch 37/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1735 - accuracy: 0.9517 - val_loss: 0.1146 - val_accuracy: 0.9660\n","Epoch 38/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1645 - accuracy: 0.9555 - val_loss: 0.1119 - val_accuracy: 0.9672\n","Epoch 39/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1586 - accuracy: 0.9560 - val_loss: 0.1107 - val_accuracy: 0.9681\n","Epoch 40/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.9560 - val_loss: 0.1090 - val_accuracy: 0.9681\n","Epoch 41/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1583 - accuracy: 0.9569 - val_loss: 0.1079 - val_accuracy: 0.9693\n","Epoch 42/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1588 - accuracy: 0.9563 - val_loss: 0.1069 - val_accuracy: 0.9689\n","Epoch 43/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1503 - accuracy: 0.9585 - val_loss: 0.1044 - val_accuracy: 0.9696\n","Epoch 44/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9589 - val_loss: 0.1044 - val_accuracy: 0.9703\n","Epoch 45/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9603 - val_loss: 0.1028 - val_accuracy: 0.9704\n","Epoch 46/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1420 - accuracy: 0.9602 - val_loss: 0.1017 - val_accuracy: 0.9707\n","Epoch 47/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9610 - val_loss: 0.1011 - val_accuracy: 0.9706\n","Epoch 48/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1420 - accuracy: 0.9613 - val_loss: 0.1000 - val_accuracy: 0.9708\n","Epoch 49/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9619 - val_loss: 0.1003 - val_accuracy: 0.9712\n","Epoch 50/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.1359 - accuracy: 0.9612 - val_loss: 0.0995 - val_accuracy: 0.9712\n","\n","Training with -->elu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 3s 5ms/step - loss: 1.7028 - accuracy: 0.4374 - val_loss: 0.5446 - val_accuracy: 0.8679\n","Epoch 2/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.7409 - accuracy: 0.7724 - val_loss: 0.3846 - val_accuracy: 0.8929\n","Epoch 3/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5850 - accuracy: 0.8261 - val_loss: 0.3367 - val_accuracy: 0.9015\n","Epoch 4/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5222 - accuracy: 0.8439 - val_loss: 0.3146 - val_accuracy: 0.9078\n","Epoch 5/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4812 - accuracy: 0.8576 - val_loss: 0.2988 - val_accuracy: 0.9113\n","Epoch 6/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4582 - accuracy: 0.8661 - val_loss: 0.2864 - val_accuracy: 0.9150\n","Epoch 7/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4358 - accuracy: 0.8704 - val_loss: 0.2754 - val_accuracy: 0.9193\n","Epoch 8/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4242 - accuracy: 0.8760 - val_loss: 0.2681 - val_accuracy: 0.9206\n","Epoch 9/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4153 - accuracy: 0.8803 - val_loss: 0.2603 - val_accuracy: 0.9239\n","Epoch 10/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3969 - accuracy: 0.8826 - val_loss: 0.2525 - val_accuracy: 0.9265\n","Epoch 11/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3872 - accuracy: 0.8855 - val_loss: 0.2484 - val_accuracy: 0.9264\n","Epoch 12/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3850 - accuracy: 0.8863 - val_loss: 0.2433 - val_accuracy: 0.9282\n","Epoch 13/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3797 - accuracy: 0.8891 - val_loss: 0.2383 - val_accuracy: 0.9296\n","Epoch 14/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8924 - val_loss: 0.2327 - val_accuracy: 0.9315\n","Epoch 15/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3540 - accuracy: 0.8962 - val_loss: 0.2286 - val_accuracy: 0.9337\n","Epoch 16/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.9020 - val_loss: 0.2250 - val_accuracy: 0.9330\n","Epoch 17/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3389 - accuracy: 0.9005 - val_loss: 0.2202 - val_accuracy: 0.9358\n","Epoch 18/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.9035 - val_loss: 0.2164 - val_accuracy: 0.9368\n","Epoch 19/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3357 - accuracy: 0.8999 - val_loss: 0.2130 - val_accuracy: 0.9381\n","Epoch 20/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.9029 - val_loss: 0.2094 - val_accuracy: 0.9388\n","Epoch 21/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.9065 - val_loss: 0.2070 - val_accuracy: 0.9394\n","Epoch 22/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3176 - accuracy: 0.9053 - val_loss: 0.2021 - val_accuracy: 0.9417\n","Epoch 23/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3055 - accuracy: 0.9089 - val_loss: 0.1989 - val_accuracy: 0.9431\n","Epoch 24/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.9133 - val_loss: 0.1960 - val_accuracy: 0.9434\n","Epoch 25/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2995 - accuracy: 0.9127 - val_loss: 0.1933 - val_accuracy: 0.9449\n","Epoch 26/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2946 - accuracy: 0.9152 - val_loss: 0.1913 - val_accuracy: 0.9455\n","Epoch 27/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2986 - accuracy: 0.9128 - val_loss: 0.1866 - val_accuracy: 0.9463\n","Epoch 28/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.9164 - val_loss: 0.1835 - val_accuracy: 0.9474\n","Epoch 29/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2928 - accuracy: 0.9150 - val_loss: 0.1802 - val_accuracy: 0.9485\n","Epoch 30/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.9205 - val_loss: 0.1805 - val_accuracy: 0.9499\n","Epoch 31/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2724 - accuracy: 0.9191 - val_loss: 0.1775 - val_accuracy: 0.9495\n","Epoch 32/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2744 - accuracy: 0.9207 - val_loss: 0.1739 - val_accuracy: 0.9510\n","Epoch 33/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.9229 - val_loss: 0.1725 - val_accuracy: 0.9517\n","Epoch 34/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2607 - accuracy: 0.9228 - val_loss: 0.1706 - val_accuracy: 0.9520\n","Epoch 35/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2579 - accuracy: 0.9244 - val_loss: 0.1686 - val_accuracy: 0.9526\n","Epoch 36/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2562 - accuracy: 0.9232 - val_loss: 0.1659 - val_accuracy: 0.9534\n","Epoch 37/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2518 - accuracy: 0.9254 - val_loss: 0.1636 - val_accuracy: 0.9542\n","Epoch 38/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2559 - accuracy: 0.9267 - val_loss: 0.1615 - val_accuracy: 0.9553\n","Epoch 39/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2531 - accuracy: 0.9257 - val_loss: 0.1625 - val_accuracy: 0.9544\n","Epoch 40/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2548 - accuracy: 0.9242 - val_loss: 0.1589 - val_accuracy: 0.9557\n","Epoch 41/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2421 - accuracy: 0.9296 - val_loss: 0.1556 - val_accuracy: 0.9557\n","Epoch 42/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9292 - val_loss: 0.1541 - val_accuracy: 0.9562\n","Epoch 43/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2339 - accuracy: 0.9307 - val_loss: 0.1535 - val_accuracy: 0.9557\n","Epoch 44/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2362 - accuracy: 0.9297 - val_loss: 0.1511 - val_accuracy: 0.9567\n","Epoch 45/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2351 - accuracy: 0.9295 - val_loss: 0.1495 - val_accuracy: 0.9580\n","Epoch 46/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.9328 - val_loss: 0.1487 - val_accuracy: 0.9582\n","Epoch 47/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9340 - val_loss: 0.1472 - val_accuracy: 0.9582\n","Epoch 48/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2271 - accuracy: 0.9337 - val_loss: 0.1466 - val_accuracy: 0.9588\n","Epoch 49/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2233 - accuracy: 0.9331 - val_loss: 0.1451 - val_accuracy: 0.9585\n","Epoch 50/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9367 - val_loss: 0.1424 - val_accuracy: 0.9599\n","\n","Training with -->selu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 3s 5ms/step - loss: 2.8296 - accuracy: 0.1074 - val_loss: 1.6485 - val_accuracy: 0.4087\n","Epoch 2/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3317 - accuracy: 0.1687 - val_loss: 1.2849 - val_accuracy: 0.5402\n","Epoch 3/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.9649 - accuracy: 0.2885 - val_loss: 1.1805 - val_accuracy: 0.6484\n","Epoch 4/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.6392 - accuracy: 0.4034 - val_loss: 1.1499 - val_accuracy: 0.6939\n","Epoch 5/50\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4063 - accuracy: 0.4938 - val_loss: 1.1379 - val_accuracy: 0.7303\n","Epoch 6/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.2265 - accuracy: 0.5664 - val_loss: 1.1400 - val_accuracy: 0.7548\n","Epoch 7/50\n","375/375 [==============================] - 1s 4ms/step - loss: 1.1214 - accuracy: 0.6039 - val_loss: 1.1002 - val_accuracy: 0.7812\n","Epoch 8/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.0244 - accuracy: 0.6518 - val_loss: 1.0962 - val_accuracy: 0.8040\n","Epoch 9/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.9603 - accuracy: 0.6806 - val_loss: 1.0972 - val_accuracy: 0.8177\n","Epoch 10/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.9098 - accuracy: 0.7017 - val_loss: 1.0833 - val_accuracy: 0.8291\n","Epoch 11/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.8593 - accuracy: 0.7173 - val_loss: 1.0507 - val_accuracy: 0.8403\n","Epoch 12/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.8274 - accuracy: 0.7348 - val_loss: 1.0484 - val_accuracy: 0.8472\n","Epoch 13/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.7915 - accuracy: 0.7447 - val_loss: 1.0609 - val_accuracy: 0.8509\n","Epoch 14/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.7574 - accuracy: 0.7547 - val_loss: 1.0176 - val_accuracy: 0.8581\n","Epoch 15/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.7242 - accuracy: 0.7692 - val_loss: 1.0165 - val_accuracy: 0.8618\n","Epoch 16/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.7295 - accuracy: 0.7713 - val_loss: 0.9810 - val_accuracy: 0.8701\n","Epoch 17/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6989 - accuracy: 0.7810 - val_loss: 1.0080 - val_accuracy: 0.8708\n","Epoch 18/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.7857 - val_loss: 0.9886 - val_accuracy: 0.8742\n","Epoch 19/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6671 - accuracy: 0.7932 - val_loss: 0.9623 - val_accuracy: 0.8773\n","Epoch 20/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6558 - accuracy: 0.7959 - val_loss: 0.9860 - val_accuracy: 0.8790\n","Epoch 21/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6316 - accuracy: 0.8042 - val_loss: 0.9387 - val_accuracy: 0.8824\n","Epoch 22/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6300 - accuracy: 0.8069 - val_loss: 0.9402 - val_accuracy: 0.8841\n","Epoch 23/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6173 - accuracy: 0.8104 - val_loss: 0.9308 - val_accuracy: 0.8869\n","Epoch 24/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.6088 - accuracy: 0.8149 - val_loss: 0.9201 - val_accuracy: 0.8885\n","Epoch 25/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5956 - accuracy: 0.8184 - val_loss: 0.9359 - val_accuracy: 0.8896\n","Epoch 26/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5922 - accuracy: 0.8202 - val_loss: 0.9140 - val_accuracy: 0.8921\n","Epoch 27/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5713 - accuracy: 0.8280 - val_loss: 0.9284 - val_accuracy: 0.8936\n","Epoch 28/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5676 - accuracy: 0.8295 - val_loss: 0.8989 - val_accuracy: 0.8957\n","Epoch 29/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5508 - accuracy: 0.8350 - val_loss: 0.8875 - val_accuracy: 0.8967\n","Epoch 30/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5604 - accuracy: 0.8322 - val_loss: 0.8960 - val_accuracy: 0.8980\n","Epoch 31/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5465 - accuracy: 0.8361 - val_loss: 0.8860 - val_accuracy: 0.8978\n","Epoch 32/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5368 - accuracy: 0.8391 - val_loss: 0.8797 - val_accuracy: 0.8998\n","Epoch 33/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5240 - accuracy: 0.8461 - val_loss: 0.8801 - val_accuracy: 0.8999\n","Epoch 34/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5348 - accuracy: 0.8433 - val_loss: 0.8576 - val_accuracy: 0.9036\n","Epoch 35/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5141 - accuracy: 0.8484 - val_loss: 0.8765 - val_accuracy: 0.9025\n","Epoch 36/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5207 - accuracy: 0.8478 - val_loss: 0.8576 - val_accuracy: 0.9055\n","Epoch 37/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5163 - accuracy: 0.8469 - val_loss: 0.8489 - val_accuracy: 0.9052\n","Epoch 38/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.5017 - accuracy: 0.8517 - val_loss: 0.8427 - val_accuracy: 0.9056\n","Epoch 39/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5020 - accuracy: 0.8530 - val_loss: 0.8358 - val_accuracy: 0.9080\n","Epoch 40/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4882 - accuracy: 0.8581 - val_loss: 0.8290 - val_accuracy: 0.9085\n","Epoch 41/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4827 - accuracy: 0.8598 - val_loss: 0.8260 - val_accuracy: 0.9093\n","Epoch 42/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4778 - accuracy: 0.8582 - val_loss: 0.8360 - val_accuracy: 0.9086\n","Epoch 43/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4723 - accuracy: 0.8598 - val_loss: 0.8233 - val_accuracy: 0.9121\n","Epoch 44/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4702 - accuracy: 0.8654 - val_loss: 0.8242 - val_accuracy: 0.9112\n","Epoch 45/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4753 - accuracy: 0.8628 - val_loss: 0.7987 - val_accuracy: 0.9129\n","Epoch 46/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4658 - accuracy: 0.8638 - val_loss: 0.8128 - val_accuracy: 0.9125\n","Epoch 47/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4684 - accuracy: 0.8627 - val_loss: 0.7972 - val_accuracy: 0.9136\n","Epoch 48/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4681 - accuracy: 0.8668 - val_loss: 0.7879 - val_accuracy: 0.9155\n","Epoch 49/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4465 - accuracy: 0.8715 - val_loss: 0.7889 - val_accuracy: 0.9154\n","Epoch 50/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4483 - accuracy: 0.8701 - val_loss: 0.8100 - val_accuracy: 0.9147\n","\n","Training with -->gelu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 3s 6ms/step - loss: 2.2895 - accuracy: 0.1663 - val_loss: 2.2302 - val_accuracy: 0.5488\n","Epoch 2/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.1955 - accuracy: 0.4060 - val_loss: 1.8675 - val_accuracy: 0.6458\n","Epoch 3/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.6962 - accuracy: 0.5108 - val_loss: 0.8764 - val_accuracy: 0.7742\n","Epoch 4/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.0970 - accuracy: 0.6500 - val_loss: 0.5972 - val_accuracy: 0.8476\n","Epoch 5/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.8501 - accuracy: 0.7350 - val_loss: 0.4747 - val_accuracy: 0.8736\n","Epoch 6/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7173 - accuracy: 0.7844 - val_loss: 0.4095 - val_accuracy: 0.8888\n","Epoch 7/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6486 - accuracy: 0.8089 - val_loss: 0.3701 - val_accuracy: 0.8963\n","Epoch 8/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5729 - accuracy: 0.8292 - val_loss: 0.3450 - val_accuracy: 0.9019\n","Epoch 9/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5367 - accuracy: 0.8426 - val_loss: 0.3254 - val_accuracy: 0.9058\n","Epoch 10/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5088 - accuracy: 0.8535 - val_loss: 0.3065 - val_accuracy: 0.9115\n","Epoch 11/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4749 - accuracy: 0.8632 - val_loss: 0.2922 - val_accuracy: 0.9135\n","Epoch 12/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4521 - accuracy: 0.8701 - val_loss: 0.2758 - val_accuracy: 0.9193\n","Epoch 13/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4357 - accuracy: 0.8774 - val_loss: 0.2671 - val_accuracy: 0.9203\n","Epoch 14/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4138 - accuracy: 0.8828 - val_loss: 0.2546 - val_accuracy: 0.9242\n","Epoch 15/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3925 - accuracy: 0.8885 - val_loss: 0.2462 - val_accuracy: 0.9259\n","Epoch 16/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3877 - accuracy: 0.8887 - val_loss: 0.2379 - val_accuracy: 0.9295\n","Epoch 17/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3780 - accuracy: 0.8932 - val_loss: 0.2302 - val_accuracy: 0.9312\n","Epoch 18/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3574 - accuracy: 0.9015 - val_loss: 0.2218 - val_accuracy: 0.9340\n","Epoch 19/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3554 - accuracy: 0.8990 - val_loss: 0.2156 - val_accuracy: 0.9349\n","Epoch 20/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3398 - accuracy: 0.9048 - val_loss: 0.2087 - val_accuracy: 0.9371\n","Epoch 21/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3155 - accuracy: 0.9102 - val_loss: 0.2026 - val_accuracy: 0.9394\n","Epoch 22/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3174 - accuracy: 0.9106 - val_loss: 0.1970 - val_accuracy: 0.9403\n","Epoch 23/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3058 - accuracy: 0.9127 - val_loss: 0.1917 - val_accuracy: 0.9416\n","Epoch 24/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2975 - accuracy: 0.9160 - val_loss: 0.1867 - val_accuracy: 0.9438\n","Epoch 25/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2788 - accuracy: 0.9201 - val_loss: 0.1817 - val_accuracy: 0.9460\n","Epoch 26/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2775 - accuracy: 0.9214 - val_loss: 0.1771 - val_accuracy: 0.9472\n","Epoch 27/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2681 - accuracy: 0.9248 - val_loss: 0.1725 - val_accuracy: 0.9487\n","Epoch 28/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2700 - accuracy: 0.9234 - val_loss: 0.1693 - val_accuracy: 0.9498\n","Epoch 29/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.2589 - accuracy: 0.9269 - val_loss: 0.1660 - val_accuracy: 0.9506\n","Epoch 30/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.2547 - accuracy: 0.9278 - val_loss: 0.1631 - val_accuracy: 0.9507\n","Epoch 31/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2486 - accuracy: 0.9307 - val_loss: 0.1593 - val_accuracy: 0.9517\n","Epoch 32/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2448 - accuracy: 0.9331 - val_loss: 0.1560 - val_accuracy: 0.9528\n","Epoch 33/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.2345 - accuracy: 0.9342 - val_loss: 0.1529 - val_accuracy: 0.9540\n","Epoch 34/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2371 - accuracy: 0.9331 - val_loss: 0.1505 - val_accuracy: 0.9542\n","Epoch 35/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2280 - accuracy: 0.9371 - val_loss: 0.1484 - val_accuracy: 0.9548\n","Epoch 36/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2215 - accuracy: 0.9371 - val_loss: 0.1451 - val_accuracy: 0.9563\n","Epoch 37/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2189 - accuracy: 0.9398 - val_loss: 0.1427 - val_accuracy: 0.9558\n","Epoch 38/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2152 - accuracy: 0.9388 - val_loss: 0.1405 - val_accuracy: 0.9571\n","Epoch 39/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2106 - accuracy: 0.9399 - val_loss: 0.1387 - val_accuracy: 0.9577\n","Epoch 40/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2012 - accuracy: 0.9437 - val_loss: 0.1360 - val_accuracy: 0.9586\n","Epoch 41/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.2065 - accuracy: 0.9422 - val_loss: 0.1344 - val_accuracy: 0.9581\n","Epoch 42/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.1966 - accuracy: 0.9443 - val_loss: 0.1322 - val_accuracy: 0.9586\n","Epoch 43/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.1997 - accuracy: 0.9448 - val_loss: 0.1316 - val_accuracy: 0.9595\n","Epoch 44/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.1928 - accuracy: 0.9466 - val_loss: 0.1301 - val_accuracy: 0.9594\n","Epoch 45/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.1914 - accuracy: 0.9454 - val_loss: 0.1277 - val_accuracy: 0.9609\n","Epoch 46/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.1834 - accuracy: 0.9490 - val_loss: 0.1259 - val_accuracy: 0.9615\n","Epoch 47/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.1830 - accuracy: 0.9491 - val_loss: 0.1239 - val_accuracy: 0.9634\n","Epoch 48/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.1855 - accuracy: 0.9483 - val_loss: 0.1234 - val_accuracy: 0.9627\n","Epoch 49/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.1763 - accuracy: 0.9502 - val_loss: 0.1215 - val_accuracy: 0.9631\n","Epoch 50/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.1790 - accuracy: 0.9491 - val_loss: 0.1206 - val_accuracy: 0.9629\n","\n","Training with -->swish<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 3s 5ms/step - loss: 2.2800 - accuracy: 0.1771 - val_loss: 2.1963 - val_accuracy: 0.5605\n","Epoch 2/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.1395 - accuracy: 0.4139 - val_loss: 1.7772 - val_accuracy: 0.5905\n","Epoch 3/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.6664 - accuracy: 0.5046 - val_loss: 1.0467 - val_accuracy: 0.7202\n","Epoch 4/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.1816 - accuracy: 0.6184 - val_loss: 0.7300 - val_accuracy: 0.8156\n","Epoch 5/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.9230 - accuracy: 0.7072 - val_loss: 0.5769 - val_accuracy: 0.8524\n","Epoch 6/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7814 - accuracy: 0.7603 - val_loss: 0.4901 - val_accuracy: 0.8740\n","Epoch 7/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6915 - accuracy: 0.7922 - val_loss: 0.4379 - val_accuracy: 0.8871\n","Epoch 8/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6332 - accuracy: 0.8137 - val_loss: 0.3990 - val_accuracy: 0.8933\n","Epoch 9/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5760 - accuracy: 0.8336 - val_loss: 0.3720 - val_accuracy: 0.8982\n","Epoch 10/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5506 - accuracy: 0.8412 - val_loss: 0.3518 - val_accuracy: 0.9035\n","Epoch 11/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5091 - accuracy: 0.8538 - val_loss: 0.3350 - val_accuracy: 0.9060\n","Epoch 12/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4851 - accuracy: 0.8610 - val_loss: 0.3219 - val_accuracy: 0.9095\n","Epoch 13/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4626 - accuracy: 0.8671 - val_loss: 0.3115 - val_accuracy: 0.9118\n","Epoch 14/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4591 - accuracy: 0.8689 - val_loss: 0.3003 - val_accuracy: 0.9137\n","Epoch 15/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4374 - accuracy: 0.8753 - val_loss: 0.2916 - val_accuracy: 0.9158\n","Epoch 16/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4306 - accuracy: 0.8762 - val_loss: 0.2835 - val_accuracy: 0.9175\n","Epoch 17/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3931 - accuracy: 0.8886 - val_loss: 0.2744 - val_accuracy: 0.9199\n","Epoch 18/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.4065 - accuracy: 0.8826 - val_loss: 0.2669 - val_accuracy: 0.9210\n","Epoch 19/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3940 - accuracy: 0.8891 - val_loss: 0.2621 - val_accuracy: 0.9233\n","Epoch 20/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3847 - accuracy: 0.8906 - val_loss: 0.2552 - val_accuracy: 0.9249\n","Epoch 21/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3727 - accuracy: 0.8950 - val_loss: 0.2500 - val_accuracy: 0.9249\n","Epoch 22/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3680 - accuracy: 0.8988 - val_loss: 0.2441 - val_accuracy: 0.9270\n","Epoch 23/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3561 - accuracy: 0.8992 - val_loss: 0.2396 - val_accuracy: 0.9287\n","Epoch 24/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3497 - accuracy: 0.8997 - val_loss: 0.2341 - val_accuracy: 0.9307\n","Epoch 25/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.9032 - val_loss: 0.2291 - val_accuracy: 0.9318\n","Epoch 26/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3314 - accuracy: 0.9064 - val_loss: 0.2243 - val_accuracy: 0.9345\n","Epoch 27/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.9082 - val_loss: 0.2203 - val_accuracy: 0.9350\n","Epoch 28/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3139 - accuracy: 0.9093 - val_loss: 0.2151 - val_accuracy: 0.9364\n","Epoch 29/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3120 - accuracy: 0.9122 - val_loss: 0.2119 - val_accuracy: 0.9376\n","Epoch 30/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.3131 - accuracy: 0.9106 - val_loss: 0.2096 - val_accuracy: 0.9381\n","Epoch 31/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3082 - accuracy: 0.9119 - val_loss: 0.2049 - val_accuracy: 0.9395\n","Epoch 32/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.9151 - val_loss: 0.2016 - val_accuracy: 0.9398\n","Epoch 33/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2887 - accuracy: 0.9185 - val_loss: 0.1980 - val_accuracy: 0.9408\n","Epoch 34/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2854 - accuracy: 0.9190 - val_loss: 0.1938 - val_accuracy: 0.9427\n","Epoch 35/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2810 - accuracy: 0.9193 - val_loss: 0.1920 - val_accuracy: 0.9427\n","Epoch 36/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2734 - accuracy: 0.9206 - val_loss: 0.1887 - val_accuracy: 0.9442\n","Epoch 37/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2758 - accuracy: 0.9216 - val_loss: 0.1865 - val_accuracy: 0.9448\n","Epoch 38/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2651 - accuracy: 0.9254 - val_loss: 0.1829 - val_accuracy: 0.9458\n","Epoch 39/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2642 - accuracy: 0.9247 - val_loss: 0.1799 - val_accuracy: 0.9466\n","Epoch 40/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.9252 - val_loss: 0.1766 - val_accuracy: 0.9477\n","Epoch 41/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2596 - accuracy: 0.9255 - val_loss: 0.1745 - val_accuracy: 0.9486\n","Epoch 42/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2443 - accuracy: 0.9305 - val_loss: 0.1719 - val_accuracy: 0.9493\n","Epoch 43/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2578 - accuracy: 0.9282 - val_loss: 0.1699 - val_accuracy: 0.9492\n","Epoch 44/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2535 - accuracy: 0.9273 - val_loss: 0.1681 - val_accuracy: 0.9500\n","Epoch 45/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2436 - accuracy: 0.9294 - val_loss: 0.1652 - val_accuracy: 0.9513\n","Epoch 46/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2367 - accuracy: 0.9334 - val_loss: 0.1627 - val_accuracy: 0.9522\n","Epoch 47/50\n","375/375 [==============================] - 1s 4ms/step - loss: 0.2417 - accuracy: 0.9298 - val_loss: 0.1607 - val_accuracy: 0.9523\n","Epoch 48/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2305 - accuracy: 0.9329 - val_loss: 0.1585 - val_accuracy: 0.9530\n","Epoch 49/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2313 - accuracy: 0.9335 - val_loss: 0.1564 - val_accuracy: 0.9530\n","Epoch 50/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2274 - accuracy: 0.9341 - val_loss: 0.1549 - val_accuracy: 0.9539\n","{'loss': [2.476874589920044, 2.3974552154541016, 2.3646140098571777, 2.345811605453491, 2.3357629776000977, 2.3308358192443848, 2.3223485946655273, 2.318422555923462, 2.316812753677368, 2.3140969276428223, 2.3134686946868896, 2.3114140033721924, 2.3096163272857666, 2.3116681575775146, 2.3094711303710938, 2.3075692653656006, 2.307560920715332, 2.305997610092163, 2.30655837059021, 2.3067166805267334, 2.3056185245513916, 2.3048667907714844, 2.305443286895752, 2.304807186126709, 2.3052456378936768, 2.3053383827209473, 2.3040194511413574, 2.3040809631347656, 2.303575038909912, 2.30307674407959, 2.3036179542541504, 2.303379774093628, 2.3027405738830566, 2.3036205768585205, 2.303304433822632, 2.3030402660369873, 2.3031387329101562, 2.3030037879943848, 2.3021204471588135, 2.3028624057769775, 2.3028576374053955, 2.3021512031555176, 2.3032021522521973, 2.302335500717163, 2.3021841049194336, 2.3027713298797607, 2.302548885345459, 2.302316427230835, 2.3023831844329834, 2.3025734424591064], 'accuracy': [0.10168749839067459, 0.10043749958276749, 0.10212499648332596, 0.10362499952316284, 0.10266666859388351, 0.10037499666213989, 0.10533333569765091, 0.10243750363588333, 0.10247916728258133, 0.10606250166893005, 0.10229166597127914, 0.10450000315904617, 0.10722916573286057, 0.10245833545923233, 0.1041041687130928, 0.1054999977350235, 0.10637500137090683, 0.10625000298023224, 0.1067499965429306, 0.10479166358709335, 0.1068333312869072, 0.10599999874830246, 0.10522916913032532, 0.10656250268220901, 0.10743749886751175, 0.10637500137090683, 0.10902083665132523, 0.10849999636411667, 0.10831250250339508, 0.11079166829586029, 0.10735416412353516, 0.1080833300948143, 0.11020833253860474, 0.10881250351667404, 0.10779166966676712, 0.1093124970793724, 0.10981249809265137, 0.10891667008399963, 0.1120833307504654, 0.1107083335518837, 0.109354168176651, 0.11114583164453506, 0.10993749648332596, 0.11116666346788406, 0.11054166406393051, 0.11035417020320892, 0.10899999737739563, 0.10981249809265137, 0.11041666567325592, 0.11218749731779099], 'val_loss': [2.302493095397949, 2.3023762702941895, 2.302314043045044, 2.301999568939209, 2.301811456680298, 2.301826000213623, 2.301511526107788, 2.301553964614868, 2.3015975952148438, 2.301729440689087, 2.30163836479187, 2.3017289638519287, 2.3015592098236084, 2.3016738891601562, 2.3016533851623535, 2.301593542098999, 2.30155086517334, 2.3016867637634277, 2.30167555809021, 2.301630973815918, 2.301642656326294, 2.3016464710235596, 2.3016350269317627, 2.3016884326934814, 2.3016622066497803, 2.3017141819000244, 2.30173921585083, 2.3017184734344482, 2.3017172813415527, 2.3016715049743652, 2.3016610145568848, 2.3016586303710938, 2.3016271591186523, 2.3016843795776367, 2.3016958236694336, 2.3016929626464844, 2.301649808883667, 2.3016791343688965, 2.301704168319702, 2.3017168045043945, 2.3016750812530518, 2.3016903400421143, 2.3016841411590576, 2.3017079830169678, 2.3017101287841797, 2.3016674518585205, 2.301722288131714, 2.3016936779022217, 2.301693916320801, 2.3016886711120605], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n","{'loss': [1.285434365272522, 0.720841646194458, 0.5785356163978577, 0.5158482789993286, 0.4814072549343109, 0.4622582197189331, 0.43716248869895935, 0.4257569909095764, 0.41309496760368347, 0.4054833650588989, 0.3948099911212921, 0.3886902630329132, 0.383566677570343, 0.37501102685928345, 0.36951911449432373, 0.3680690824985504, 0.35879576206207275, 0.35237666964530945, 0.3506503999233246, 0.3485206663608551, 0.3398849666118622, 0.34051746129989624, 0.33702781796455383, 0.3291931748390198, 0.3284640312194824, 0.3212025761604309, 0.3174452483654022, 0.31501010060310364, 0.31244057416915894, 0.3064767122268677, 0.30673694610595703, 0.29899248480796814, 0.2971302270889282, 0.29657307267189026, 0.2905169129371643, 0.28982535004615784, 0.28756266832351685, 0.283006876707077, 0.28655293583869934, 0.2751079797744751, 0.2760426104068756, 0.27245405316352844, 0.2720026969909668, 0.26901888847351074, 0.2663906514644623, 0.2650933265686035, 0.26531437039375305, 0.2579573690891266, 0.25786247849464417, 0.25627362728118896], 'accuracy': [0.5922916531562805, 0.7885833382606506, 0.82791668176651, 0.8492500185966492, 0.8573750257492065, 0.8630416393280029, 0.8707083463668823, 0.8755416870117188, 0.8784999847412109, 0.8796250224113464, 0.8852499723434448, 0.8856250047683716, 0.887458324432373, 0.8897916674613953, 0.8914999961853027, 0.8917083144187927, 0.893875002861023, 0.8975208401679993, 0.8979583382606506, 0.8997708559036255, 0.9004791378974915, 0.9019791483879089, 0.9017083048820496, 0.9047708511352539, 0.9055833220481873, 0.906125009059906, 0.9096458554267883, 0.9087499976158142, 0.9102916717529297, 0.9123958349227905, 0.9118333458900452, 0.9135208129882812, 0.9139999747276306, 0.9127500057220459, 0.9156458377838135, 0.9152916669845581, 0.9169374704360962, 0.9180833101272583, 0.9174791574478149, 0.9197916388511658, 0.9202083349227905, 0.9214583039283752, 0.9214166402816772, 0.9226458072662354, 0.9229166507720947, 0.9229999780654907, 0.9233541488647461, 0.9243958592414856, 0.9253125190734863, 0.9252708554267883], 'val_loss': [0.5964251756668091, 0.4125708043575287, 0.3531404137611389, 0.3254968225955963, 0.308305025100708, 0.29293838143348694, 0.284760057926178, 0.27829185128211975, 0.2723405063152313, 0.2658357322216034, 0.2608785331249237, 0.25743773579597473, 0.25325945019721985, 0.25096890330314636, 0.24626532196998596, 0.2458925098180771, 0.24027307331562042, 0.23825101554393768, 0.23343996703624725, 0.2327369749546051, 0.23097597062587738, 0.22837874293327332, 0.22542354464530945, 0.22330954670906067, 0.2195558100938797, 0.22154493629932404, 0.21540109813213348, 0.21455179154872894, 0.21288610994815826, 0.20906925201416016, 0.20527999103069305, 0.20515230298042297, 0.2041606456041336, 0.20173749327659607, 0.1986733227968216, 0.19700740277767181, 0.19569529592990875, 0.19522789120674133, 0.19139732420444489, 0.1892855167388916, 0.18760326504707336, 0.18570446968078613, 0.1834893375635147, 0.18271958827972412, 0.18109138309955597, 0.1792527437210083, 0.17690333724021912, 0.17612041532993317, 0.1753271222114563, 0.17239785194396973], 'val_accuracy': [0.8539166450500488, 0.8897500038146973, 0.9000833630561829, 0.9048333168029785, 0.9098333120346069, 0.9142500162124634, 0.9161666631698608, 0.918666660785675, 0.9206666946411133, 0.921833336353302, 0.9229999780654907, 0.9229166507720947, 0.925166666507721, 0.9255833625793457, 0.9273333549499512, 0.9271666407585144, 0.9292500019073486, 0.9300833344459534, 0.9319166541099548, 0.9319999814033508, 0.9329166412353516, 0.9327499866485596, 0.9334166646003723, 0.9351666569709778, 0.9358333349227905, 0.9353333115577698, 0.937166690826416, 0.937333345413208, 0.9379166960716248, 0.9394166469573975, 0.940416693687439, 0.940833330154419, 0.9411666393280029, 0.9414166808128357, 0.9425833225250244, 0.9430833458900452, 0.9437500238418579, 0.9443333148956299, 0.9450833201408386, 0.9455833435058594, 0.9461666941642761, 0.9474166631698608, 0.9478333592414856, 0.9474166631698608, 0.9489166736602783, 0.9497500061988831, 0.950166642665863, 0.950166642665863, 0.9503333568572998, 0.9514999985694885]}\n","{'loss': [2.1582703590393066, 1.4922473430633545, 1.0106133222579956, 0.7882875204086304, 0.6671326756477356, 0.5882425904273987, 0.532464861869812, 0.4856257736682892, 0.44791918992996216, 0.41675540804862976, 0.39085209369659424, 0.36477839946746826, 0.34787920117378235, 0.3284296989440918, 0.31008073687553406, 0.3005429208278656, 0.28265589475631714, 0.2737579643726349, 0.2623862624168396, 0.25307947397232056, 0.24285666644573212, 0.23186007142066956, 0.22652284801006317, 0.21696016192436218, 0.2127898931503296, 0.20268955826759338, 0.19876427948474884, 0.19587339460849762, 0.1858707070350647, 0.1779937595129013, 0.17663024365901947, 0.17347940802574158, 0.168958842754364, 0.16413530707359314, 0.15919359028339386, 0.15348929166793823, 0.1513413041830063, 0.14717383682727814, 0.14610862731933594, 0.1393878310918808, 0.1379697620868683, 0.13280172646045685, 0.13373976945877075, 0.13002344965934753, 0.12441393733024597, 0.12206042557954788, 0.11825491487979889, 0.11877118796110153, 0.11279769241809845, 0.11127900332212448], 'accuracy': [0.23285417258739471, 0.500333309173584, 0.6696041822433472, 0.7521666884422302, 0.7961041927337646, 0.8251875042915344, 0.8440208435058594, 0.8608750104904175, 0.8738750219345093, 0.8834166526794434, 0.8908958435058594, 0.8991875052452087, 0.9047916531562805, 0.9096458554267883, 0.9154583215713501, 0.9179791808128357, 0.9236666560173035, 0.926562488079071, 0.929562509059906, 0.9331458210945129, 0.9349374771118164, 0.9380416870117188, 0.9393958449363708, 0.942229151725769, 0.9435208439826965, 0.9461874961853027, 0.9472708106040955, 0.9480000138282776, 0.950041651725769, 0.9512916803359985, 0.953125, 0.9543125033378601, 0.9553541541099548, 0.9560208320617676, 0.957895815372467, 0.9596041440963745, 0.9603750109672546, 0.9604583382606506, 0.9635833501815796, 0.9638124704360962, 0.9636458158493042, 0.9651666879653931, 0.9642916917800903, 0.9660416841506958, 0.9660416841506958, 0.9681249856948853, 0.9681875109672546, 0.9687291383743286, 0.9704166650772095, 0.9710624814033508], 'val_loss': [1.673101544380188, 0.7983237504959106, 0.5142984390258789, 0.4122740924358368, 0.3526636064052582, 0.3156888782978058, 0.28765252232551575, 0.26378366351127625, 0.24413049221038818, 0.22719325125217438, 0.213927760720253, 0.2024298906326294, 0.18880878388881683, 0.1801433265209198, 0.17082837224006653, 0.1637350618839264, 0.15659165382385254, 0.15084397792816162, 0.14707021415233612, 0.1433221697807312, 0.13812841475009918, 0.13435186445713043, 0.12955543398857117, 0.12763914465904236, 0.12382528930902481, 0.1216200664639473, 0.12175071984529495, 0.1165764257311821, 0.1149832233786583, 0.1136658638715744, 0.11058741062879562, 0.10926532000303268, 0.10683922469615936, 0.10653480887413025, 0.10477255284786224, 0.10507825762033463, 0.10354107618331909, 0.10027150809764862, 0.10196329653263092, 0.10003075003623962, 0.09863597899675369, 0.09810139983892441, 0.09702137112617493, 0.09591004252433777, 0.09614640474319458, 0.09479570388793945, 0.09261293709278107, 0.09268369525671005, 0.09248992800712585, 0.09295795857906342], 'val_accuracy': [0.6308333277702332, 0.8179166913032532, 0.8674166798591614, 0.8858333230018616, 0.8991666436195374, 0.9088333249092102, 0.9160833358764648, 0.9229999780654907, 0.9286666512489319, 0.9332500100135803, 0.9365833401679993, 0.940416693687439, 0.9436666369438171, 0.9458333253860474, 0.9475833177566528, 0.9511666893959045, 0.95333331823349, 0.9554166793823242, 0.956166684627533, 0.9578333497047424, 0.9598333239555359, 0.9605000019073486, 0.9607499837875366, 0.9619166851043701, 0.9634166955947876, 0.9639999866485596, 0.9635000228881836, 0.9650833606719971, 0.9659166932106018, 0.9666666388511658, 0.9672499895095825, 0.9681666493415833, 0.968583345413208, 0.968583345413208, 0.9695833325386047, 0.968583345413208, 0.9696666598320007, 0.9706666469573975, 0.9696666598320007, 0.9707499742507935, 0.9714166522026062, 0.971916675567627, 0.972083330154419, 0.9723333120346069, 0.971833348274231, 0.971833348274231, 0.9736666679382324, 0.9733333587646484, 0.9736666679382324, 0.9739166498184204]}\n","{'loss': [2.0008232593536377, 1.219891905784607, 0.8315091133117676, 0.6627309322357178, 0.5731377601623535, 0.5159885287284851, 0.4731631577014923, 0.4405457377433777, 0.40640929341316223, 0.3885442614555359, 0.3721424639225006, 0.3491995334625244, 0.33267268538475037, 0.3212476670742035, 0.3092023730278015, 0.29581332206726074, 0.2885448932647705, 0.2729763090610504, 0.2681088447570801, 0.25735387206077576, 0.251837819814682, 0.24312646687030792, 0.2342858612537384, 0.22748087346553802, 0.2215266078710556, 0.21601472795009613, 0.2126406729221344, 0.20392155647277832, 0.19786334037780762, 0.19974073767662048, 0.19187040627002716, 0.1880582720041275, 0.18020156025886536, 0.17955714464187622, 0.17515994608402252, 0.17355935275554657, 0.1708328276872635, 0.1671154946088791, 0.16023984551429749, 0.15999746322631836, 0.15701298415660858, 0.15595534443855286, 0.15076157450675964, 0.14908508956432343, 0.1440933346748352, 0.14501668512821198, 0.1393868774175644, 0.14121608436107635, 0.13710547983646393, 0.1350557506084442], 'accuracy': [0.3085833191871643, 0.5912083387374878, 0.7351041436195374, 0.7958958148956299, 0.8293750286102295, 0.8502500057220459, 0.8627499938011169, 0.8740000128746033, 0.8849375247955322, 0.8898958563804626, 0.8962708115577698, 0.9025416374206543, 0.9068541526794434, 0.9105625152587891, 0.913979172706604, 0.9172083139419556, 0.918958306312561, 0.9223333597183228, 0.9257291555404663, 0.9287083148956299, 0.9307500123977661, 0.9322083592414856, 0.9353958368301392, 0.937250018119812, 0.9384583234786987, 0.9401666522026062, 0.9411458373069763, 0.9417708516120911, 0.945395827293396, 0.9455833435058594, 0.9471458196640015, 0.9472500085830688, 0.9492916464805603, 0.9511874914169312, 0.9509791731834412, 0.9514166712760925, 0.9522500038146973, 0.9541875123977661, 0.9558749794960022, 0.9559583067893982, 0.9560208320617676, 0.9574999809265137, 0.9583333134651184, 0.9598958492279053, 0.9603750109672546, 0.9595208168029785, 0.9616666436195374, 0.9613749980926514, 0.9623333215713501, 0.9614791870117188], 'val_loss': [1.311913251876831, 0.6275342106819153, 0.43800854682922363, 0.36420145630836487, 0.3236803710460663, 0.29596152901649475, 0.2749072313308716, 0.2576694190502167, 0.2421702742576599, 0.23259739577770233, 0.21963131427764893, 0.2101825773715973, 0.20180471241474152, 0.19484664499759674, 0.18724699318408966, 0.18169911205768585, 0.17436674237251282, 0.16843082010746002, 0.16558662056922913, 0.1595313400030136, 0.15577396750450134, 0.1499224454164505, 0.14626426994800568, 0.14259423315525055, 0.1394324004650116, 0.13484786450862885, 0.13248541951179504, 0.12941953539848328, 0.1277870535850525, 0.12539555132389069, 0.12501002848148346, 0.12196990102529526, 0.11991426348686218, 0.11828447133302689, 0.11529602110385895, 0.11398053914308548, 0.11459562927484512, 0.11186285316944122, 0.11066022515296936, 0.10899477452039719, 0.10785678774118423, 0.10693929344415665, 0.10437903553247452, 0.10436666756868362, 0.102752685546875, 0.10168283432722092, 0.10111002624034882, 0.10001654922962189, 0.10026425123214722, 0.09954408556222916], 'val_accuracy': [0.6891666650772095, 0.8548333048820496, 0.887666642665863, 0.8992499709129333, 0.909583330154419, 0.9155833125114441, 0.9211666584014893, 0.9255833625793457, 0.9297500252723694, 0.9311666488647461, 0.9350833296775818, 0.937833309173584, 0.9399166703224182, 0.9414166808128357, 0.9431666731834412, 0.9455000162124634, 0.9482499957084656, 0.9495000243186951, 0.9509166479110718, 0.9518333077430725, 0.953083336353302, 0.9554166793823242, 0.9564999938011169, 0.9577500224113464, 0.9584166407585144, 0.9605000019073486, 0.9614999890327454, 0.9624166488647461, 0.9625833630561829, 0.9623333215713501, 0.9627500176429749, 0.9649999737739563, 0.965583324432373, 0.9649999737739563, 0.9669166803359985, 0.9663333296775818, 0.9660000205039978, 0.9671666622161865, 0.9680833220481873, 0.9680833220481873, 0.9692500233650208, 0.968916654586792, 0.9695833325386047, 0.9702500104904175, 0.9704166650772095, 0.9706666469573975, 0.9705833196640015, 0.9708333611488342, 0.9712499976158142, 0.9712499976158142]}\n","{'loss': [1.2816566228866577, 0.6844112873077393, 0.5672542452812195, 0.5151205658912659, 0.4818764626979828, 0.45728862285614014, 0.4375060498714447, 0.4229784309864044, 0.4111299514770508, 0.3959582448005676, 0.38830944895744324, 0.3767266869544983, 0.3747323751449585, 0.3615071475505829, 0.3565340042114258, 0.3494744598865509, 0.344077467918396, 0.33022966980934143, 0.33358603715896606, 0.32336100935935974, 0.318035364151001, 0.31377407908439636, 0.3104698956012726, 0.299885630607605, 0.30011460185050964, 0.29645106196403503, 0.29435139894485474, 0.2835984528064728, 0.2835279405117035, 0.27221253514289856, 0.2760937213897705, 0.27125272154808044, 0.26927611231803894, 0.2636895775794983, 0.2616024911403656, 0.2549935281276703, 0.25669124722480774, 0.2510387897491455, 0.24816229939460754, 0.245250403881073, 0.23846487700939178, 0.23615537583827972, 0.2356884628534317, 0.2336149364709854, 0.2347678244113922, 0.23219381272792816, 0.22874361276626587, 0.22424206137657166, 0.22194436192512512, 0.2168131172657013], 'accuracy': [0.6036875247955322, 0.7909166812896729, 0.8299791812896729, 0.8459166884422302, 0.8572499752044678, 0.8652916550636292, 0.871708333492279, 0.8757083415985107, 0.8802291750907898, 0.8840000033378601, 0.8859166502952576, 0.8901249766349792, 0.8905624747276306, 0.8937291502952576, 0.8960624933242798, 0.8991458415985107, 0.898312509059906, 0.9042916893959045, 0.9025416374206543, 0.9047083258628845, 0.9067500233650208, 0.9078750014305115, 0.9082499742507935, 0.9120000004768372, 0.9122499823570251, 0.9129583239555359, 0.9131875038146973, 0.9166666865348816, 0.9162708520889282, 0.9199583530426025, 0.9185208082199097, 0.9208750128746033, 0.921791672706604, 0.9219375252723694, 0.9233958125114441, 0.9246875047683716, 0.9246249794960022, 0.9272083044052124, 0.9274583458900452, 0.9273541569709778, 0.930020809173584, 0.9302083253860474, 0.9305624961853027, 0.9303958415985107, 0.929729163646698, 0.9312916398048401, 0.9325416684150696, 0.9336875081062317, 0.9339166879653931, 0.9349791407585144], 'val_loss': [0.5446320176124573, 0.38461771607398987, 0.3366885483264923, 0.31463828682899475, 0.298798143863678, 0.2864389419555664, 0.27537140250205994, 0.2680605947971344, 0.2603011131286621, 0.2525245249271393, 0.2483687400817871, 0.24333664774894714, 0.23833756148815155, 0.23269297182559967, 0.22855331003665924, 0.22504183650016785, 0.2201813906431198, 0.21637742221355438, 0.21301351487636566, 0.2094239741563797, 0.20695333182811737, 0.20213350653648376, 0.1989363133907318, 0.196022629737854, 0.19330602884292603, 0.19126124680042267, 0.18662475049495697, 0.18346896767616272, 0.1802172064781189, 0.18052315711975098, 0.1774510145187378, 0.1739056259393692, 0.17247503995895386, 0.17058558762073517, 0.16857017576694489, 0.16590212285518646, 0.16361241042613983, 0.1614859402179718, 0.16250494122505188, 0.15885503590106964, 0.15560992062091827, 0.15412110090255737, 0.1535477340221405, 0.1511170119047165, 0.14951077103614807, 0.14867505431175232, 0.14717181026935577, 0.1465751826763153, 0.14513425529003143, 0.14242631196975708], 'val_accuracy': [0.8679166436195374, 0.8929166793823242, 0.9014999866485596, 0.9077500104904175, 0.9113333225250244, 0.9150000214576721, 0.9192500114440918, 0.9205833077430725, 0.9239166378974915, 0.9265000224113464, 0.9264166951179504, 0.9281666874885559, 0.9295833110809326, 0.9315000176429749, 0.9336666464805603, 0.9330000281333923, 0.9358333349227905, 0.9368333220481873, 0.9380833506584167, 0.9387500286102295, 0.9394166469573975, 0.9416666626930237, 0.9430833458900452, 0.9434166550636292, 0.9449166655540466, 0.9455000162124634, 0.9463333487510681, 0.9474166631698608, 0.9484999775886536, 0.949916660785675, 0.9495000243186951, 0.9509999752044678, 0.9517499804496765, 0.9520000219345093, 0.9525833129882812, 0.953416645526886, 0.9541666507720947, 0.9552500247955322, 0.9544166922569275, 0.9557499885559082, 0.9556666612625122, 0.956166684627533, 0.9557499885559082, 0.9566666483879089, 0.9580000042915344, 0.9582499861717224, 0.9581666588783264, 0.9588333368301392, 0.9585000276565552, 0.9599166512489319]}\n","{'loss': [2.674792528152466, 2.2400872707366943, 1.8721120357513428, 1.5772531032562256, 1.3560117483139038, 1.1952331066131592, 1.0928914546966553, 1.0032236576080322, 0.9453338384628296, 0.8948992490768433, 0.8522238731384277, 0.8134371638298035, 0.7796791791915894, 0.7620134949684143, 0.7316514253616333, 0.7115926146507263, 0.6941918730735779, 0.6804491281509399, 0.6623820662498474, 0.647725522518158, 0.6369163393974304, 0.6262040734291077, 0.6158438324928284, 0.6022729873657227, 0.592118501663208, 0.5849096775054932, 0.5739754438400269, 0.5661706328392029, 0.5567649006843567, 0.5530346035957336, 0.5431233048439026, 0.5392129421234131, 0.5295961499214172, 0.5234589576721191, 0.515825092792511, 0.5095846056938171, 0.5072763562202454, 0.5000120997428894, 0.4931395947933197, 0.4900343120098114, 0.48379382491111755, 0.4815179407596588, 0.4758193790912628, 0.4722934067249298, 0.47362378239631653, 0.46597254276275635, 0.46650081872940063, 0.4598495662212372, 0.4550890326499939, 0.4474913775920868], 'accuracy': [0.11914583295583725, 0.19741666316986084, 0.3213541805744171, 0.42791667580604553, 0.512499988079071, 0.5803958177566528, 0.6195208430290222, 0.6588958501815796, 0.6859999895095825, 0.706208348274231, 0.7208958268165588, 0.7385625243186951, 0.7482083439826965, 0.757687509059906, 0.768916666507721, 0.7758958339691162, 0.7845625281333923, 0.7878958582878113, 0.7947291731834412, 0.8003958463668823, 0.8042500019073486, 0.8091041445732117, 0.8123541474342346, 0.8177291750907898, 0.8212708234786987, 0.8237916827201843, 0.8260208368301392, 0.8296874761581421, 0.8330625295639038, 0.8341458439826965, 0.8373749852180481, 0.8389166593551636, 0.8452291488647461, 0.8454375267028809, 0.8476458191871643, 0.8495625257492065, 0.8504375219345093, 0.8533124923706055, 0.8551041483879089, 0.8559166789054871, 0.8582083582878113, 0.8587916493415833, 0.8597708344459534, 0.862541675567627, 0.862500011920929, 0.8651666641235352, 0.863979160785675, 0.8663958311080933, 0.8685625195503235, 0.8705416917800903], 'val_loss': [1.6484888792037964, 1.2848857641220093, 1.1805392503738403, 1.149884581565857, 1.1379244327545166, 1.1399762630462646, 1.1002495288848877, 1.0961833000183105, 1.0972405672073364, 1.0832650661468506, 1.0507175922393799, 1.0484353303909302, 1.0609016418457031, 1.0176397562026978, 1.016476035118103, 0.9809544086456299, 1.0079951286315918, 0.9885578751564026, 0.9623108506202698, 0.9860073328018188, 0.938709557056427, 0.9402175545692444, 0.9307963252067566, 0.9201448559761047, 0.9358776807785034, 0.9140468835830688, 0.9284001588821411, 0.8989213705062866, 0.8874760866165161, 0.8960011601448059, 0.8860195875167847, 0.8797350525856018, 0.8801048994064331, 0.8576446771621704, 0.8764756917953491, 0.857633113861084, 0.848884105682373, 0.8426791429519653, 0.8358167409896851, 0.828972578048706, 0.8260128498077393, 0.8359717726707458, 0.8232741951942444, 0.8242218494415283, 0.798726499080658, 0.8128312826156616, 0.797230064868927, 0.7879021763801575, 0.7889398336410522, 0.8100091218948364], 'val_accuracy': [0.4087499976158142, 0.5401666760444641, 0.6484166383743286, 0.6939166784286499, 0.7302500009536743, 0.7548333406448364, 0.78125, 0.8040000200271606, 0.8177499771118164, 0.8290833234786987, 0.8402500152587891, 0.8471666574478149, 0.8509166836738586, 0.8580833077430725, 0.8618333339691162, 0.8700833320617676, 0.8707500100135803, 0.8741666674613953, 0.8772500157356262, 0.8790000081062317, 0.8824166655540466, 0.8840833306312561, 0.8869166374206543, 0.8884999752044678, 0.8895833492279053, 0.8920833468437195, 0.893583357334137, 0.8957499861717224, 0.8967499732971191, 0.8980000019073486, 0.8978333473205566, 0.8998333215713501, 0.8999166488647461, 0.9035833477973938, 0.9024999737739563, 0.9054999947547913, 0.9051666855812073, 0.9055833220481873, 0.9079999923706055, 0.9085000157356262, 0.909250020980835, 0.9085833430290222, 0.9120833277702332, 0.9111666679382324, 0.9129166603088379, 0.9125000238418579, 0.9135833382606506, 0.9154999852180481, 0.9154166579246521, 0.9147499799728394]}\n","{'loss': [2.272700786590576, 2.1343929767608643, 1.4986608028411865, 1.0197616815567017, 0.8103215098381042, 0.6933321356773376, 0.6225350499153137, 0.5678452253341675, 0.528526782989502, 0.5042911171913147, 0.4717198610305786, 0.44782552123069763, 0.4311671257019043, 0.4124302566051483, 0.3937006890773773, 0.37780070304870605, 0.3671186864376068, 0.3548969328403473, 0.3439883589744568, 0.3303649127483368, 0.3192550539970398, 0.31028860807418823, 0.30043816566467285, 0.29198041558265686, 0.2848437428474426, 0.2795877456665039, 0.2734018862247467, 0.26619577407836914, 0.25773030519485474, 0.25036996603012085, 0.24753282964229584, 0.24270695447921753, 0.23433633148670197, 0.23387084901332855, 0.2280692160129547, 0.22084090113639832, 0.21809455752372742, 0.2156016081571579, 0.20661866664886475, 0.20690181851387024, 0.20439347624778748, 0.19998674094676971, 0.19767989218235016, 0.19124102592468262, 0.18996316194534302, 0.18663397431373596, 0.18301615118980408, 0.17994628846645355, 0.1775004267692566, 0.17318136990070343], 'accuracy': [0.22939583659172058, 0.43797916173934937, 0.5476250052452087, 0.6754791736602783, 0.7489166855812073, 0.7912291884422302, 0.8163958191871643, 0.8334583044052124, 0.8474791646003723, 0.8567916750907898, 0.8642916679382324, 0.8721874952316284, 0.877958357334137, 0.8835625052452087, 0.8887708187103271, 0.8913958072662354, 0.8964375257492065, 0.9019374847412109, 0.9028958082199097, 0.9078750014305115, 0.9094374775886536, 0.9127708077430725, 0.9147083163261414, 0.9178958535194397, 0.9196249842643738, 0.9218541383743286, 0.9236458539962769, 0.9243749976158142, 0.926770806312561, 0.92989581823349, 0.9307083487510681, 0.9319375157356262, 0.934333324432373, 0.934291660785675, 0.9368541836738586, 0.937874972820282, 0.9388958215713501, 0.9392916560173035, 0.9408749938011169, 0.9425625205039978, 0.9417916536331177, 0.9443333148956299, 0.9441249966621399, 0.9465208053588867, 0.9462916851043701, 0.9479374885559082, 0.9494583606719971, 0.9487916827201843, 0.9493541717529297, 0.9504583477973938], 'val_loss': [2.2301695346832275, 1.8675493001937866, 0.8764368295669556, 0.5972354412078857, 0.47469115257263184, 0.40946128964424133, 0.3701101541519165, 0.34496745467185974, 0.32535994052886963, 0.30646395683288574, 0.2922459542751312, 0.27577635645866394, 0.2670563757419586, 0.2546478807926178, 0.24618051946163177, 0.2378995567560196, 0.23018744587898254, 0.22181686758995056, 0.21558040380477905, 0.20867112278938293, 0.2026299238204956, 0.1969781070947647, 0.1916923075914383, 0.18667295575141907, 0.181742325425148, 0.1770745813846588, 0.17250056564807892, 0.16925543546676636, 0.16597874462604523, 0.1630975604057312, 0.15925711393356323, 0.1560126096010208, 0.15292270481586456, 0.1505172997713089, 0.14835412800312042, 0.14509645104408264, 0.142702117562294, 0.14045271277427673, 0.13868102431297302, 0.13600952923297882, 0.134441077709198, 0.13219769299030304, 0.13160476088523865, 0.13005609810352325, 0.1276918649673462, 0.12591774761676788, 0.12393417209386826, 0.12338758260011673, 0.12146864086389542, 0.12058453261852264], 'val_accuracy': [0.5488333106040955, 0.6458333134651184, 0.7742499709129333, 0.8475833535194397, 0.8735833168029785, 0.8888333439826965, 0.8963333368301392, 0.9019166827201843, 0.9058333039283752, 0.9114999771118164, 0.9135000109672546, 0.9192500114440918, 0.9203333258628845, 0.9241666793823242, 0.9259166717529297, 0.9294999837875366, 0.9312499761581421, 0.9340000152587891, 0.9349166750907898, 0.9370833039283752, 0.9394166469573975, 0.9403333067893982, 0.9415833353996277, 0.9438333511352539, 0.9459999799728394, 0.9471666812896729, 0.9486666917800903, 0.9497500061988831, 0.9505833387374878, 0.9506666660308838, 0.9517499804496765, 0.952750027179718, 0.9539999961853027, 0.9541666507720947, 0.9547500014305115, 0.956250011920929, 0.9558333158493042, 0.9570833444595337, 0.9576666951179504, 0.9585833549499512, 0.9580833315849304, 0.9585833549499512, 0.9595000147819519, 0.9594166874885559, 0.9609166383743286, 0.9614999890327454, 0.9634166955947876, 0.9626666903495789, 0.9630833268165588, 0.9629166722297668]}\n","{'loss': [2.256739854812622, 2.0545456409454346, 1.521504282951355, 1.1086753606796265, 0.8864378929138184, 0.7564900517463684, 0.6732800006866455, 0.6134908199310303, 0.5689389109611511, 0.5361316204071045, 0.5076756477355957, 0.48433855175971985, 0.46430569887161255, 0.45278966426849365, 0.43344101309776306, 0.42494505643844604, 0.4044499397277832, 0.3998088836669922, 0.39010775089263916, 0.37813660502433777, 0.3705524802207947, 0.3616381883621216, 0.3568669855594635, 0.3454018235206604, 0.3380091190338135, 0.33061182498931885, 0.32403796911239624, 0.3168441653251648, 0.31411755084991455, 0.3076680898666382, 0.30379560589790344, 0.29427483677864075, 0.29127004742622375, 0.28606894612312317, 0.28362739086151123, 0.27566224336624146, 0.2743411958217621, 0.2652050852775574, 0.26503896713256836, 0.2625764012336731, 0.2586376667022705, 0.2513219118118286, 0.24840034544467926, 0.24586905539035797, 0.24041105806827545, 0.23715631663799286, 0.2366233766078949, 0.23131003975868225, 0.22643369436264038, 0.22511409223079681], 'accuracy': [0.2549583315849304, 0.43443751335144043, 0.5309791564941406, 0.6445208191871643, 0.7223749756813049, 0.770354151725769, 0.7992916703224182, 0.8192916512489319, 0.8344166874885559, 0.8454791903495789, 0.8546666502952576, 0.8619583249092102, 0.8680416941642761, 0.8709166646003723, 0.8765208125114441, 0.8786249756813049, 0.8848541378974915, 0.8857083320617676, 0.890583336353302, 0.8924583196640015, 0.895145833492279, 0.898812472820282, 0.8996666669845581, 0.9005833268165588, 0.9038541913032532, 0.906374990940094, 0.9080625176429749, 0.9098333120346069, 0.9111875295639038, 0.9114999771118164, 0.9131041765213013, 0.9167708158493042, 0.9182291626930237, 0.9182083606719971, 0.9190624952316284, 0.9201250076293945, 0.9216458201408386, 0.9240833520889282, 0.9238541722297668, 0.9256250262260437, 0.9260416626930237, 0.9287916421890259, 0.929395854473114, 0.930020809173584, 0.9316458106040955, 0.9319375157356262, 0.9313750267028809, 0.9334166646003723, 0.9356874823570251, 0.9350416660308838], 'val_loss': [2.1962926387786865, 1.7772407531738281, 1.0466949939727783, 0.7299729585647583, 0.5769119262695312, 0.4901241064071655, 0.43791720271110535, 0.3989945948123932, 0.372020959854126, 0.35176417231559753, 0.3349759876728058, 0.3218669891357422, 0.3114681839942932, 0.30028945207595825, 0.29163888096809387, 0.28348398208618164, 0.27435553073883057, 0.26693734526634216, 0.2621331512928009, 0.25517788529396057, 0.25002673268318176, 0.2441389113664627, 0.23962263762950897, 0.2341042011976242, 0.22910861670970917, 0.22425276041030884, 0.22025388479232788, 0.215089350938797, 0.2118520885705948, 0.2096143364906311, 0.20486056804656982, 0.2016381174325943, 0.19802182912826538, 0.1937820017337799, 0.19201892614364624, 0.18868951499462128, 0.18654051423072815, 0.18290430307388306, 0.1798655241727829, 0.17663592100143433, 0.17454245686531067, 0.1719110757112503, 0.16990146040916443, 0.16814036667346954, 0.16520501673221588, 0.16272003948688507, 0.16066525876522064, 0.1585090458393097, 0.1564478874206543, 0.15489500761032104], 'val_accuracy': [0.5605000257492065, 0.590499997138977, 0.7201666831970215, 0.815583348274231, 0.8524166941642761, 0.8740000128746033, 0.8870833516120911, 0.8933333158493042, 0.8982499837875366, 0.9035000205039978, 0.906000018119812, 0.909500002861023, 0.9118333458900452, 0.9137499928474426, 0.9158333539962769, 0.9175000190734863, 0.9199166893959045, 0.9210000038146973, 0.9232500195503235, 0.924916684627533, 0.924916684627533, 0.9269999861717224, 0.9287499785423279, 0.9306666851043701, 0.9318333268165588, 0.934499979019165, 0.9350000023841858, 0.9364166855812073, 0.937583327293396, 0.9380833506584167, 0.9394999742507935, 0.9398333430290222, 0.940750002861023, 0.9426666498184204, 0.9427499771118164, 0.9441666603088379, 0.9448333382606506, 0.9458333253860474, 0.9465833306312561, 0.9477499723434448, 0.9485833048820496, 0.9493333101272583, 0.9492499828338623, 0.949999988079071, 0.9512500166893005, 0.9521666765213013, 0.9522500038146973, 0.953000009059906, 0.953000009059906, 0.9539166688919067]}\n"],"name":"stdout"}]}]}