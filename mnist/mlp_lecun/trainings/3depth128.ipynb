{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 655585,
     "status": "ok",
     "timestamp": 1627300081416,
     "user": {
      "displayName": "TRUNG Nguyễn Thành",
      "photoUrl": "",
      "userId": "02848241069421510082"
     },
     "user_tz": -420
    },
    "id": "JnHhSjZec4W6",
    "outputId": "9d333184-643b-40c8-b0f2-3634413b37c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 16s 5ms/step - loss: 2.5402 - accuracy: 0.1008 - val_loss: 2.3000 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.4102 - accuracy: 0.1046 - val_loss: 2.2986 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3694 - accuracy: 0.1071 - val_loss: 2.2972 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3499 - accuracy: 0.1075 - val_loss: 2.2961 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3360 - accuracy: 0.1035 - val_loss: 2.2954 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3276 - accuracy: 0.1071 - val_loss: 2.2949 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3219 - accuracy: 0.1068 - val_loss: 2.2946 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3174 - accuracy: 0.1081 - val_loss: 2.2942 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3135 - accuracy: 0.1098 - val_loss: 2.2939 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3099 - accuracy: 0.1112 - val_loss: 2.2935 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3073 - accuracy: 0.1076 - val_loss: 2.2933 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3065 - accuracy: 0.1134 - val_loss: 2.2929 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3025 - accuracy: 0.1134 - val_loss: 2.2926 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3040 - accuracy: 0.1111 - val_loss: 2.2923 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3020 - accuracy: 0.1148 - val_loss: 2.2920 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3009 - accuracy: 0.1186 - val_loss: 2.2915 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2991 - accuracy: 0.1188 - val_loss: 2.2910 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2988 - accuracy: 0.1192 - val_loss: 2.2905 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2975 - accuracy: 0.1232 - val_loss: 2.2900 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2986 - accuracy: 0.1197 - val_loss: 2.2895 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2972 - accuracy: 0.1207 - val_loss: 2.2887 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2951 - accuracy: 0.1234 - val_loss: 2.2880 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2943 - accuracy: 0.1243 - val_loss: 2.2874 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2947 - accuracy: 0.1214 - val_loss: 2.2862 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2945 - accuracy: 0.1263 - val_loss: 2.2852 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2934 - accuracy: 0.1276 - val_loss: 2.2840 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2913 - accuracy: 0.1314 - val_loss: 2.2827 - val_accuracy: 0.1063\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2890 - accuracy: 0.1377 - val_loss: 2.2812 - val_accuracy: 0.1072\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2873 - accuracy: 0.1395 - val_loss: 2.2796 - val_accuracy: 0.1061\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2851 - accuracy: 0.1414 - val_loss: 2.2773 - val_accuracy: 0.1211\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2860 - accuracy: 0.1375 - val_loss: 2.2750 - val_accuracy: 0.1254\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2840 - accuracy: 0.1414 - val_loss: 2.2719 - val_accuracy: 0.1565\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2819 - accuracy: 0.1423 - val_loss: 2.2684 - val_accuracy: 0.1775\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2762 - accuracy: 0.1523 - val_loss: 2.2640 - val_accuracy: 0.2220\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2751 - accuracy: 0.1485 - val_loss: 2.2589 - val_accuracy: 0.1936\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2688 - accuracy: 0.1557 - val_loss: 2.2521 - val_accuracy: 0.2178\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2650 - accuracy: 0.1649 - val_loss: 2.2441 - val_accuracy: 0.2130\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2579 - accuracy: 0.1668 - val_loss: 2.2333 - val_accuracy: 0.2530\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2502 - accuracy: 0.1745 - val_loss: 2.2196 - val_accuracy: 0.2654\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2409 - accuracy: 0.1801 - val_loss: 2.2020 - val_accuracy: 0.2858\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2266 - accuracy: 0.1900 - val_loss: 2.1785 - val_accuracy: 0.3164\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2047 - accuracy: 0.1998 - val_loss: 2.1470 - val_accuracy: 0.3504\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1773 - accuracy: 0.2182 - val_loss: 2.1065 - val_accuracy: 0.3536\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1450 - accuracy: 0.2309 - val_loss: 2.0562 - val_accuracy: 0.4006\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1062 - accuracy: 0.2469 - val_loss: 1.9986 - val_accuracy: 0.4268\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0556 - accuracy: 0.2639 - val_loss: 1.9361 - val_accuracy: 0.4482\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0017 - accuracy: 0.2832 - val_loss: 1.8692 - val_accuracy: 0.4373\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9524 - accuracy: 0.2998 - val_loss: 1.8033 - val_accuracy: 0.4642\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8932 - accuracy: 0.3188 - val_loss: 1.7352 - val_accuracy: 0.5261\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8409 - accuracy: 0.3347 - val_loss: 1.6663 - val_accuracy: 0.5391\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5148 - accuracy: 0.5153 - val_loss: 0.5101 - val_accuracy: 0.8742\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6246 - accuracy: 0.8203 - val_loss: 0.3881 - val_accuracy: 0.8917\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.8488 - val_loss: 0.3449 - val_accuracy: 0.9005\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8639 - val_loss: 0.3223 - val_accuracy: 0.9060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.8738 - val_loss: 0.3080 - val_accuracy: 0.9097\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4114 - accuracy: 0.8771 - val_loss: 0.2968 - val_accuracy: 0.9133\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3894 - accuracy: 0.8843 - val_loss: 0.2887 - val_accuracy: 0.9155\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8865 - val_loss: 0.2841 - val_accuracy: 0.9181\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8890 - val_loss: 0.2773 - val_accuracy: 0.9192\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3713 - accuracy: 0.8904 - val_loss: 0.2728 - val_accuracy: 0.9217\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3601 - accuracy: 0.8946 - val_loss: 0.2677 - val_accuracy: 0.9226\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3556 - accuracy: 0.8947 - val_loss: 0.2645 - val_accuracy: 0.9232\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3464 - accuracy: 0.8962 - val_loss: 0.2606 - val_accuracy: 0.9238\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8995 - val_loss: 0.2574 - val_accuracy: 0.9256\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3455 - accuracy: 0.8969 - val_loss: 0.2542 - val_accuracy: 0.9260\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3332 - accuracy: 0.9022 - val_loss: 0.2516 - val_accuracy: 0.9273\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.9052 - val_loss: 0.2490 - val_accuracy: 0.9276\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3160 - accuracy: 0.9077 - val_loss: 0.2469 - val_accuracy: 0.9288\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3168 - accuracy: 0.9071 - val_loss: 0.2452 - val_accuracy: 0.9277\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3181 - accuracy: 0.9061 - val_loss: 0.2430 - val_accuracy: 0.9293\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.9089 - val_loss: 0.2398 - val_accuracy: 0.9303\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.9093 - val_loss: 0.2369 - val_accuracy: 0.9313\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3119 - accuracy: 0.9083 - val_loss: 0.2372 - val_accuracy: 0.9312\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3039 - accuracy: 0.9102 - val_loss: 0.2359 - val_accuracy: 0.9317\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.9116 - val_loss: 0.2324 - val_accuracy: 0.9331\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2991 - accuracy: 0.9114 - val_loss: 0.2302 - val_accuracy: 0.9333\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3029 - accuracy: 0.9128 - val_loss: 0.2276 - val_accuracy: 0.9341\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2932 - accuracy: 0.9138 - val_loss: 0.2248 - val_accuracy: 0.9361\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2996 - accuracy: 0.9140 - val_loss: 0.2234 - val_accuracy: 0.9363\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2859 - accuracy: 0.9165 - val_loss: 0.2223 - val_accuracy: 0.9366\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.9130 - val_loss: 0.2205 - val_accuracy: 0.9369\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.9168 - val_loss: 0.2180 - val_accuracy: 0.9376\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.9199 - val_loss: 0.2172 - val_accuracy: 0.9374\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.9177 - val_loss: 0.2145 - val_accuracy: 0.9383\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2700 - accuracy: 0.9202 - val_loss: 0.2125 - val_accuracy: 0.9389\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.9184 - val_loss: 0.2116 - val_accuracy: 0.9388\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.9186 - val_loss: 0.2079 - val_accuracy: 0.9404\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.9217 - val_loss: 0.2065 - val_accuracy: 0.9399\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9194 - val_loss: 0.2045 - val_accuracy: 0.9415\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.9240 - val_loss: 0.2037 - val_accuracy: 0.9421\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2607 - accuracy: 0.9227 - val_loss: 0.2018 - val_accuracy: 0.9423\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2565 - accuracy: 0.9239 - val_loss: 0.1997 - val_accuracy: 0.9437\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2599 - accuracy: 0.9227 - val_loss: 0.1977 - val_accuracy: 0.9445\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2502 - accuracy: 0.9260 - val_loss: 0.1963 - val_accuracy: 0.9451\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2513 - accuracy: 0.9248 - val_loss: 0.1950 - val_accuracy: 0.9447\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2493 - accuracy: 0.9280 - val_loss: 0.1949 - val_accuracy: 0.9445\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2550 - accuracy: 0.9265 - val_loss: 0.1926 - val_accuracy: 0.9457\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2422 - accuracy: 0.9276 - val_loss: 0.1910 - val_accuracy: 0.9467\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2424 - accuracy: 0.9267 - val_loss: 0.1884 - val_accuracy: 0.9482\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.9271 - val_loss: 0.1873 - val_accuracy: 0.9477\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 4ms/step - loss: 2.1308 - accuracy: 0.2466 - val_loss: 1.0087 - val_accuracy: 0.8045\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1198 - accuracy: 0.6514 - val_loss: 0.5177 - val_accuracy: 0.8742\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7502 - accuracy: 0.7686 - val_loss: 0.3975 - val_accuracy: 0.8970\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5978 - accuracy: 0.8206 - val_loss: 0.3451 - val_accuracy: 0.9057\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.8413 - val_loss: 0.3103 - val_accuracy: 0.9119\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4792 - accuracy: 0.8585 - val_loss: 0.2864 - val_accuracy: 0.9167\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4372 - accuracy: 0.8718 - val_loss: 0.2690 - val_accuracy: 0.9211\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4053 - accuracy: 0.8828 - val_loss: 0.2516 - val_accuracy: 0.9250\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3842 - accuracy: 0.8903 - val_loss: 0.2378 - val_accuracy: 0.9305\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8981 - val_loss: 0.2272 - val_accuracy: 0.9322\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3430 - accuracy: 0.9020 - val_loss: 0.2148 - val_accuracy: 0.9375\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.9080 - val_loss: 0.2040 - val_accuracy: 0.9405\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3088 - accuracy: 0.9139 - val_loss: 0.1973 - val_accuracy: 0.9417\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2946 - accuracy: 0.9161 - val_loss: 0.1877 - val_accuracy: 0.9449\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2795 - accuracy: 0.9198 - val_loss: 0.1794 - val_accuracy: 0.9470\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.9200 - val_loss: 0.1734 - val_accuracy: 0.9489\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2627 - accuracy: 0.9256 - val_loss: 0.1667 - val_accuracy: 0.9513\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2489 - accuracy: 0.9281 - val_loss: 0.1613 - val_accuracy: 0.9532\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9333 - val_loss: 0.1549 - val_accuracy: 0.9552\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2321 - accuracy: 0.9345 - val_loss: 0.1497 - val_accuracy: 0.9571\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2275 - accuracy: 0.9351 - val_loss: 0.1473 - val_accuracy: 0.9569\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9391 - val_loss: 0.1415 - val_accuracy: 0.9593\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9409 - val_loss: 0.1387 - val_accuracy: 0.9593\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2027 - accuracy: 0.9415 - val_loss: 0.1349 - val_accuracy: 0.9606\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1992 - accuracy: 0.9447 - val_loss: 0.1314 - val_accuracy: 0.9613\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1905 - accuracy: 0.9447 - val_loss: 0.1295 - val_accuracy: 0.9613\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9475 - val_loss: 0.1271 - val_accuracy: 0.9614\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1795 - accuracy: 0.9494 - val_loss: 0.1229 - val_accuracy: 0.9628\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1740 - accuracy: 0.9511 - val_loss: 0.1220 - val_accuracy: 0.9628\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1722 - accuracy: 0.9501 - val_loss: 0.1193 - val_accuracy: 0.9638\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9541 - val_loss: 0.1171 - val_accuracy: 0.9637\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1637 - accuracy: 0.9526 - val_loss: 0.1145 - val_accuracy: 0.9654\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1566 - accuracy: 0.9547 - val_loss: 0.1128 - val_accuracy: 0.9661\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1566 - accuracy: 0.9545 - val_loss: 0.1111 - val_accuracy: 0.9666\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1478 - accuracy: 0.9590 - val_loss: 0.1098 - val_accuracy: 0.9672\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9578 - val_loss: 0.1076 - val_accuracy: 0.9678\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1448 - accuracy: 0.9595 - val_loss: 0.1071 - val_accuracy: 0.9682\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1440 - accuracy: 0.9600 - val_loss: 0.1056 - val_accuracy: 0.9682\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.9596 - val_loss: 0.1037 - val_accuracy: 0.9688\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1355 - accuracy: 0.9609 - val_loss: 0.1029 - val_accuracy: 0.9693\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1337 - accuracy: 0.9608 - val_loss: 0.1006 - val_accuracy: 0.9693\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1313 - accuracy: 0.9611 - val_loss: 0.1004 - val_accuracy: 0.9694\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9636 - val_loss: 0.0994 - val_accuracy: 0.9703\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9638 - val_loss: 0.0976 - val_accuracy: 0.9699\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1243 - accuracy: 0.9645 - val_loss: 0.0967 - val_accuracy: 0.9703\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1236 - accuracy: 0.9641 - val_loss: 0.0961 - val_accuracy: 0.9707\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1236 - accuracy: 0.9648 - val_loss: 0.0947 - val_accuracy: 0.9710\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9681 - val_loss: 0.0937 - val_accuracy: 0.9712\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9685 - val_loss: 0.0934 - val_accuracy: 0.9713\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.9704 - val_loss: 0.0920 - val_accuracy: 0.9713\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.0086 - accuracy: 0.3244 - val_loss: 0.8529 - val_accuracy: 0.8217\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9666 - accuracy: 0.7046 - val_loss: 0.4789 - val_accuracy: 0.8766\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6680 - accuracy: 0.7980 - val_loss: 0.3812 - val_accuracy: 0.8984\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5450 - accuracy: 0.8364 - val_loss: 0.3342 - val_accuracy: 0.9072\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.8572 - val_loss: 0.3052 - val_accuracy: 0.9147\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4410 - accuracy: 0.8730 - val_loss: 0.2847 - val_accuracy: 0.9193\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8803 - val_loss: 0.2697 - val_accuracy: 0.9218\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3836 - accuracy: 0.8882 - val_loss: 0.2555 - val_accuracy: 0.9262\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3710 - accuracy: 0.8914 - val_loss: 0.2439 - val_accuracy: 0.9289\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3481 - accuracy: 0.9000 - val_loss: 0.2339 - val_accuracy: 0.9312\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.9044 - val_loss: 0.2250 - val_accuracy: 0.9346\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3225 - accuracy: 0.9072 - val_loss: 0.2167 - val_accuracy: 0.9368\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3078 - accuracy: 0.9115 - val_loss: 0.2079 - val_accuracy: 0.9395\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2896 - accuracy: 0.9159 - val_loss: 0.2022 - val_accuracy: 0.9409\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2830 - accuracy: 0.9193 - val_loss: 0.1954 - val_accuracy: 0.9422\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9200 - val_loss: 0.1887 - val_accuracy: 0.9438\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2648 - accuracy: 0.9232 - val_loss: 0.1835 - val_accuracy: 0.9461\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2534 - accuracy: 0.9261 - val_loss: 0.1785 - val_accuracy: 0.9477\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2536 - accuracy: 0.9252 - val_loss: 0.1739 - val_accuracy: 0.9500\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2408 - accuracy: 0.9308 - val_loss: 0.1698 - val_accuracy: 0.9520\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2388 - accuracy: 0.9313 - val_loss: 0.1653 - val_accuracy: 0.9524\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2271 - accuracy: 0.9334 - val_loss: 0.1628 - val_accuracy: 0.9531\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2249 - accuracy: 0.9362 - val_loss: 0.1582 - val_accuracy: 0.9539\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9413 - val_loss: 0.1543 - val_accuracy: 0.9551\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2140 - accuracy: 0.9384 - val_loss: 0.1533 - val_accuracy: 0.9549\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9389 - val_loss: 0.1487 - val_accuracy: 0.9556\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2089 - accuracy: 0.9407 - val_loss: 0.1463 - val_accuracy: 0.9567\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1998 - accuracy: 0.9425 - val_loss: 0.1431 - val_accuracy: 0.9572\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1986 - accuracy: 0.9430 - val_loss: 0.1409 - val_accuracy: 0.9588\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1933 - accuracy: 0.9442 - val_loss: 0.1376 - val_accuracy: 0.9598\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1833 - accuracy: 0.9478 - val_loss: 0.1358 - val_accuracy: 0.9600\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1834 - accuracy: 0.9462 - val_loss: 0.1340 - val_accuracy: 0.9607\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1765 - accuracy: 0.9497 - val_loss: 0.1313 - val_accuracy: 0.9617\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1748 - accuracy: 0.9502 - val_loss: 0.1297 - val_accuracy: 0.9617\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1707 - accuracy: 0.9513 - val_loss: 0.1275 - val_accuracy: 0.9627\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1696 - accuracy: 0.9519 - val_loss: 0.1264 - val_accuracy: 0.9632\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9499 - val_loss: 0.1242 - val_accuracy: 0.9637\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1583 - accuracy: 0.9536 - val_loss: 0.1215 - val_accuracy: 0.9646\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1578 - accuracy: 0.9541 - val_loss: 0.1202 - val_accuracy: 0.9648\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1540 - accuracy: 0.9551 - val_loss: 0.1191 - val_accuracy: 0.9664\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9554 - val_loss: 0.1182 - val_accuracy: 0.9657\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9536 - val_loss: 0.1164 - val_accuracy: 0.9672\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1493 - accuracy: 0.9566 - val_loss: 0.1154 - val_accuracy: 0.9663\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1468 - accuracy: 0.9582 - val_loss: 0.1142 - val_accuracy: 0.9667\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1463 - accuracy: 0.9567 - val_loss: 0.1132 - val_accuracy: 0.9671\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1428 - accuracy: 0.9584 - val_loss: 0.1110 - val_accuracy: 0.9679\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1480 - accuracy: 0.9571 - val_loss: 0.1110 - val_accuracy: 0.9678\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1395 - accuracy: 0.9590 - val_loss: 0.1097 - val_accuracy: 0.9682\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1348 - accuracy: 0.9597 - val_loss: 0.1080 - val_accuracy: 0.9689\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9615 - val_loss: 0.1086 - val_accuracy: 0.9682\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5366 - accuracy: 0.5038 - val_loss: 0.4991 - val_accuracy: 0.8767\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6165 - accuracy: 0.8168 - val_loss: 0.3768 - val_accuracy: 0.8947\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4985 - accuracy: 0.8526 - val_loss: 0.3359 - val_accuracy: 0.9031\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4499 - accuracy: 0.8659 - val_loss: 0.3146 - val_accuracy: 0.9082\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4247 - accuracy: 0.8770 - val_loss: 0.2993 - val_accuracy: 0.9134\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4086 - accuracy: 0.8765 - val_loss: 0.2887 - val_accuracy: 0.9166\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3845 - accuracy: 0.8859 - val_loss: 0.2803 - val_accuracy: 0.9187\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3731 - accuracy: 0.8885 - val_loss: 0.2737 - val_accuracy: 0.9211\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3658 - accuracy: 0.8930 - val_loss: 0.2675 - val_accuracy: 0.9226\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3477 - accuracy: 0.8980 - val_loss: 0.2624 - val_accuracy: 0.9233\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3486 - accuracy: 0.8982 - val_loss: 0.2565 - val_accuracy: 0.9263\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8989 - val_loss: 0.2524 - val_accuracy: 0.9269\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.9020 - val_loss: 0.2477 - val_accuracy: 0.9283\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3197 - accuracy: 0.9078 - val_loss: 0.2424 - val_accuracy: 0.9302\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3188 - accuracy: 0.9067 - val_loss: 0.2378 - val_accuracy: 0.9314\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3101 - accuracy: 0.9075 - val_loss: 0.2345 - val_accuracy: 0.9321\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3086 - accuracy: 0.9104 - val_loss: 0.2306 - val_accuracy: 0.9340\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3126 - accuracy: 0.9115 - val_loss: 0.2276 - val_accuracy: 0.9340\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3003 - accuracy: 0.9133 - val_loss: 0.2241 - val_accuracy: 0.9358\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2938 - accuracy: 0.9138 - val_loss: 0.2214 - val_accuracy: 0.9362\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2908 - accuracy: 0.9142 - val_loss: 0.2171 - val_accuracy: 0.9383\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2921 - accuracy: 0.9139 - val_loss: 0.2131 - val_accuracy: 0.9394\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.9178 - val_loss: 0.2110 - val_accuracy: 0.9392\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.9182 - val_loss: 0.2084 - val_accuracy: 0.9394\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2738 - accuracy: 0.9184 - val_loss: 0.2042 - val_accuracy: 0.9408\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2628 - accuracy: 0.9222 - val_loss: 0.2021 - val_accuracy: 0.9425\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.9229 - val_loss: 0.1986 - val_accuracy: 0.9438\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2624 - accuracy: 0.9213 - val_loss: 0.1971 - val_accuracy: 0.9444\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.9208 - val_loss: 0.1933 - val_accuracy: 0.9452\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2582 - accuracy: 0.9234 - val_loss: 0.1908 - val_accuracy: 0.9467\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2546 - accuracy: 0.9234 - val_loss: 0.1894 - val_accuracy: 0.9454\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2489 - accuracy: 0.9250 - val_loss: 0.1879 - val_accuracy: 0.9477\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.9263 - val_loss: 0.1840 - val_accuracy: 0.9484\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2527 - accuracy: 0.9243 - val_loss: 0.1824 - val_accuracy: 0.9492\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2421 - accuracy: 0.9291 - val_loss: 0.1809 - val_accuracy: 0.9503\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2423 - accuracy: 0.9291 - val_loss: 0.1787 - val_accuracy: 0.9506\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2394 - accuracy: 0.9298 - val_loss: 0.1772 - val_accuracy: 0.9501\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2288 - accuracy: 0.9304 - val_loss: 0.1741 - val_accuracy: 0.9528\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2338 - accuracy: 0.9317 - val_loss: 0.1729 - val_accuracy: 0.9523\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2296 - accuracy: 0.9306 - val_loss: 0.1706 - val_accuracy: 0.9533\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2296 - accuracy: 0.9331 - val_loss: 0.1687 - val_accuracy: 0.9539\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2271 - accuracy: 0.9313 - val_loss: 0.1679 - val_accuracy: 0.9535\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2249 - accuracy: 0.9329 - val_loss: 0.1660 - val_accuracy: 0.9541\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2228 - accuracy: 0.9350 - val_loss: 0.1645 - val_accuracy: 0.9549\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2200 - accuracy: 0.9343 - val_loss: 0.1616 - val_accuracy: 0.9556\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2139 - accuracy: 0.9368 - val_loss: 0.1605 - val_accuracy: 0.9558\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2131 - accuracy: 0.9337 - val_loss: 0.1584 - val_accuracy: 0.9567\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9359 - val_loss: 0.1566 - val_accuracy: 0.9563\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9376 - val_loss: 0.1563 - val_accuracy: 0.9563\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9370 - val_loss: 0.1537 - val_accuracy: 0.9576\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.6819 - accuracy: 0.1412 - val_loss: 0.8539 - val_accuracy: 0.7333\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8382 - accuracy: 0.3473 - val_loss: 0.8017 - val_accuracy: 0.7635\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3316 - accuracy: 0.5195 - val_loss: 0.8142 - val_accuracy: 0.7927\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0891 - accuracy: 0.6155 - val_loss: 0.7943 - val_accuracy: 0.8222\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9594 - accuracy: 0.6712 - val_loss: 0.7814 - val_accuracy: 0.8393\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8774 - accuracy: 0.7036 - val_loss: 0.7570 - val_accuracy: 0.8535\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8048 - accuracy: 0.7317 - val_loss: 0.7520 - val_accuracy: 0.8626\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7453 - accuracy: 0.7539 - val_loss: 0.7431 - val_accuracy: 0.8691\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7172 - accuracy: 0.7642 - val_loss: 0.7229 - val_accuracy: 0.8752\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6850 - accuracy: 0.7816 - val_loss: 0.7239 - val_accuracy: 0.8789\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6499 - accuracy: 0.7937 - val_loss: 0.7047 - val_accuracy: 0.8847\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6387 - accuracy: 0.7998 - val_loss: 0.6917 - val_accuracy: 0.8892\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6209 - accuracy: 0.8062 - val_loss: 0.6748 - val_accuracy: 0.8923\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5978 - accuracy: 0.8152 - val_loss: 0.6660 - val_accuracy: 0.8947\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5901 - accuracy: 0.8162 - val_loss: 0.6494 - val_accuracy: 0.8963\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5662 - accuracy: 0.8267 - val_loss: 0.6426 - val_accuracy: 0.8978\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5650 - accuracy: 0.8256 - val_loss: 0.6429 - val_accuracy: 0.8990\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5423 - accuracy: 0.8304 - val_loss: 0.6285 - val_accuracy: 0.9011\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5350 - accuracy: 0.8380 - val_loss: 0.6190 - val_accuracy: 0.9027\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5238 - accuracy: 0.8401 - val_loss: 0.6175 - val_accuracy: 0.9032\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5075 - accuracy: 0.8459 - val_loss: 0.6155 - val_accuracy: 0.9050\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5032 - accuracy: 0.8482 - val_loss: 0.6021 - val_accuracy: 0.9057\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4948 - accuracy: 0.8502 - val_loss: 0.6007 - val_accuracy: 0.9072\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4847 - accuracy: 0.8541 - val_loss: 0.5923 - val_accuracy: 0.9078\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4932 - accuracy: 0.8506 - val_loss: 0.5901 - val_accuracy: 0.9090\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4778 - accuracy: 0.8572 - val_loss: 0.5873 - val_accuracy: 0.9106\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4696 - accuracy: 0.8565 - val_loss: 0.5802 - val_accuracy: 0.9109\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4550 - accuracy: 0.8609 - val_loss: 0.5739 - val_accuracy: 0.9113\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4658 - accuracy: 0.8601 - val_loss: 0.5681 - val_accuracy: 0.9128\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4589 - accuracy: 0.8644 - val_loss: 0.5594 - val_accuracy: 0.9134\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4498 - accuracy: 0.8673 - val_loss: 0.5549 - val_accuracy: 0.9152\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.8683 - val_loss: 0.5554 - val_accuracy: 0.9146\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4307 - accuracy: 0.8705 - val_loss: 0.5430 - val_accuracy: 0.9157\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4322 - accuracy: 0.8698 - val_loss: 0.5408 - val_accuracy: 0.9175\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4309 - accuracy: 0.8707 - val_loss: 0.5409 - val_accuracy: 0.9174\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.8710 - val_loss: 0.5333 - val_accuracy: 0.9190\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4133 - accuracy: 0.8747 - val_loss: 0.5336 - val_accuracy: 0.9198\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4109 - accuracy: 0.8803 - val_loss: 0.5282 - val_accuracy: 0.9200\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8802 - val_loss: 0.5222 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4046 - accuracy: 0.8787 - val_loss: 0.5264 - val_accuracy: 0.9214\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3990 - accuracy: 0.8803 - val_loss: 0.5183 - val_accuracy: 0.9220\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3902 - accuracy: 0.8817 - val_loss: 0.5138 - val_accuracy: 0.9223\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4005 - accuracy: 0.8818 - val_loss: 0.5167 - val_accuracy: 0.9220\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3983 - accuracy: 0.8834 - val_loss: 0.5129 - val_accuracy: 0.9231\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3856 - accuracy: 0.8843 - val_loss: 0.5078 - val_accuracy: 0.9234\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3948 - accuracy: 0.8841 - val_loss: 0.5043 - val_accuracy: 0.9249\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.8865 - val_loss: 0.5020 - val_accuracy: 0.9249\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3838 - accuracy: 0.8850 - val_loss: 0.5000 - val_accuracy: 0.9255\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3784 - accuracy: 0.8899 - val_loss: 0.4925 - val_accuracy: 0.9264\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3775 - accuracy: 0.8868 - val_loss: 0.4862 - val_accuracy: 0.9268\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2054 - accuracy: 0.2704 - val_loss: 1.5975 - val_accuracy: 0.7207\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4081 - accuracy: 0.5997 - val_loss: 0.6743 - val_accuracy: 0.8443\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8365 - accuracy: 0.7397 - val_loss: 0.4879 - val_accuracy: 0.8738\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6625 - accuracy: 0.8016 - val_loss: 0.4112 - val_accuracy: 0.8914\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5739 - accuracy: 0.8277 - val_loss: 0.3701 - val_accuracy: 0.8993\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5151 - accuracy: 0.8510 - val_loss: 0.3410 - val_accuracy: 0.9062\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4806 - accuracy: 0.8636 - val_loss: 0.3199 - val_accuracy: 0.9098\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4424 - accuracy: 0.8722 - val_loss: 0.3027 - val_accuracy: 0.9150\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4221 - accuracy: 0.8783 - val_loss: 0.2892 - val_accuracy: 0.9177\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4003 - accuracy: 0.8833 - val_loss: 0.2769 - val_accuracy: 0.9198\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8871 - val_loss: 0.2664 - val_accuracy: 0.9234\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3719 - accuracy: 0.8928 - val_loss: 0.2575 - val_accuracy: 0.9258\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3594 - accuracy: 0.8946 - val_loss: 0.2475 - val_accuracy: 0.9285\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8984 - val_loss: 0.2400 - val_accuracy: 0.9307\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3410 - accuracy: 0.8994 - val_loss: 0.2331 - val_accuracy: 0.9323\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3291 - accuracy: 0.9043 - val_loss: 0.2264 - val_accuracy: 0.9345\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3140 - accuracy: 0.9088 - val_loss: 0.2194 - val_accuracy: 0.9364\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3103 - accuracy: 0.9090 - val_loss: 0.2145 - val_accuracy: 0.9383\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2967 - accuracy: 0.9141 - val_loss: 0.2084 - val_accuracy: 0.9401\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2938 - accuracy: 0.9153 - val_loss: 0.2027 - val_accuracy: 0.9419\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2869 - accuracy: 0.9156 - val_loss: 0.1981 - val_accuracy: 0.9431\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2802 - accuracy: 0.9177 - val_loss: 0.1926 - val_accuracy: 0.9451\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2703 - accuracy: 0.9204 - val_loss: 0.1889 - val_accuracy: 0.9454\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2593 - accuracy: 0.9239 - val_loss: 0.1846 - val_accuracy: 0.9470\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2585 - accuracy: 0.9243 - val_loss: 0.1801 - val_accuracy: 0.9480\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2519 - accuracy: 0.9271 - val_loss: 0.1772 - val_accuracy: 0.9492\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2386 - accuracy: 0.9301 - val_loss: 0.1737 - val_accuracy: 0.9494\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9306 - val_loss: 0.1690 - val_accuracy: 0.9519\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2305 - accuracy: 0.9311 - val_loss: 0.1658 - val_accuracy: 0.9522\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2321 - accuracy: 0.9316 - val_loss: 0.1628 - val_accuracy: 0.9529\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2300 - accuracy: 0.9325 - val_loss: 0.1597 - val_accuracy: 0.9536\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2159 - accuracy: 0.9358 - val_loss: 0.1579 - val_accuracy: 0.9536\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2181 - accuracy: 0.9360 - val_loss: 0.1544 - val_accuracy: 0.9550\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9386 - val_loss: 0.1523 - val_accuracy: 0.9551\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9408 - val_loss: 0.1491 - val_accuracy: 0.9563\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9386 - val_loss: 0.1474 - val_accuracy: 0.9565\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2016 - accuracy: 0.9398 - val_loss: 0.1452 - val_accuracy: 0.9574\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1943 - accuracy: 0.9429 - val_loss: 0.1427 - val_accuracy: 0.9576\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1922 - accuracy: 0.9435 - val_loss: 0.1414 - val_accuracy: 0.9582\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9427 - val_loss: 0.1393 - val_accuracy: 0.9592\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1940 - accuracy: 0.9464 - val_loss: 0.1373 - val_accuracy: 0.9596\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1860 - accuracy: 0.9448 - val_loss: 0.1364 - val_accuracy: 0.9596\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1802 - accuracy: 0.9465 - val_loss: 0.1350 - val_accuracy: 0.9597\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1756 - accuracy: 0.9486 - val_loss: 0.1331 - val_accuracy: 0.9606\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1802 - accuracy: 0.9467 - val_loss: 0.1310 - val_accuracy: 0.9610\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1812 - accuracy: 0.9476 - val_loss: 0.1293 - val_accuracy: 0.9617\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1730 - accuracy: 0.9496 - val_loss: 0.1283 - val_accuracy: 0.9619\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1673 - accuracy: 0.9505 - val_loss: 0.1268 - val_accuracy: 0.9619\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1679 - accuracy: 0.9508 - val_loss: 0.1260 - val_accuracy: 0.9620\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1687 - accuracy: 0.9502 - val_loss: 0.1243 - val_accuracy: 0.9628\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2408 - accuracy: 0.2331 - val_loss: 1.9325 - val_accuracy: 0.6760\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7530 - accuracy: 0.5872 - val_loss: 0.9775 - val_accuracy: 0.7835\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0221 - accuracy: 0.6932 - val_loss: 0.6081 - val_accuracy: 0.8518\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7625 - accuracy: 0.7673 - val_loss: 0.4864 - val_accuracy: 0.8741\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6481 - accuracy: 0.8063 - val_loss: 0.4229 - val_accuracy: 0.8875\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5766 - accuracy: 0.8299 - val_loss: 0.3884 - val_accuracy: 0.8955\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5222 - accuracy: 0.8463 - val_loss: 0.3641 - val_accuracy: 0.9005\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4961 - accuracy: 0.8537 - val_loss: 0.3445 - val_accuracy: 0.9053\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4615 - accuracy: 0.8644 - val_loss: 0.3303 - val_accuracy: 0.9082\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4436 - accuracy: 0.8714 - val_loss: 0.3162 - val_accuracy: 0.9108\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4244 - accuracy: 0.8767 - val_loss: 0.3060 - val_accuracy: 0.9137\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4201 - accuracy: 0.8777 - val_loss: 0.2963 - val_accuracy: 0.9161\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3999 - accuracy: 0.8830 - val_loss: 0.2883 - val_accuracy: 0.9176\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3862 - accuracy: 0.8871 - val_loss: 0.2799 - val_accuracy: 0.9191\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3787 - accuracy: 0.8877 - val_loss: 0.2738 - val_accuracy: 0.9218\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3768 - accuracy: 0.8902 - val_loss: 0.2660 - val_accuracy: 0.9226\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3634 - accuracy: 0.8952 - val_loss: 0.2603 - val_accuracy: 0.9243\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.8964 - val_loss: 0.2546 - val_accuracy: 0.9266\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.8994 - val_loss: 0.2501 - val_accuracy: 0.9270\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.9009 - val_loss: 0.2452 - val_accuracy: 0.9289\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3312 - accuracy: 0.9018 - val_loss: 0.2401 - val_accuracy: 0.9296\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.9039 - val_loss: 0.2366 - val_accuracy: 0.9305\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3127 - accuracy: 0.9084 - val_loss: 0.2322 - val_accuracy: 0.9314\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3074 - accuracy: 0.9096 - val_loss: 0.2272 - val_accuracy: 0.9324\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3047 - accuracy: 0.9105 - val_loss: 0.2238 - val_accuracy: 0.9337\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2994 - accuracy: 0.9101 - val_loss: 0.2199 - val_accuracy: 0.9344\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2936 - accuracy: 0.9123 - val_loss: 0.2157 - val_accuracy: 0.9368\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2931 - accuracy: 0.9135 - val_loss: 0.2121 - val_accuracy: 0.9383\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2807 - accuracy: 0.9168 - val_loss: 0.2084 - val_accuracy: 0.9391\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2801 - accuracy: 0.9179 - val_loss: 0.2053 - val_accuracy: 0.9407\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2826 - accuracy: 0.9168 - val_loss: 0.2022 - val_accuracy: 0.9409\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2765 - accuracy: 0.9196 - val_loss: 0.1989 - val_accuracy: 0.9423\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2683 - accuracy: 0.9224 - val_loss: 0.1966 - val_accuracy: 0.9432\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2641 - accuracy: 0.9240 - val_loss: 0.1936 - val_accuracy: 0.9442\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2569 - accuracy: 0.9248 - val_loss: 0.1910 - val_accuracy: 0.9442\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2580 - accuracy: 0.9241 - val_loss: 0.1871 - val_accuracy: 0.9466\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2570 - accuracy: 0.9258 - val_loss: 0.1847 - val_accuracy: 0.9473\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2484 - accuracy: 0.9277 - val_loss: 0.1819 - val_accuracy: 0.9482\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2523 - accuracy: 0.9256 - val_loss: 0.1800 - val_accuracy: 0.9485\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2465 - accuracy: 0.9265 - val_loss: 0.1773 - val_accuracy: 0.9498\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2367 - accuracy: 0.9302 - val_loss: 0.1751 - val_accuracy: 0.9503\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2336 - accuracy: 0.9314 - val_loss: 0.1735 - val_accuracy: 0.9503\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2277 - accuracy: 0.9323 - val_loss: 0.1713 - val_accuracy: 0.9507\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2274 - accuracy: 0.9341 - val_loss: 0.1697 - val_accuracy: 0.9513\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2242 - accuracy: 0.9344 - val_loss: 0.1669 - val_accuracy: 0.9525\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9326 - val_loss: 0.1651 - val_accuracy: 0.9526\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9374 - val_loss: 0.1625 - val_accuracy: 0.9542\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9372 - val_loss: 0.1612 - val_accuracy: 0.9544\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9362 - val_loss: 0.1590 - val_accuracy: 0.9548\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9362 - val_loss: 0.1574 - val_accuracy: 0.9551\n",
      "{'loss': [2.4842147827148438, 2.3993430137634277, 2.364985466003418, 2.3454813957214355, 2.333737850189209, 2.325162172317505, 2.3200674057006836, 2.315764904022217, 2.312699794769287, 2.3101515769958496, 2.3067867755889893, 2.3060059547424316, 2.30411434173584, 2.3031606674194336, 2.3013641834259033, 2.3007373809814453, 2.300360679626465, 2.299551486968994, 2.2989442348480225, 2.2977774143218994, 2.2965383529663086, 2.2953174114227295, 2.294344425201416, 2.2943027019500732, 2.2937090396881104, 2.2935476303100586, 2.291534423828125, 2.2896018028259277, 2.2883009910583496, 2.2856318950653076, 2.285099744796753, 2.2819318771362305, 2.2807693481445312, 2.2765398025512695, 2.2743289470672607, 2.2683300971984863, 2.263336658477783, 2.255758047103882, 2.2479076385498047, 2.2368359565734863, 2.220637798309326, 2.2002665996551514, 2.1694562435150146, 2.13537335395813, 2.0941073894500732, 2.047196865081787, 1.9883368015289307, 1.9366949796676636, 1.880157232284546, 1.8282874822616577], 'accuracy': [0.09968750178813934, 0.1027916669845581, 0.10460416972637177, 0.10727083683013916, 0.1041666641831398, 0.10687500238418579, 0.10658333450555801, 0.1094375029206276, 0.10875000059604645, 0.11097916960716248, 0.1107291653752327, 0.11254166811704636, 0.11245833337306976, 0.11147916316986084, 0.11656250059604645, 0.11777083575725555, 0.11627083271741867, 0.11885416507720947, 0.12075000256299973, 0.12131249904632568, 0.1224791631102562, 0.1236250028014183, 0.12558333575725555, 0.12320833653211594, 0.12683333456516266, 0.12729166448116302, 0.13104166090488434, 0.13483333587646484, 0.13752083480358124, 0.13977083563804626, 0.14014583826065063, 0.14487500488758087, 0.1443749964237213, 0.1485416740179062, 0.15066666901111603, 0.15806250274181366, 0.1652083396911621, 0.16952084004878998, 0.17524999380111694, 0.18408332765102386, 0.19322916865348816, 0.20266667008399963, 0.22185416519641876, 0.23347917199134827, 0.25204166769981384, 0.26662498712539673, 0.2879374921321869, 0.30395832657814026, 0.32379165291786194, 0.3373124897480011], 'val_loss': [2.3000285625457764, 2.298614025115967, 2.297183036804199, 2.2960591316223145, 2.295436143875122, 2.2948737144470215, 2.2946009635925293, 2.294210433959961, 2.2938947677612305, 2.2934608459472656, 2.2933082580566406, 2.292860746383667, 2.2925915718078613, 2.2923424243927, 2.2919766902923584, 2.2914586067199707, 2.2910208702087402, 2.290515422821045, 2.2899930477142334, 2.2894644737243652, 2.2886741161346436, 2.287980079650879, 2.287353277206421, 2.2862398624420166, 2.285154104232788, 2.284001588821411, 2.282665491104126, 2.281155824661255, 2.2796316146850586, 2.27725887298584, 2.275014877319336, 2.271937608718872, 2.2684123516082764, 2.2639970779418945, 2.258885145187378, 2.252133369445801, 2.244148015975952, 2.233279228210449, 2.219573736190796, 2.202045440673828, 2.1784894466400146, 2.1469810009002686, 2.106456995010376, 2.056248426437378, 1.9985663890838623, 1.936145305633545, 1.869198203086853, 1.8032807111740112, 1.7351818084716797, 1.6663166284561157], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10625000298023224, 0.10716667026281357, 0.10608333349227905, 0.1210833340883255, 0.12541666626930237, 0.15649999678134918, 0.17749999463558197, 0.22200000286102295, 0.19358333945274353, 0.21783334016799927, 0.21299999952316284, 0.2529999911785126, 0.2654166519641876, 0.28575000166893005, 0.3164166808128357, 0.3504166603088379, 0.35358333587646484, 0.40058332681655884, 0.4268333315849304, 0.4482499957084656, 0.437333345413208, 0.46416667103767395, 0.5260833501815796, 0.5390833616256714]}\n",
      "{'loss': [1.0955564975738525, 0.5875011682510376, 0.495510458946228, 0.45228487253189087, 0.4275849163532257, 0.406331330537796, 0.3901655375957489, 0.38108256459236145, 0.3703126311302185, 0.36537623405456543, 0.35933783650398254, 0.35087651014328003, 0.3454115092754364, 0.3425784111022949, 0.3340560793876648, 0.3329305946826935, 0.3273836076259613, 0.32248979806900024, 0.3206459581851959, 0.31668800115585327, 0.3137463927268982, 0.3097292184829712, 0.30747857689857483, 0.30481043457984924, 0.30187445878982544, 0.29769107699394226, 0.29801303148269653, 0.29454654455184937, 0.29173487424850464, 0.285825252532959, 0.28347188234329224, 0.28356078267097473, 0.2800177335739136, 0.27635446190834045, 0.27697283029556274, 0.2720876932144165, 0.2687130868434906, 0.2685236930847168, 0.2693654000759125, 0.2656298279762268, 0.25957927107810974, 0.2598477900028229, 0.26163798570632935, 0.25485727190971375, 0.2555720806121826, 0.25319966673851013, 0.2511845827102661, 0.24868962168693542, 0.2430298924446106, 0.24299894273281097], 'accuracy': [0.6722291707992554, 0.828499972820282, 0.8526458144187927, 0.8654375076293945, 0.8727708458900452, 0.8787291646003723, 0.8834791779518127, 0.8867499828338623, 0.890791654586792, 0.8928750157356262, 0.8949375152587891, 0.8963333368301392, 0.8972708582878113, 0.8989791870117188, 0.9005208611488342, 0.9018958210945129, 0.9031041860580444, 0.9056458473205566, 0.9072499871253967, 0.9066666960716248, 0.9070624709129333, 0.9088333249092102, 0.9088125228881836, 0.9104791879653931, 0.9102500081062317, 0.9127500057220459, 0.9122916460037231, 0.913687527179718, 0.9149166941642761, 0.9163749814033508, 0.9167916774749756, 0.9166874885559082, 0.917020857334137, 0.9179166555404663, 0.918541669845581, 0.9203958511352539, 0.9193124771118164, 0.9208124876022339, 0.9199374914169312, 0.921916663646698, 0.9235208630561829, 0.9229375123977661, 0.9232500195503235, 0.9243749976158142, 0.9244166612625122, 0.9256458282470703, 0.9260833263397217, 0.9263125061988831, 0.9275208115577698, 0.9277708530426025], 'val_loss': [0.5101448893547058, 0.38812246918678284, 0.344868928194046, 0.3222610354423523, 0.30795592069625854, 0.29678699374198914, 0.2887123227119446, 0.2840808033943176, 0.2772645950317383, 0.27275460958480835, 0.26768720149993896, 0.2644668519496918, 0.26059263944625854, 0.2574348747730255, 0.2541969418525696, 0.25164249539375305, 0.2490055114030838, 0.24694280326366425, 0.24519971013069153, 0.24304917454719543, 0.23981256783008575, 0.2368939369916916, 0.23722657561302185, 0.23591502010822296, 0.23237298429012299, 0.23024673759937286, 0.22764581441879272, 0.2247788906097412, 0.22342385351657867, 0.22228164970874786, 0.22051043808460236, 0.21798823773860931, 0.21723197400569916, 0.21448220312595367, 0.21245735883712769, 0.2115713357925415, 0.20787954330444336, 0.2065364420413971, 0.20448942482471466, 0.20368410646915436, 0.20184096693992615, 0.1996947079896927, 0.19771337509155273, 0.1962665170431137, 0.19504250586032867, 0.19486546516418457, 0.19256961345672607, 0.19103838503360748, 0.18837577104568481, 0.18725146353244781], 'val_accuracy': [0.8741666674613953, 0.8916666507720947, 0.9004999995231628, 0.906000018119812, 0.9096666574478149, 0.9132500290870667, 0.9154999852180481, 0.9180833101272583, 0.9191666841506958, 0.92166668176651, 0.9225833415985107, 0.9231666922569275, 0.9238333106040955, 0.9255833625793457, 0.9259999990463257, 0.9273333549499512, 0.9275833368301392, 0.9288333058357239, 0.9276666641235352, 0.9292500019073486, 0.9303333163261414, 0.9313333630561829, 0.9312499761581421, 0.9316666722297668, 0.9330833554267883, 0.9332500100135803, 0.9340833425521851, 0.9360833168029785, 0.9363333582878113, 0.9365833401679993, 0.9369166493415833, 0.937583327293396, 0.937416672706604, 0.9383333325386047, 0.9389166831970215, 0.9388333559036255, 0.940416693687439, 0.9399166703224182, 0.9415000081062317, 0.9420833587646484, 0.9422500133514404, 0.9436666369438171, 0.9445000290870667, 0.9450833201408386, 0.9446666836738586, 0.9445000290870667, 0.9456666707992554, 0.9467499852180481, 0.9482499957084656, 0.9477499723434448]}\n",
      "{'loss': [1.8695993423461914, 0.9932076930999756, 0.7065649628639221, 0.5822494029998779, 0.5149027705192566, 0.4699660539627075, 0.43386080861091614, 0.4029201567173004, 0.37780681252479553, 0.3531899154186249, 0.3383488059043884, 0.3222092390060425, 0.3055804371833801, 0.2883102595806122, 0.27783456444740295, 0.26787033677101135, 0.25744184851646423, 0.2456805258989334, 0.23409166932106018, 0.22978946566581726, 0.22303277254104614, 0.2116686850786209, 0.20984070003032684, 0.20212623476982117, 0.1965125948190689, 0.19212590157985687, 0.1849781721830368, 0.18172550201416016, 0.17780806124210358, 0.17416521906852722, 0.16399236023426056, 0.1616307944059372, 0.15857402980327606, 0.15771661698818207, 0.15484358370304108, 0.1492823362350464, 0.1431012600660324, 0.1437770575284958, 0.13629837334156036, 0.13755272328853607, 0.13485178351402283, 0.13050858676433563, 0.12834575772285461, 0.12650136649608612, 0.12488371133804321, 0.1223357543349266, 0.1205674558877945, 0.11420310288667679, 0.11592037230730057, 0.11088388413190842], 'accuracy': [0.38449999690055847, 0.6894583106040955, 0.7824166417121887, 0.8252291679382324, 0.8472916483879089, 0.8621041774749756, 0.8743125200271606, 0.882520854473114, 0.8927916884422302, 0.8995000123977661, 0.9036458134651184, 0.9082499742507935, 0.9133750200271606, 0.9179166555404663, 0.9196249842643738, 0.9241666793823242, 0.9272083044052124, 0.929354190826416, 0.9339374899864197, 0.9337708353996277, 0.9358333349227905, 0.9392916560173035, 0.9404374957084656, 0.9421250224113464, 0.9447708129882812, 0.945145845413208, 0.9471458196640015, 0.948604166507721, 0.9498124718666077, 0.950041651725769, 0.9545416831970215, 0.9537291526794434, 0.9546250104904175, 0.9546666741371155, 0.9560208320617676, 0.9571874737739563, 0.9593541622161865, 0.9599583148956299, 0.9610833525657654, 0.9605000019073486, 0.9611250162124634, 0.9621250033378601, 0.9634166955947876, 0.9639999866485596, 0.9645833373069763, 0.9651666879653931, 0.9651458263397217, 0.9671666622161865, 0.9673958420753479, 0.9691041707992554], 'val_loss': [1.0087107419967651, 0.5176758766174316, 0.3974728584289551, 0.3451392352581024, 0.31029972434043884, 0.28644225001335144, 0.2690269947052002, 0.2515753507614136, 0.23780710995197296, 0.2272406667470932, 0.21480385959148407, 0.20403093099594116, 0.19726529717445374, 0.187718003988266, 0.17941898107528687, 0.17340172827243805, 0.1667083203792572, 0.16129973530769348, 0.15493616461753845, 0.14966833591461182, 0.14733456075191498, 0.14146603643894196, 0.13869646191596985, 0.13488250970840454, 0.13135486841201782, 0.12945541739463806, 0.12706422805786133, 0.12293262779712677, 0.12200207263231277, 0.11927567422389984, 0.11707576364278793, 0.11452037841081619, 0.11284391582012177, 0.11105339229106903, 0.1098443791270256, 0.10763294249773026, 0.1070602536201477, 0.10560488700866699, 0.10372212529182434, 0.10293728858232498, 0.10059929639101028, 0.10042118281126022, 0.0994354635477066, 0.09761496633291245, 0.09672612696886063, 0.09608347713947296, 0.0946836918592453, 0.09374988079071045, 0.09343308210372925, 0.09196397662162781], 'val_accuracy': [0.8044999837875366, 0.8742499947547913, 0.8970000147819519, 0.9057499766349792, 0.9119166731834412, 0.9166666865348816, 0.9210833311080933, 0.925000011920929, 0.9304999709129333, 0.9321666955947876, 0.9375, 0.940500020980835, 0.9417499899864197, 0.9449166655540466, 0.9470000267028809, 0.9489166736602783, 0.9512500166893005, 0.953249990940094, 0.9551666378974915, 0.9570833444595337, 0.9569166898727417, 0.9593333601951599, 0.9593333601951599, 0.9605833292007446, 0.9612500071525574, 0.9612500071525574, 0.9614166617393494, 0.9627500176429749, 0.9627500176429749, 0.9637500047683716, 0.9636666774749756, 0.965416669845581, 0.9660833477973938, 0.9665833115577698, 0.9671666622161865, 0.9678333401679993, 0.9681666493415833, 0.9682499766349792, 0.968833327293396, 0.9692500233650208, 0.9692500233650208, 0.9694166779518127, 0.9703333377838135, 0.9699166417121887, 0.9702500104904175, 0.9707499742507935, 0.9710000157356262, 0.9711666703224182, 0.9713333249092102, 0.9713333249092102]}\n",
      "{'loss': [1.689037561416626, 0.8634138107299805, 0.6308303475379944, 0.5310551524162292, 0.47464048862457275, 0.43271589279174805, 0.4062823951244354, 0.38163232803344727, 0.3615908920764923, 0.34622713923454285, 0.32918456196784973, 0.31486982107162476, 0.3022809624671936, 0.291531503200531, 0.28121277689933777, 0.2711169123649597, 0.2660365104675293, 0.25476938486099243, 0.2512015700340271, 0.24373990297317505, 0.237168088555336, 0.2285122126340866, 0.22313079237937927, 0.21964560449123383, 0.2119351625442505, 0.20897874236106873, 0.20249104499816895, 0.19823254644870758, 0.1953352838754654, 0.19210419058799744, 0.18460363149642944, 0.1829686462879181, 0.1799461841583252, 0.17579622566699982, 0.1719655990600586, 0.17037981748580933, 0.16633109748363495, 0.16268999874591827, 0.16335229575634003, 0.15779922902584076, 0.15353018045425415, 0.15540499985218048, 0.15229468047618866, 0.14752165973186493, 0.14551177620887756, 0.14280693233013153, 0.14362403750419617, 0.1388644576072693, 0.13393354415893555, 0.13444140553474426], 'accuracy': [0.46956250071525574, 0.7344791889190674, 0.809291660785675, 0.8421041369438171, 0.8598750233650208, 0.8741875290870667, 0.8817291855812073, 0.8891249895095825, 0.8943750262260437, 0.9004583358764648, 0.9049999713897705, 0.9087291955947876, 0.9131458401679993, 0.9154999852180481, 0.9192916750907898, 0.9208958148956299, 0.9234583377838135, 0.9268541932106018, 0.9274166822433472, 0.9302499890327454, 0.9313750267028809, 0.9324583411216736, 0.9363124966621399, 0.9378125071525574, 0.9386875033378601, 0.9394166469573975, 0.9419583082199097, 0.942312479019165, 0.9432083368301392, 0.9437083601951599, 0.9466041922569275, 0.9473541378974915, 0.9478958249092102, 0.9502916932106018, 0.9498958587646484, 0.9511250257492065, 0.9514166712760925, 0.9522916674613953, 0.952750027179718, 0.9544374942779541, 0.9553333520889282, 0.9545624852180481, 0.9555208086967468, 0.9572291374206543, 0.9576249718666077, 0.9588750004768372, 0.9583333134651184, 0.9591458439826965, 0.9603958129882812, 0.96072918176651], 'val_loss': [0.8528754711151123, 0.47885724902153015, 0.38119426369667053, 0.3342061936855316, 0.30515727400779724, 0.2847271263599396, 0.2696819603443146, 0.2554548382759094, 0.24387986958026886, 0.233931764960289, 0.22498148679733276, 0.2166644036769867, 0.20785917341709137, 0.2022114098072052, 0.19537435472011566, 0.1887345016002655, 0.18348386883735657, 0.17849332094192505, 0.1738681048154831, 0.16980582475662231, 0.16529572010040283, 0.16281285881996155, 0.1582416296005249, 0.15428920090198517, 0.15334776043891907, 0.1486920714378357, 0.14626307785511017, 0.1430598795413971, 0.14092330634593964, 0.13756780326366425, 0.13583998382091522, 0.13400113582611084, 0.13126301765441895, 0.12970738112926483, 0.12754908204078674, 0.12639367580413818, 0.12417434900999069, 0.12153322994709015, 0.12023986130952835, 0.11911197751760483, 0.11817684024572372, 0.11641845852136612, 0.11544033885002136, 0.11419877409934998, 0.11320435255765915, 0.11101361364126205, 0.11102812737226486, 0.10974918305873871, 0.10804810374975204, 0.10861895978450775], 'val_accuracy': [0.8216666579246521, 0.8765833377838135, 0.8984166383743286, 0.9071666598320007, 0.9146666526794434, 0.9193333387374878, 0.921750009059906, 0.9261666536331177, 0.9289166927337646, 0.9312499761581421, 0.934583306312561, 0.9368333220481873, 0.9394999742507935, 0.9409166574478149, 0.9421666860580444, 0.9437500238418579, 0.9460833072662354, 0.9476666450500488, 0.949999988079071, 0.9520000219345093, 0.9524166584014893, 0.953083336353302, 0.9539166688919067, 0.9550833106040955, 0.9549166560173035, 0.9555833339691162, 0.9566666483879089, 0.9571666717529297, 0.9587500095367432, 0.9598333239555359, 0.9599999785423279, 0.9606666564941406, 0.9617499709129333, 0.9616666436195374, 0.9626666903495789, 0.9632499814033508, 0.9636666774749756, 0.9645833373069763, 0.9648333191871643, 0.9664166569709778, 0.965749979019165, 0.9671666622161865, 0.9663333296775818, 0.9666666388511658, 0.9670833349227905, 0.9679166674613953, 0.9678333401679993, 0.9681666493415833, 0.968916654586792, 0.9682499766349792]}\n",
      "{'loss': [1.1096705198287964, 0.5755656361579895, 0.4869041442871094, 0.442486971616745, 0.41620007157325745, 0.3996538519859314, 0.38125157356262207, 0.3716244697570801, 0.3641398549079895, 0.35491451621055603, 0.34732356667518616, 0.3397899270057678, 0.33204591274261475, 0.32210370898246765, 0.32097911834716797, 0.3138839900493622, 0.3088837265968323, 0.30585649609565735, 0.2982769012451172, 0.29361528158187866, 0.2932007908821106, 0.28915324807167053, 0.2818814814090729, 0.27727916836738586, 0.27292880415916443, 0.270430326461792, 0.266203910112381, 0.26239559054374695, 0.2601020932197571, 0.25697192549705505, 0.2549425959587097, 0.2519052028656006, 0.2479272484779358, 0.24874578416347504, 0.24203133583068848, 0.2387547641992569, 0.23878605663776398, 0.2342422753572464, 0.23332960903644562, 0.2288336157798767, 0.22628945112228394, 0.2258075326681137, 0.22209079563617706, 0.22242014110088348, 0.218647301197052, 0.21556635200977325, 0.21311527490615845, 0.21474914252758026, 0.2101726084947586, 0.2069367617368698], 'accuracy': [0.6639583110809326, 0.8296874761581421, 0.854729175567627, 0.8679583072662354, 0.8773333430290222, 0.8821041584014893, 0.8862500190734863, 0.890874981880188, 0.8926666378974915, 0.8956249952316284, 0.8984166383743286, 0.8994166851043701, 0.9026041626930237, 0.9064791798591614, 0.9054583311080933, 0.9078124761581421, 0.9087916612625122, 0.9120208621025085, 0.9123749732971191, 0.9136041402816772, 0.913937509059906, 0.9157500267028809, 0.917104184627533, 0.9181458353996277, 0.9189375042915344, 0.9201250076293945, 0.9218958616256714, 0.9223333597183228, 0.9231666922569275, 0.9239166378974915, 0.9233333468437195, 0.924916684627533, 0.9261041879653931, 0.9258124828338623, 0.9285625219345093, 0.929562509059906, 0.9292083382606506, 0.9291458129882812, 0.9315208196640015, 0.9311666488647461, 0.9326666593551636, 0.9316666722297668, 0.932687520980835, 0.9346666932106018, 0.9350208044052124, 0.9355416893959045, 0.9353541731834412, 0.9363333582878113, 0.9370416402816772, 0.9375208616256714], 'val_loss': [0.49914297461509705, 0.3767678141593933, 0.3358624577522278, 0.3146161735057831, 0.2992725074291229, 0.28871798515319824, 0.2803032100200653, 0.27371877431869507, 0.2674577534198761, 0.2624146044254303, 0.2565113306045532, 0.2523544430732727, 0.24768565595149994, 0.24236035346984863, 0.2378157526254654, 0.23452074825763702, 0.23060669004917145, 0.2276078462600708, 0.2241121381521225, 0.22140179574489594, 0.2170710414648056, 0.2130763977766037, 0.21101704239845276, 0.20841644704341888, 0.20424556732177734, 0.20209380984306335, 0.1986495554447174, 0.19705410301685333, 0.19330424070358276, 0.19080820679664612, 0.18944065272808075, 0.1878548115491867, 0.18403270840644836, 0.18238523602485657, 0.18090654909610748, 0.1786775290966034, 0.17722299695014954, 0.1741221696138382, 0.17291709780693054, 0.17064128816127777, 0.16866810619831085, 0.1679292470216751, 0.165970116853714, 0.1645391434431076, 0.16158710420131683, 0.16045404970645905, 0.15842293202877045, 0.15655170381069183, 0.15634897351264954, 0.1536794900894165], 'val_accuracy': [0.8766666650772095, 0.8946666717529297, 0.903083324432373, 0.9082499742507935, 0.9134166836738586, 0.9165833592414856, 0.918749988079071, 0.9210833311080933, 0.9225833415985107, 0.9233333468437195, 0.9263333082199097, 0.9269166588783264, 0.9283333420753479, 0.9301666617393494, 0.9314166903495789, 0.9320833086967468, 0.9340000152587891, 0.9340000152587891, 0.9358333349227905, 0.9361666440963745, 0.9382500052452087, 0.9394166469573975, 0.9391666650772095, 0.9394166469573975, 0.940833330154419, 0.9424999952316284, 0.9437500238418579, 0.9444166421890259, 0.9451666474342346, 0.9466666579246521, 0.9454166889190674, 0.9477499723434448, 0.9484166502952576, 0.9492499828338623, 0.9503333568572998, 0.9505833387374878, 0.950083315372467, 0.952750027179718, 0.9522500038146973, 0.95333331823349, 0.9539166688919067, 0.953499972820282, 0.9540833234786987, 0.9549166560173035, 0.9555833339691162, 0.9558333158493042, 0.9566666483879089, 0.956250011920929, 0.956333339214325, 0.9575833082199097]}\n",
      "{'loss': [2.438467025756836, 1.6829363107681274, 1.2583855390548706, 1.0527814626693726, 0.9344528913497925, 0.8551887273788452, 0.781998872756958, 0.7373602986335754, 0.708441972732544, 0.6781095266342163, 0.6491391062736511, 0.6314798593521118, 0.6137419939041138, 0.5942853093147278, 0.5822726488113403, 0.563880443572998, 0.553199827671051, 0.5433406829833984, 0.5299864411354065, 0.5256221890449524, 0.5081295967102051, 0.5053001046180725, 0.4951993525028229, 0.4903803765773773, 0.48131799697875977, 0.47051355242729187, 0.4699515700340271, 0.4601513147354126, 0.45984119176864624, 0.453877329826355, 0.4461079239845276, 0.4389292001724243, 0.4378220736980438, 0.43401041626930237, 0.4289001524448395, 0.4279748797416687, 0.4188131093978882, 0.41689181327819824, 0.4144650399684906, 0.4072842597961426, 0.4046705663204193, 0.40156200528144836, 0.39451897144317627, 0.39256522059440613, 0.3892778754234314, 0.38653475046157837, 0.3849845230579376, 0.3807891309261322, 0.3799547851085663, 0.3796512484550476], 'accuracy': [0.1849791705608368, 0.3998749852180481, 0.5487708449363708, 0.6314583420753479, 0.6813750267028809, 0.7126250267028809, 0.7401666641235352, 0.7581250071525574, 0.7706041932106018, 0.784416675567627, 0.7940624952316284, 0.8013125061988831, 0.8093125224113464, 0.8166041374206543, 0.8197083473205566, 0.8263333439826965, 0.8302916884422302, 0.8320000171661377, 0.8393124938011169, 0.8396041393280029, 0.846791684627533, 0.8469374775886536, 0.8490416407585144, 0.8532083630561829, 0.8551874756813049, 0.8579791784286499, 0.8583750128746033, 0.8591874837875366, 0.8620208501815796, 0.8646458387374878, 0.8676666617393494, 0.8693541884422302, 0.8675416707992554, 0.8689791560173035, 0.8710416555404663, 0.8736875057220459, 0.8744791746139526, 0.878333330154419, 0.8787083625793457, 0.8783749938011169, 0.8787708282470703, 0.8793958425521851, 0.882854163646698, 0.8840416669845581, 0.8836874961853027, 0.885895848274231, 0.886145830154419, 0.8863958120346069, 0.8885208368301392, 0.886145830154419], 'val_loss': [0.853931725025177, 0.8017481565475464, 0.8141855597496033, 0.7942878603935242, 0.7814476490020752, 0.7570335268974304, 0.7520344853401184, 0.7431035041809082, 0.7229295372962952, 0.7238567471504211, 0.7047305703163147, 0.6916902661323547, 0.6747952699661255, 0.6659705638885498, 0.64939284324646, 0.6425595879554749, 0.6428912281990051, 0.6285080313682556, 0.6190359592437744, 0.6174766421318054, 0.6155388355255127, 0.602066695690155, 0.6007069945335388, 0.5923027992248535, 0.5900503396987915, 0.5872583389282227, 0.5802186131477356, 0.5738573670387268, 0.5680966973304749, 0.5593960881233215, 0.5549048781394958, 0.555376410484314, 0.5429568290710449, 0.5407633185386658, 0.5409284830093384, 0.5333186984062195, 0.5335555672645569, 0.5281786322593689, 0.5222108960151672, 0.5263558626174927, 0.5183228850364685, 0.5138021111488342, 0.5167290568351746, 0.5128976106643677, 0.5078338384628296, 0.5042756199836731, 0.5019658207893372, 0.5000168085098267, 0.4924689829349518, 0.48622164130210876], 'val_accuracy': [0.7333333492279053, 0.7634999752044678, 0.7926666736602783, 0.8221666812896729, 0.8392500281333923, 0.8535000085830688, 0.862583339214325, 0.8690833449363708, 0.875166654586792, 0.8789166808128357, 0.8846666812896729, 0.8891666531562805, 0.8922500014305115, 0.8946666717529297, 0.8962500095367432, 0.8978333473205566, 0.8989999890327454, 0.9010833501815796, 0.9026666879653931, 0.903166651725769, 0.9049999713897705, 0.9057499766349792, 0.9072499871253967, 0.9077500104904175, 0.9089999794960022, 0.9105833172798157, 0.9109166860580444, 0.9113333225250244, 0.9128333330154419, 0.9134166836738586, 0.9151666760444641, 0.9145833253860474, 0.9156666398048401, 0.9175000190734863, 0.9174166917800903, 0.9190000295639038, 0.9198333621025085, 0.9200000166893005, 0.9210833311080933, 0.9214166402816772, 0.921999990940094, 0.9223333597183228, 0.921999990940094, 0.9230833053588867, 0.9234166741371155, 0.924916684627533, 0.924916684627533, 0.9254999756813049, 0.9264166951179504, 0.9267500042915344]}\n",
      "{'loss': [2.0716118812561035, 1.2086565494537354, 0.7899103164672852, 0.6408905982971191, 0.560800313949585, 0.5076717734336853, 0.4730541706085205, 0.44328072667121887, 0.423115998506546, 0.40345343947410583, 0.38459959626197815, 0.3685700297355652, 0.3579433262348175, 0.3459005653858185, 0.33457908034324646, 0.32388490438461304, 0.3158884346485138, 0.30506423115730286, 0.29572147130966187, 0.29025232791900635, 0.2784256935119629, 0.2761298418045044, 0.2665557563304901, 0.25908181071281433, 0.2538052201271057, 0.2481120228767395, 0.24255305528640747, 0.23638568818569183, 0.23477840423583984, 0.2302848845720291, 0.22372783720493317, 0.21838456392288208, 0.2145986109972, 0.21235255897045135, 0.2053898125886917, 0.20443612337112427, 0.20034566521644592, 0.19759640097618103, 0.19350337982177734, 0.19304580986499786, 0.19039160013198853, 0.1857880800962448, 0.18052174150943756, 0.1784742772579193, 0.17685721814632416, 0.17560681700706482, 0.17307354509830475, 0.1691886931657791, 0.1652248650789261, 0.16797909140586853], 'accuracy': [0.3866041600704193, 0.6411666870117188, 0.7566249966621399, 0.8087499737739563, 0.8330000042915344, 0.8530833125114441, 0.863854169845581, 0.8712291717529297, 0.8777916431427002, 0.883062481880188, 0.887708306312561, 0.8923958539962769, 0.895354151725769, 0.8999166488647461, 0.901770830154419, 0.9057291746139526, 0.9086458086967468, 0.9117500185966492, 0.9136250019073486, 0.9157708287239075, 0.9191666841506958, 0.9196666479110718, 0.9224791526794434, 0.9244375228881836, 0.9263333082199097, 0.9278541803359985, 0.9298333525657654, 0.9309583306312561, 0.9302499890327454, 0.9324791431427002, 0.9343125224113464, 0.9358333349227905, 0.9369791746139526, 0.9387708306312561, 0.9401249885559082, 0.9398541450500488, 0.9411666393280029, 0.9422916769981384, 0.9436458349227905, 0.9441875219345093, 0.945062518119812, 0.944937527179718, 0.9470000267028809, 0.9480000138282776, 0.9479374885559082, 0.9479791522026062, 0.949833333492279, 0.9498958587646484, 0.9513124823570251, 0.9507083296775818], 'val_loss': [1.5975383520126343, 0.6742886304855347, 0.4879097044467926, 0.41117990016937256, 0.37005290389060974, 0.34098318219184875, 0.3199104070663452, 0.30267634987831116, 0.28919073939323425, 0.27692243456840515, 0.2664492726325989, 0.257504403591156, 0.24750831723213196, 0.24002805352210999, 0.23309330642223358, 0.22639767825603485, 0.21939867734909058, 0.21451835334300995, 0.20841339230537415, 0.20266148447990417, 0.19808147847652435, 0.19258056581020355, 0.1888943910598755, 0.18456284701824188, 0.1801430732011795, 0.17717815935611725, 0.17371195554733276, 0.16900038719177246, 0.16579169034957886, 0.16276180744171143, 0.15966102480888367, 0.15789857506752014, 0.15444643795490265, 0.1523483544588089, 0.1491144299507141, 0.14737766981124878, 0.14522217214107513, 0.14269216358661652, 0.14140371978282928, 0.13933533430099487, 0.13725535571575165, 0.1363534927368164, 0.13500583171844482, 0.13305607438087463, 0.13098183274269104, 0.12928873300552368, 0.12831033766269684, 0.1268489509820938, 0.12603698670864105, 0.1243106871843338], 'val_accuracy': [0.7207499742507935, 0.8443333506584167, 0.8738333582878113, 0.8914166688919067, 0.8993333578109741, 0.906166672706604, 0.9098333120346069, 0.9150000214576721, 0.9176666736602783, 0.9198333621025085, 0.9234166741371155, 0.9257500171661377, 0.9284999966621399, 0.9306666851043701, 0.9322500228881836, 0.934499979019165, 0.9364166855812073, 0.9383333325386047, 0.9400833249092102, 0.9419166445732117, 0.9430833458900452, 0.9450833201408386, 0.9454166889190674, 0.9470000267028809, 0.9480000138282776, 0.9492499828338623, 0.9494166374206543, 0.9519166946411133, 0.9521666765213013, 0.95291668176651, 0.9535833597183228, 0.9535833597183228, 0.9549999833106995, 0.9550833106040955, 0.956250011920929, 0.9564999938011169, 0.9574166536331177, 0.9575833082199097, 0.9582499861717224, 0.9592499732971191, 0.9595833420753479, 0.9595833420753479, 0.9597499966621399, 0.9605833292007446, 0.9610000252723694, 0.9616666436195374, 0.9619166851043701, 0.9619166851043701, 0.9620000123977661, 0.9627500176429749]}\n",
      "{'loss': [2.159329652786255, 1.537594199180603, 0.9382441639900208, 0.727507472038269, 0.619447648525238, 0.5616150498390198, 0.5203009247779846, 0.48706087470054626, 0.4617387354373932, 0.44055044651031494, 0.4253717064857483, 0.40993425250053406, 0.40175074338912964, 0.3856286108493805, 0.37868550419807434, 0.36731696128845215, 0.35698404908180237, 0.3521310091018677, 0.3419311046600342, 0.33354517817497253, 0.3276771605014801, 0.3219323456287384, 0.3144133388996124, 0.31227368116378784, 0.30284255743026733, 0.2984233796596527, 0.29324430227279663, 0.2897307872772217, 0.2818973958492279, 0.27933940291404724, 0.2755991220474243, 0.2708713710308075, 0.2667160928249359, 0.2611129879951477, 0.25967708230018616, 0.2526959776878357, 0.2518512010574341, 0.24678686261177063, 0.24478602409362793, 0.24124428629875183, 0.23873461782932281, 0.2353959083557129, 0.22839339077472687, 0.22833451628684998, 0.22324860095977783, 0.22078099846839905, 0.218248188495636, 0.21503324806690216, 0.21345704793930054, 0.21169403195381165], 'accuracy': [0.36752083897590637, 0.6146458387374878, 0.7147083282470703, 0.7782708406448364, 0.8153125047683716, 0.8351666927337646, 0.8464375138282776, 0.8579375147819519, 0.8647916913032532, 0.8709166646003723, 0.8758958578109741, 0.879895806312561, 0.8828333616256714, 0.8881250023841858, 0.8878958225250244, 0.8925625085830688, 0.8957708477973938, 0.8965625166893005, 0.8992499709129333, 0.9020208120346069, 0.9034791588783264, 0.9056458473205566, 0.9083333611488342, 0.9090416431427002, 0.9111250042915344, 0.9121041893959045, 0.9135416746139526, 0.9139166474342346, 0.9174166917800903, 0.9183124899864197, 0.9196249842643738, 0.9198541641235352, 0.9223124980926514, 0.9238333106040955, 0.924916684627533, 0.9255416393280029, 0.9267083406448364, 0.9275833368301392, 0.9273124933242798, 0.9282291531562805, 0.9290833473205566, 0.9305416941642761, 0.9319791793823242, 0.932687520980835, 0.9348124861717224, 0.9336666464805603, 0.9352083206176758, 0.9363541603088379, 0.9364374876022339, 0.9369791746139526], 'val_loss': [1.9325320720672607, 0.9775130748748779, 0.6081210374832153, 0.48644694685935974, 0.42294445633888245, 0.3884199261665344, 0.3640560805797577, 0.34453633427619934, 0.3302733898162842, 0.31624171137809753, 0.30604004859924316, 0.2963407039642334, 0.2882609963417053, 0.27988916635513306, 0.2738019824028015, 0.2660440504550934, 0.2602676451206207, 0.2546178698539734, 0.25005903840065, 0.24515500664710999, 0.24008943140506744, 0.23663769662380219, 0.23221014440059662, 0.2271704375743866, 0.2237939089536667, 0.21991705894470215, 0.21573255956172943, 0.21207468211650848, 0.2084438055753708, 0.20526422560214996, 0.2021714448928833, 0.19885550439357758, 0.19655703008174896, 0.1935679316520691, 0.1910228431224823, 0.18711069226264954, 0.18471403419971466, 0.1819136142730713, 0.18001674115657806, 0.1773136854171753, 0.1751432567834854, 0.17351023852825165, 0.17127248644828796, 0.16970285773277283, 0.16687621176242828, 0.16512513160705566, 0.16245953738689423, 0.16116732358932495, 0.15897290408611298, 0.15743133425712585], 'val_accuracy': [0.6759999990463257, 0.7835000157356262, 0.8517500162124634, 0.8740833401679993, 0.887499988079071, 0.8955000042915344, 0.9004999995231628, 0.9052500128746033, 0.9082499742507935, 0.9108333587646484, 0.9137499928474426, 0.9160833358764648, 0.9175833463668823, 0.9190833568572998, 0.921833336353302, 0.9225833415985107, 0.9242500066757202, 0.9265833497047424, 0.9269999861717224, 0.9289166927337646, 0.9295833110809326, 0.9304999709129333, 0.9314166903495789, 0.9324166774749756, 0.9336666464805603, 0.934416651725769, 0.9368333220481873, 0.9383333325386047, 0.9390833377838135, 0.940666675567627, 0.9409166574478149, 0.9423333406448364, 0.9431666731834412, 0.9441666603088379, 0.9442499876022339, 0.9465833306312561, 0.9472500085830688, 0.9482499957084656, 0.9484999775886536, 0.9497500061988831, 0.9503333568572998, 0.9503333568572998, 0.9507499933242798, 0.9513333439826965, 0.9524999856948853, 0.9525833129882812, 0.9541666507720947, 0.9544166922569275, 0.9547500014305115, 0.9550833106040955]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
