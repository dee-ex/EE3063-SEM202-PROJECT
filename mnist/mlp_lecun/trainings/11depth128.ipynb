{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11depth128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "ee271c7a-7b38-4b6b-a7c0-5fdff3cb2626"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "    input_shape = (28 * 28,)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    if(activation == 'selu'):\n",
        "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.25))\n",
        "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(AlphaDropout(0.5))\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "    else:\n",
        "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Training with -->sigmoid<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 21s 11ms/step - loss: 2.4359 - accuracy: 0.1022 - val_loss: 2.3035 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3850 - accuracy: 0.1002 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3586 - accuracy: 0.1003 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3432 - accuracy: 0.1037 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.3382 - accuracy: 0.0992 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3306 - accuracy: 0.1008 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3257 - accuracy: 0.1016 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3218 - accuracy: 0.1030 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3196 - accuracy: 0.1041 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3170 - accuracy: 0.1009 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3165 - accuracy: 0.1036 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3143 - accuracy: 0.1046 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3127 - accuracy: 0.1040 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3104 - accuracy: 0.1039 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3106 - accuracy: 0.1046 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3073 - accuracy: 0.1054 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3072 - accuracy: 0.1051 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.3071 - accuracy: 0.1033 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3073 - accuracy: 0.1055 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3075 - accuracy: 0.1054 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3082 - accuracy: 0.1031 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3067 - accuracy: 0.1039 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3071 - accuracy: 0.1025 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3061 - accuracy: 0.1060 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3057 - accuracy: 0.1049 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3039 - accuracy: 0.1079 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3057 - accuracy: 0.1048 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3051 - accuracy: 0.1071 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3042 - accuracy: 0.1086 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3047 - accuracy: 0.1074 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3042 - accuracy: 0.1093 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3031 - accuracy: 0.1106 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3040 - accuracy: 0.1101 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3038 - accuracy: 0.1100 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3047 - accuracy: 0.1049 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3027 - accuracy: 0.1105 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3023 - accuracy: 0.1108 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3023 - accuracy: 0.1105 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3032 - accuracy: 0.1104 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3046 - accuracy: 0.1077 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3031 - accuracy: 0.1070 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3030 - accuracy: 0.1101 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3034 - accuracy: 0.1106 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3030 - accuracy: 0.1108 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3033 - accuracy: 0.1064 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3024 - accuracy: 0.1088 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3022 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3020 - accuracy: 0.1155 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3023 - accuracy: 0.1116 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "\n",
            "Training with -->tanh<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 6s 11ms/step - loss: 2.2714 - accuracy: 0.1688 - val_loss: 1.4417 - val_accuracy: 0.6177\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.7991 - accuracy: 0.3703 - val_loss: 1.1582 - val_accuracy: 0.6678\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.5735 - accuracy: 0.4558 - val_loss: 0.9609 - val_accuracy: 0.7623\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.4082 - accuracy: 0.5224 - val_loss: 0.8043 - val_accuracy: 0.8133\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2723 - accuracy: 0.5816 - val_loss: 0.6863 - val_accuracy: 0.8430\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.1637 - accuracy: 0.6249 - val_loss: 0.6100 - val_accuracy: 0.8622\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.0769 - accuracy: 0.6592 - val_loss: 0.5567 - val_accuracy: 0.8685\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.9994 - accuracy: 0.6888 - val_loss: 0.5224 - val_accuracy: 0.8712\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9565 - accuracy: 0.7090 - val_loss: 0.4942 - val_accuracy: 0.8810\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.9111 - accuracy: 0.7254 - val_loss: 0.4758 - val_accuracy: 0.8838\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.8833 - accuracy: 0.7404 - val_loss: 0.4677 - val_accuracy: 0.8847\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8553 - accuracy: 0.7535 - val_loss: 0.4550 - val_accuracy: 0.8887\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.8075 - accuracy: 0.7726 - val_loss: 0.4324 - val_accuracy: 0.8945\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7957 - accuracy: 0.7797 - val_loss: 0.4203 - val_accuracy: 0.8979\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7762 - accuracy: 0.7855 - val_loss: 0.4074 - val_accuracy: 0.9027\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7573 - accuracy: 0.7971 - val_loss: 0.4006 - val_accuracy: 0.9038\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7459 - accuracy: 0.8002 - val_loss: 0.3948 - val_accuracy: 0.9052\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7188 - accuracy: 0.8124 - val_loss: 0.3845 - val_accuracy: 0.9073\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6992 - accuracy: 0.8194 - val_loss: 0.3794 - val_accuracy: 0.9105\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6899 - accuracy: 0.8260 - val_loss: 0.3873 - val_accuracy: 0.9099\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6777 - accuracy: 0.8295 - val_loss: 0.3739 - val_accuracy: 0.9156\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6636 - accuracy: 0.8370 - val_loss: 0.3601 - val_accuracy: 0.9175\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6504 - accuracy: 0.8387 - val_loss: 0.3582 - val_accuracy: 0.9184\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6494 - accuracy: 0.8427 - val_loss: 0.3455 - val_accuracy: 0.9208\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6223 - accuracy: 0.8504 - val_loss: 0.3457 - val_accuracy: 0.9217\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6256 - accuracy: 0.8482 - val_loss: 0.3432 - val_accuracy: 0.9238\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6021 - accuracy: 0.8546 - val_loss: 0.3354 - val_accuracy: 0.9251\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6094 - accuracy: 0.8546 - val_loss: 0.3337 - val_accuracy: 0.9264\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5977 - accuracy: 0.8599 - val_loss: 0.3277 - val_accuracy: 0.9286\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5930 - accuracy: 0.8610 - val_loss: 0.3305 - val_accuracy: 0.9287\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5802 - accuracy: 0.8639 - val_loss: 0.3329 - val_accuracy: 0.9283\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5700 - accuracy: 0.8675 - val_loss: 0.3253 - val_accuracy: 0.9300\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5613 - accuracy: 0.8694 - val_loss: 0.3348 - val_accuracy: 0.9285\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5571 - accuracy: 0.8727 - val_loss: 0.3063 - val_accuracy: 0.9345\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5449 - accuracy: 0.8766 - val_loss: 0.3046 - val_accuracy: 0.9354\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5558 - accuracy: 0.8726 - val_loss: 0.3061 - val_accuracy: 0.9358\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5435 - accuracy: 0.8777 - val_loss: 0.3009 - val_accuracy: 0.9366\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5339 - accuracy: 0.8809 - val_loss: 0.3043 - val_accuracy: 0.9373\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5203 - accuracy: 0.8825 - val_loss: 0.3014 - val_accuracy: 0.9371\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5185 - accuracy: 0.8805 - val_loss: 0.2917 - val_accuracy: 0.9388\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5215 - accuracy: 0.8842 - val_loss: 0.3031 - val_accuracy: 0.9367\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5171 - accuracy: 0.8856 - val_loss: 0.2868 - val_accuracy: 0.9410\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5079 - accuracy: 0.8866 - val_loss: 0.2887 - val_accuracy: 0.9400\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4961 - accuracy: 0.8908 - val_loss: 0.2845 - val_accuracy: 0.9414\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5014 - accuracy: 0.8873 - val_loss: 0.2806 - val_accuracy: 0.9427\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4948 - accuracy: 0.8904 - val_loss: 0.2757 - val_accuracy: 0.9438\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4824 - accuracy: 0.8941 - val_loss: 0.2722 - val_accuracy: 0.9427\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4743 - accuracy: 0.8949 - val_loss: 0.2770 - val_accuracy: 0.9436\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4754 - accuracy: 0.8945 - val_loss: 0.2775 - val_accuracy: 0.9447\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4733 - accuracy: 0.8973 - val_loss: 0.2686 - val_accuracy: 0.9464\n",
            "\n",
            "Training with -->relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 6s 10ms/step - loss: 2.3040 - accuracy: 0.1093 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3021 - accuracy: 0.1175 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3014 - accuracy: 0.1161 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3005 - accuracy: 0.1169 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3000 - accuracy: 0.1155 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.2997 - accuracy: 0.1176 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.2992 - accuracy: 0.1169 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.2984 - accuracy: 0.1196 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.2966 - accuracy: 0.1286 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.2936 - accuracy: 0.1364 - val_loss: 2.2887 - val_accuracy: 0.1150\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.2855 - accuracy: 0.1502 - val_loss: 2.2638 - val_accuracy: 0.2032\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.2630 - accuracy: 0.1694 - val_loss: 2.1990 - val_accuracy: 0.2102\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.2179 - accuracy: 0.1767 - val_loss: 2.1158 - val_accuracy: 0.2226\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.1707 - accuracy: 0.1852 - val_loss: 2.0302 - val_accuracy: 0.2253\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.1016 - accuracy: 0.2072 - val_loss: 1.9716 - val_accuracy: 0.2383\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.0298 - accuracy: 0.2267 - val_loss: 1.8924 - val_accuracy: 0.2543\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.9613 - accuracy: 0.2444 - val_loss: 1.8352 - val_accuracy: 0.2812\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.8843 - accuracy: 0.2640 - val_loss: 1.7460 - val_accuracy: 0.3043\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.8244 - accuracy: 0.2754 - val_loss: 1.6887 - val_accuracy: 0.3188\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.7556 - accuracy: 0.2901 - val_loss: 1.6313 - val_accuracy: 0.3607\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.7102 - accuracy: 0.2984 - val_loss: 1.5480 - val_accuracy: 0.3814\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.6549 - accuracy: 0.3096 - val_loss: 1.5167 - val_accuracy: 0.3865\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.6111 - accuracy: 0.3133 - val_loss: 1.4391 - val_accuracy: 0.4057\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.5814 - accuracy: 0.3198 - val_loss: 1.4152 - val_accuracy: 0.4098\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.5585 - accuracy: 0.3280 - val_loss: 1.3935 - val_accuracy: 0.4137\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.5308 - accuracy: 0.3265 - val_loss: 1.3634 - val_accuracy: 0.4068\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4969 - accuracy: 0.3384 - val_loss: 1.3435 - val_accuracy: 0.4016\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.4741 - accuracy: 0.3428 - val_loss: 1.3522 - val_accuracy: 0.4058\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4633 - accuracy: 0.3474 - val_loss: 1.2967 - val_accuracy: 0.3983\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.4420 - accuracy: 0.3541 - val_loss: 1.2878 - val_accuracy: 0.4042\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4175 - accuracy: 0.3531 - val_loss: 1.2875 - val_accuracy: 0.4127\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4182 - accuracy: 0.3599 - val_loss: 1.2673 - val_accuracy: 0.4203\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3997 - accuracy: 0.3593 - val_loss: 1.2665 - val_accuracy: 0.4232\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3872 - accuracy: 0.3590 - val_loss: 1.2564 - val_accuracy: 0.3997\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3705 - accuracy: 0.3720 - val_loss: 1.2568 - val_accuracy: 0.4201\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3688 - accuracy: 0.3726 - val_loss: 1.2308 - val_accuracy: 0.4375\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3585 - accuracy: 0.3745 - val_loss: 1.2356 - val_accuracy: 0.4173\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3506 - accuracy: 0.3737 - val_loss: 1.2240 - val_accuracy: 0.4052\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3297 - accuracy: 0.3716 - val_loss: 1.2216 - val_accuracy: 0.4062\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3484 - accuracy: 0.3733 - val_loss: 1.2188 - val_accuracy: 0.4142\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3258 - accuracy: 0.3768 - val_loss: 1.2051 - val_accuracy: 0.4053\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3338 - accuracy: 0.3725 - val_loss: 1.2063 - val_accuracy: 0.4479\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2973 - accuracy: 0.3860 - val_loss: 1.2352 - val_accuracy: 0.4411\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3000 - accuracy: 0.3794 - val_loss: 1.2003 - val_accuracy: 0.4330\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3348 - accuracy: 0.3775 - val_loss: 1.2035 - val_accuracy: 0.4426\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.2890 - accuracy: 0.3880 - val_loss: 1.2186 - val_accuracy: 0.4230\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.2889 - accuracy: 0.3788 - val_loss: 1.1868 - val_accuracy: 0.4159\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2808 - accuracy: 0.3821 - val_loss: 1.2271 - val_accuracy: 0.3778\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.2850 - accuracy: 0.3802 - val_loss: 1.2070 - val_accuracy: 0.4151\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.2652 - accuracy: 0.3873 - val_loss: 1.2131 - val_accuracy: 0.4232\n",
            "\n",
            "Training with -->leaky-relu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 7s 11ms/step - loss: 2.3030 - accuracy: 0.1084 - val_loss: 2.3007 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.2987 - accuracy: 0.1352 - val_loss: 2.2915 - val_accuracy: 0.1849\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.2865 - accuracy: 0.1569 - val_loss: 2.2217 - val_accuracy: 0.2038\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.2289 - accuracy: 0.1901 - val_loss: 2.0743 - val_accuracy: 0.2122\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.1423 - accuracy: 0.2008 - val_loss: 2.0054 - val_accuracy: 0.2247\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.0708 - accuracy: 0.2169 - val_loss: 1.9336 - val_accuracy: 0.2407\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.0167 - accuracy: 0.2294 - val_loss: 1.8812 - val_accuracy: 0.2641\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.9567 - accuracy: 0.2451 - val_loss: 1.8296 - val_accuracy: 0.2895\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.9156 - accuracy: 0.2593 - val_loss: 1.7742 - val_accuracy: 0.3262\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.8666 - accuracy: 0.2662 - val_loss: 1.7197 - val_accuracy: 0.3467\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.8097 - accuracy: 0.2810 - val_loss: 1.6734 - val_accuracy: 0.3556\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.7699 - accuracy: 0.2930 - val_loss: 1.6473 - val_accuracy: 0.3568\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.7211 - accuracy: 0.3105 - val_loss: 1.5716 - val_accuracy: 0.3873\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.6823 - accuracy: 0.3195 - val_loss: 1.5075 - val_accuracy: 0.4053\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.6247 - accuracy: 0.3290 - val_loss: 1.4567 - val_accuracy: 0.4215\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.5942 - accuracy: 0.3417 - val_loss: 1.3901 - val_accuracy: 0.4155\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.5414 - accuracy: 0.3566 - val_loss: 1.3553 - val_accuracy: 0.4608\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.4990 - accuracy: 0.3636 - val_loss: 1.3193 - val_accuracy: 0.4692\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4628 - accuracy: 0.3799 - val_loss: 1.2621 - val_accuracy: 0.4701\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.4157 - accuracy: 0.3978 - val_loss: 1.2213 - val_accuracy: 0.5008\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3882 - accuracy: 0.4129 - val_loss: 1.1787 - val_accuracy: 0.5372\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3319 - accuracy: 0.4273 - val_loss: 1.1540 - val_accuracy: 0.5499\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3013 - accuracy: 0.4335 - val_loss: 1.0832 - val_accuracy: 0.5560\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.2704 - accuracy: 0.4560 - val_loss: 1.0556 - val_accuracy: 0.5702\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.2262 - accuracy: 0.4738 - val_loss: 1.0163 - val_accuracy: 0.5698\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1951 - accuracy: 0.4920 - val_loss: 0.9922 - val_accuracy: 0.5796\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.1617 - accuracy: 0.5004 - val_loss: 0.9946 - val_accuracy: 0.5901\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1471 - accuracy: 0.5193 - val_loss: 0.9521 - val_accuracy: 0.5732\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1016 - accuracy: 0.5325 - val_loss: 0.9225 - val_accuracy: 0.6187\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.0763 - accuracy: 0.5458 - val_loss: 0.8988 - val_accuracy: 0.6290\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0562 - accuracy: 0.5607 - val_loss: 0.8618 - val_accuracy: 0.6689\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0194 - accuracy: 0.5775 - val_loss: 0.8067 - val_accuracy: 0.6985\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.9787 - accuracy: 0.5970 - val_loss: 0.7669 - val_accuracy: 0.6724\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.9433 - accuracy: 0.6166 - val_loss: 0.7243 - val_accuracy: 0.6823\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.9043 - accuracy: 0.6343 - val_loss: 0.7093 - val_accuracy: 0.7082\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.8945 - accuracy: 0.6476 - val_loss: 0.6753 - val_accuracy: 0.7113\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8659 - accuracy: 0.6529 - val_loss: 0.6635 - val_accuracy: 0.6995\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.8542 - accuracy: 0.6693 - val_loss: 0.6482 - val_accuracy: 0.7310\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.8223 - accuracy: 0.6808 - val_loss: 0.6152 - val_accuracy: 0.7940\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.8063 - accuracy: 0.6949 - val_loss: 0.5897 - val_accuracy: 0.8316\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7915 - accuracy: 0.7090 - val_loss: 0.5783 - val_accuracy: 0.8398\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7501 - accuracy: 0.7245 - val_loss: 0.5454 - val_accuracy: 0.8413\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7478 - accuracy: 0.7367 - val_loss: 0.5112 - val_accuracy: 0.8501\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7277 - accuracy: 0.7462 - val_loss: 0.4656 - val_accuracy: 0.8602\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7078 - accuracy: 0.7519 - val_loss: 0.4729 - val_accuracy: 0.8553\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6809 - accuracy: 0.7682 - val_loss: 0.4120 - val_accuracy: 0.8634\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6535 - accuracy: 0.7774 - val_loss: 0.4084 - val_accuracy: 0.8654\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6583 - accuracy: 0.7846 - val_loss: 0.4013 - val_accuracy: 0.8680\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6257 - accuracy: 0.7932 - val_loss: 0.3801 - val_accuracy: 0.8715\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5987 - accuracy: 0.7998 - val_loss: 0.3664 - val_accuracy: 0.8716\n",
            "\n",
            "Training with -->elu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 6s 10ms/step - loss: 2.2403 - accuracy: 0.1743 - val_loss: 1.2407 - val_accuracy: 0.6228\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.6746 - accuracy: 0.3913 - val_loss: 0.7965 - val_accuracy: 0.8048\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.3818 - accuracy: 0.5049 - val_loss: 0.6106 - val_accuracy: 0.8460\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2106 - accuracy: 0.5827 - val_loss: 0.5298 - val_accuracy: 0.8679\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0859 - accuracy: 0.6298 - val_loss: 0.4728 - val_accuracy: 0.8805\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0113 - accuracy: 0.6659 - val_loss: 0.4390 - val_accuracy: 0.8898\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.9480 - accuracy: 0.6950 - val_loss: 0.4111 - val_accuracy: 0.8953\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9030 - accuracy: 0.7159 - val_loss: 0.3919 - val_accuracy: 0.9001\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8518 - accuracy: 0.7318 - val_loss: 0.3704 - val_accuracy: 0.9056\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8270 - accuracy: 0.7482 - val_loss: 0.3561 - val_accuracy: 0.9097\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.8038 - accuracy: 0.7585 - val_loss: 0.3436 - val_accuracy: 0.9120\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7797 - accuracy: 0.7699 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7436 - accuracy: 0.7800 - val_loss: 0.3206 - val_accuracy: 0.9163\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7314 - accuracy: 0.7905 - val_loss: 0.3115 - val_accuracy: 0.9186\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7227 - accuracy: 0.7960 - val_loss: 0.3089 - val_accuracy: 0.9207\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6955 - accuracy: 0.8046 - val_loss: 0.2983 - val_accuracy: 0.9208\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6690 - accuracy: 0.8126 - val_loss: 0.2881 - val_accuracy: 0.9259\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6575 - accuracy: 0.8180 - val_loss: 0.2815 - val_accuracy: 0.9271\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6388 - accuracy: 0.8261 - val_loss: 0.2756 - val_accuracy: 0.9286\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6219 - accuracy: 0.8304 - val_loss: 0.2685 - val_accuracy: 0.9307\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6213 - accuracy: 0.8360 - val_loss: 0.2605 - val_accuracy: 0.9337\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5994 - accuracy: 0.8409 - val_loss: 0.2599 - val_accuracy: 0.9358\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5871 - accuracy: 0.8429 - val_loss: 0.2612 - val_accuracy: 0.9352\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5798 - accuracy: 0.8496 - val_loss: 0.2549 - val_accuracy: 0.9342\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.5627 - accuracy: 0.8540 - val_loss: 0.2502 - val_accuracy: 0.9361\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5421 - accuracy: 0.8598 - val_loss: 0.2413 - val_accuracy: 0.9415\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5426 - accuracy: 0.8595 - val_loss: 0.2364 - val_accuracy: 0.9413\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5484 - accuracy: 0.8608 - val_loss: 0.2377 - val_accuracy: 0.9423\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5217 - accuracy: 0.8678 - val_loss: 0.2309 - val_accuracy: 0.9417\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5176 - accuracy: 0.8681 - val_loss: 0.2285 - val_accuracy: 0.9446\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5197 - accuracy: 0.8702 - val_loss: 0.2262 - val_accuracy: 0.9446\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5114 - accuracy: 0.8721 - val_loss: 0.2304 - val_accuracy: 0.9448\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.5065 - accuracy: 0.8745 - val_loss: 0.2244 - val_accuracy: 0.9456\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4821 - accuracy: 0.8814 - val_loss: 0.2174 - val_accuracy: 0.9468\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4749 - accuracy: 0.8806 - val_loss: 0.2147 - val_accuracy: 0.9482\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4798 - accuracy: 0.8829 - val_loss: 0.2141 - val_accuracy: 0.9492\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4707 - accuracy: 0.8837 - val_loss: 0.2179 - val_accuracy: 0.9488\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4561 - accuracy: 0.8878 - val_loss: 0.2110 - val_accuracy: 0.9504\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4589 - accuracy: 0.8865 - val_loss: 0.2151 - val_accuracy: 0.9505\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4553 - accuracy: 0.8869 - val_loss: 0.2148 - val_accuracy: 0.9498\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4445 - accuracy: 0.8895 - val_loss: 0.2114 - val_accuracy: 0.9504\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4452 - accuracy: 0.8919 - val_loss: 0.2030 - val_accuracy: 0.9516\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4434 - accuracy: 0.8945 - val_loss: 0.1972 - val_accuracy: 0.9540\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4303 - accuracy: 0.8959 - val_loss: 0.1963 - val_accuracy: 0.9543\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4185 - accuracy: 0.8978 - val_loss: 0.2007 - val_accuracy: 0.9540\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4316 - accuracy: 0.8927 - val_loss: 0.1973 - val_accuracy: 0.9557\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4113 - accuracy: 0.9008 - val_loss: 0.1955 - val_accuracy: 0.9552\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4077 - accuracy: 0.9018 - val_loss: 0.1895 - val_accuracy: 0.9550\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4073 - accuracy: 0.9028 - val_loss: 0.1897 - val_accuracy: 0.9565\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4020 - accuracy: 0.9033 - val_loss: 0.2019 - val_accuracy: 0.9545\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 7s 11ms/step - loss: 2.6934 - accuracy: 0.0987 - val_loss: 2.4038 - val_accuracy: 0.1306\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.4880 - accuracy: 0.0978 - val_loss: 2.3392 - val_accuracy: 0.1251\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.4067 - accuracy: 0.0967 - val_loss: 2.3042 - val_accuracy: 0.1218\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.3608 - accuracy: 0.1024 - val_loss: 2.2897 - val_accuracy: 0.1238\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3341 - accuracy: 0.1017 - val_loss: 2.2851 - val_accuracy: 0.1448\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3231 - accuracy: 0.1021 - val_loss: 2.2849 - val_accuracy: 0.1667\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3167 - accuracy: 0.1016 - val_loss: 2.2873 - val_accuracy: 0.1472\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3103 - accuracy: 0.1029 - val_loss: 2.2888 - val_accuracy: 0.1397\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3059 - accuracy: 0.1078 - val_loss: 2.2902 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3048 - accuracy: 0.1098 - val_loss: 2.2918 - val_accuracy: 0.1063\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 2.3040 - accuracy: 0.1106 - val_loss: 2.2938 - val_accuracy: 0.1062\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3023 - accuracy: 0.1106 - val_loss: 2.2947 - val_accuracy: 0.1130\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3024 - accuracy: 0.1089 - val_loss: 2.2948 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 2.3020 - accuracy: 0.1122 - val_loss: 2.2971 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3021 - accuracy: 0.1120 - val_loss: 2.2977 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3018 - accuracy: 0.1127 - val_loss: 2.2989 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3015 - accuracy: 0.1135 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3015 - accuracy: 0.1121 - val_loss: 2.2994 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3013 - accuracy: 0.1117 - val_loss: 2.2978 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.2971 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3010 - accuracy: 0.1146 - val_loss: 2.2989 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3012 - accuracy: 0.1153 - val_loss: 2.2983 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3015 - accuracy: 0.1121 - val_loss: 2.2997 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3014 - accuracy: 0.1137 - val_loss: 2.2986 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3015 - accuracy: 0.1116 - val_loss: 2.2994 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3012 - accuracy: 0.1138 - val_loss: 2.3005 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1138 - val_loss: 2.3002 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1126 - val_loss: 2.2978 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3012 - accuracy: 0.1141 - val_loss: 2.2978 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.2998 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3006 - accuracy: 0.1153 - val_loss: 2.2977 - val_accuracy: 0.1205\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3015 - accuracy: 0.1141 - val_loss: 2.2999 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3009 - accuracy: 0.1151 - val_loss: 2.2999 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3012 - accuracy: 0.1136 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3016 - accuracy: 0.1126 - val_loss: 2.3000 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3018 - accuracy: 0.1127 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3012 - accuracy: 0.1119 - val_loss: 2.3006 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.2997 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.2990 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 2.3009 - accuracy: 0.1153 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3009 - accuracy: 0.1153 - val_loss: 2.2989 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3010 - accuracy: 0.1159 - val_loss: 2.2989 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3013 - accuracy: 0.1151 - val_loss: 2.2989 - val_accuracy: 0.1105\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1127 - val_loss: 2.2984 - val_accuracy: 0.1110\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.2971 - val_accuracy: 0.1075\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3013 - accuracy: 0.1149 - val_loss: 2.2963 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3009 - accuracy: 0.1166 - val_loss: 2.2970 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.2983 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3013 - accuracy: 0.1134 - val_loss: 2.2999 - val_accuracy: 0.1062\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3016 - accuracy: 0.1137 - val_loss: 2.2990 - val_accuracy: 0.1087\n",
            "\n",
            "Training with -->gelu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 8s 13ms/step - loss: 2.3022 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3014 - accuracy: 0.1130 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1138 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3012 - accuracy: 0.1132 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3007 - accuracy: 0.1157 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3008 - accuracy: 0.1159 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3006 - accuracy: 0.1154 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1127 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3009 - accuracy: 0.1154 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3005 - accuracy: 0.1167 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1128 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3009 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3007 - accuracy: 0.1145 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3013 - accuracy: 0.1116 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3007 - accuracy: 0.1150 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3007 - accuracy: 0.1146 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3013 - accuracy: 0.1119 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1118 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3012 - accuracy: 0.1116 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3013 - accuracy: 0.1122 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3004 - accuracy: 0.1159 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3008 - accuracy: 0.1144 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3011 - accuracy: 0.1131 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3005 - accuracy: 0.1160 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3006 - accuracy: 0.1152 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3008 - accuracy: 0.1151 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3009 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3008 - accuracy: 0.1145 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3008 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1133 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3008 - accuracy: 0.1128 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3009 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3006 - accuracy: 0.1148 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3004 - accuracy: 0.1150 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3009 - accuracy: 0.1140 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3009 - accuracy: 0.1128 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3007 - accuracy: 0.1148 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3004 - accuracy: 0.1149 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.3008 - accuracy: 0.1141 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.3004 - accuracy: 0.1171 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3005 - accuracy: 0.1135 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.3005 - accuracy: 0.1140 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3005 - accuracy: 0.1142 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3010 - accuracy: 0.1116 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.3005 - accuracy: 0.1125 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
            "\n",
            "Training with -->swish<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 7s 11ms/step - loss: 2.3023 - accuracy: 0.1136 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3017 - accuracy: 0.1116 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3012 - accuracy: 0.1149 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3005 - accuracy: 0.1182 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3007 - accuracy: 0.1149 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3011 - accuracy: 0.1150 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3007 - accuracy: 0.1148 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3005 - accuracy: 0.1166 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3007 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3010 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3009 - accuracy: 0.1145 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3012 - accuracy: 0.1111 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3007 - accuracy: 0.1162 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3008 - accuracy: 0.1148 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3006 - accuracy: 0.1161 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1146 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3011 - accuracy: 0.1142 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3004 - accuracy: 0.1152 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3008 - accuracy: 0.1162 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3006 - accuracy: 0.1161 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3009 - accuracy: 0.1135 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3009 - accuracy: 0.1136 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3006 - accuracy: 0.1172 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3006 - accuracy: 0.1146 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3008 - accuracy: 0.1151 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1119 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3008 - accuracy: 0.1133 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3005 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3006 - accuracy: 0.1160 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3007 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3004 - accuracy: 0.1167 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3011 - accuracy: 0.1132 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3005 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3008 - accuracy: 0.1148 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3007 - accuracy: 0.1157 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3006 - accuracy: 0.1155 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3003 - accuracy: 0.1160 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1118 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3007 - accuracy: 0.1147 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3006 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3006 - accuracy: 0.1121 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3011 - accuracy: 0.1120 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
            "{'loss': [2.4180514812469482, 2.3771867752075195, 2.3558106422424316, 2.3409581184387207, 2.335582733154297, 2.328428030014038, 2.325183391571045, 2.3204619884490967, 2.317746162414551, 2.3165714740753174, 2.3156371116638184, 2.3127126693725586, 2.3118996620178223, 2.310551166534424, 2.311474084854126, 2.308199882507324, 2.307432174682617, 2.307685375213623, 2.3077096939086914, 2.3070592880249023, 2.306887626647949, 2.3066329956054688, 2.306880474090576, 2.305609703063965, 2.3051726818084717, 2.3043460845947266, 2.3055918216705322, 2.3045666217803955, 2.304299831390381, 2.3043034076690674, 2.3045551776885986, 2.303507089614868, 2.3040969371795654, 2.3039653301239014, 2.304328441619873, 2.3031857013702393, 2.302830457687378, 2.3029465675354004, 2.3030264377593994, 2.3034307956695557, 2.303067445755005, 2.303030014038086, 2.303363084793091, 2.3030595779418945, 2.3029286861419678, 2.3028993606567383, 2.302579641342163, 2.3029043674468994, 2.3025777339935303, 2.302558183670044], 'accuracy': [0.09991666674613953, 0.09956250339746475, 0.1002083346247673, 0.10360416769981384, 0.10037499666213989, 0.10181249678134918, 0.10181249678134918, 0.1041041687130928, 0.1042708307504654, 0.10385416448116302, 0.10360416769981384, 0.10366666316986084, 0.10581249743700027, 0.10345833003520966, 0.1028541699051857, 0.10358333587646484, 0.1041458323597908, 0.10249999910593033, 0.10443750023841858, 0.10556250065565109, 0.10493750125169754, 0.10491666942834854, 0.10300000011920929, 0.10656250268220901, 0.10652083158493042, 0.10829166322946548, 0.1054166629910469, 0.10645833611488342, 0.109375, 0.10875000059604645, 0.10818749666213989, 0.10991666465997696, 0.10872916877269745, 0.10925000160932541, 0.10614583641290665, 0.10970833152532578, 0.10945833474397659, 0.11010416597127914, 0.1106041669845581, 0.10972916334867477, 0.1081250011920929, 0.11045833677053452, 0.10972916334867477, 0.11112499982118607, 0.10774999856948853, 0.10883333534002304, 0.1107499971985817, 0.11154166609048843, 0.11233333498239517, 0.11091666668653488], 'val_loss': [2.3035030364990234, 2.302042007446289, 2.302098512649536, 2.3020431995391846, 2.3020145893096924, 2.302016019821167, 2.3020005226135254, 2.3019983768463135, 2.302015781402588, 2.3020524978637695, 2.3020179271698, 2.3020474910736084, 2.3020780086517334, 2.3020479679107666, 2.3020248413085938, 2.3020308017730713, 2.302053928375244, 2.302008628845215, 2.3020293712615967, 2.3020284175872803, 2.30204701423645, 2.3019919395446777, 2.3019919395446777, 2.3020169734954834, 2.3020129203796387, 2.302027463912964, 2.3020269870758057, 2.3020453453063965, 2.3020663261413574, 2.3020713329315186, 2.302060127258301, 2.3020482063293457, 2.302056074142456, 2.3020598888397217, 2.3020474910736084, 2.3020591735839844, 2.302051544189453, 2.3020412921905518, 2.302042007446289, 2.3020739555358887, 2.30208683013916, 2.302088975906372, 2.302060604095459, 2.3020546436309814, 2.3020734786987305, 2.302077531814575, 2.3020637035369873, 2.3020622730255127, 2.302048683166504, 2.302063226699829], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
            "{'loss': [2.1169593334198, 1.732157588005066, 1.5272331237792969, 1.3719804286956787, 1.2389729022979736, 1.1368879079818726, 1.056993842124939, 0.9898824691772461, 0.9461794495582581, 0.9048616290092468, 0.8658319711685181, 0.8406434059143066, 0.8093835711479187, 0.7883294820785522, 0.7723968625068665, 0.7582477927207947, 0.7413539886474609, 0.7162972092628479, 0.7043336629867554, 0.6866115927696228, 0.6739153861999512, 0.6617063283920288, 0.6552097797393799, 0.6382665634155273, 0.6246637105941772, 0.6229401230812073, 0.6144711375236511, 0.6027002334594727, 0.590315043926239, 0.5907870531082153, 0.5738884806632996, 0.5726855993270874, 0.5634618401527405, 0.5575838685035706, 0.5458880066871643, 0.5488362908363342, 0.5442812442779541, 0.5377052426338196, 0.5273231863975525, 0.5182742476463318, 0.5205799341201782, 0.5123401880264282, 0.500868558883667, 0.49438756704330444, 0.5002689957618713, 0.49374374747276306, 0.48728248476982117, 0.47939977049827576, 0.4736035168170929, 0.4751775860786438], 'accuracy': [0.23481249809265137, 0.3947916626930237, 0.4729791581630707, 0.5363541841506958, 0.5950208306312561, 0.6371041536331177, 0.6663333177566528, 0.6948541402816772, 0.7136666774749756, 0.7298750281333923, 0.746958315372467, 0.7589166760444641, 0.7728124856948853, 0.781374990940094, 0.7868333458900452, 0.7959583401679993, 0.8027708530426025, 0.8136249780654907, 0.8185208439826965, 0.8259583115577698, 0.8306458592414856, 0.8364999890327454, 0.8375416398048401, 0.8452708125114441, 0.8495416641235352, 0.8515416383743286, 0.8533333539962769, 0.856374979019165, 0.8599583506584167, 0.8607500195503235, 0.8677916526794434, 0.8684375286102295, 0.8692083358764648, 0.8733958601951599, 0.8753958344459534, 0.8738958239555359, 0.8769166469573975, 0.8785416483879089, 0.8817291855812073, 0.8827499747276306, 0.8836458325386047, 0.8851666450500488, 0.8885416388511658, 0.8904374837875366, 0.8867916464805603, 0.8901875019073486, 0.8931458592414856, 0.8938541412353516, 0.895229160785675, 0.8957708477973938], 'val_loss': [1.4417262077331543, 1.1582372188568115, 0.9609229564666748, 0.8042934536933899, 0.6862697005271912, 0.6099790334701538, 0.5567293167114258, 0.5224307775497437, 0.4941968619823456, 0.47582587599754333, 0.4676907956600189, 0.45501598715782166, 0.43239539861679077, 0.4203340709209442, 0.4074413776397705, 0.40064722299575806, 0.3947744071483612, 0.38454219698905945, 0.3793795108795166, 0.38734593987464905, 0.3739219903945923, 0.3601478636264801, 0.3582471013069153, 0.34549808502197266, 0.34565943479537964, 0.343221515417099, 0.335410475730896, 0.333721399307251, 0.32767826318740845, 0.330474853515625, 0.3329283595085144, 0.3253285586833954, 0.33480480313301086, 0.3062935471534729, 0.30457833409309387, 0.3060948848724365, 0.3008934557437897, 0.30426329374313354, 0.3013770282268524, 0.2917380630970001, 0.3030916452407837, 0.28680506348609924, 0.2886539101600647, 0.28452467918395996, 0.28059518337249756, 0.2756502330303192, 0.27215632796287537, 0.2769773006439209, 0.2775112986564636, 0.2685626447200775], 'val_accuracy': [0.6176666617393494, 0.6677500009536743, 0.7622500061988831, 0.8133333325386047, 0.8429999947547913, 0.8621666431427002, 0.8684999942779541, 0.8711666464805603, 0.8809999823570251, 0.8838333487510681, 0.8846666812896729, 0.8886666893959045, 0.8945000171661377, 0.8979166746139526, 0.9026666879653931, 0.9038333296775818, 0.9051666855812073, 0.9073333144187927, 0.9104999899864197, 0.9099166393280029, 0.9155833125114441, 0.9175000190734863, 0.9184166789054871, 0.9207500219345093, 0.92166668176651, 0.9238333106040955, 0.925083339214325, 0.9264166951179504, 0.9285833239555359, 0.9287499785423279, 0.9282500147819519, 0.9300000071525574, 0.9284999966621399, 0.934499979019165, 0.9354166388511658, 0.9357500076293945, 0.9365833401679993, 0.937250018119812, 0.9370833039283752, 0.9388333559036255, 0.9367499947547913, 0.9409999847412109, 0.9399999976158142, 0.9414166808128357, 0.9427499771118164, 0.9438333511352539, 0.9427499771118164, 0.9435833096504211, 0.9446666836738586, 0.9464166760444641]}\n",
            "{'loss': [2.3034892082214355, 2.3019096851348877, 2.3011698722839355, 2.300602674484253, 2.300156831741333, 2.299901247024536, 2.2990550994873047, 2.2980973720550537, 2.2959206104278564, 2.292022228240967, 2.2811646461486816, 2.253969669342041, 2.2051258087158203, 2.151649236679077, 2.080948829650879, 2.0087313652038574, 1.943532109260559, 1.871352195739746, 1.806755542755127, 1.7445588111877441, 1.6925913095474243, 1.6546121835708618, 1.6037174463272095, 1.5717052221298218, 1.5401835441589355, 1.520303726196289, 1.4956963062286377, 1.4754571914672852, 1.4624391794204712, 1.4456950426101685, 1.4235179424285889, 1.4145543575286865, 1.4012393951416016, 1.3904041051864624, 1.3745243549346924, 1.3678605556488037, 1.359643816947937, 1.3525874614715576, 1.3355368375778198, 1.3423981666564941, 1.3308650255203247, 1.3237248659133911, 1.2988530397415161, 1.3006988763809204, 1.3179017305374146, 1.2909998893737793, 1.2871670722961426, 1.2994095087051392, 1.2798388004302979, 1.2692394256591797], 'accuracy': [0.11362499743700027, 0.11599999666213989, 0.11529166996479034, 0.11577083170413971, 0.11574999988079071, 0.11683333665132523, 0.11833333224058151, 0.12150000035762787, 0.13106249272823334, 0.14129166305065155, 0.156208336353302, 0.17091666162014008, 0.17789582908153534, 0.19202083349227905, 0.2123541682958603, 0.23466666042804718, 0.24964582920074463, 0.26477083563804626, 0.27904167771339417, 0.2920624911785126, 0.30252084136009216, 0.3096874952316284, 0.31177082657814026, 0.3205833435058594, 0.32989582419395447, 0.3310624957084656, 0.33816665410995483, 0.34568750858306885, 0.3463333249092102, 0.35210415720939636, 0.35618749260902405, 0.359312504529953, 0.3580000102519989, 0.36281248927116394, 0.3701041638851166, 0.36937499046325684, 0.3720208406448364, 0.37164583802223206, 0.3738958239555359, 0.374895840883255, 0.3747083246707916, 0.37533333897590637, 0.38229167461395264, 0.3789375126361847, 0.3798333406448364, 0.3825624883174896, 0.3800833225250244, 0.37825000286102295, 0.3838958442211151, 0.38381248712539673], 'val_loss': [2.3019766807556152, 2.3017969131469727, 2.301875591278076, 2.3020360469818115, 2.301940679550171, 2.3018667697906494, 2.302055597305298, 2.300720453262329, 2.298206090927124, 2.2887072563171387, 2.2637879848480225, 2.199030876159668, 2.115752935409546, 2.030210494995117, 1.9716036319732666, 1.8923768997192383, 1.8352214097976685, 1.7459913492202759, 1.68871009349823, 1.6312553882598877, 1.5479923486709595, 1.5167157649993896, 1.4390690326690674, 1.4151638746261597, 1.3935043811798096, 1.363362193107605, 1.3435008525848389, 1.352209448814392, 1.2966854572296143, 1.2877808809280396, 1.2875241041183472, 1.2673002481460571, 1.2664942741394043, 1.2563823461532593, 1.2567739486694336, 1.2307682037353516, 1.2355927228927612, 1.2239582538604736, 1.2216392755508423, 1.218785047531128, 1.2050840854644775, 1.206316590309143, 1.2351531982421875, 1.200264573097229, 1.2034939527511597, 1.2185580730438232, 1.1868419647216797, 1.2270547151565552, 1.2069908380508423, 1.2130831480026245], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.11500000208616257, 0.203166663646698, 0.21016666293144226, 0.2225833386182785, 0.2253333330154419, 0.2382500022649765, 0.25433334708213806, 0.281166672706604, 0.30425000190734863, 0.3188333213329315, 0.3606666624546051, 0.3814166784286499, 0.3865000009536743, 0.40566667914390564, 0.4098333418369293, 0.4137499928474426, 0.40683332085609436, 0.40158334374427795, 0.40575000643730164, 0.398333340883255, 0.40416666865348816, 0.4126666784286499, 0.4203333258628845, 0.4232499897480011, 0.3996666669845581, 0.42008334398269653, 0.4375, 0.41725000739097595, 0.4051666557788849, 0.406166672706604, 0.414249986410141, 0.40533334016799927, 0.4479166567325592, 0.4410833418369293, 0.43299999833106995, 0.4425833225250244, 0.4230000078678131, 0.41591668128967285, 0.3778333365917206, 0.4150833189487457, 0.4231666624546051]}\n",
            "{'loss': [2.3016483783721924, 2.2968482971191406, 2.277860403060913, 2.2056832313537598, 2.122972011566162, 2.05940842628479, 2.0017995834350586, 1.9467746019363403, 1.8999775648117065, 1.8507589101791382, 1.8050874471664429, 1.7582451105117798, 1.71479332447052, 1.670851230621338, 1.6174355745315552, 1.582165241241455, 1.5296558141708374, 1.4878058433532715, 1.4526519775390625, 1.4133630990982056, 1.3729732036590576, 1.337117314338684, 1.298285722732544, 1.2653939723968506, 1.225882887840271, 1.1907576322555542, 1.1622062921524048, 1.136942982673645, 1.101262092590332, 1.0769981145858765, 1.046210527420044, 1.0058062076568604, 0.9758928418159485, 0.9367388486862183, 0.9106494784355164, 0.887876570224762, 0.8620608448982239, 0.845112144947052, 0.8189463019371033, 0.7975025177001953, 0.7898414731025696, 0.7559462785720825, 0.737515389919281, 0.7173448204994202, 0.6940908432006836, 0.6806679368019104, 0.6505674123764038, 0.6405126452445984, 0.6188985109329224, 0.5876151323318481], 'accuracy': [0.11968749761581421, 0.13870833814144135, 0.1626874953508377, 0.1941249966621399, 0.20352083444595337, 0.21916666626930237, 0.23131249845027924, 0.24687500298023224, 0.2602500021457672, 0.27243751287460327, 0.28349998593330383, 0.29870831966400146, 0.3113333284854889, 0.32106250524520874, 0.3333125114440918, 0.34339582920074463, 0.36272916197776794, 0.3698541522026062, 0.3812708258628845, 0.39893749356269836, 0.4153749942779541, 0.4282083213329315, 0.4398125112056732, 0.46018749475479126, 0.47706249356269836, 0.492208331823349, 0.5016041398048401, 0.5206875205039978, 0.531166672706604, 0.5474583506584167, 0.5620833039283752, 0.5838541388511658, 0.6033333539962769, 0.6182916760444641, 0.6367708444595337, 0.6467708349227905, 0.6559791564941406, 0.671999990940094, 0.6846250295639038, 0.6995416879653931, 0.7086874842643738, 0.7249166369438171, 0.7390833497047424, 0.7489583492279053, 0.7603750228881836, 0.7704166769981384, 0.7807916402816772, 0.7864791750907898, 0.7945833206176758, 0.8030624985694885], 'val_loss': [2.3006889820098877, 2.2915496826171875, 2.22171688079834, 2.0743281841278076, 2.0054352283477783, 1.9335726499557495, 1.8811631202697754, 1.8295643329620361, 1.7741725444793701, 1.7196756601333618, 1.6733571290969849, 1.6473456621170044, 1.5715692043304443, 1.5074920654296875, 1.4566692113876343, 1.3901389837265015, 1.355303168296814, 1.319305181503296, 1.2620660066604614, 1.2212917804718018, 1.178698182106018, 1.1540031433105469, 1.0831536054611206, 1.0556185245513916, 1.0162798166275024, 0.9922171831130981, 0.9946131110191345, 0.9520729184150696, 0.9225022792816162, 0.898802638053894, 0.8617527484893799, 0.8067471385002136, 0.7668554782867432, 0.7243249416351318, 0.7093454003334045, 0.6753200888633728, 0.6634828448295593, 0.6481586694717407, 0.6152255535125732, 0.5897067189216614, 0.5783228874206543, 0.5454471707344055, 0.5111532807350159, 0.4656168222427368, 0.47291329503059387, 0.41202402114868164, 0.40835145115852356, 0.401326984167099, 0.38010144233703613, 0.3664443790912628], 'val_accuracy': [0.10599999874830246, 0.1849166601896286, 0.20383332669734955, 0.2121666669845581, 0.22466666996479034, 0.2407499998807907, 0.2640833258628845, 0.28949999809265137, 0.32624998688697815, 0.3466666638851166, 0.3555833399295807, 0.3568333387374878, 0.38725000619888306, 0.40525001287460327, 0.42149999737739563, 0.4154999852180481, 0.460750013589859, 0.46916666626930237, 0.4700833261013031, 0.5008333325386047, 0.5371666550636292, 0.549916684627533, 0.5559999942779541, 0.5701666474342346, 0.5698333382606506, 0.5795833468437195, 0.5900833606719971, 0.5732499957084656, 0.6186666488647461, 0.6290000081062317, 0.668916642665863, 0.6984999775886536, 0.6724166870117188, 0.6823333501815796, 0.7081666588783264, 0.7113333344459534, 0.6995000243186951, 0.7310000061988831, 0.7940000295639038, 0.8315833210945129, 0.8398333191871643, 0.8412500023841858, 0.8500833511352539, 0.8601666688919067, 0.8553333282470703, 0.8634166717529297, 0.8654166460037231, 0.8679999709129333, 0.8715000152587891, 0.8715833425521851]}\n",
            "{'loss': [2.068390130996704, 1.5918796062469482, 1.3303196430206299, 1.1702666282653809, 1.059695839881897, 0.9958142638206482, 0.9353106021881104, 0.8940562605857849, 0.8472820520401001, 0.8172358274459839, 0.7930044531822205, 0.7693247199058533, 0.746004045009613, 0.7267470955848694, 0.7134730815887451, 0.6871808171272278, 0.6690828204154968, 0.6544404029846191, 0.6329231262207031, 0.6181398034095764, 0.6165623664855957, 0.6003475189208984, 0.5866292715072632, 0.580041766166687, 0.5655195116996765, 0.5489062666893005, 0.5401799082756042, 0.5404396653175354, 0.5261529684066772, 0.5203813910484314, 0.5157443284988403, 0.5054613351821899, 0.4992304742336273, 0.4809913635253906, 0.4796908497810364, 0.4784192740917206, 0.47250622510910034, 0.45286479592323303, 0.4560166001319885, 0.45301005244255066, 0.4460327923297882, 0.4409977197647095, 0.4341244399547577, 0.42819181084632874, 0.42210930585861206, 0.4168643355369568, 0.41219356656074524, 0.4170569181442261, 0.4035525321960449, 0.40543150901794434], 'accuracy': [0.24029166996479034, 0.42014583945274353, 0.5246875286102295, 0.5968958139419556, 0.6409375071525574, 0.672166645526886, 0.7011250257492065, 0.7181249856948853, 0.7372708320617676, 0.7502291798591614, 0.7603333592414856, 0.7745833396911621, 0.7808333039283752, 0.7914583086967468, 0.7975833415985107, 0.8082291483879089, 0.8140000104904175, 0.819937527179718, 0.8287500143051147, 0.8328333497047424, 0.8358749747276306, 0.8414791822433472, 0.8411458134651184, 0.8488125205039978, 0.8521875143051147, 0.8570625185966492, 0.8614791631698608, 0.8617291450500488, 0.8666874766349792, 0.8674166798591614, 0.8707083463668823, 0.8731041550636292, 0.8761458396911621, 0.8818958401679993, 0.8807083368301392, 0.882437527179718, 0.8845833539962769, 0.8889999985694885, 0.8876041769981384, 0.8890208601951599, 0.8888541460037231, 0.8928750157356262, 0.8960416913032532, 0.8965208530426025, 0.8973958492279053, 0.8971666693687439, 0.9009374976158142, 0.9004999995231628, 0.9033541679382324, 0.9035833477973938], 'val_loss': [1.2407116889953613, 0.7964687347412109, 0.6106278300285339, 0.5297504663467407, 0.47280794382095337, 0.4389968812465668, 0.4111272394657135, 0.3918699026107788, 0.37044230103492737, 0.35609087347984314, 0.34357646107673645, 0.3282683193683624, 0.3205506503582001, 0.3114832639694214, 0.30887478590011597, 0.2983161211013794, 0.28806832432746887, 0.2814621925354004, 0.2756134569644928, 0.2684820294380188, 0.2604629397392273, 0.25994136929512024, 0.26116684079170227, 0.2549169659614563, 0.2501787841320038, 0.24126780033111572, 0.2364150583744049, 0.23767735064029694, 0.2309478223323822, 0.22852522134780884, 0.226248636841774, 0.2304103821516037, 0.22444091737270355, 0.21739740669727325, 0.21469071507453918, 0.21412554383277893, 0.21793992817401886, 0.2110438197851181, 0.21507558226585388, 0.2147800475358963, 0.21135181188583374, 0.20296816527843475, 0.19721649587154388, 0.1962609589099884, 0.20072735846042633, 0.19732598960399628, 0.1954532265663147, 0.1894850730895996, 0.18966400623321533, 0.2018914371728897], 'val_accuracy': [0.6228333115577698, 0.8047500252723694, 0.8460000157356262, 0.8679166436195374, 0.8805000185966492, 0.8897500038146973, 0.8952500224113464, 0.9000833630561829, 0.9055833220481873, 0.9097499847412109, 0.9120000004768372, 0.9149166941642761, 0.9163333177566528, 0.918583333492279, 0.9206666946411133, 0.9207500219345093, 0.9259166717529297, 0.9270833134651184, 0.9285833239555359, 0.9306666851043701, 0.9336666464805603, 0.9357500076293945, 0.9351666569709778, 0.934166669845581, 0.9360833168029785, 0.9415000081062317, 0.9412500262260437, 0.9423333406448364, 0.9417499899864197, 0.9445833563804626, 0.9445833563804626, 0.9448333382606506, 0.9455833435058594, 0.9468333125114441, 0.9481666684150696, 0.9492499828338623, 0.9487500190734863, 0.9504166841506958, 0.9505000114440918, 0.949833333492279, 0.9504166841506958, 0.9515833258628845, 0.9539999961853027, 0.9543333053588867, 0.9539999961853027, 0.9556666612625122, 0.9551666378974915, 0.9549999833106995, 0.9564999938011169, 0.9545000195503235]}\n",
            "{'loss': [2.6251485347747803, 2.461352825164795, 2.3909335136413574, 2.3535513877868652, 2.3330562114715576, 2.3207955360412598, 2.3141872882843018, 2.3087949752807617, 2.306175708770752, 2.3046329021453857, 2.303746461868286, 2.3024113178253174, 2.3021583557128906, 2.3018276691436768, 2.3018689155578613, 2.3015525341033936, 2.301360845565796, 2.3013455867767334, 2.3012101650238037, 2.301119327545166, 2.30115008354187, 2.30117130279541, 2.3013417720794678, 2.3011386394500732, 2.301283121109009, 2.301163673400879, 2.3012185096740723, 2.301116466522217, 2.3011348247528076, 2.3012561798095703, 2.301039457321167, 2.3012893199920654, 2.3011138439178467, 2.301208972930908, 2.301190137863159, 2.301201105117798, 2.3010482788085938, 2.3011913299560547, 2.301187753677368, 2.3012428283691406, 2.301128387451172, 2.301335096359253, 2.3010666370391846, 2.3011646270751953, 2.3010857105255127, 2.301105499267578, 2.3012754917144775, 2.301097869873047, 2.3010785579681396, 2.301241159439087], 'accuracy': [0.09795833379030228, 0.09920833259820938, 0.09956250339746475, 0.10112500190734863, 0.10114583373069763, 0.10252083092927933, 0.10318750143051147, 0.10389583557844162, 0.10750000178813934, 0.10822916775941849, 0.11095833033323288, 0.11145833134651184, 0.1119583323597908, 0.11352083086967468, 0.11393749713897705, 0.11397916823625565, 0.11383333057165146, 0.11397916823625565, 0.11383333057165146, 0.11391666531562805, 0.11395833641290665, 0.11400000005960464, 0.11391666531562805, 0.11397916823625565, 0.11395833641290665, 0.11395833641290665, 0.11397916823625565, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11393749713897705, 0.11393749713897705, 0.11395833641290665, 0.11404166370630264, 0.11391666531562805, 0.11397916823625565, 0.11397916823625565, 0.11395833641290665, 0.11393749713897705, 0.11404166370630264, 0.11356250196695328, 0.11381249874830246, 0.11354167014360428, 0.11391666531562805, 0.11397916823625565, 0.11391666531562805, 0.11400000005960464], 'val_loss': [2.4038338661193848, 2.3391785621643066, 2.304215431213379, 2.289722442626953, 2.28505539894104, 2.2848751544952393, 2.287294864654541, 2.288846492767334, 2.2902488708496094, 2.2917826175689697, 2.2938075065612793, 2.2947065830230713, 2.2948365211486816, 2.2970855236053467, 2.297680377960205, 2.298915386199951, 2.300752639770508, 2.2993998527526855, 2.297780990600586, 2.2971138954162598, 2.2988603115081787, 2.298306703567505, 2.299741268157959, 2.2986032962799072, 2.299384832382202, 2.300497055053711, 2.300208568572998, 2.297776937484741, 2.297785758972168, 2.2997844219207764, 2.297740936279297, 2.2999210357666016, 2.299947500228882, 2.300353765487671, 2.3000071048736572, 2.3000752925872803, 2.3006343841552734, 2.2997477054595947, 2.2990288734436035, 2.2993407249450684, 2.298851728439331, 2.298942804336548, 2.2988595962524414, 2.2984120845794678, 2.297055721282959, 2.2963130474090576, 2.297044277191162, 2.298326015472412, 2.2998833656311035, 2.299020767211914], 'val_accuracy': [0.13058333098888397, 0.125083327293396, 0.12183333188295364, 0.12383333593606949, 0.14483332633972168, 0.1667499989271164, 0.1471666693687439, 0.13966666162014008, 0.10599999874830246, 0.10625000298023224, 0.10616666823625565, 0.11299999803304672, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.12049999833106995, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.11050000041723251, 0.11100000143051147, 0.10750000178813934, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10616666823625565, 0.10866666585206985]}\n",
            "{'loss': [2.301835775375366, 2.3013086318969727, 2.301072359085083, 2.301138401031494, 2.301053762435913, 2.30112361907959, 2.300985336303711, 2.301029682159424, 2.300942897796631, 2.300992727279663, 2.3009493350982666, 2.3008711338043213, 2.3009426593780518, 2.3009965419769287, 2.300976514816284, 2.300992250442505, 2.3009746074676514, 2.3009192943573, 2.300957679748535, 2.3009798526763916, 2.300900936126709, 2.300896167755127, 2.3008675575256348, 2.3009026050567627, 2.3008956909179688, 2.3008854389190674, 2.3008646965026855, 2.3008110523223877, 2.3008408546447754, 2.300826072692871, 2.3008389472961426, 2.3008275032043457, 2.3008153438568115, 2.300785541534424, 2.3007876873016357, 2.3007867336273193, 2.3007729053497314, 2.3007612228393555, 2.3007562160491943, 2.300752878189087, 2.3007075786590576, 2.3007140159606934, 2.300687551498413, 2.300698757171631, 2.3006742000579834, 2.300633430480957, 2.300647020339966, 2.300624132156372, 2.300612449645996, 2.3006041049957275], 'accuracy': [0.11391666531562805, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.302049398422241, 2.3020012378692627, 2.302039623260498, 2.301994562149048, 2.3020167350769043, 2.301971912384033, 2.302002191543579, 2.3020098209381104, 2.3019750118255615, 2.3019745349884033, 2.30199933052063, 2.302018880844116, 2.3020284175872803, 2.3020434379577637, 2.3020009994506836, 2.3019754886627197, 2.30197811126709, 2.301992893218994, 2.3019680976867676, 2.30191707611084, 2.301939010620117, 2.301949977874756, 2.3019566535949707, 2.3019931316375732, 2.3019511699676514, 2.301884174346924, 2.3018620014190674, 2.3019180297851562, 2.3018877506256104, 2.3018722534179688, 2.301891326904297, 2.3019096851348877, 2.301940679550171, 2.3019421100616455, 2.301891326904297, 2.3018712997436523, 2.301872491836548, 2.301830530166626, 2.3018314838409424, 2.301809549331665, 2.3017983436584473, 2.3017754554748535, 2.3017525672912598, 2.301765203475952, 2.3017263412475586, 2.301753520965576, 2.301750898361206, 2.3016982078552246, 2.3017048835754395, 2.3017027378082275], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
            "{'loss': [2.302072048187256, 2.301417589187622, 2.3011832237243652, 2.3011109828948975, 2.3009965419769287, 2.301032781600952, 2.3009705543518066, 2.301020622253418, 2.300989866256714, 2.3009979724884033, 2.3009328842163086, 2.3009586334228516, 2.300962448120117, 2.3009238243103027, 2.300933599472046, 2.300969123840332, 2.3009538650512695, 2.300930976867676, 2.300943613052368, 2.300926685333252, 2.3009393215179443, 2.300912618637085, 2.300948143005371, 2.300896644592285, 2.3009088039398193, 2.3008968830108643, 2.3009233474731445, 2.300912380218506, 2.3009145259857178, 2.300870418548584, 2.3008718490600586, 2.3008882999420166, 2.3009142875671387, 2.3008806705474854, 2.300882577896118, 2.300844669342041, 2.3008768558502197, 2.3008766174316406, 2.300860643386841, 2.300863027572632, 2.300826072692871, 2.300818920135498, 2.3008480072021484, 2.3008110523223877, 2.300809860229492, 2.3008248805999756, 2.3007657527923584, 2.3007962703704834, 2.3008060455322266, 2.3007969856262207], 'accuracy': [0.11397916823625565, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3020663261413574, 2.3019487857818604, 2.301931858062744, 2.3019297122955322, 2.3019893169403076, 2.3019914627075195, 2.301990509033203, 2.3019838333129883, 2.3019750118255615, 2.301985502243042, 2.3020310401916504, 2.302032947540283, 2.30204176902771, 2.3020222187042236, 2.302030324935913, 2.301985263824463, 2.301959276199341, 2.3019587993621826, 2.3019723892211914, 2.301997661590576, 2.301975965499878, 2.301995038986206, 2.3019826412200928, 2.301997184753418, 2.301968574523926, 2.3019771575927734, 2.3019821643829346, 2.301974058151245, 2.3019533157348633, 2.3019580841064453, 2.3019773960113525, 2.301936149597168, 2.301936626434326, 2.301941156387329, 2.3019192218780518, 2.30189847946167, 2.3019521236419678, 2.3019626140594482, 2.3019888401031494, 2.30196213722229, 2.3019444942474365, 2.301929235458374, 2.3018746376037598, 2.301849126815796, 2.301901340484619, 2.30191707611084, 2.301919937133789, 2.301887273788452, 2.3018693923950195, 2.3018994331359863], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}