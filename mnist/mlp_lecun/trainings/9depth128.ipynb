{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"9depth128.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnHhSjZec4W6","executionInfo":{"status":"ok","timestamp":1627302204765,"user_tz":-420,"elapsed":992248,"user":{"displayName":"Trung Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjz3Gx8BE3WlqqWlg0FDtKUcK2DEtQ_rPNQD4mLTA=s64","userId":"01683412142186761760"}},"outputId":"8a1099b8-7e46-4c6c-e06a-19375ae7e184"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n","from keras.layers.noise import AlphaDropout\n","from keras.utils.generic_utils import get_custom_objects\n","from keras import backend as K\n","from keras.optimizers import Adam, SGD\n","\n","def preprocess_mnist(x_train, y_train, x_test, y_test):\n","    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n","    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n","    input_shape = (28 * 28,)\n","    \n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    \n","    x_train /= 255\n","    x_test /= 255\n","    \n","    y_train = to_categorical(y_train)\n","    y_test= to_categorical(y_test)\n","    \n","    return x_train, y_train, x_test, y_test, input_shape\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n","\n","def build_cnn(activation,\n","              dropout_rate,\n","              optimizer):\n","    model = Sequential()\n","    \n","    if(activation == 'selu'):\n","        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.25))\n","        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(AlphaDropout(0.5))\n","        model.add(Dense(10, activation='softmax'))\n","    else:\n","        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.25))\n","        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(10, activation='softmax'))\n","    \n","    model.compile(\n","        loss='categorical_crossentropy', \n","        optimizer=optimizer, \n","        metrics=['accuracy']\n","    )\n","    \n","    return model\n","\n","\n","def gelu(x):\n","    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n","get_custom_objects().update({'gelu': Activation(gelu)})\n","\n","def swish(x):\n","    return x * tf.sigmoid(x)\n","get_custom_objects().update({'swish': Activation(swish)})\n","\n","get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n","\n","act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n","\n","result = []\n","\n","\n","for activation in act_func:\n","    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n","    \n","    model = build_cnn(activation=activation,\n","                      dropout_rate=0.2,\n","                      optimizer=SGD())\n","    \n","    history = model.fit(x_train, y_train,\n","          validation_split=0.20,\n","          batch_size=128,\n","          epochs=50,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","    \n","    result.append(history)\n","    \n","    K.clear_session()\n","    del model\n","\n","for r in result:\n","    print(r.history)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","\n","Training with -->sigmoid<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 20s 7ms/step - loss: 2.5509 - accuracy: 0.0974 - val_loss: 2.3052 - val_accuracy: 0.1060\n","Epoch 2/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3879 - accuracy: 0.1031 - val_loss: 2.3025 - val_accuracy: 0.1060\n","Epoch 3/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3563 - accuracy: 0.1034 - val_loss: 2.3024 - val_accuracy: 0.1060\n","Epoch 4/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3427 - accuracy: 0.1019 - val_loss: 2.3023 - val_accuracy: 0.1060\n","Epoch 5/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3355 - accuracy: 0.1022 - val_loss: 2.3022 - val_accuracy: 0.1060\n","Epoch 6/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3273 - accuracy: 0.1038 - val_loss: 2.3022 - val_accuracy: 0.1060\n","Epoch 7/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3201 - accuracy: 0.1067 - val_loss: 2.3022 - val_accuracy: 0.1060\n","Epoch 8/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3206 - accuracy: 0.1027 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 9/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3162 - accuracy: 0.1026 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 10/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3152 - accuracy: 0.1037 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 11/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3156 - accuracy: 0.1032 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 12/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3103 - accuracy: 0.1067 - val_loss: 2.3022 - val_accuracy: 0.1060\n","Epoch 13/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3100 - accuracy: 0.1028 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 14/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3098 - accuracy: 0.1040 - val_loss: 2.3020 - val_accuracy: 0.1060\n","Epoch 15/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3086 - accuracy: 0.1039 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 16/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3078 - accuracy: 0.1069 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 17/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3075 - accuracy: 0.1060 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 18/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3062 - accuracy: 0.1062 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 19/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3068 - accuracy: 0.1058 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 20/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3075 - accuracy: 0.1048 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 21/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3056 - accuracy: 0.1039 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 22/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3055 - accuracy: 0.1068 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 23/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3059 - accuracy: 0.1029 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 24/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3042 - accuracy: 0.1080 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 25/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3038 - accuracy: 0.1086 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 26/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3050 - accuracy: 0.1072 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 27/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3037 - accuracy: 0.1107 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 28/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3036 - accuracy: 0.1091 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 29/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3037 - accuracy: 0.1066 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 30/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3048 - accuracy: 0.1070 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 31/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3042 - accuracy: 0.1090 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 32/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3033 - accuracy: 0.1074 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 33/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3035 - accuracy: 0.1083 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 34/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3039 - accuracy: 0.1085 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 35/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3027 - accuracy: 0.1108 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 36/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3037 - accuracy: 0.1088 - val_loss: 2.3022 - val_accuracy: 0.1060\n","Epoch 37/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.1100 - val_loss: 2.3022 - val_accuracy: 0.1060\n","Epoch 38/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3028 - accuracy: 0.1110 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 39/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3029 - accuracy: 0.1109 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 40/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.1096 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 41/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3020 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 42/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.1089 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 43/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3022 - accuracy: 0.1109 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 44/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3019 - accuracy: 0.1136 - val_loss: 2.3020 - val_accuracy: 0.1060\n","Epoch 45/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3030 - accuracy: 0.1091 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 46/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.1095 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 47/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3025 - accuracy: 0.1089 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 48/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3017 - accuracy: 0.1121 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 49/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3024 - accuracy: 0.1122 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 50/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3016 - accuracy: 0.1112 - val_loss: 2.3021 - val_accuracy: 0.1060\n","\n","Training with -->tanh<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 4s 6ms/step - loss: 2.0726 - accuracy: 0.2462 - val_loss: 1.1426 - val_accuracy: 0.7065\n","Epoch 2/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.4826 - accuracy: 0.4881 - val_loss: 0.8645 - val_accuracy: 0.7993\n","Epoch 3/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.2551 - accuracy: 0.5715 - val_loss: 0.7096 - val_accuracy: 0.8303\n","Epoch 4/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.1244 - accuracy: 0.6291 - val_loss: 0.6215 - val_accuracy: 0.8465\n","Epoch 5/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.0162 - accuracy: 0.6655 - val_loss: 0.5597 - val_accuracy: 0.8542\n","Epoch 6/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9568 - accuracy: 0.6919 - val_loss: 0.5270 - val_accuracy: 0.8577\n","Epoch 7/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.8920 - accuracy: 0.7165 - val_loss: 0.4973 - val_accuracy: 0.8637\n","Epoch 8/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.8567 - accuracy: 0.7336 - val_loss: 0.4763 - val_accuracy: 0.8697\n","Epoch 9/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.8281 - accuracy: 0.7430 - val_loss: 0.4607 - val_accuracy: 0.8717\n","Epoch 10/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7960 - accuracy: 0.7606 - val_loss: 0.4431 - val_accuracy: 0.8802\n","Epoch 11/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7729 - accuracy: 0.7688 - val_loss: 0.4230 - val_accuracy: 0.8877\n","Epoch 12/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7529 - accuracy: 0.7787 - val_loss: 0.4062 - val_accuracy: 0.8923\n","Epoch 13/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7402 - accuracy: 0.7889 - val_loss: 0.3970 - val_accuracy: 0.8972\n","Epoch 14/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7075 - accuracy: 0.7980 - val_loss: 0.3859 - val_accuracy: 0.9008\n","Epoch 15/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6967 - accuracy: 0.8052 - val_loss: 0.3764 - val_accuracy: 0.9049\n","Epoch 16/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6799 - accuracy: 0.8126 - val_loss: 0.3675 - val_accuracy: 0.9068\n","Epoch 17/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6707 - accuracy: 0.8176 - val_loss: 0.3550 - val_accuracy: 0.9103\n","Epoch 18/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6582 - accuracy: 0.8220 - val_loss: 0.3615 - val_accuracy: 0.9106\n","Epoch 19/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6348 - accuracy: 0.8302 - val_loss: 0.3489 - val_accuracy: 0.9139\n","Epoch 20/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.6259 - accuracy: 0.8363 - val_loss: 0.3430 - val_accuracy: 0.9153\n","Epoch 21/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6246 - accuracy: 0.8355 - val_loss: 0.3403 - val_accuracy: 0.9161\n","Epoch 22/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6189 - accuracy: 0.8409 - val_loss: 0.3284 - val_accuracy: 0.9196\n","Epoch 23/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5983 - accuracy: 0.8473 - val_loss: 0.3280 - val_accuracy: 0.9193\n","Epoch 24/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5957 - accuracy: 0.8476 - val_loss: 0.3169 - val_accuracy: 0.9233\n","Epoch 25/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5776 - accuracy: 0.8532 - val_loss: 0.3146 - val_accuracy: 0.9241\n","Epoch 26/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5804 - accuracy: 0.8532 - val_loss: 0.3106 - val_accuracy: 0.9247\n","Epoch 27/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5598 - accuracy: 0.8608 - val_loss: 0.3092 - val_accuracy: 0.9266\n","Epoch 28/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5520 - accuracy: 0.8630 - val_loss: 0.3038 - val_accuracy: 0.9277\n","Epoch 29/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5474 - accuracy: 0.8622 - val_loss: 0.3041 - val_accuracy: 0.9283\n","Epoch 30/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5314 - accuracy: 0.8661 - val_loss: 0.2970 - val_accuracy: 0.9298\n","Epoch 31/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5319 - accuracy: 0.8677 - val_loss: 0.2916 - val_accuracy: 0.9310\n","Epoch 32/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5382 - accuracy: 0.8678 - val_loss: 0.2918 - val_accuracy: 0.9307\n","Epoch 33/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5186 - accuracy: 0.8715 - val_loss: 0.2878 - val_accuracy: 0.9327\n","Epoch 34/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5178 - accuracy: 0.8732 - val_loss: 0.2821 - val_accuracy: 0.9341\n","Epoch 35/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5093 - accuracy: 0.8765 - val_loss: 0.2821 - val_accuracy: 0.9342\n","Epoch 36/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5010 - accuracy: 0.8762 - val_loss: 0.2779 - val_accuracy: 0.9356\n","Epoch 37/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5105 - accuracy: 0.8741 - val_loss: 0.2776 - val_accuracy: 0.9351\n","Epoch 38/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5007 - accuracy: 0.8763 - val_loss: 0.2752 - val_accuracy: 0.9355\n","Epoch 39/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4899 - accuracy: 0.8808 - val_loss: 0.2716 - val_accuracy: 0.9375\n","Epoch 40/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4730 - accuracy: 0.8828 - val_loss: 0.2695 - val_accuracy: 0.9379\n","Epoch 41/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4750 - accuracy: 0.8836 - val_loss: 0.2621 - val_accuracy: 0.9402\n","Epoch 42/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4752 - accuracy: 0.8850 - val_loss: 0.2598 - val_accuracy: 0.9403\n","Epoch 43/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4725 - accuracy: 0.8856 - val_loss: 0.2592 - val_accuracy: 0.9417\n","Epoch 44/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4678 - accuracy: 0.8877 - val_loss: 0.2601 - val_accuracy: 0.9401\n","Epoch 45/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4660 - accuracy: 0.8876 - val_loss: 0.2560 - val_accuracy: 0.9424\n","Epoch 46/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4647 - accuracy: 0.8878 - val_loss: 0.2524 - val_accuracy: 0.9428\n","Epoch 47/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4499 - accuracy: 0.8899 - val_loss: 0.2474 - val_accuracy: 0.9439\n","Epoch 48/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4489 - accuracy: 0.8911 - val_loss: 0.2459 - val_accuracy: 0.9449\n","Epoch 49/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4398 - accuracy: 0.8924 - val_loss: 0.2430 - val_accuracy: 0.9458\n","Epoch 50/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4295 - accuracy: 0.8958 - val_loss: 0.2427 - val_accuracy: 0.9455\n","\n","Training with -->relu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 4s 6ms/step - loss: 2.3047 - accuracy: 0.1119 - val_loss: 2.3015 - val_accuracy: 0.1060\n","Epoch 2/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3011 - accuracy: 0.1241 - val_loss: 2.3004 - val_accuracy: 0.1060\n","Epoch 3/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.2990 - accuracy: 0.1254 - val_loss: 2.2976 - val_accuracy: 0.1060\n","Epoch 4/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.2966 - accuracy: 0.1326 - val_loss: 2.2870 - val_accuracy: 0.1062\n","Epoch 5/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.2888 - accuracy: 0.1495 - val_loss: 2.2617 - val_accuracy: 0.1689\n","Epoch 6/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2692 - accuracy: 0.1717 - val_loss: 2.1980 - val_accuracy: 0.2711\n","Epoch 7/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2213 - accuracy: 0.1979 - val_loss: 2.0697 - val_accuracy: 0.3019\n","Epoch 8/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.1257 - accuracy: 0.2236 - val_loss: 1.8327 - val_accuracy: 0.3224\n","Epoch 9/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.9684 - accuracy: 0.2656 - val_loss: 1.6143 - val_accuracy: 0.3652\n","Epoch 10/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.8166 - accuracy: 0.3073 - val_loss: 1.4446 - val_accuracy: 0.4439\n","Epoch 11/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.6903 - accuracy: 0.3410 - val_loss: 1.3138 - val_accuracy: 0.5223\n","Epoch 12/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.5778 - accuracy: 0.3746 - val_loss: 1.2173 - val_accuracy: 0.5487\n","Epoch 13/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.4998 - accuracy: 0.3979 - val_loss: 1.1235 - val_accuracy: 0.6177\n","Epoch 14/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.4330 - accuracy: 0.4231 - val_loss: 1.0575 - val_accuracy: 0.6118\n","Epoch 15/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.3588 - accuracy: 0.4458 - val_loss: 0.9945 - val_accuracy: 0.6568\n","Epoch 16/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.3225 - accuracy: 0.4710 - val_loss: 0.9350 - val_accuracy: 0.6448\n","Epoch 17/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.2745 - accuracy: 0.4842 - val_loss: 0.8998 - val_accuracy: 0.6589\n","Epoch 18/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.2195 - accuracy: 0.5031 - val_loss: 0.8831 - val_accuracy: 0.6519\n","Epoch 19/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.1851 - accuracy: 0.5235 - val_loss: 0.8270 - val_accuracy: 0.6743\n","Epoch 20/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.1590 - accuracy: 0.5273 - val_loss: 0.8065 - val_accuracy: 0.6795\n","Epoch 21/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.1345 - accuracy: 0.5392 - val_loss: 0.7842 - val_accuracy: 0.7214\n","Epoch 22/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.1013 - accuracy: 0.5509 - val_loss: 0.7664 - val_accuracy: 0.6966\n","Epoch 23/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.0925 - accuracy: 0.5531 - val_loss: 0.7523 - val_accuracy: 0.7052\n","Epoch 24/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.0650 - accuracy: 0.5621 - val_loss: 0.7253 - val_accuracy: 0.7387\n","Epoch 25/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.0372 - accuracy: 0.5758 - val_loss: 0.7121 - val_accuracy: 0.7128\n","Epoch 26/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.0155 - accuracy: 0.5891 - val_loss: 0.7058 - val_accuracy: 0.7130\n","Epoch 27/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.9911 - accuracy: 0.5895 - val_loss: 0.6863 - val_accuracy: 0.7563\n","Epoch 28/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9778 - accuracy: 0.5994 - val_loss: 0.6728 - val_accuracy: 0.7639\n","Epoch 29/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9663 - accuracy: 0.6068 - val_loss: 0.6679 - val_accuracy: 0.7586\n","Epoch 30/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9387 - accuracy: 0.6172 - val_loss: 0.6681 - val_accuracy: 0.7307\n","Epoch 31/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9299 - accuracy: 0.6186 - val_loss: 0.6457 - val_accuracy: 0.7633\n","Epoch 32/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9186 - accuracy: 0.6298 - val_loss: 0.6384 - val_accuracy: 0.7707\n","Epoch 33/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9057 - accuracy: 0.6318 - val_loss: 0.6283 - val_accuracy: 0.7676\n","Epoch 34/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8871 - accuracy: 0.6365 - val_loss: 0.6111 - val_accuracy: 0.7818\n","Epoch 35/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8762 - accuracy: 0.6431 - val_loss: 0.6152 - val_accuracy: 0.7686\n","Epoch 36/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8626 - accuracy: 0.6474 - val_loss: 0.6065 - val_accuracy: 0.7804\n","Epoch 37/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8426 - accuracy: 0.6548 - val_loss: 0.5897 - val_accuracy: 0.7875\n","Epoch 38/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8450 - accuracy: 0.6616 - val_loss: 0.6008 - val_accuracy: 0.7680\n","Epoch 39/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8332 - accuracy: 0.6638 - val_loss: 0.5636 - val_accuracy: 0.8066\n","Epoch 40/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8148 - accuracy: 0.6668 - val_loss: 0.5940 - val_accuracy: 0.7672\n","Epoch 41/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8007 - accuracy: 0.6718 - val_loss: 0.5748 - val_accuracy: 0.8000\n","Epoch 42/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7966 - accuracy: 0.6676 - val_loss: 0.5545 - val_accuracy: 0.7975\n","Epoch 43/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7872 - accuracy: 0.6722 - val_loss: 0.5372 - val_accuracy: 0.7919\n","Epoch 44/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7758 - accuracy: 0.6779 - val_loss: 0.5464 - val_accuracy: 0.7805\n","Epoch 45/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7711 - accuracy: 0.6766 - val_loss: 0.5381 - val_accuracy: 0.8004\n","Epoch 46/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7477 - accuracy: 0.6877 - val_loss: 0.5330 - val_accuracy: 0.7923\n","Epoch 47/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7499 - accuracy: 0.6821 - val_loss: 0.5280 - val_accuracy: 0.7897\n","Epoch 48/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7519 - accuracy: 0.6799 - val_loss: 0.5358 - val_accuracy: 0.8010\n","Epoch 49/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7303 - accuracy: 0.6892 - val_loss: 0.5146 - val_accuracy: 0.8033\n","Epoch 50/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.7276 - accuracy: 0.6933 - val_loss: 0.5268 - val_accuracy: 0.7999\n","\n","Training with -->leaky-relu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 5s 7ms/step - loss: 2.3046 - accuracy: 0.1103 - val_loss: 2.2944 - val_accuracy: 0.1225\n","Epoch 2/50\n","375/375 [==============================] - 2s 4ms/step - loss: 2.2929 - accuracy: 0.1487 - val_loss: 2.2587 - val_accuracy: 0.1882\n","Epoch 3/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2606 - accuracy: 0.1825 - val_loss: 2.1342 - val_accuracy: 0.1998\n","Epoch 4/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.1668 - accuracy: 0.2097 - val_loss: 1.9733 - val_accuracy: 0.2991\n","Epoch 5/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.0459 - accuracy: 0.2259 - val_loss: 1.8411 - val_accuracy: 0.3352\n","Epoch 6/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.9349 - accuracy: 0.2542 - val_loss: 1.6789 - val_accuracy: 0.4059\n","Epoch 7/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.7971 - accuracy: 0.3257 - val_loss: 1.4293 - val_accuracy: 0.5056\n","Epoch 8/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.6305 - accuracy: 0.3905 - val_loss: 1.1710 - val_accuracy: 0.5894\n","Epoch 9/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.4508 - accuracy: 0.4527 - val_loss: 0.9992 - val_accuracy: 0.6177\n","Epoch 10/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.3332 - accuracy: 0.4998 - val_loss: 0.9057 - val_accuracy: 0.6457\n","Epoch 11/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.2210 - accuracy: 0.5385 - val_loss: 0.8431 - val_accuracy: 0.6772\n","Epoch 12/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.1481 - accuracy: 0.5684 - val_loss: 0.7920 - val_accuracy: 0.7085\n","Epoch 13/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.0806 - accuracy: 0.5998 - val_loss: 0.7428 - val_accuracy: 0.7835\n","Epoch 14/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.0374 - accuracy: 0.6254 - val_loss: 0.6929 - val_accuracy: 0.8304\n","Epoch 15/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9771 - accuracy: 0.6539 - val_loss: 0.6484 - val_accuracy: 0.8423\n","Epoch 16/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9319 - accuracy: 0.6756 - val_loss: 0.6028 - val_accuracy: 0.8751\n","Epoch 17/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8971 - accuracy: 0.6989 - val_loss: 0.5660 - val_accuracy: 0.8863\n","Epoch 18/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8556 - accuracy: 0.7205 - val_loss: 0.5305 - val_accuracy: 0.8979\n","Epoch 19/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8036 - accuracy: 0.7378 - val_loss: 0.4887 - val_accuracy: 0.9062\n","Epoch 20/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7575 - accuracy: 0.7552 - val_loss: 0.4523 - val_accuracy: 0.9150\n","Epoch 21/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7331 - accuracy: 0.7678 - val_loss: 0.4035 - val_accuracy: 0.9218\n","Epoch 22/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6855 - accuracy: 0.7897 - val_loss: 0.3721 - val_accuracy: 0.9277\n","Epoch 23/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6639 - accuracy: 0.8017 - val_loss: 0.3417 - val_accuracy: 0.9324\n","Epoch 24/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6137 - accuracy: 0.8196 - val_loss: 0.3084 - val_accuracy: 0.9359\n","Epoch 25/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6041 - accuracy: 0.8230 - val_loss: 0.2843 - val_accuracy: 0.9404\n","Epoch 26/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5735 - accuracy: 0.8359 - val_loss: 0.2727 - val_accuracy: 0.9408\n","Epoch 27/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5452 - accuracy: 0.8485 - val_loss: 0.2558 - val_accuracy: 0.9447\n","Epoch 28/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5244 - accuracy: 0.8562 - val_loss: 0.2431 - val_accuracy: 0.9455\n","Epoch 29/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.5095 - accuracy: 0.8603 - val_loss: 0.2367 - val_accuracy: 0.9490\n","Epoch 30/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4690 - accuracy: 0.8730 - val_loss: 0.2227 - val_accuracy: 0.9495\n","Epoch 31/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4524 - accuracy: 0.8793 - val_loss: 0.2129 - val_accuracy: 0.9517\n","Epoch 32/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4623 - accuracy: 0.8782 - val_loss: 0.2163 - val_accuracy: 0.9523\n","Epoch 33/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4323 - accuracy: 0.8833 - val_loss: 0.2137 - val_accuracy: 0.9540\n","Epoch 34/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4162 - accuracy: 0.8895 - val_loss: 0.1978 - val_accuracy: 0.9553\n","Epoch 35/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4051 - accuracy: 0.8911 - val_loss: 0.1964 - val_accuracy: 0.9558\n","Epoch 36/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3962 - accuracy: 0.8935 - val_loss: 0.1864 - val_accuracy: 0.9574\n","Epoch 37/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3894 - accuracy: 0.8984 - val_loss: 0.1903 - val_accuracy: 0.9578\n","Epoch 38/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3631 - accuracy: 0.9050 - val_loss: 0.1830 - val_accuracy: 0.9583\n","Epoch 39/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3629 - accuracy: 0.9053 - val_loss: 0.1840 - val_accuracy: 0.9592\n","Epoch 40/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3612 - accuracy: 0.9058 - val_loss: 0.1824 - val_accuracy: 0.9600\n","Epoch 41/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3427 - accuracy: 0.9104 - val_loss: 0.1825 - val_accuracy: 0.9607\n","Epoch 42/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3366 - accuracy: 0.9124 - val_loss: 0.1799 - val_accuracy: 0.9608\n","Epoch 43/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3315 - accuracy: 0.9125 - val_loss: 0.1823 - val_accuracy: 0.9610\n","Epoch 44/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.3252 - accuracy: 0.9163 - val_loss: 0.1757 - val_accuracy: 0.9611\n","Epoch 45/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3266 - accuracy: 0.9147 - val_loss: 0.1738 - val_accuracy: 0.9620\n","Epoch 46/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3080 - accuracy: 0.9184 - val_loss: 0.1747 - val_accuracy: 0.9630\n","Epoch 47/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3012 - accuracy: 0.9225 - val_loss: 0.1707 - val_accuracy: 0.9627\n","Epoch 48/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.2970 - accuracy: 0.9221 - val_loss: 0.1688 - val_accuracy: 0.9633\n","Epoch 49/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.2882 - accuracy: 0.9246 - val_loss: 0.1685 - val_accuracy: 0.9643\n","Epoch 50/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.2826 - accuracy: 0.9270 - val_loss: 0.1714 - val_accuracy: 0.9639\n","\n","Training with -->elu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 4s 6ms/step - loss: 2.1762 - accuracy: 0.2061 - val_loss: 1.2534 - val_accuracy: 0.6208\n","Epoch 2/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.5724 - accuracy: 0.4413 - val_loss: 0.7904 - val_accuracy: 0.7803\n","Epoch 3/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.2422 - accuracy: 0.5683 - val_loss: 0.5707 - val_accuracy: 0.8426\n","Epoch 4/50\n","375/375 [==============================] - 2s 4ms/step - loss: 1.0454 - accuracy: 0.6463 - val_loss: 0.4662 - val_accuracy: 0.8749\n","Epoch 5/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.9555 - accuracy: 0.6837 - val_loss: 0.4166 - val_accuracy: 0.8898\n","Epoch 6/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8749 - accuracy: 0.7156 - val_loss: 0.3790 - val_accuracy: 0.8976\n","Epoch 7/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.8133 - accuracy: 0.7434 - val_loss: 0.3554 - val_accuracy: 0.9034\n","Epoch 8/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7734 - accuracy: 0.7618 - val_loss: 0.3377 - val_accuracy: 0.9068\n","Epoch 9/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7402 - accuracy: 0.7796 - val_loss: 0.3245 - val_accuracy: 0.9102\n","Epoch 10/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.7211 - accuracy: 0.7864 - val_loss: 0.3088 - val_accuracy: 0.9154\n","Epoch 11/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6848 - accuracy: 0.8005 - val_loss: 0.3015 - val_accuracy: 0.9160\n","Epoch 12/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6651 - accuracy: 0.8091 - val_loss: 0.2893 - val_accuracy: 0.9204\n","Epoch 13/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6540 - accuracy: 0.8131 - val_loss: 0.2853 - val_accuracy: 0.9206\n","Epoch 14/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6365 - accuracy: 0.8174 - val_loss: 0.2743 - val_accuracy: 0.9243\n","Epoch 15/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.6124 - accuracy: 0.8273 - val_loss: 0.2701 - val_accuracy: 0.9265\n","Epoch 16/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5961 - accuracy: 0.8351 - val_loss: 0.2645 - val_accuracy: 0.9273\n","Epoch 17/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5823 - accuracy: 0.8419 - val_loss: 0.2602 - val_accuracy: 0.9280\n","Epoch 18/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5690 - accuracy: 0.8434 - val_loss: 0.2521 - val_accuracy: 0.9292\n","Epoch 19/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5556 - accuracy: 0.8493 - val_loss: 0.2443 - val_accuracy: 0.9318\n","Epoch 20/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5444 - accuracy: 0.8499 - val_loss: 0.2363 - val_accuracy: 0.9352\n","Epoch 21/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5234 - accuracy: 0.8587 - val_loss: 0.2369 - val_accuracy: 0.9336\n","Epoch 22/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5297 - accuracy: 0.8599 - val_loss: 0.2322 - val_accuracy: 0.9354\n","Epoch 23/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5095 - accuracy: 0.8641 - val_loss: 0.2266 - val_accuracy: 0.9370\n","Epoch 24/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.5055 - accuracy: 0.8667 - val_loss: 0.2223 - val_accuracy: 0.9393\n","Epoch 25/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4895 - accuracy: 0.8715 - val_loss: 0.2189 - val_accuracy: 0.9395\n","Epoch 26/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4900 - accuracy: 0.8742 - val_loss: 0.2133 - val_accuracy: 0.9417\n","Epoch 27/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4759 - accuracy: 0.8745 - val_loss: 0.2099 - val_accuracy: 0.9442\n","Epoch 28/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4697 - accuracy: 0.8768 - val_loss: 0.2091 - val_accuracy: 0.9415\n","Epoch 29/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4539 - accuracy: 0.8830 - val_loss: 0.2042 - val_accuracy: 0.9454\n","Epoch 30/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4472 - accuracy: 0.8836 - val_loss: 0.2044 - val_accuracy: 0.9453\n","Epoch 31/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4381 - accuracy: 0.8879 - val_loss: 0.1962 - val_accuracy: 0.9456\n","Epoch 32/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4423 - accuracy: 0.8886 - val_loss: 0.1928 - val_accuracy: 0.9486\n","Epoch 33/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4166 - accuracy: 0.8917 - val_loss: 0.1916 - val_accuracy: 0.9488\n","Epoch 34/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4257 - accuracy: 0.8893 - val_loss: 0.1883 - val_accuracy: 0.9500\n","Epoch 35/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4121 - accuracy: 0.8947 - val_loss: 0.1866 - val_accuracy: 0.9497\n","Epoch 36/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4206 - accuracy: 0.8933 - val_loss: 0.1899 - val_accuracy: 0.9505\n","Epoch 37/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4070 - accuracy: 0.8950 - val_loss: 0.1853 - val_accuracy: 0.9509\n","Epoch 38/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.4034 - accuracy: 0.9006 - val_loss: 0.1840 - val_accuracy: 0.9517\n","Epoch 39/50\n","375/375 [==============================] - 2s 4ms/step - loss: 0.4162 - accuracy: 0.8955 - val_loss: 0.1768 - val_accuracy: 0.9527\n","Epoch 40/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3975 - accuracy: 0.8993 - val_loss: 0.1766 - val_accuracy: 0.9548\n","Epoch 41/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3924 - accuracy: 0.9001 - val_loss: 0.1770 - val_accuracy: 0.9528\n","Epoch 42/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3930 - accuracy: 0.9022 - val_loss: 0.1724 - val_accuracy: 0.9552\n","Epoch 43/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3832 - accuracy: 0.9050 - val_loss: 0.1720 - val_accuracy: 0.9551\n","Epoch 44/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3750 - accuracy: 0.9052 - val_loss: 0.1700 - val_accuracy: 0.9560\n","Epoch 45/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3783 - accuracy: 0.9068 - val_loss: 0.1720 - val_accuracy: 0.9553\n","Epoch 46/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3634 - accuracy: 0.9083 - val_loss: 0.1658 - val_accuracy: 0.9563\n","Epoch 47/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3613 - accuracy: 0.9092 - val_loss: 0.1648 - val_accuracy: 0.9581\n","Epoch 48/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3642 - accuracy: 0.9110 - val_loss: 0.1671 - val_accuracy: 0.9572\n","Epoch 49/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3525 - accuracy: 0.9108 - val_loss: 0.1684 - val_accuracy: 0.9572\n","Epoch 50/50\n","375/375 [==============================] - 2s 5ms/step - loss: 0.3625 - accuracy: 0.9118 - val_loss: 0.1602 - val_accuracy: 0.9592\n","\n","Training with -->selu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 4s 7ms/step - loss: 2.6894 - accuracy: 0.1019 - val_loss: 2.4664 - val_accuracy: 0.1408\n","Epoch 2/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.4885 - accuracy: 0.1025 - val_loss: 2.3819 - val_accuracy: 0.1375\n","Epoch 3/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3956 - accuracy: 0.1019 - val_loss: 2.3399 - val_accuracy: 0.1461\n","Epoch 4/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3551 - accuracy: 0.1006 - val_loss: 2.3167 - val_accuracy: 0.1620\n","Epoch 5/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3290 - accuracy: 0.1046 - val_loss: 2.3064 - val_accuracy: 0.1729\n","Epoch 6/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3209 - accuracy: 0.1046 - val_loss: 2.3006 - val_accuracy: 0.1705\n","Epoch 7/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3133 - accuracy: 0.1022 - val_loss: 2.2969 - val_accuracy: 0.1623\n","Epoch 8/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3089 - accuracy: 0.1060 - val_loss: 2.2948 - val_accuracy: 0.1786\n","Epoch 9/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3068 - accuracy: 0.1046 - val_loss: 2.2943 - val_accuracy: 0.1625\n","Epoch 10/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3042 - accuracy: 0.1074 - val_loss: 2.2958 - val_accuracy: 0.1161\n","Epoch 11/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3031 - accuracy: 0.1125 - val_loss: 2.2959 - val_accuracy: 0.1441\n","Epoch 12/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3022 - accuracy: 0.1092 - val_loss: 2.2946 - val_accuracy: 0.1634\n","Epoch 13/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3020 - accuracy: 0.1141 - val_loss: 2.2955 - val_accuracy: 0.1364\n","Epoch 14/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3018 - accuracy: 0.1125 - val_loss: 2.2961 - val_accuracy: 0.1003\n","Epoch 15/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1123 - val_loss: 2.2951 - val_accuracy: 0.1000\n","Epoch 16/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3015 - accuracy: 0.1123 - val_loss: 2.2948 - val_accuracy: 0.1052\n","Epoch 17/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1150 - val_loss: 2.2949 - val_accuracy: 0.0998\n","Epoch 18/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1146 - val_loss: 2.2962 - val_accuracy: 0.0998\n","Epoch 19/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1149 - val_loss: 2.2951 - val_accuracy: 0.1152\n","Epoch 20/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1121 - val_loss: 2.2945 - val_accuracy: 0.0957\n","Epoch 21/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1161 - val_loss: 2.2948 - val_accuracy: 0.1018\n","Epoch 22/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1128 - val_loss: 2.2947 - val_accuracy: 0.1000\n","Epoch 23/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1136 - val_loss: 2.2935 - val_accuracy: 0.1061\n","Epoch 24/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1126 - val_loss: 2.2931 - val_accuracy: 0.0957\n","Epoch 25/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1121 - val_loss: 2.2917 - val_accuracy: 0.1076\n","Epoch 26/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1138 - val_loss: 2.2891 - val_accuracy: 0.0999\n","Epoch 27/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1128 - val_loss: 2.2887 - val_accuracy: 0.1109\n","Epoch 28/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1124 - val_loss: 2.2905 - val_accuracy: 0.1047\n","Epoch 29/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1124 - val_loss: 2.2878 - val_accuracy: 0.1322\n","Epoch 30/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1123 - val_loss: 2.2898 - val_accuracy: 0.1000\n","Epoch 31/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1142 - val_loss: 2.2892 - val_accuracy: 0.1002\n","Epoch 32/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3008 - accuracy: 0.1116 - val_loss: 2.2865 - val_accuracy: 0.1001\n","Epoch 33/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1123 - val_loss: 2.2874 - val_accuracy: 0.1000\n","Epoch 34/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3005 - accuracy: 0.1124 - val_loss: 2.2893 - val_accuracy: 0.1001\n","Epoch 35/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3004 - accuracy: 0.1149 - val_loss: 2.2845 - val_accuracy: 0.1192\n","Epoch 36/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1130 - val_loss: 2.2826 - val_accuracy: 0.1167\n","Epoch 37/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1138 - val_loss: 2.2816 - val_accuracy: 0.1053\n","Epoch 38/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1118 - val_loss: 2.2828 - val_accuracy: 0.1173\n","Epoch 39/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1153 - val_loss: 2.2816 - val_accuracy: 0.1292\n","Epoch 40/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2988 - accuracy: 0.1155 - val_loss: 2.2762 - val_accuracy: 0.1282\n","Epoch 41/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2990 - accuracy: 0.1167 - val_loss: 2.2731 - val_accuracy: 0.1404\n","Epoch 42/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2992 - accuracy: 0.1135 - val_loss: 2.2612 - val_accuracy: 0.1710\n","Epoch 43/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2988 - accuracy: 0.1163 - val_loss: 2.2497 - val_accuracy: 0.1561\n","Epoch 44/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2977 - accuracy: 0.1185 - val_loss: 2.2313 - val_accuracy: 0.1658\n","Epoch 45/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2956 - accuracy: 0.1222 - val_loss: 2.1997 - val_accuracy: 0.1753\n","Epoch 46/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2956 - accuracy: 0.1251 - val_loss: 2.1495 - val_accuracy: 0.1864\n","Epoch 47/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2943 - accuracy: 0.1216 - val_loss: 2.0757 - val_accuracy: 0.1975\n","Epoch 48/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2908 - accuracy: 0.1256 - val_loss: 2.0092 - val_accuracy: 0.2109\n","Epoch 49/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2785 - accuracy: 0.1384 - val_loss: 2.3902 - val_accuracy: 0.2422\n","Epoch 50/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2422 - accuracy: 0.1605 - val_loss: 4.8562 - val_accuracy: 0.2747\n","\n","Training with -->gelu<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 5s 8ms/step - loss: 2.3022 - accuracy: 0.1194 - val_loss: 2.3019 - val_accuracy: 0.1060\n","Epoch 2/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3016 - accuracy: 0.1121 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 3/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3009 - accuracy: 0.1124 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 4/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3008 - accuracy: 0.1135 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 5/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1163 - val_loss: 2.3015 - val_accuracy: 0.1060\n","Epoch 6/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3007 - accuracy: 0.1144 - val_loss: 2.3014 - val_accuracy: 0.1060\n","Epoch 7/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3005 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1060\n","Epoch 8/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3000 - accuracy: 0.1152 - val_loss: 2.3012 - val_accuracy: 0.1060\n","Epoch 9/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1060\n","Epoch 10/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3004 - accuracy: 0.1116 - val_loss: 2.3010 - val_accuracy: 0.1060\n","Epoch 11/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2998 - accuracy: 0.1134 - val_loss: 2.3008 - val_accuracy: 0.1060\n","Epoch 12/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3001 - accuracy: 0.1122 - val_loss: 2.3007 - val_accuracy: 0.1060\n","Epoch 13/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2993 - accuracy: 0.1151 - val_loss: 2.3005 - val_accuracy: 0.1060\n","Epoch 14/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2992 - accuracy: 0.1155 - val_loss: 2.3003 - val_accuracy: 0.1060\n","Epoch 15/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2993 - accuracy: 0.1134 - val_loss: 2.3001 - val_accuracy: 0.1060\n","Epoch 16/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2991 - accuracy: 0.1143 - val_loss: 2.2998 - val_accuracy: 0.1060\n","Epoch 17/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2985 - accuracy: 0.1166 - val_loss: 2.2995 - val_accuracy: 0.1060\n","Epoch 18/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2981 - accuracy: 0.1146 - val_loss: 2.2992 - val_accuracy: 0.1060\n","Epoch 19/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2984 - accuracy: 0.1113 - val_loss: 2.2988 - val_accuracy: 0.1060\n","Epoch 20/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2973 - accuracy: 0.1151 - val_loss: 2.2982 - val_accuracy: 0.1060\n","Epoch 21/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2968 - accuracy: 0.1122 - val_loss: 2.2974 - val_accuracy: 0.1060\n","Epoch 22/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2960 - accuracy: 0.1142 - val_loss: 2.2963 - val_accuracy: 0.1060\n","Epoch 23/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2951 - accuracy: 0.1132 - val_loss: 2.2945 - val_accuracy: 0.1060\n","Epoch 24/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2930 - accuracy: 0.1181 - val_loss: 2.2904 - val_accuracy: 0.1078\n","Epoch 25/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2874 - accuracy: 0.1341 - val_loss: 2.2709 - val_accuracy: 0.1604\n","Epoch 26/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2600 - accuracy: 0.1766 - val_loss: 2.1736 - val_accuracy: 0.1809\n","Epoch 27/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.1824 - accuracy: 0.1711 - val_loss: 2.0546 - val_accuracy: 0.2015\n","Epoch 28/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.0957 - accuracy: 0.1956 - val_loss: 1.9790 - val_accuracy: 0.2139\n","Epoch 29/50\n","375/375 [==============================] - 2s 6ms/step - loss: 2.0237 - accuracy: 0.2131 - val_loss: 1.9217 - val_accuracy: 0.2492\n","Epoch 30/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.9681 - accuracy: 0.2414 - val_loss: 1.8484 - val_accuracy: 0.2961\n","Epoch 31/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.9134 - accuracy: 0.2708 - val_loss: 1.7412 - val_accuracy: 0.3577\n","Epoch 32/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.8327 - accuracy: 0.3077 - val_loss: 1.6145 - val_accuracy: 0.4665\n","Epoch 33/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.7517 - accuracy: 0.3495 - val_loss: 1.5092 - val_accuracy: 0.5042\n","Epoch 34/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.6661 - accuracy: 0.3807 - val_loss: 1.4331 - val_accuracy: 0.5249\n","Epoch 35/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.6050 - accuracy: 0.4032 - val_loss: 1.3667 - val_accuracy: 0.5514\n","Epoch 36/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.5513 - accuracy: 0.4243 - val_loss: 1.3056 - val_accuracy: 0.5719\n","Epoch 37/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.4949 - accuracy: 0.4497 - val_loss: 1.2412 - val_accuracy: 0.6054\n","Epoch 38/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.4489 - accuracy: 0.4685 - val_loss: 1.1858 - val_accuracy: 0.6187\n","Epoch 39/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.3929 - accuracy: 0.4886 - val_loss: 1.1339 - val_accuracy: 0.6372\n","Epoch 40/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.3477 - accuracy: 0.5031 - val_loss: 1.0811 - val_accuracy: 0.6452\n","Epoch 41/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.3084 - accuracy: 0.5154 - val_loss: 1.0397 - val_accuracy: 0.6553\n","Epoch 42/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.2678 - accuracy: 0.5315 - val_loss: 1.0023 - val_accuracy: 0.6687\n","Epoch 43/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.2361 - accuracy: 0.5498 - val_loss: 0.9732 - val_accuracy: 0.6774\n","Epoch 44/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.2124 - accuracy: 0.5644 - val_loss: 0.9294 - val_accuracy: 0.6839\n","Epoch 45/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.1699 - accuracy: 0.5741 - val_loss: 0.8917 - val_accuracy: 0.7067\n","Epoch 46/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.1238 - accuracy: 0.6031 - val_loss: 0.8615 - val_accuracy: 0.7246\n","Epoch 47/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.1094 - accuracy: 0.6066 - val_loss: 0.8193 - val_accuracy: 0.7384\n","Epoch 48/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.0735 - accuracy: 0.6236 - val_loss: 0.8010 - val_accuracy: 0.7463\n","Epoch 49/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.0467 - accuracy: 0.6335 - val_loss: 0.7563 - val_accuracy: 0.7846\n","Epoch 50/50\n","375/375 [==============================] - 2s 6ms/step - loss: 1.0258 - accuracy: 0.6472 - val_loss: 0.7207 - val_accuracy: 0.8023\n","\n","Training with -->swish<-- activation function\n","\n","Epoch 1/50\n","375/375 [==============================] - 5s 8ms/step - loss: 2.3022 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1060\n","Epoch 2/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3018 - val_accuracy: 0.1060\n","Epoch 3/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 4/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1158 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 5/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1121 - val_loss: 2.3016 - val_accuracy: 0.1060\n","Epoch 6/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3009 - accuracy: 0.1131 - val_loss: 2.3015 - val_accuracy: 0.1060\n","Epoch 7/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1140 - val_loss: 2.3015 - val_accuracy: 0.1060\n","Epoch 8/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3007 - accuracy: 0.1121 - val_loss: 2.3014 - val_accuracy: 0.1060\n","Epoch 9/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1134 - val_loss: 2.3013 - val_accuracy: 0.1060\n","Epoch 10/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3001 - accuracy: 0.1147 - val_loss: 2.3012 - val_accuracy: 0.1060\n","Epoch 11/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1060\n","Epoch 12/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1160 - val_loss: 2.3009 - val_accuracy: 0.1060\n","Epoch 13/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1124 - val_loss: 2.3008 - val_accuracy: 0.1060\n","Epoch 14/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3000 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1060\n","Epoch 15/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.3003 - accuracy: 0.1100 - val_loss: 2.3005 - val_accuracy: 0.1060\n","Epoch 16/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2998 - accuracy: 0.1124 - val_loss: 2.3004 - val_accuracy: 0.1060\n","Epoch 17/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2990 - accuracy: 0.1158 - val_loss: 2.3001 - val_accuracy: 0.1060\n","Epoch 18/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2989 - accuracy: 0.1144 - val_loss: 2.2999 - val_accuracy: 0.1060\n","Epoch 19/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2987 - accuracy: 0.1146 - val_loss: 2.2996 - val_accuracy: 0.1060\n","Epoch 20/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2987 - accuracy: 0.1124 - val_loss: 2.2993 - val_accuracy: 0.1060\n","Epoch 21/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2981 - accuracy: 0.1134 - val_loss: 2.2990 - val_accuracy: 0.1060\n","Epoch 22/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2981 - accuracy: 0.1126 - val_loss: 2.2985 - val_accuracy: 0.1060\n","Epoch 23/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2972 - accuracy: 0.1153 - val_loss: 2.2979 - val_accuracy: 0.1060\n","Epoch 24/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2965 - accuracy: 0.1149 - val_loss: 2.2972 - val_accuracy: 0.1060\n","Epoch 25/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2960 - accuracy: 0.1150 - val_loss: 2.2962 - val_accuracy: 0.1060\n","Epoch 26/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2947 - accuracy: 0.1169 - val_loss: 2.2948 - val_accuracy: 0.1060\n","Epoch 27/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2935 - accuracy: 0.1159 - val_loss: 2.2928 - val_accuracy: 0.1060\n","Epoch 28/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2915 - accuracy: 0.1181 - val_loss: 2.2894 - val_accuracy: 0.1067\n","Epoch 29/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2875 - accuracy: 0.1279 - val_loss: 2.2829 - val_accuracy: 0.1327\n","Epoch 30/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2794 - accuracy: 0.1436 - val_loss: 2.2658 - val_accuracy: 0.1822\n","Epoch 31/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.2559 - accuracy: 0.1758 - val_loss: 2.1905 - val_accuracy: 0.1989\n","Epoch 32/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.1697 - accuracy: 0.1918 - val_loss: 2.0055 - val_accuracy: 0.2103\n","Epoch 33/50\n","375/375 [==============================] - 2s 5ms/step - loss: 2.0612 - accuracy: 0.2090 - val_loss: 1.9148 - val_accuracy: 0.2829\n","Epoch 34/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.9934 - accuracy: 0.2336 - val_loss: 1.8547 - val_accuracy: 0.2990\n","Epoch 35/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.9488 - accuracy: 0.2481 - val_loss: 1.8081 - val_accuracy: 0.3247\n","Epoch 36/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.9134 - accuracy: 0.2655 - val_loss: 1.7704 - val_accuracy: 0.3659\n","Epoch 37/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.8689 - accuracy: 0.2865 - val_loss: 1.7320 - val_accuracy: 0.3779\n","Epoch 38/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.8347 - accuracy: 0.3042 - val_loss: 1.6933 - val_accuracy: 0.4038\n","Epoch 39/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.8057 - accuracy: 0.3196 - val_loss: 1.6500 - val_accuracy: 0.4297\n","Epoch 40/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.7701 - accuracy: 0.3361 - val_loss: 1.6044 - val_accuracy: 0.4088\n","Epoch 41/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.7236 - accuracy: 0.3571 - val_loss: 1.5619 - val_accuracy: 0.4236\n","Epoch 42/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.6954 - accuracy: 0.3664 - val_loss: 1.5225 - val_accuracy: 0.4320\n","Epoch 43/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.6463 - accuracy: 0.3831 - val_loss: 1.4886 - val_accuracy: 0.4499\n","Epoch 44/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.6135 - accuracy: 0.3961 - val_loss: 1.4552 - val_accuracy: 0.4565\n","Epoch 45/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.5919 - accuracy: 0.4045 - val_loss: 1.4240 - val_accuracy: 0.4657\n","Epoch 46/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.5585 - accuracy: 0.4125 - val_loss: 1.3872 - val_accuracy: 0.4856\n","Epoch 47/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.5410 - accuracy: 0.4238 - val_loss: 1.3516 - val_accuracy: 0.5058\n","Epoch 48/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.5195 - accuracy: 0.4349 - val_loss: 1.3110 - val_accuracy: 0.5254\n","Epoch 49/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.4677 - accuracy: 0.4559 - val_loss: 1.2641 - val_accuracy: 0.5474\n","Epoch 50/50\n","375/375 [==============================] - 2s 5ms/step - loss: 1.4432 - accuracy: 0.4722 - val_loss: 1.2111 - val_accuracy: 0.5732\n","{'loss': [2.4716904163360596, 2.3791143894195557, 2.355476140975952, 2.340646505355835, 2.3328797817230225, 2.325207471847534, 2.3208303451538086, 2.320740222930908, 2.315821647644043, 2.315309524536133, 2.314047336578369, 2.310253143310547, 2.3111746311187744, 2.3096108436584473, 2.3086161613464355, 2.307389259338379, 2.3071656227111816, 2.3063366413116455, 2.3056023120880127, 2.30639910697937, 2.3051934242248535, 2.30574369430542, 2.304783582687378, 2.304164409637451, 2.3038997650146484, 2.3044559955596924, 2.3035473823547363, 2.3035337924957275, 2.3038480281829834, 2.3039748668670654, 2.3038508892059326, 2.3031787872314453, 2.3031015396118164, 2.303685188293457, 2.302898645401001, 2.3030834197998047, 2.3026645183563232, 2.302905797958374, 2.3029708862304688, 2.302556276321411, 2.302478551864624, 2.302349328994751, 2.302319049835205, 2.3024699687957764, 2.3028507232666016, 2.302445650100708, 2.3024284839630127, 2.302258014678955, 2.3022494316101074, 2.302100658416748], 'accuracy': [0.09914582967758179, 0.10304166376590729, 0.10243750363588333, 0.101604163646698, 0.10358333587646484, 0.1041041687130928, 0.10443750023841858, 0.101604163646698, 0.10370833426713943, 0.10222916305065155, 0.10222916305065155, 0.1054791659116745, 0.1028958335518837, 0.10402083396911621, 0.10447916388511658, 0.10716667026281357, 0.10768750309944153, 0.10602083057165146, 0.1066875010728836, 0.10841666907072067, 0.10437499731779099, 0.10695832967758179, 0.10729166865348816, 0.10770833492279053, 0.11043749749660492, 0.10708333551883698, 0.109416663646698, 0.109416663646698, 0.10879166424274445, 0.10885416716337204, 0.10962499678134918, 0.10712499916553497, 0.11033333092927933, 0.10856249928474426, 0.10987500101327896, 0.11025000363588333, 0.10916666686534882, 0.11008333414793015, 0.11081250011920929, 0.10979166626930237, 0.1119375005364418, 0.11041666567325592, 0.1120416671037674, 0.11160416901111603, 0.10970833152532578, 0.11095833033323288, 0.11033333092927933, 0.1106458306312561, 0.11133333295583725, 0.11135416477918625], 'val_loss': [2.305173873901367, 2.3025095462799072, 2.3024137020111084, 2.3022680282592773, 2.302152156829834, 2.302187919616699, 2.3021609783172607, 2.3021113872528076, 2.302124500274658, 2.302072048187256, 2.302128553390503, 2.302154779434204, 2.3020782470703125, 2.3020412921905518, 2.3020613193511963, 2.302086353302002, 2.3020591735839844, 2.302072048187256, 2.302098512649536, 2.3021254539489746, 2.3021047115325928, 2.30208420753479, 2.302056312561035, 2.3020823001861572, 2.302107810974121, 2.3020951747894287, 2.302086353302002, 2.3020904064178467, 2.302093029022217, 2.30210018157959, 2.3021042346954346, 2.3020827770233154, 2.3020896911621094, 2.302088975906372, 2.302119493484497, 2.302154064178467, 2.3021650314331055, 2.3021461963653564, 2.3021390438079834, 2.302093505859375, 2.302086114883423, 2.3020806312561035, 2.302067756652832, 2.302036762237549, 2.30206561088562, 2.3020827770233154, 2.302093744277954, 2.302114248275757, 2.302093029022217, 2.3020966053009033], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n","{'loss': [1.8503631353378296, 1.4213581085205078, 1.2136445045471191, 1.0927561521530151, 1.0031851530075073, 0.939132571220398, 0.8894080519676208, 0.8475458025932312, 0.8204545974731445, 0.790800154209137, 0.7698407173156738, 0.7517600655555725, 0.7285481691360474, 0.7099957466125488, 0.6984102129936218, 0.682628333568573, 0.6627799868583679, 0.6461426019668579, 0.6370275020599365, 0.6298041939735413, 0.6173044443130493, 0.6046871542930603, 0.6015780568122864, 0.5908761620521545, 0.5781843066215515, 0.5702199935913086, 0.5581013560295105, 0.5555291771888733, 0.5511253476142883, 0.5366682410240173, 0.534015953540802, 0.5319241285324097, 0.5178828239440918, 0.5227555632591248, 0.5092909336090088, 0.5040667057037354, 0.4982464909553528, 0.4982149302959442, 0.49180924892425537, 0.4872332215309143, 0.48249173164367676, 0.47848963737487793, 0.4729957580566406, 0.4695996046066284, 0.46591219305992126, 0.4587113857269287, 0.4543072581291199, 0.4505360424518585, 0.4421192705631256, 0.4403179883956909], 'accuracy': [0.3394375145435333, 0.5096250176429749, 0.5896875262260437, 0.6386041641235352, 0.6714166402816772, 0.6976041793823242, 0.7192291617393494, 0.7363749742507935, 0.7486458420753479, 0.7621458172798157, 0.7699166536331177, 0.781624972820282, 0.7918124794960022, 0.7986041903495789, 0.8062499761581421, 0.8116458058357239, 0.8226249814033508, 0.8270208239555359, 0.8297500014305115, 0.8365625143051147, 0.8378541469573975, 0.8458541631698608, 0.8461458086967468, 0.8486875295639038, 0.8532708287239075, 0.8556249737739563, 0.8611458539962769, 0.8612916469573975, 0.8612499833106995, 0.8650833368301392, 0.867020845413208, 0.8690624833106995, 0.8713333606719971, 0.8725416660308838, 0.8756874799728394, 0.8746041655540466, 0.8772291541099548, 0.8778541684150696, 0.8803125023841858, 0.8818541765213013, 0.882854163646698, 0.8832083344459534, 0.8858749866485596, 0.8862916827201843, 0.8876041769981384, 0.8887291550636292, 0.8887083530426025, 0.8914583325386047, 0.8920624852180481, 0.8938958048820496], 'val_loss': [1.1426457166671753, 0.864544689655304, 0.7095993757247925, 0.621488094329834, 0.5597195029258728, 0.5269542932510376, 0.4973306953907013, 0.47628316283226013, 0.4606841504573822, 0.44305220246315, 0.4230172634124756, 0.40618741512298584, 0.3970244526863098, 0.3859170377254486, 0.37642645835876465, 0.36750462651252747, 0.3549642860889435, 0.3614517152309418, 0.34891703724861145, 0.34296634793281555, 0.3402974307537079, 0.32839393615722656, 0.3280107378959656, 0.3169277608394623, 0.3145822584629059, 0.3105658292770386, 0.30919238924980164, 0.30375489592552185, 0.3041251003742218, 0.2969672977924347, 0.29157158732414246, 0.2917555868625641, 0.2877872586250305, 0.28212642669677734, 0.2821434736251831, 0.27785030007362366, 0.27758291363716125, 0.27523109316825867, 0.2716386616230011, 0.26950186491012573, 0.2620503604412079, 0.2598085105419159, 0.25923794507980347, 0.2600710988044739, 0.25604453682899475, 0.2524426579475403, 0.2474290430545807, 0.24594025313854218, 0.24299409985542297, 0.24267083406448364], 'val_accuracy': [0.7064999938011169, 0.7992500066757202, 0.8302500247955322, 0.8464999794960022, 0.8541666865348816, 0.8576666712760925, 0.8637499809265137, 0.8696666955947876, 0.871749997138977, 0.8802499771118164, 0.887666642665863, 0.8923333287239075, 0.8971666693687439, 0.9008333086967468, 0.9049166440963745, 0.9068333506584167, 0.9102500081062317, 0.9105833172798157, 0.9139166474342346, 0.9152500033378601, 0.9160833358764648, 0.9195833206176758, 0.9193333387374878, 0.9233333468437195, 0.9240833520889282, 0.9246666431427002, 0.9265833497047424, 0.9276666641235352, 0.9282500147819519, 0.9297500252723694, 0.9309999942779541, 0.9306666851043701, 0.9327499866485596, 0.9340833425521851, 0.934166669845581, 0.9355833530426025, 0.9350833296775818, 0.9355000257492065, 0.9375, 0.9379166960716248, 0.9402499794960022, 0.9403333067893982, 0.9417499899864197, 0.9400833249092102, 0.9424166679382324, 0.9428333044052124, 0.9439166784286499, 0.9449166655540466, 0.9458333253860474, 0.9455000162124634]}\n","{'loss': [2.303673505783081, 2.3005809783935547, 2.2987213134765625, 2.295034646987915, 2.285341739654541, 2.2609646320343018, 2.203162431716919, 2.0920181274414062, 1.9253290891647339, 1.7815686464309692, 1.653899073600769, 1.563144326210022, 1.4830375909805298, 1.4213498830795288, 1.3530495166778564, 1.3035471439361572, 1.26038658618927, 1.2167185544967651, 1.1850221157073975, 1.154390811920166, 1.1324529647827148, 1.0982969999313354, 1.072895884513855, 1.0617905855178833, 1.0338646173477173, 1.0103389024734497, 0.9848393797874451, 0.972008466720581, 0.9654533863067627, 0.9425458908081055, 0.9244036674499512, 0.9176831841468811, 0.901921808719635, 0.8871798515319824, 0.8777496814727783, 0.8633301854133606, 0.8434600234031677, 0.8386286497116089, 0.8344878554344177, 0.8185334205627441, 0.7981107831001282, 0.7893445491790771, 0.7824628949165344, 0.7679159045219421, 0.7706180214881897, 0.7520685195922852, 0.7494950294494629, 0.7491639256477356, 0.7316519618034363, 0.7211765050888062], 'accuracy': [0.11616666615009308, 0.12556250393390656, 0.12695834040641785, 0.1365624964237213, 0.15462499856948853, 0.1771250069141388, 0.20020833611488342, 0.23264583945274353, 0.2772083282470703, 0.3151041567325592, 0.34810417890548706, 0.3789583444595337, 0.40664583444595337, 0.4283541738986969, 0.45214584469795227, 0.4776875078678131, 0.48997917771339417, 0.5075833201408386, 0.5206666588783264, 0.5300833582878113, 0.5418958067893982, 0.5525000095367432, 0.5609375238418579, 0.5688333511352539, 0.5761041641235352, 0.5899166464805603, 0.5953958630561829, 0.6033124923706055, 0.6065624952316284, 0.6172500252723694, 0.6231458187103271, 0.6284375190734863, 0.636062502861023, 0.6396041512489319, 0.6425208449363708, 0.6485000252723694, 0.6570416688919067, 0.6596875190734863, 0.6617083549499512, 0.6652708053588867, 0.6738541722297668, 0.6707083582878113, 0.6773333549499512, 0.679604172706604, 0.6757708191871643, 0.6857708096504211, 0.687458336353302, 0.6846874952316284, 0.6907291412353516, 0.6957708597183228], 'val_loss': [2.301522731781006, 2.3003969192504883, 2.2975759506225586, 2.287036418914795, 2.2616934776306152, 2.1979897022247314, 2.0697286128997803, 1.8326665163040161, 1.6142841577529907, 1.4446176290512085, 1.3138223886489868, 1.2173306941986084, 1.123516321182251, 1.0574595928192139, 0.9945471286773682, 0.9349697828292847, 0.8997649550437927, 0.8831340074539185, 0.8269534707069397, 0.8065004944801331, 0.7841834425926208, 0.766391932964325, 0.7522850036621094, 0.7252542972564697, 0.7121334075927734, 0.7058237195014954, 0.6862758994102478, 0.6728014945983887, 0.6678597927093506, 0.6680580973625183, 0.645748496055603, 0.6383749842643738, 0.6282567381858826, 0.6111220121383667, 0.6151590347290039, 0.6064953207969666, 0.5897185206413269, 0.6008175611495972, 0.5636229515075684, 0.5939997434616089, 0.5747821927070618, 0.5545099973678589, 0.5372490882873535, 0.5463842153549194, 0.5380600094795227, 0.5330438017845154, 0.5280205011367798, 0.5357845425605774, 0.5146495699882507, 0.5268215537071228], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10616666823625565, 0.16891667246818542, 0.2710833251476288, 0.3019166588783264, 0.32241666316986084, 0.36516666412353516, 0.4439166784286499, 0.5223333239555359, 0.5486666560173035, 0.6176666617393494, 0.6118333339691162, 0.6567500233650208, 0.6448333263397217, 0.6589166522026062, 0.6519166827201843, 0.6742500066757202, 0.6794999837875366, 0.7214166522026062, 0.6965833306312561, 0.7051666378974915, 0.7387499809265137, 0.7128333449363708, 0.7129999995231628, 0.7562500238418579, 0.7639166712760925, 0.7585833072662354, 0.7306666374206543, 0.7633333206176758, 0.7706666588783264, 0.7675833106040955, 0.7818333506584167, 0.768583357334137, 0.7804166674613953, 0.7875000238418579, 0.7680000066757202, 0.8065833449363708, 0.7671666741371155, 0.800000011920929, 0.7975000143051147, 0.7919166684150696, 0.7804999947547913, 0.8004166483879089, 0.7923333048820496, 0.7896666526794434, 0.8009999990463257, 0.8033333420753479, 0.799916684627533]}\n","{'loss': [2.300733804702759, 2.2884409427642822, 2.2412054538726807, 2.13767147064209, 2.0201399326324463, 1.9051786661148071, 1.7608238458633423, 1.5832041501998901, 1.4179575443267822, 1.3009734153747559, 1.2122783660888672, 1.1380399465560913, 1.0744571685791016, 1.019645094871521, 0.9694659113883972, 0.9232853055000305, 0.884206235408783, 0.8380333781242371, 0.7998751401901245, 0.7559284567832947, 0.71893709897995, 0.6846237182617188, 0.6486095190048218, 0.617592453956604, 0.5970761775970459, 0.5676194429397583, 0.5392873287200928, 0.5209559202194214, 0.5013213157653809, 0.4712921977043152, 0.4517362415790558, 0.4551156759262085, 0.42999589443206787, 0.4147056043148041, 0.4044136703014374, 0.39655306935310364, 0.38883307576179504, 0.3643854856491089, 0.3602589964866638, 0.35377925634384155, 0.3440224528312683, 0.3332313895225525, 0.33351030945777893, 0.31745490431785583, 0.31868308782577515, 0.3010101020336151, 0.29870229959487915, 0.2936173677444458, 0.2840554118156433, 0.2808097004890442], 'accuracy': [0.12277083098888397, 0.15816666185855865, 0.19066666066646576, 0.2135625034570694, 0.2290624976158142, 0.26877084374427795, 0.34054166078567505, 0.4078750014305115, 0.46875, 0.5113124847412109, 0.5428749918937683, 0.5758125185966492, 0.6065000295639038, 0.63302081823349, 0.6582499742507935, 0.6821666955947876, 0.7034791707992554, 0.7219374775886536, 0.7398750185966492, 0.757895827293396, 0.7745208144187927, 0.7917916774749756, 0.8052083253860474, 0.8189166784286499, 0.8276666402816772, 0.8396875262260437, 0.8508541584014893, 0.856249988079071, 0.8637499809265137, 0.8729166388511658, 0.8780208230018616, 0.8793333172798157, 0.8845624923706055, 0.8876875042915344, 0.8922708630561829, 0.8944374918937683, 0.8979166746139526, 0.9045208096504211, 0.9056458473205566, 0.9071458578109741, 0.9096041917800903, 0.9126458168029785, 0.9131875038146973, 0.9174791574478149, 0.9156875014305115, 0.9197083115577698, 0.9228125214576721, 0.9237499833106995, 0.9248958230018616, 0.9271041750907898], 'val_loss': [2.294442892074585, 2.2587063312530518, 2.1341848373413086, 1.973305344581604, 1.8410906791687012, 1.6789108514785767, 1.4292874336242676, 1.1710431575775146, 0.9992135167121887, 0.9057189226150513, 0.8431362509727478, 0.792034924030304, 0.7427753210067749, 0.6929042935371399, 0.6484276652336121, 0.602784276008606, 0.5659622550010681, 0.5305364727973938, 0.48871320486068726, 0.4522722065448761, 0.40348580479621887, 0.37205949425697327, 0.3416845202445984, 0.30844277143478394, 0.2843209505081177, 0.27270805835723877, 0.25583702325820923, 0.2431321144104004, 0.23668082058429718, 0.22266849875450134, 0.21289704740047455, 0.21627017855644226, 0.21374306082725525, 0.19776205718517303, 0.19644494354724884, 0.18644113838672638, 0.1903153657913208, 0.1829654723405838, 0.18395423889160156, 0.18237416446208954, 0.18247540295124054, 0.1799248605966568, 0.18228104710578918, 0.17566163837909698, 0.17382073402404785, 0.1746738851070404, 0.17068158090114594, 0.16879917681217194, 0.16853941977024078, 0.17135001718997955], 'val_accuracy': [0.12250000238418579, 0.18816666305065155, 0.19983333349227905, 0.29908332228660583, 0.33524999022483826, 0.40591666102409363, 0.5055833458900452, 0.5894166827201843, 0.6177499890327454, 0.6457499861717224, 0.6771666407585144, 0.7085000276565552, 0.7835000157356262, 0.8304166793823242, 0.8423333168029785, 0.875083327293396, 0.8863333463668823, 0.8979166746139526, 0.906166672706604, 0.9150000214576721, 0.921833336353302, 0.9277499914169312, 0.9324166774749756, 0.9359166622161865, 0.940416693687439, 0.940833330154419, 0.9446666836738586, 0.9455000162124634, 0.9490000009536743, 0.9495000243186951, 0.9516666531562805, 0.9523333311080933, 0.9539999961853027, 0.9552500247955322, 0.9558333158493042, 0.9574166536331177, 0.9578333497047424, 0.9583333134651184, 0.9592499732971191, 0.9599999785423279, 0.9606666564941406, 0.9608333110809326, 0.9610000252723694, 0.9610833525657654, 0.9620000123977661, 0.9629999995231628, 0.9626666903495789, 0.9633333086967468, 0.9643333554267883, 0.9639166593551636]}\n","{'loss': [1.9839656352996826, 1.4803239107131958, 1.1879006624221802, 1.0250474214553833, 0.9350330233573914, 0.8599468469619751, 0.8085139393806458, 0.7663926482200623, 0.731651782989502, 0.7112048268318176, 0.6760136485099792, 0.6574013233184814, 0.6414372324943542, 0.6258090138435364, 0.6075958013534546, 0.586443305015564, 0.5802851915359497, 0.5629581212997437, 0.5564575791358948, 0.5412079095840454, 0.5223673582077026, 0.5236619710922241, 0.5083658695220947, 0.504991352558136, 0.49380871653556824, 0.48086339235305786, 0.4662696123123169, 0.469042032957077, 0.45089608430862427, 0.4475906491279602, 0.44436904788017273, 0.4396151006221771, 0.42897844314575195, 0.42227762937545776, 0.4184807538986206, 0.4161975383758545, 0.4005814492702484, 0.4039044976234436, 0.4004954397678375, 0.3881094455718994, 0.38826411962509155, 0.38298165798187256, 0.3834545612335205, 0.3797413408756256, 0.37758734822273254, 0.36801525950431824, 0.35724586248397827, 0.3639666438102722, 0.3549329340457916, 0.3561626374721527], 'accuracy': [0.28962498903274536, 0.47483333945274353, 0.589104175567627, 0.6563958525657654, 0.6929791569709778, 0.723437488079071, 0.7460833191871643, 0.7647083401679993, 0.7817083597183228, 0.7898125052452087, 0.8026875257492065, 0.8107500076293945, 0.8166041374206543, 0.8221458196640015, 0.8296666741371155, 0.8366875052452087, 0.8403124809265137, 0.8462499976158142, 0.8492083549499512, 0.8527291417121887, 0.8601041436195374, 0.8608958125114441, 0.8653749823570251, 0.867020845413208, 0.8714791536331177, 0.8760625123977661, 0.8777916431427002, 0.8789791464805603, 0.8841041922569275, 0.8837916851043701, 0.885770857334137, 0.8880624771118164, 0.8893958330154419, 0.8917916417121887, 0.8938958048820496, 0.8926041722297668, 0.8972499966621399, 0.8998958468437195, 0.898770809173584, 0.9024375081062317, 0.9012916684150696, 0.9045000076293945, 0.9047499895095825, 0.9054791927337646, 0.9075416922569275, 0.9080416560173035, 0.9101250171661377, 0.9101874828338623, 0.9103124737739563, 0.9122499823570251], 'val_loss': [1.2533869743347168, 0.7904179096221924, 0.5707381367683411, 0.46621161699295044, 0.41655269265174866, 0.3789900839328766, 0.35541826486587524, 0.33770498633384705, 0.3245334327220917, 0.30884861946105957, 0.3014949560165405, 0.2892913818359375, 0.28533849120140076, 0.2743249237537384, 0.2700951397418976, 0.26445382833480835, 0.26016077399253845, 0.2520882189273834, 0.24425998330116272, 0.23630522191524506, 0.2368898093700409, 0.23215049505233765, 0.22660665214061737, 0.22227415442466736, 0.21887975931167603, 0.21330784261226654, 0.2099398970603943, 0.20912951231002808, 0.20420090854167938, 0.20440293848514557, 0.19623737037181854, 0.19277136027812958, 0.19164849817752838, 0.18828250467777252, 0.18657740950584412, 0.18991775810718536, 0.18532735109329224, 0.18397122621536255, 0.1767713874578476, 0.17659610509872437, 0.17702345550060272, 0.17242157459259033, 0.17197644710540771, 0.16995984315872192, 0.17202134430408478, 0.1657755821943283, 0.16475486755371094, 0.16712673008441925, 0.16835199296474457, 0.1602218896150589], 'val_accuracy': [0.6207500100135803, 0.7802500128746033, 0.8425833582878113, 0.874916672706604, 0.8897500038146973, 0.8975833058357239, 0.9034166932106018, 0.9068333506584167, 0.9101666808128357, 0.9154166579246521, 0.9160000085830688, 0.9204166531562805, 0.9205833077430725, 0.9243333339691162, 0.9265000224113464, 0.9273333549499512, 0.9279999732971191, 0.9291666746139526, 0.9318333268165588, 0.9352499842643738, 0.9335833191871643, 0.9354166388511658, 0.9369999766349792, 0.9393333196640015, 0.9394999742507935, 0.9416666626930237, 0.9442499876022339, 0.9415000081062317, 0.9454166889190674, 0.9453333616256714, 0.9455833435058594, 0.9485833048820496, 0.9487500190734863, 0.949999988079071, 0.9496666789054871, 0.9505000114440918, 0.9509166479110718, 0.9517499804496765, 0.9526666402816772, 0.9547500014305115, 0.952833354473114, 0.9551666378974915, 0.9550833106040955, 0.9559999704360962, 0.9553333520889282, 0.956250011920929, 0.9580833315849304, 0.9571666717529297, 0.9572499990463257, 0.9591666460037231]}\n","{'loss': [2.6222753524780273, 2.4617605209350586, 2.3837409019470215, 2.349663496017456, 2.3256263732910156, 2.3174891471862793, 2.311760663986206, 2.307570219039917, 2.305847406387329, 2.3039286136627197, 2.302600145339966, 2.3025031089782715, 2.3019890785217285, 2.3013999462127686, 2.301098108291626, 2.301394462585449, 2.3011069297790527, 2.301093101501465, 2.3007781505584717, 2.300903081893921, 2.300886631011963, 2.300771951675415, 2.3005475997924805, 2.3008954524993896, 2.3007290363311768, 2.300718307495117, 2.300243854522705, 2.3005290031433105, 2.300692558288574, 2.300499439239502, 2.3001937866210938, 2.3003342151641846, 2.3003203868865967, 2.30039381980896, 2.3003621101379395, 2.2998576164245605, 2.300173759460449, 2.2998738288879395, 2.2996745109558105, 2.2991864681243896, 2.299288034439087, 2.298567295074463, 2.2987565994262695, 2.297532320022583, 2.296173095703125, 2.295192003250122, 2.2926809787750244, 2.2879703044891357, 2.274174213409424, 2.223726987838745], 'accuracy': [0.10264583677053452, 0.10016666352748871, 0.10137499868869781, 0.1002708300948143, 0.10616666823625565, 0.10468749701976776, 0.10275000333786011, 0.10645833611488342, 0.10583333671092987, 0.10827083140611649, 0.11002083122730255, 0.10997916758060455, 0.11185416579246521, 0.11395833641290665, 0.11231250315904617, 0.11433333158493042, 0.11389583349227905, 0.11287499964237213, 0.11508333683013916, 0.11306250095367432, 0.11352083086967468, 0.11297916620969772, 0.1133541688323021, 0.1132916659116745, 0.1132708340883255, 0.11362499743700027, 0.11341666430234909, 0.1133333370089531, 0.1133124977350235, 0.11345833539962769, 0.11539583653211594, 0.11385416984558105, 0.11299999803304672, 0.1132916659116745, 0.11474999785423279, 0.11427083611488342, 0.11474999785423279, 0.11418750137090683, 0.11481250077486038, 0.11554166674613953, 0.11518750339746475, 0.11556249856948853, 0.11664583534002304, 0.11941666901111603, 0.1210625022649765, 0.12381249666213989, 0.125041663646698, 0.12981249392032623, 0.14143750071525574, 0.16699999570846558], 'val_loss': [2.466430425643921, 2.381929397583008, 2.339944839477539, 2.3166821002960205, 2.3063535690307617, 2.300640344619751, 2.2968826293945312, 2.2947590351104736, 2.294292688369751, 2.29579496383667, 2.2959351539611816, 2.2945826053619385, 2.2954766750335693, 2.296067476272583, 2.2950570583343506, 2.2947609424591064, 2.2949013710021973, 2.2961959838867188, 2.2951292991638184, 2.294517993927002, 2.2947895526885986, 2.294734001159668, 2.2934885025024414, 2.293107748031616, 2.2917275428771973, 2.28909969329834, 2.2886860370635986, 2.290475845336914, 2.287825107574463, 2.2897608280181885, 2.289170026779175, 2.2864670753479004, 2.2874085903167725, 2.289306879043579, 2.284498453140259, 2.2826454639434814, 2.281641960144043, 2.282822370529175, 2.281571626663208, 2.2762417793273926, 2.2730727195739746, 2.2611825466156006, 2.249668598175049, 2.231283664703369, 2.1997406482696533, 2.1495184898376465, 2.0756545066833496, 2.0092382431030273, 2.3901963233947754, 4.8561553955078125], 'val_accuracy': [0.1407500058412552, 0.13750000298023224, 0.14608334004878998, 0.16200000047683716, 0.17291666567325592, 0.1704999953508377, 0.16233333945274353, 0.17858333885669708, 0.16249999403953552, 0.11608333140611649, 0.14408333599567413, 0.16341666877269745, 0.13641667366027832, 0.1003333330154419, 0.10000000149011612, 0.10516666620969772, 0.09983333200216293, 0.09983333200216293, 0.11524999886751175, 0.09566666930913925, 0.10183333605527878, 0.10000000149011612, 0.10608333349227905, 0.09574999660253525, 0.10758333653211594, 0.09991666674613953, 0.11091666668653488, 0.10466666519641876, 0.13216666877269745, 0.10000000149011612, 0.10016666352748871, 0.10008333623409271, 0.10000000149011612, 0.10008333623409271, 0.11924999952316284, 0.11666666716337204, 0.10525000095367432, 0.1172500029206276, 0.12916666269302368, 0.12816666066646576, 0.14041666686534882, 0.17100000381469727, 0.15608333051204681, 0.16583333909511566, 0.17533333599567413, 0.18641667068004608, 0.19750000536441803, 0.210916668176651, 0.242166668176651, 0.2746666669845581]}\n","{'loss': [2.301990509033203, 2.3012876510620117, 2.300957679748535, 2.300738573074341, 2.3006205558776855, 2.3005530834198, 2.300391435623169, 2.3001983165740967, 2.300198554992676, 2.300079107284546, 2.2998383045196533, 2.2997660636901855, 2.2995762825012207, 2.299388885498047, 2.2992141246795654, 2.29897403717041, 2.298704147338867, 2.2983453273773193, 2.297940492630005, 2.2974419593811035, 2.2967469692230225, 2.2958950996398926, 2.294461488723755, 2.2917137145996094, 2.283034086227417, 2.24556040763855, 2.1575324535369873, 2.076530933380127, 2.012769937515259, 1.9542522430419922, 1.8945428133010864, 1.8126839399337769, 1.7331713438034058, 1.6585841178894043, 1.591146469116211, 1.5365194082260132, 1.482375144958496, 1.4341082572937012, 1.3848356008529663, 1.3339519500732422, 1.302655816078186, 1.2570220232009888, 1.2323929071426392, 1.1984220743179321, 1.160738468170166, 1.1317570209503174, 1.1038111448287964, 1.067082405090332, 1.0424175262451172, 1.0208110809326172], 'accuracy': [0.11608333140611649, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11404166370630264, 0.11412499845027924, 0.11552083492279053, 0.12191666662693024, 0.14558333158493042, 0.17241667211055756, 0.17606249451637268, 0.19983333349227905, 0.21931250393390656, 0.24533332884311676, 0.27952083945274353, 0.31812500953674316, 0.3566041588783264, 0.3864166736602783, 0.4086458384990692, 0.42929166555404663, 0.45352083444595337, 0.4736666679382324, 0.49125000834465027, 0.5070624947547913, 0.5209791660308838, 0.538812518119812, 0.5538541674613953, 0.5666666626930237, 0.5817291736602783, 0.5999583601951599, 0.6092708110809326, 0.6256874799728394, 0.6390416622161865, 0.6485416889190674], 'val_loss': [2.3018922805786133, 2.3017165660858154, 2.301633358001709, 2.3015599250793457, 2.3014607429504395, 2.301380157470703, 2.3013112545013428, 2.301199436187744, 2.3010692596435547, 2.3009517192840576, 2.3008313179016113, 2.300689220428467, 2.3005199432373047, 2.3002772331237793, 2.3001084327697754, 2.299849510192871, 2.299535036087036, 2.299152135848999, 2.2987606525421143, 2.2982094287872314, 2.297417402267456, 2.296287775039673, 2.2944555282592773, 2.2904305458068848, 2.270886182785034, 2.173609733581543, 2.054572820663452, 1.9789628982543945, 1.9216668605804443, 1.8483859300613403, 1.741230845451355, 1.614515781402588, 1.509172797203064, 1.4330607652664185, 1.366668939590454, 1.305566430091858, 1.2412103414535522, 1.1857614517211914, 1.1339014768600464, 1.0811368227005005, 1.0397193431854248, 1.0022871494293213, 0.973238468170166, 0.929385244846344, 0.8917475342750549, 0.861469566822052, 0.8192508220672607, 0.8009832501411438, 0.756273090839386, 0.7206953167915344], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10783333331346512, 0.16041666269302368, 0.1809166669845581, 0.20149999856948853, 0.21391665935516357, 0.24916666746139526, 0.29608333110809326, 0.3577499985694885, 0.46650001406669617, 0.5041666626930237, 0.5249166488647461, 0.5514166951179504, 0.5719166398048401, 0.6054166555404663, 0.6187499761581421, 0.6371666789054871, 0.6451666951179504, 0.6552500128746033, 0.668749988079071, 0.6774166822433472, 0.6839166879653931, 0.7066666483879089, 0.7245833277702332, 0.7384166717529297, 0.7463333606719971, 0.784583330154419, 0.8022500276565552]}\n","{'loss': [2.301924228668213, 2.3012919425964355, 2.300959348678589, 2.300813913345337, 2.3006293773651123, 2.3006114959716797, 2.3004841804504395, 2.300408124923706, 2.3003382682800293, 2.3002169132232666, 2.3001084327697754, 2.2999367713928223, 2.299806594848633, 2.2997822761535645, 2.2995173931121826, 2.2994165420532227, 2.2991650104522705, 2.2989935874938965, 2.2987570762634277, 2.2984750270843506, 2.298131227493286, 2.2976932525634766, 2.297297477722168, 2.296567678451538, 2.2957398891448975, 2.294680595397949, 2.293118715286255, 2.2907094955444336, 2.2861907482147217, 2.2758700847625732, 2.242689847946167, 2.1364476680755615, 2.0417404174804688, 1.9821616411209106, 1.9381451606750488, 1.9028568267822266, 1.864931583404541, 1.8324313163757324, 1.7954089641571045, 1.757005214691162, 1.719420075416565, 1.6818976402282715, 1.6455256938934326, 1.617262840270996, 1.5850242376327515, 1.5499740839004517, 1.525248646736145, 1.4970502853393555, 1.455052137374878, 1.4197580814361572], 'accuracy': [0.11400000005960464, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11402083188295364, 0.11414583027362823, 0.1145416647195816, 0.11664583534002304, 0.12031249701976776, 0.12941665947437286, 0.1524374932050705, 0.17947916686534882, 0.19718749821186066, 0.21572916209697723, 0.23868750035762787, 0.2552500069141388, 0.2710416615009308, 0.29002082347869873, 0.30791667103767395, 0.3230625092983246, 0.3414583206176758, 0.35768750309944153, 0.3713541626930237, 0.38491666316986084, 0.3957916796207428, 0.4051874876022339, 0.41622915863990784, 0.42918750643730164, 0.4413333237171173, 0.4597916603088379, 0.4792916774749756], 'val_loss': [2.3019394874572754, 2.3017923831939697, 2.301720142364502, 2.301661968231201, 2.301588296890259, 2.301527261734009, 2.3014678955078125, 2.301380157470703, 2.3012702465057373, 2.3011553287506104, 2.3010709285736084, 2.300938844680786, 2.3008272647857666, 2.300650119781494, 2.300535202026367, 2.30035138130188, 2.3001434803009033, 2.2999167442321777, 2.2996420860290527, 2.2993345260620117, 2.2989838123321533, 2.298535108566284, 2.2979283332824707, 2.2971951961517334, 2.2962303161621094, 2.294828176498413, 2.2927796840667725, 2.2894086837768555, 2.2828726768493652, 2.2658376693725586, 2.190490961074829, 2.0055277347564697, 1.9147926568984985, 1.8547179698944092, 1.8081344366073608, 1.7704445123672485, 1.7320430278778076, 1.6933197975158691, 1.6500297784805298, 1.6043671369552612, 1.5618507862091064, 1.5225049257278442, 1.4886072874069214, 1.455190896987915, 1.4239609241485596, 1.3871865272521973, 1.3516472578048706, 1.3109668493270874, 1.2640820741653442, 1.2111448049545288], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.1066666692495346, 0.1326666623353958, 0.1822499930858612, 0.19891667366027832, 0.21033333241939545, 0.2829166650772095, 0.29899999499320984, 0.32466667890548706, 0.3659166693687439, 0.3779166638851166, 0.4037500023841858, 0.429749995470047, 0.4088333249092102, 0.42358332872390747, 0.4320000112056732, 0.44991666078567505, 0.45649999380111694, 0.46566668152809143, 0.4855833351612091, 0.5057500004768372, 0.5254166722297668, 0.5474166870117188, 0.5732499957084656]}\n"],"name":"stdout"}]}]}