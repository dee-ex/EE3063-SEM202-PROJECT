{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 802255,
     "status": "ok",
     "timestamp": 1627301840463,
     "user": {
      "displayName": "TRUNG Nguyễn Thành",
      "photoUrl": "",
      "userId": "02848241069421510082"
     },
     "user_tz": -420
    },
    "id": "JnHhSjZec4W6",
    "outputId": "7d82956a-f070-4303-de21-e0ed0df708c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 17s 5ms/step - loss: 2.4584 - accuracy: 0.0983 - val_loss: 2.3046 - val_accuracy: 0.0975\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3658 - accuracy: 0.1031 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3473 - accuracy: 0.1034 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3360 - accuracy: 0.1038 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3294 - accuracy: 0.1021 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3254 - accuracy: 0.1035 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3214 - accuracy: 0.1041 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3184 - accuracy: 0.1012 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3166 - accuracy: 0.1007 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3151 - accuracy: 0.1035 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3106 - accuracy: 0.1083 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3098 - accuracy: 0.1085 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3088 - accuracy: 0.1081 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3085 - accuracy: 0.1061 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3100 - accuracy: 0.1008 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3073 - accuracy: 0.1061 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3069 - accuracy: 0.1047 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3063 - accuracy: 0.1022 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3058 - accuracy: 0.1061 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3064 - accuracy: 0.1089 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3056 - accuracy: 0.1071 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3060 - accuracy: 0.1065 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3044 - accuracy: 0.1099 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3062 - accuracy: 0.1039 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3057 - accuracy: 0.1048 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3043 - accuracy: 0.1090 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3034 - accuracy: 0.1093 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3041 - accuracy: 0.1082 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3039 - accuracy: 0.1085 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3037 - accuracy: 0.1084 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3043 - accuracy: 0.1080 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3031 - accuracy: 0.1121 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3027 - accuracy: 0.1111 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3038 - accuracy: 0.1092 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3040 - accuracy: 0.1088 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3033 - accuracy: 0.1090 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3034 - accuracy: 0.1088 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3027 - accuracy: 0.1099 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3035 - accuracy: 0.1061 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3032 - accuracy: 0.1111 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3029 - accuracy: 0.1098 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3028 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3017 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3028 - accuracy: 0.1102 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3027 - accuracy: 0.1115 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.1135 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3024 - accuracy: 0.1114 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3024 - accuracy: 0.1129 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3023 - accuracy: 0.1126 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.0735 - accuracy: 0.2570 - val_loss: 1.1323 - val_accuracy: 0.7517\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4696 - accuracy: 0.5115 - val_loss: 0.8312 - val_accuracy: 0.8253\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2243 - accuracy: 0.6050 - val_loss: 0.6778 - val_accuracy: 0.8513\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0870 - accuracy: 0.6549 - val_loss: 0.5869 - val_accuracy: 0.8598\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9926 - accuracy: 0.6841 - val_loss: 0.5273 - val_accuracy: 0.8698\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9318 - accuracy: 0.7076 - val_loss: 0.4835 - val_accuracy: 0.8758\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8751 - accuracy: 0.7333 - val_loss: 0.4530 - val_accuracy: 0.8798\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8420 - accuracy: 0.7423 - val_loss: 0.4271 - val_accuracy: 0.8853\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7955 - accuracy: 0.7598 - val_loss: 0.4076 - val_accuracy: 0.8880\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7852 - accuracy: 0.7666 - val_loss: 0.3918 - val_accuracy: 0.8930\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7462 - accuracy: 0.7824 - val_loss: 0.3804 - val_accuracy: 0.8960\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7311 - accuracy: 0.7910 - val_loss: 0.3668 - val_accuracy: 0.8994\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7089 - accuracy: 0.7966 - val_loss: 0.3585 - val_accuracy: 0.9010\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.8090 - val_loss: 0.3454 - val_accuracy: 0.9067\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6671 - accuracy: 0.8133 - val_loss: 0.3434 - val_accuracy: 0.9063\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6481 - accuracy: 0.8206 - val_loss: 0.3358 - val_accuracy: 0.9107\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6397 - accuracy: 0.8261 - val_loss: 0.3318 - val_accuracy: 0.9106\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6190 - accuracy: 0.8319 - val_loss: 0.3255 - val_accuracy: 0.9151\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6103 - accuracy: 0.8391 - val_loss: 0.3182 - val_accuracy: 0.9161\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6005 - accuracy: 0.8415 - val_loss: 0.3192 - val_accuracy: 0.9158\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5924 - accuracy: 0.8446 - val_loss: 0.3120 - val_accuracy: 0.9201\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5764 - accuracy: 0.8478 - val_loss: 0.3122 - val_accuracy: 0.9187\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5715 - accuracy: 0.8505 - val_loss: 0.3035 - val_accuracy: 0.9227\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5652 - accuracy: 0.8535 - val_loss: 0.3004 - val_accuracy: 0.9222\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5540 - accuracy: 0.8580 - val_loss: 0.2996 - val_accuracy: 0.9241\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5551 - accuracy: 0.8596 - val_loss: 0.2921 - val_accuracy: 0.9264\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5479 - accuracy: 0.8589 - val_loss: 0.2927 - val_accuracy: 0.9268\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5322 - accuracy: 0.8651 - val_loss: 0.2876 - val_accuracy: 0.9268\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5256 - accuracy: 0.8676 - val_loss: 0.2904 - val_accuracy: 0.9283\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5100 - accuracy: 0.8697 - val_loss: 0.2848 - val_accuracy: 0.9296\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5252 - accuracy: 0.8667 - val_loss: 0.2838 - val_accuracy: 0.9298\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5063 - accuracy: 0.8740 - val_loss: 0.2784 - val_accuracy: 0.9308\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5134 - accuracy: 0.8718 - val_loss: 0.2736 - val_accuracy: 0.9321\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4998 - accuracy: 0.8768 - val_loss: 0.2713 - val_accuracy: 0.9334\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4966 - accuracy: 0.8770 - val_loss: 0.2697 - val_accuracy: 0.9348\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4898 - accuracy: 0.8782 - val_loss: 0.2696 - val_accuracy: 0.9337\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4994 - accuracy: 0.8762 - val_loss: 0.2645 - val_accuracy: 0.9373\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4884 - accuracy: 0.8795 - val_loss: 0.2582 - val_accuracy: 0.9381\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4687 - accuracy: 0.8837 - val_loss: 0.2565 - val_accuracy: 0.9396\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4677 - accuracy: 0.8862 - val_loss: 0.2547 - val_accuracy: 0.9408\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4653 - accuracy: 0.8862 - val_loss: 0.2502 - val_accuracy: 0.9403\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4642 - accuracy: 0.8853 - val_loss: 0.2500 - val_accuracy: 0.9410\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4436 - accuracy: 0.8904 - val_loss: 0.2450 - val_accuracy: 0.9420\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4489 - accuracy: 0.8879 - val_loss: 0.2476 - val_accuracy: 0.9431\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4534 - accuracy: 0.8903 - val_loss: 0.2406 - val_accuracy: 0.9439\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4354 - accuracy: 0.8939 - val_loss: 0.2405 - val_accuracy: 0.9449\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4400 - accuracy: 0.8915 - val_loss: 0.2347 - val_accuracy: 0.9452\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4389 - accuracy: 0.8931 - val_loss: 0.2338 - val_accuracy: 0.9457\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.8930 - val_loss: 0.2295 - val_accuracy: 0.9465\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4343 - accuracy: 0.8941 - val_loss: 0.2316 - val_accuracy: 0.9461\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 5ms/step - loss: 2.3049 - accuracy: 0.1068 - val_loss: 2.2963 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2963 - accuracy: 0.1337 - val_loss: 2.2700 - val_accuracy: 0.1710\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2754 - accuracy: 0.1506 - val_loss: 2.1568 - val_accuracy: 0.2747\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1917 - accuracy: 0.1826 - val_loss: 1.9701 - val_accuracy: 0.3248\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0613 - accuracy: 0.2191 - val_loss: 1.7338 - val_accuracy: 0.3332\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.9064 - accuracy: 0.2693 - val_loss: 1.5228 - val_accuracy: 0.4046\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7610 - accuracy: 0.3014 - val_loss: 1.3759 - val_accuracy: 0.4665\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6415 - accuracy: 0.3388 - val_loss: 1.2617 - val_accuracy: 0.4897\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5455 - accuracy: 0.3703 - val_loss: 1.1747 - val_accuracy: 0.5261\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4628 - accuracy: 0.3989 - val_loss: 1.1185 - val_accuracy: 0.5488\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4025 - accuracy: 0.4215 - val_loss: 1.0556 - val_accuracy: 0.5685\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3405 - accuracy: 0.4443 - val_loss: 1.0006 - val_accuracy: 0.5767\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2865 - accuracy: 0.4677 - val_loss: 0.9478 - val_accuracy: 0.5997\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2465 - accuracy: 0.4866 - val_loss: 0.9121 - val_accuracy: 0.6184\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1861 - accuracy: 0.5122 - val_loss: 0.8633 - val_accuracy: 0.6269\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1664 - accuracy: 0.5188 - val_loss: 0.8265 - val_accuracy: 0.6347\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1219 - accuracy: 0.5396 - val_loss: 0.7890 - val_accuracy: 0.6623\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0805 - accuracy: 0.5608 - val_loss: 0.7551 - val_accuracy: 0.6853\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0528 - accuracy: 0.5771 - val_loss: 0.7204 - val_accuracy: 0.7365\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0127 - accuracy: 0.6023 - val_loss: 0.6772 - val_accuracy: 0.7610\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9698 - accuracy: 0.6235 - val_loss: 0.6462 - val_accuracy: 0.8083\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9583 - accuracy: 0.6319 - val_loss: 0.6193 - val_accuracy: 0.8398\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9170 - accuracy: 0.6528 - val_loss: 0.5843 - val_accuracy: 0.8562\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8967 - accuracy: 0.6663 - val_loss: 0.5592 - val_accuracy: 0.8809\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8799 - accuracy: 0.6795 - val_loss: 0.5400 - val_accuracy: 0.8743\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8534 - accuracy: 0.6853 - val_loss: 0.5206 - val_accuracy: 0.8957\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8311 - accuracy: 0.7029 - val_loss: 0.5033 - val_accuracy: 0.9043\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8195 - accuracy: 0.7104 - val_loss: 0.4833 - val_accuracy: 0.9076\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7959 - accuracy: 0.7182 - val_loss: 0.4742 - val_accuracy: 0.9109\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7782 - accuracy: 0.7246 - val_loss: 0.4546 - val_accuracy: 0.9114\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7505 - accuracy: 0.7358 - val_loss: 0.4401 - val_accuracy: 0.9222\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7521 - accuracy: 0.7389 - val_loss: 0.4330 - val_accuracy: 0.9183\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7143 - accuracy: 0.7519 - val_loss: 0.4166 - val_accuracy: 0.9248\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7051 - accuracy: 0.7577 - val_loss: 0.4098 - val_accuracy: 0.9249\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7017 - accuracy: 0.7621 - val_loss: 0.3965 - val_accuracy: 0.9283\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6761 - accuracy: 0.7735 - val_loss: 0.3841 - val_accuracy: 0.9335\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6632 - accuracy: 0.7773 - val_loss: 0.3756 - val_accuracy: 0.9339\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6417 - accuracy: 0.7874 - val_loss: 0.3699 - val_accuracy: 0.9351\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6366 - accuracy: 0.7909 - val_loss: 0.3654 - val_accuracy: 0.9408\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6277 - accuracy: 0.7960 - val_loss: 0.3601 - val_accuracy: 0.9399\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6046 - accuracy: 0.8045 - val_loss: 0.3572 - val_accuracy: 0.9443\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6065 - accuracy: 0.8080 - val_loss: 0.3444 - val_accuracy: 0.9405\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5963 - accuracy: 0.8088 - val_loss: 0.3409 - val_accuracy: 0.9411\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5814 - accuracy: 0.8152 - val_loss: 0.3446 - val_accuracy: 0.9488\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5597 - accuracy: 0.8227 - val_loss: 0.3239 - val_accuracy: 0.9505\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5522 - accuracy: 0.8273 - val_loss: 0.3394 - val_accuracy: 0.9523\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5442 - accuracy: 0.8285 - val_loss: 0.3327 - val_accuracy: 0.9441\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5476 - accuracy: 0.8303 - val_loss: 0.3268 - val_accuracy: 0.9438\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5332 - accuracy: 0.8358 - val_loss: 0.3139 - val_accuracy: 0.9463\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5279 - accuracy: 0.8376 - val_loss: 0.3295 - val_accuracy: 0.9533\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.3020 - accuracy: 0.1129 - val_loss: 2.2821 - val_accuracy: 0.2871\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2808 - accuracy: 0.1524 - val_loss: 2.1863 - val_accuracy: 0.3296\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1938 - accuracy: 0.2115 - val_loss: 1.9305 - val_accuracy: 0.3536\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0118 - accuracy: 0.2775 - val_loss: 1.5824 - val_accuracy: 0.5122\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7757 - accuracy: 0.3682 - val_loss: 1.2386 - val_accuracy: 0.6284\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5343 - accuracy: 0.4555 - val_loss: 0.9380 - val_accuracy: 0.7366\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3200 - accuracy: 0.5292 - val_loss: 0.7377 - val_accuracy: 0.8132\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1613 - accuracy: 0.5954 - val_loss: 0.6196 - val_accuracy: 0.8462\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0372 - accuracy: 0.6454 - val_loss: 0.5319 - val_accuracy: 0.8702\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9468 - accuracy: 0.6877 - val_loss: 0.4679 - val_accuracy: 0.8826\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8658 - accuracy: 0.7218 - val_loss: 0.4222 - val_accuracy: 0.8904\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7971 - accuracy: 0.7520 - val_loss: 0.3827 - val_accuracy: 0.9037\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7512 - accuracy: 0.7652 - val_loss: 0.3495 - val_accuracy: 0.9136\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7026 - accuracy: 0.7845 - val_loss: 0.3231 - val_accuracy: 0.9184\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6658 - accuracy: 0.8013 - val_loss: 0.3017 - val_accuracy: 0.9227\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6349 - accuracy: 0.8124 - val_loss: 0.2739 - val_accuracy: 0.9327\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5948 - accuracy: 0.8292 - val_loss: 0.2616 - val_accuracy: 0.9333\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5698 - accuracy: 0.8350 - val_loss: 0.2463 - val_accuracy: 0.9362\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5471 - accuracy: 0.8434 - val_loss: 0.2310 - val_accuracy: 0.9429\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5185 - accuracy: 0.8540 - val_loss: 0.2197 - val_accuracy: 0.9447\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4914 - accuracy: 0.8622 - val_loss: 0.2093 - val_accuracy: 0.9473\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4761 - accuracy: 0.8638 - val_loss: 0.2001 - val_accuracy: 0.9516\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4700 - accuracy: 0.8700 - val_loss: 0.1940 - val_accuracy: 0.9518\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4438 - accuracy: 0.8770 - val_loss: 0.1833 - val_accuracy: 0.9538\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4292 - accuracy: 0.8826 - val_loss: 0.1799 - val_accuracy: 0.9547\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4078 - accuracy: 0.8880 - val_loss: 0.1735 - val_accuracy: 0.9571\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4079 - accuracy: 0.8869 - val_loss: 0.1708 - val_accuracy: 0.9572\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3924 - accuracy: 0.8919 - val_loss: 0.1641 - val_accuracy: 0.9595\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3739 - accuracy: 0.8943 - val_loss: 0.1639 - val_accuracy: 0.9585\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3676 - accuracy: 0.8995 - val_loss: 0.1637 - val_accuracy: 0.9605\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3585 - accuracy: 0.8996 - val_loss: 0.1599 - val_accuracy: 0.9609\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3462 - accuracy: 0.9021 - val_loss: 0.1544 - val_accuracy: 0.9607\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3407 - accuracy: 0.9072 - val_loss: 0.1557 - val_accuracy: 0.9614\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3298 - accuracy: 0.9084 - val_loss: 0.1583 - val_accuracy: 0.9616\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3343 - accuracy: 0.9120 - val_loss: 0.1477 - val_accuracy: 0.9646\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3162 - accuracy: 0.9136 - val_loss: 0.1484 - val_accuracy: 0.9642\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3002 - accuracy: 0.9179 - val_loss: 0.1442 - val_accuracy: 0.9637\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3023 - accuracy: 0.9155 - val_loss: 0.1410 - val_accuracy: 0.9637\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2907 - accuracy: 0.9189 - val_loss: 0.1428 - val_accuracy: 0.9643\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2929 - accuracy: 0.9200 - val_loss: 0.1444 - val_accuracy: 0.9657\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2912 - accuracy: 0.9238 - val_loss: 0.1442 - val_accuracy: 0.9658\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2784 - accuracy: 0.9254 - val_loss: 0.1411 - val_accuracy: 0.9663\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2752 - accuracy: 0.9257 - val_loss: 0.1405 - val_accuracy: 0.9668\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2752 - accuracy: 0.9257 - val_loss: 0.1436 - val_accuracy: 0.9669\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2595 - accuracy: 0.9288 - val_loss: 0.1382 - val_accuracy: 0.9683\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2650 - accuracy: 0.9289 - val_loss: 0.1331 - val_accuracy: 0.9688\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2552 - accuracy: 0.9298 - val_loss: 0.1327 - val_accuracy: 0.9678\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2505 - accuracy: 0.9322 - val_loss: 0.1361 - val_accuracy: 0.9671\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2480 - accuracy: 0.9333 - val_loss: 0.1383 - val_accuracy: 0.9686\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2368 - accuracy: 0.9366 - val_loss: 0.1326 - val_accuracy: 0.9701\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.0712 - accuracy: 0.2499 - val_loss: 1.0043 - val_accuracy: 0.7375\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3612 - accuracy: 0.5301 - val_loss: 0.6356 - val_accuracy: 0.8443\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0962 - accuracy: 0.6270 - val_loss: 0.4868 - val_accuracy: 0.8767\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9485 - accuracy: 0.6831 - val_loss: 0.4216 - val_accuracy: 0.8872\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8601 - accuracy: 0.7212 - val_loss: 0.3782 - val_accuracy: 0.8969\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8135 - accuracy: 0.7382 - val_loss: 0.3535 - val_accuracy: 0.9040\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7528 - accuracy: 0.7602 - val_loss: 0.3358 - val_accuracy: 0.9064\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7255 - accuracy: 0.7755 - val_loss: 0.3198 - val_accuracy: 0.9102\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7026 - accuracy: 0.7853 - val_loss: 0.3082 - val_accuracy: 0.9143\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6773 - accuracy: 0.7954 - val_loss: 0.2996 - val_accuracy: 0.9158\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6576 - accuracy: 0.8041 - val_loss: 0.2960 - val_accuracy: 0.9158\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6389 - accuracy: 0.8131 - val_loss: 0.2839 - val_accuracy: 0.9227\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6101 - accuracy: 0.8255 - val_loss: 0.2761 - val_accuracy: 0.9237\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5967 - accuracy: 0.8263 - val_loss: 0.2698 - val_accuracy: 0.9246\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5857 - accuracy: 0.8320 - val_loss: 0.2639 - val_accuracy: 0.9272\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5815 - accuracy: 0.8318 - val_loss: 0.2567 - val_accuracy: 0.9290\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5584 - accuracy: 0.8444 - val_loss: 0.2535 - val_accuracy: 0.9294\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5461 - accuracy: 0.8473 - val_loss: 0.2508 - val_accuracy: 0.9300\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5365 - accuracy: 0.8523 - val_loss: 0.2419 - val_accuracy: 0.9337\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5205 - accuracy: 0.8563 - val_loss: 0.2389 - val_accuracy: 0.9329\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5034 - accuracy: 0.8600 - val_loss: 0.2318 - val_accuracy: 0.9356\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5120 - accuracy: 0.8607 - val_loss: 0.2277 - val_accuracy: 0.9352\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4899 - accuracy: 0.8678 - val_loss: 0.2255 - val_accuracy: 0.9391\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4871 - accuracy: 0.8706 - val_loss: 0.2171 - val_accuracy: 0.9398\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4785 - accuracy: 0.8714 - val_loss: 0.2140 - val_accuracy: 0.9409\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4631 - accuracy: 0.8750 - val_loss: 0.2157 - val_accuracy: 0.9426\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4463 - accuracy: 0.8822 - val_loss: 0.2102 - val_accuracy: 0.9438\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4456 - accuracy: 0.8805 - val_loss: 0.2091 - val_accuracy: 0.9443\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4442 - accuracy: 0.8815 - val_loss: 0.2042 - val_accuracy: 0.9450\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4398 - accuracy: 0.8852 - val_loss: 0.2023 - val_accuracy: 0.9463\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4273 - accuracy: 0.8896 - val_loss: 0.2016 - val_accuracy: 0.9464\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4110 - accuracy: 0.8904 - val_loss: 0.1917 - val_accuracy: 0.9487\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4307 - accuracy: 0.8875 - val_loss: 0.1919 - val_accuracy: 0.9496\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4035 - accuracy: 0.8939 - val_loss: 0.1886 - val_accuracy: 0.9498\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4054 - accuracy: 0.8962 - val_loss: 0.1880 - val_accuracy: 0.9505\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3870 - accuracy: 0.8996 - val_loss: 0.1842 - val_accuracy: 0.9523\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3911 - accuracy: 0.8988 - val_loss: 0.1813 - val_accuracy: 0.9512\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3811 - accuracy: 0.8993 - val_loss: 0.1816 - val_accuracy: 0.9532\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3898 - accuracy: 0.8956 - val_loss: 0.1784 - val_accuracy: 0.9534\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3824 - accuracy: 0.8993 - val_loss: 0.1780 - val_accuracy: 0.9537\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3807 - accuracy: 0.9014 - val_loss: 0.1749 - val_accuracy: 0.9549\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3770 - accuracy: 0.9027 - val_loss: 0.1747 - val_accuracy: 0.9554\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3607 - accuracy: 0.9084 - val_loss: 0.1714 - val_accuracy: 0.9563\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3518 - accuracy: 0.9077 - val_loss: 0.1682 - val_accuracy: 0.9553\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3618 - accuracy: 0.9050 - val_loss: 0.1735 - val_accuracy: 0.9563\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3450 - accuracy: 0.9116 - val_loss: 0.1673 - val_accuracy: 0.9572\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3493 - accuracy: 0.9095 - val_loss: 0.1620 - val_accuracy: 0.9580\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3481 - accuracy: 0.9119 - val_loss: 0.1646 - val_accuracy: 0.9582\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.9125 - val_loss: 0.1676 - val_accuracy: 0.9572\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3391 - accuracy: 0.9154 - val_loss: 0.1619 - val_accuracy: 0.9592\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.6961 - accuracy: 0.0970 - val_loss: 2.3159 - val_accuracy: 0.1036\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4942 - accuracy: 0.1002 - val_loss: 2.2726 - val_accuracy: 0.1018\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4002 - accuracy: 0.1008 - val_loss: 2.2538 - val_accuracy: 0.1002\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3591 - accuracy: 0.1043 - val_loss: 2.2541 - val_accuracy: 0.0995\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3313 - accuracy: 0.1067 - val_loss: 2.2624 - val_accuracy: 0.1125\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3183 - accuracy: 0.1076 - val_loss: 2.2739 - val_accuracy: 0.1542\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3089 - accuracy: 0.1140 - val_loss: 2.2755 - val_accuracy: 0.1502\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3070 - accuracy: 0.1120 - val_loss: 2.2836 - val_accuracy: 0.1421\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3012 - accuracy: 0.1181 - val_loss: 2.2912 - val_accuracy: 0.1307\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2965 - accuracy: 0.1214 - val_loss: 2.2927 - val_accuracy: 0.1023\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2934 - accuracy: 0.1247 - val_loss: 2.2445 - val_accuracy: 0.1299\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2848 - accuracy: 0.1354 - val_loss: 2.1116 - val_accuracy: 0.1787\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2688 - accuracy: 0.1498 - val_loss: 2.1032 - val_accuracy: 0.2002\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2184 - accuracy: 0.1820 - val_loss: 2.7703 - val_accuracy: 0.2035\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1484 - accuracy: 0.2020 - val_loss: 3.0692 - val_accuracy: 0.2027\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0998 - accuracy: 0.2128 - val_loss: 3.0091 - val_accuracy: 0.2017\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0748 - accuracy: 0.2148 - val_loss: 2.9126 - val_accuracy: 0.2019\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0567 - accuracy: 0.2147 - val_loss: 2.9168 - val_accuracy: 0.2018\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0439 - accuracy: 0.2182 - val_loss: 2.9414 - val_accuracy: 0.2019\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0358 - accuracy: 0.2213 - val_loss: 2.9980 - val_accuracy: 0.2018\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0340 - accuracy: 0.2213 - val_loss: 3.0216 - val_accuracy: 0.2017\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0334 - accuracy: 0.2210 - val_loss: 3.1741 - val_accuracy: 0.2017\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0316 - accuracy: 0.2215 - val_loss: 3.2800 - val_accuracy: 0.2020\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0267 - accuracy: 0.2189 - val_loss: 3.3651 - val_accuracy: 0.2023\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0235 - accuracy: 0.2212 - val_loss: 3.3330 - val_accuracy: 0.2020\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0233 - accuracy: 0.2216 - val_loss: 3.3689 - val_accuracy: 0.2017\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0217 - accuracy: 0.2207 - val_loss: 3.2929 - val_accuracy: 0.2023\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0206 - accuracy: 0.2222 - val_loss: 3.9015 - val_accuracy: 0.2024\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0114 - accuracy: 0.2261 - val_loss: 4.1831 - val_accuracy: 0.2026\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0089 - accuracy: 0.2289 - val_loss: 4.5359 - val_accuracy: 0.2028\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0058 - accuracy: 0.2302 - val_loss: 4.6372 - val_accuracy: 0.2027\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0067 - accuracy: 0.2316 - val_loss: 5.3962 - val_accuracy: 0.2027\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9958 - accuracy: 0.2358 - val_loss: 5.7580 - val_accuracy: 0.2041\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9898 - accuracy: 0.2460 - val_loss: 5.9201 - val_accuracy: 0.2157\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9633 - accuracy: 0.2566 - val_loss: 6.2043 - val_accuracy: 0.2796\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8896 - accuracy: 0.2794 - val_loss: 7.1550 - val_accuracy: 0.3054\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7933 - accuracy: 0.2953 - val_loss: 6.7445 - val_accuracy: 0.3124\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7413 - accuracy: 0.3047 - val_loss: 7.3522 - val_accuracy: 0.3097\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6931 - accuracy: 0.3135 - val_loss: 7.1249 - val_accuracy: 0.3069\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3170 - val_loss: 5.7860 - val_accuracy: 0.3233\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6648 - accuracy: 0.3161 - val_loss: 6.6641 - val_accuracy: 0.3069\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6459 - accuracy: 0.3208 - val_loss: 6.7952 - val_accuracy: 0.3161\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6383 - accuracy: 0.3131 - val_loss: 6.3768 - val_accuracy: 0.3067\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6306 - accuracy: 0.3167 - val_loss: 7.5964 - val_accuracy: 0.3070\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6253 - accuracy: 0.3219 - val_loss: 7.9154 - val_accuracy: 0.3063\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6214 - accuracy: 0.3184 - val_loss: 7.1398 - val_accuracy: 0.3071\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6103 - accuracy: 0.3236 - val_loss: 6.7603 - val_accuracy: 0.3072\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5941 - accuracy: 0.3292 - val_loss: 8.9067 - val_accuracy: 0.3058\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5946 - accuracy: 0.3277 - val_loss: 7.8799 - val_accuracy: 0.3067\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6005 - accuracy: 0.3246 - val_loss: 7.5530 - val_accuracy: 0.3075\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 7ms/step - loss: 2.3020 - accuracy: 0.1155 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3006 - accuracy: 0.1137 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3002 - accuracy: 0.1116 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2990 - accuracy: 0.1167 - val_loss: 2.2996 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2983 - accuracy: 0.1135 - val_loss: 2.2988 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2974 - accuracy: 0.1158 - val_loss: 2.2978 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2964 - accuracy: 0.1155 - val_loss: 2.2963 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2948 - accuracy: 0.1203 - val_loss: 2.2939 - val_accuracy: 0.1074\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2920 - accuracy: 0.1270 - val_loss: 2.2885 - val_accuracy: 0.1278\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2843 - accuracy: 0.1565 - val_loss: 2.2670 - val_accuracy: 0.1863\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2557 - accuracy: 0.1889 - val_loss: 2.1862 - val_accuracy: 0.1971\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1931 - accuracy: 0.1924 - val_loss: 2.0561 - val_accuracy: 0.2100\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1000 - accuracy: 0.2072 - val_loss: 1.9677 - val_accuracy: 0.2298\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0210 - accuracy: 0.2380 - val_loss: 1.8679 - val_accuracy: 0.2817\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9410 - accuracy: 0.2711 - val_loss: 1.7608 - val_accuracy: 0.3519\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8626 - accuracy: 0.2945 - val_loss: 1.6452 - val_accuracy: 0.3890\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7723 - accuracy: 0.3258 - val_loss: 1.5399 - val_accuracy: 0.4485\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6739 - accuracy: 0.3622 - val_loss: 1.4031 - val_accuracy: 0.5230\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5804 - accuracy: 0.3975 - val_loss: 1.2509 - val_accuracy: 0.5809\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4806 - accuracy: 0.4384 - val_loss: 1.1412 - val_accuracy: 0.6134\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3904 - accuracy: 0.4720 - val_loss: 1.0542 - val_accuracy: 0.6338\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3117 - accuracy: 0.5053 - val_loss: 0.9824 - val_accuracy: 0.6830\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2535 - accuracy: 0.5403 - val_loss: 0.9246 - val_accuracy: 0.7062\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1885 - accuracy: 0.5722 - val_loss: 0.8734 - val_accuracy: 0.7348\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1460 - accuracy: 0.5845 - val_loss: 0.8261 - val_accuracy: 0.7656\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1082 - accuracy: 0.6074 - val_loss: 0.7825 - val_accuracy: 0.7731\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0571 - accuracy: 0.6264 - val_loss: 0.7475 - val_accuracy: 0.7707\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0372 - accuracy: 0.6400 - val_loss: 0.7144 - val_accuracy: 0.7820\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9944 - accuracy: 0.6544 - val_loss: 0.6827 - val_accuracy: 0.8022\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9714 - accuracy: 0.6634 - val_loss: 0.6579 - val_accuracy: 0.8158\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9377 - accuracy: 0.6815 - val_loss: 0.6425 - val_accuracy: 0.8215\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9250 - accuracy: 0.6838 - val_loss: 0.6203 - val_accuracy: 0.8319\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9035 - accuracy: 0.6963 - val_loss: 0.5907 - val_accuracy: 0.8475\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8817 - accuracy: 0.7113 - val_loss: 0.5717 - val_accuracy: 0.8656\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8612 - accuracy: 0.7187 - val_loss: 0.5409 - val_accuracy: 0.8788\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8398 - accuracy: 0.7262 - val_loss: 0.5123 - val_accuracy: 0.8917\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8224 - accuracy: 0.7404 - val_loss: 0.4978 - val_accuracy: 0.8927\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7969 - accuracy: 0.7479 - val_loss: 0.4769 - val_accuracy: 0.9021\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7857 - accuracy: 0.7525 - val_loss: 0.4567 - val_accuracy: 0.9018\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7666 - accuracy: 0.7664 - val_loss: 0.4384 - val_accuracy: 0.9079\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7612 - accuracy: 0.7640 - val_loss: 0.4334 - val_accuracy: 0.9044\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7325 - accuracy: 0.7770 - val_loss: 0.4067 - val_accuracy: 0.9126\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7143 - accuracy: 0.7844 - val_loss: 0.3966 - val_accuracy: 0.9167\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6997 - accuracy: 0.7886 - val_loss: 0.3911 - val_accuracy: 0.9187\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6958 - accuracy: 0.7899 - val_loss: 0.3818 - val_accuracy: 0.9188\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6880 - accuracy: 0.7957 - val_loss: 0.3687 - val_accuracy: 0.9227\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6640 - accuracy: 0.8021 - val_loss: 0.3736 - val_accuracy: 0.9217\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6662 - accuracy: 0.8046 - val_loss: 0.3532 - val_accuracy: 0.9241\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6337 - accuracy: 0.8104 - val_loss: 0.3476 - val_accuracy: 0.9275\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6366 - accuracy: 0.8107 - val_loss: 0.3418 - val_accuracy: 0.9258\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.3021 - accuracy: 0.1193 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3010 - accuracy: 0.1140 - val_loss: 2.3012 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2999 - accuracy: 0.1154 - val_loss: 2.3008 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2994 - accuracy: 0.1169 - val_loss: 2.3004 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2996 - accuracy: 0.1128 - val_loss: 2.3000 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2988 - accuracy: 0.1142 - val_loss: 2.2994 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2983 - accuracy: 0.1136 - val_loss: 2.2988 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2974 - accuracy: 0.1144 - val_loss: 2.2981 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2966 - accuracy: 0.1164 - val_loss: 2.2972 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2962 - accuracy: 0.1136 - val_loss: 2.2961 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2948 - accuracy: 0.1144 - val_loss: 2.2947 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2932 - accuracy: 0.1161 - val_loss: 2.2927 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2911 - accuracy: 0.1185 - val_loss: 2.2897 - val_accuracy: 0.1061\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2870 - accuracy: 0.1252 - val_loss: 2.2844 - val_accuracy: 0.1145\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2815 - accuracy: 0.1490 - val_loss: 2.2732 - val_accuracy: 0.1558\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2669 - accuracy: 0.1816 - val_loss: 2.2352 - val_accuracy: 0.2504\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2089 - accuracy: 0.2103 - val_loss: 2.0599 - val_accuracy: 0.2272\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0757 - accuracy: 0.2304 - val_loss: 1.9250 - val_accuracy: 0.2702\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9908 - accuracy: 0.2634 - val_loss: 1.8461 - val_accuracy: 0.3145\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9284 - accuracy: 0.2884 - val_loss: 1.7816 - val_accuracy: 0.3436\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8624 - accuracy: 0.3145 - val_loss: 1.7225 - val_accuracy: 0.3724\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8061 - accuracy: 0.3316 - val_loss: 1.6617 - val_accuracy: 0.4055\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7523 - accuracy: 0.3556 - val_loss: 1.5805 - val_accuracy: 0.4843\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6774 - accuracy: 0.3881 - val_loss: 1.4370 - val_accuracy: 0.5173\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5778 - accuracy: 0.4191 - val_loss: 1.3196 - val_accuracy: 0.5537\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4901 - accuracy: 0.4502 - val_loss: 1.2210 - val_accuracy: 0.5897\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4172 - accuracy: 0.4777 - val_loss: 1.1379 - val_accuracy: 0.6289\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3486 - accuracy: 0.5134 - val_loss: 1.0646 - val_accuracy: 0.6647\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3020 - accuracy: 0.5300 - val_loss: 0.9991 - val_accuracy: 0.6925\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2444 - accuracy: 0.5574 - val_loss: 0.9353 - val_accuracy: 0.7212\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1981 - accuracy: 0.5808 - val_loss: 0.8822 - val_accuracy: 0.7426\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1517 - accuracy: 0.5959 - val_loss: 0.8316 - val_accuracy: 0.7520\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1075 - accuracy: 0.6102 - val_loss: 0.7941 - val_accuracy: 0.7632\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0663 - accuracy: 0.6236 - val_loss: 0.7528 - val_accuracy: 0.7790\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0418 - accuracy: 0.6411 - val_loss: 0.7238 - val_accuracy: 0.7968\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0022 - accuracy: 0.6508 - val_loss: 0.6972 - val_accuracy: 0.7950\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9754 - accuracy: 0.6630 - val_loss: 0.6728 - val_accuracy: 0.8048\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9577 - accuracy: 0.6755 - val_loss: 0.6517 - val_accuracy: 0.8175\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9424 - accuracy: 0.6815 - val_loss: 0.6344 - val_accuracy: 0.8225\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9212 - accuracy: 0.6926 - val_loss: 0.6154 - val_accuracy: 0.8327\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8959 - accuracy: 0.6993 - val_loss: 0.5998 - val_accuracy: 0.8347\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8845 - accuracy: 0.7085 - val_loss: 0.5838 - val_accuracy: 0.8421\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8580 - accuracy: 0.7142 - val_loss: 0.5679 - val_accuracy: 0.8447\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8436 - accuracy: 0.7227 - val_loss: 0.5503 - val_accuracy: 0.8550\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8278 - accuracy: 0.7314 - val_loss: 0.5344 - val_accuracy: 0.8633\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8177 - accuracy: 0.7407 - val_loss: 0.5196 - val_accuracy: 0.8689\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8050 - accuracy: 0.7506 - val_loss: 0.5055 - val_accuracy: 0.8745\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7826 - accuracy: 0.7506 - val_loss: 0.4871 - val_accuracy: 0.8763\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7675 - accuracy: 0.7615 - val_loss: 0.4752 - val_accuracy: 0.8842\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7664 - accuracy: 0.7647 - val_loss: 0.4580 - val_accuracy: 0.8886\n",
      "{'loss': [2.4215915203094482, 2.3627402782440186, 2.344712018966675, 2.335618734359741, 2.329418420791626, 2.3247230052948, 2.3204829692840576, 2.3180878162384033, 2.314518928527832, 2.313589096069336, 2.310666561126709, 2.309666395187378, 2.3086585998535156, 2.308372974395752, 2.308926820755005, 2.306940793991089, 2.307079315185547, 2.3063228130340576, 2.305067777633667, 2.306272268295288, 2.305309772491455, 2.305882215499878, 2.304760694503784, 2.3055732250213623, 2.3054141998291016, 2.304441452026367, 2.304356336593628, 2.304215908050537, 2.304478406906128, 2.303508996963501, 2.3040621280670166, 2.3028860092163086, 2.3031511306762695, 2.3039212226867676, 2.3039872646331787, 2.3031721115112305, 2.3033108711242676, 2.3030545711517334, 2.3030900955200195, 2.30326771736145, 2.3031604290008545, 2.3031020164489746, 2.3025002479553223, 2.3028769493103027, 2.3025624752044678, 2.3023502826690674, 2.3026695251464844, 2.302170991897583, 2.3027355670928955, 2.3022122383117676], 'accuracy': [0.09983333200216293, 0.10247916728258133, 0.10406249761581421, 0.10185416787862778, 0.10237500071525574, 0.10229166597127914, 0.1028750017285347, 0.10225000232458115, 0.10322916507720947, 0.1028750017285347, 0.10622916370630264, 0.10631249845027924, 0.10754166543483734, 0.10512500256299973, 0.1028750017285347, 0.10627083480358124, 0.10510416328907013, 0.10406249761581421, 0.10693749785423279, 0.10760416835546494, 0.10774999856948853, 0.10710416734218597, 0.10854166746139526, 0.1054791659116745, 0.10700000077486038, 0.10958333313465118, 0.10885416716337204, 0.10787499696016312, 0.10762500017881393, 0.10833333432674408, 0.10764583200216293, 0.1107083335518837, 0.11010416597127914, 0.10827083140611649, 0.10977083444595337, 0.10893750190734863, 0.10929166525602341, 0.10956250131130219, 0.10912500321865082, 0.11079166829586029, 0.1106875017285347, 0.11170833557844162, 0.11089583486318588, 0.109395831823349, 0.11143749952316284, 0.11047916859388351, 0.11252083629369736, 0.11187499761581421, 0.11170833557844162, 0.11216666549444199], 'val_loss': [2.304610252380371, 2.3021340370178223, 2.3020315170288086, 2.302110433578491, 2.302025079727173, 2.302077054977417, 2.302067995071411, 2.302093744277954, 2.3020412921905518, 2.302016496658325, 2.302011489868164, 2.302032947540283, 2.3020265102386475, 2.3020570278167725, 2.302050828933716, 2.3020126819610596, 2.3020358085632324, 2.3020503520965576, 2.3020288944244385, 2.3020169734954834, 2.3020243644714355, 2.302015542984009, 2.3020222187042236, 2.3020524978637695, 2.302051067352295, 2.302042007446289, 2.3020317554473877, 2.3020222187042236, 2.3020365238189697, 2.302039623260498, 2.3020105361938477, 2.3020076751708984, 2.302016019821167, 2.3019979000091553, 2.302004814147949, 2.3020381927490234, 2.302043914794922, 2.302056074142456, 2.3020613193511963, 2.302056074142456, 2.302065849304199, 2.302056074142456, 2.3020310401916504, 2.302039861679077, 2.3020241260528564, 2.302016019821167, 2.3020167350769043, 2.302025318145752, 2.302009105682373, 2.302006244659424], 'val_accuracy': [0.09749999642372131, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [1.8528660535812378, 1.3934847116470337, 1.1893922090530396, 1.0630015134811401, 0.9764966368675232, 0.9157841205596924, 0.8678216934204102, 0.833157479763031, 0.791664719581604, 0.7726945877075195, 0.740242600440979, 0.7186058163642883, 0.6993386149406433, 0.6800981760025024, 0.6609567999839783, 0.6466597318649292, 0.6369554996490479, 0.6208298206329346, 0.610866367816925, 0.5954692959785461, 0.5921657681465149, 0.5749053359031677, 0.5713586211204529, 0.5651484727859497, 0.552495539188385, 0.5499646663665771, 0.5393717885017395, 0.5298720002174377, 0.5265746712684631, 0.5182984471321106, 0.5205724835395813, 0.5106070637702942, 0.5068827867507935, 0.498320996761322, 0.4977998435497284, 0.4952058494091034, 0.49060729146003723, 0.48676207661628723, 0.4700586199760437, 0.4730089604854584, 0.46478524804115295, 0.46383407711982727, 0.4525303542613983, 0.4470154345035553, 0.445281445980072, 0.4409429430961609, 0.4419328272342682, 0.43409228324890137, 0.43630146980285645, 0.42797771096229553], 'accuracy': [0.3529791533946991, 0.5410833358764648, 0.6164583563804626, 0.6619166731834412, 0.6906041502952576, 0.7150624990463257, 0.7355833053588867, 0.7475833296775818, 0.7622083425521851, 0.7728333473205566, 0.7875416874885559, 0.7949583530426025, 0.8002291917800903, 0.8102083206176758, 0.8162500262260437, 0.8207291960716248, 0.8276458382606506, 0.8330000042915344, 0.8385624885559082, 0.8425624966621399, 0.8442291617393494, 0.8488958477973938, 0.8522083163261414, 0.8536875247955322, 0.8569166660308838, 0.8600000143051147, 0.8626458048820496, 0.8647500276565552, 0.8656250238418579, 0.8683541417121887, 0.8678749799728394, 0.8726458549499512, 0.8738750219345093, 0.8763750195503235, 0.8772916793823242, 0.8760833144187927, 0.8794999718666077, 0.8799375295639038, 0.8834791779518127, 0.8842291831970215, 0.8852499723434448, 0.8859583139419556, 0.8891041874885559, 0.8892499804496765, 0.8928541541099548, 0.8925416469573975, 0.8923541903495789, 0.893625020980835, 0.8932291865348816, 0.8947083353996277], 'val_loss': [1.1323027610778809, 0.8312018513679504, 0.6778258085250854, 0.5869042873382568, 0.5272589921951294, 0.4835197627544403, 0.45297953486442566, 0.4270571172237396, 0.40758004784584045, 0.39182567596435547, 0.38038933277130127, 0.36677640676498413, 0.35849276185035706, 0.3454415798187256, 0.34343093633651733, 0.33576110005378723, 0.33184555172920227, 0.3254567086696625, 0.31816649436950684, 0.31921863555908203, 0.3120056688785553, 0.31215253472328186, 0.3034573197364807, 0.3004196286201477, 0.2996451258659363, 0.29205769300460815, 0.29270970821380615, 0.2875736355781555, 0.29037976264953613, 0.2847633361816406, 0.28375044465065, 0.27840766310691833, 0.27364301681518555, 0.27128586173057556, 0.26970916986465454, 0.26957961916923523, 0.2644880712032318, 0.2581607401371002, 0.25653380155563354, 0.2546789050102234, 0.2501846253871918, 0.24999064207077026, 0.24498023092746735, 0.24762915074825287, 0.24062740802764893, 0.24050548672676086, 0.23472900688648224, 0.2338147610425949, 0.22947059571743011, 0.23157545924186707], 'val_accuracy': [0.7516666650772095, 0.8253333568572998, 0.8513333201408386, 0.8598333597183228, 0.8697500228881836, 0.8757500052452087, 0.8798333406448364, 0.8853333592414856, 0.8880000114440918, 0.8930000066757202, 0.8960000276565552, 0.8994166851043701, 0.9010000228881836, 0.9066666960716248, 0.906333327293396, 0.9106666445732117, 0.9105833172798157, 0.9150833487510681, 0.9160833358764648, 0.9157500267028809, 0.9200833439826965, 0.918749988079071, 0.9227499961853027, 0.922166645526886, 0.9240833520889282, 0.9264166951179504, 0.9267500042915344, 0.9267500042915344, 0.9282500147819519, 0.9295833110809326, 0.9298333525657654, 0.9308333396911621, 0.9320833086967468, 0.9334166646003723, 0.9348333477973938, 0.9336666464805603, 0.937333345413208, 0.9380833506584167, 0.9395833611488342, 0.940833330154419, 0.9403333067893982, 0.9409999847412109, 0.9419999718666077, 0.9430833458900452, 0.9439166784286499, 0.9449166655540466, 0.9451666474342346, 0.9457499980926514, 0.9465000033378601, 0.9460833072662354]}\n",
      "{'loss': [2.3027162551879883, 2.2932205200195312, 2.2591519355773926, 2.1643002033233643, 2.0265846252441406, 1.8685944080352783, 1.7323119640350342, 1.6216756105422974, 1.5253735780715942, 1.4468580484390259, 1.381121277809143, 1.3273916244506836, 1.2765891551971436, 1.2326850891113281, 1.1875497102737427, 1.1487895250320435, 1.1112377643585205, 1.0761654376983643, 1.0464797019958496, 1.0081218481063843, 0.9794708490371704, 0.9570857882499695, 0.9220905900001526, 0.8943087458610535, 0.8741294145584106, 0.8497166633605957, 0.8249743580818176, 0.8084761500358582, 0.7943565845489502, 0.7733797430992126, 0.7519353628158569, 0.7412108778953552, 0.7132612466812134, 0.7091061472892761, 0.6925299763679504, 0.6748905181884766, 0.6616430282592773, 0.642579197883606, 0.6354301571846008, 0.6137668490409851, 0.6049373149871826, 0.6031621098518372, 0.5886491537094116, 0.5803333520889282, 0.5674196481704712, 0.5550769567489624, 0.5507529377937317, 0.5497483015060425, 0.5339357256889343, 0.5312663316726685], 'accuracy': [0.11397916823625565, 0.13485416769981384, 0.1575208306312561, 0.1886875033378601, 0.22977083921432495, 0.2774375081062317, 0.3095208406448364, 0.34447917342185974, 0.3789583444595337, 0.4038124978542328, 0.429791659116745, 0.453125, 0.4736458361148834, 0.4934583306312561, 0.5108333230018616, 0.5260208249092102, 0.5458750128746033, 0.5644375085830688, 0.5820000171661377, 0.6048333048820496, 0.6250625252723694, 0.6355833411216736, 0.6535833477973938, 0.6688958406448364, 0.6845625042915344, 0.6903333067893982, 0.7048333287239075, 0.7151458263397217, 0.7206458449363708, 0.7283333539962769, 0.7383333444595337, 0.7406874895095825, 0.7533541917800903, 0.7556041479110718, 0.7669166922569275, 0.7736250162124634, 0.7796249985694885, 0.7906041741371155, 0.7932500243186951, 0.7995833158493042, 0.8052083253860474, 0.8065833449363708, 0.812375009059906, 0.8150625228881836, 0.8211458325386047, 0.8286041617393494, 0.8274791836738586, 0.8297708630561829, 0.8342708349227905, 0.836062490940094], 'val_loss': [2.2963430881500244, 2.270048141479492, 2.1568384170532227, 1.970064401626587, 1.7338135242462158, 1.5228121280670166, 1.3759000301361084, 1.2616751194000244, 1.174683690071106, 1.1184821128845215, 1.0556210279464722, 1.000581979751587, 0.9477545619010925, 0.9120997190475464, 0.863323986530304, 0.8264504671096802, 0.7889506816864014, 0.7550813555717468, 0.7204338312149048, 0.6771530508995056, 0.6462497711181641, 0.6193091869354248, 0.58432936668396, 0.5591886043548584, 0.5400382876396179, 0.5205667614936829, 0.5032755732536316, 0.4832877218723297, 0.474170446395874, 0.45455512404441833, 0.4401110112667084, 0.43301862478256226, 0.4165973365306854, 0.40984147787094116, 0.3964915871620178, 0.3840540647506714, 0.37562665343284607, 0.3698902130126953, 0.3654155135154724, 0.3601146638393402, 0.357230544090271, 0.34444111585617065, 0.34092268347740173, 0.3445618152618408, 0.32393214106559753, 0.33944782614707947, 0.33274298906326294, 0.32679930329322815, 0.3138867914676666, 0.3294638693332672], 'val_accuracy': [0.10599999874830246, 0.17100000381469727, 0.2747499942779541, 0.32475000619888306, 0.3331666588783264, 0.4045833349227905, 0.46650001406669617, 0.4896666705608368, 0.5260833501815796, 0.5488333106040955, 0.5684999823570251, 0.5767499804496765, 0.5996666550636292, 0.6184166669845581, 0.6269166469573975, 0.6346666812896729, 0.6623333096504211, 0.6853333115577698, 0.7365000247955322, 0.7609999775886536, 0.8083333373069763, 0.8398333191871643, 0.856249988079071, 0.8809166550636292, 0.8743333220481873, 0.8956666588783264, 0.9043333530426025, 0.9075833559036255, 0.9109166860580444, 0.9114166498184204, 0.922249972820282, 0.9183333516120911, 0.924833357334137, 0.924916684627533, 0.9282500147819519, 0.9334999918937683, 0.9339166879653931, 0.9350833296775818, 0.940833330154419, 0.9399166703224182, 0.9443333148956299, 0.940500020980835, 0.9410833120346069, 0.9488333463668823, 0.9505000114440918, 0.9523333311080933, 0.9440833330154419, 0.9437500238418579, 0.9463333487510681, 0.95333331823349]}\n",
      "{'loss': [2.2981479167938232, 2.267676830291748, 2.1526265144348145, 1.9513719081878662, 1.716267466545105, 1.4819024801254272, 1.2752633094787598, 1.129834532737732, 1.0156843662261963, 0.9227192401885986, 0.8491387367248535, 0.7852106690406799, 0.7427719831466675, 0.6936752796173096, 0.6544001698493958, 0.6257756352424622, 0.5904237031936646, 0.5634651184082031, 0.5391747355461121, 0.5216202139854431, 0.4912000000476837, 0.48014137148857117, 0.46547338366508484, 0.44266068935394287, 0.42424044013023376, 0.4125250279903412, 0.4053981900215149, 0.3918352425098419, 0.37267863750457764, 0.3688569664955139, 0.3591102659702301, 0.3497535288333893, 0.3433390259742737, 0.33040764927864075, 0.3243948221206665, 0.31945371627807617, 0.3095472753047943, 0.3093242943286896, 0.29289841651916504, 0.294333815574646, 0.28588274121284485, 0.27976492047309875, 0.27693814039230347, 0.2673691511154175, 0.26420101523399353, 0.26108336448669434, 0.2564278542995453, 0.25426775217056274, 0.24867458641529083, 0.2435777336359024], 'accuracy': [0.12224999815225601, 0.16693750023841858, 0.22737500071525574, 0.3008958399295807, 0.39012500643730164, 0.47475001215934753, 0.5480208396911621, 0.6075000166893005, 0.6568958163261414, 0.6961666941642761, 0.7280208468437195, 0.7539583444595337, 0.7690833210945129, 0.788687527179718, 0.8047916889190674, 0.8156874775886536, 0.8298125267028809, 0.8369166851043701, 0.846750020980835, 0.8546249866485596, 0.8628125190734863, 0.8642916679382324, 0.8724166750907898, 0.8776875138282776, 0.882562518119812, 0.886145830154419, 0.8885625004768372, 0.8930416703224182, 0.8957291841506958, 0.9004374742507935, 0.9012083411216736, 0.902999997138977, 0.9080208539962769, 0.909208357334137, 0.9125208258628845, 0.9133541584014893, 0.9161249995231628, 0.9148749709129333, 0.9193750023841858, 0.9197916388511658, 0.925125002861023, 0.9244375228881836, 0.9243541955947876, 0.9268958568572998, 0.9278333187103271, 0.9296249747276306, 0.930020809173584, 0.9318749904632568, 0.9324166774749756, 0.9336249828338623], 'val_loss': [2.282097339630127, 2.1863386631011963, 1.9305490255355835, 1.582445502281189, 1.2386345863342285, 0.9379801154136658, 0.7376580238342285, 0.6195947527885437, 0.5319315791130066, 0.4679136872291565, 0.42216673493385315, 0.3827418088912964, 0.3495159149169922, 0.3230852782726288, 0.3017342984676361, 0.2739257514476776, 0.26159608364105225, 0.24633459746837616, 0.23100416362285614, 0.21967722475528717, 0.20932798087596893, 0.2000989317893982, 0.1940433531999588, 0.18328173458576202, 0.17988882958889008, 0.17347513139247894, 0.17083370685577393, 0.1640939563512802, 0.16390489041805267, 0.163651242852211, 0.1599431335926056, 0.15436163544654846, 0.15571899712085724, 0.158331036567688, 0.14771674573421478, 0.14840760827064514, 0.14418084919452667, 0.1409800797700882, 0.14281925559043884, 0.14435037970542908, 0.14416038990020752, 0.141103133559227, 0.14045169949531555, 0.14362360537052155, 0.13818466663360596, 0.13307112455368042, 0.13273093104362488, 0.13614703714847565, 0.13828350603580475, 0.13262031972408295], 'val_accuracy': [0.28708332777023315, 0.3295833468437195, 0.35358333587646484, 0.5121666789054871, 0.6284166574478149, 0.7365833520889282, 0.8131666779518127, 0.8461666703224182, 0.8702499866485596, 0.8825833201408386, 0.89041668176651, 0.9036666750907898, 0.9135833382606506, 0.9184166789054871, 0.9227499961853027, 0.9327499866485596, 0.9333333373069763, 0.9362499713897705, 0.9429166913032532, 0.9446666836738586, 0.9473333358764648, 0.9515833258628845, 0.9518333077430725, 0.9538333415985107, 0.9546666741371155, 0.9570833444595337, 0.9571666717529297, 0.9595000147819519, 0.9585000276565552, 0.9605000019073486, 0.9609166383743286, 0.9606666564941406, 0.9614166617393494, 0.9615833163261414, 0.9645833373069763, 0.9641666412353516, 0.9636666774749756, 0.9636666774749756, 0.9642500281333923, 0.965749979019165, 0.965833306312561, 0.9663333296775818, 0.9667500257492065, 0.9669166803359985, 0.9683333039283752, 0.96875, 0.9678333401679993, 0.9670833349227905, 0.968583345413208, 0.9700833559036255]}\n",
      "{'loss': [1.8268201351165771, 1.2846262454986572, 1.0499027967453003, 0.9280745983123779, 0.8456821441650391, 0.7988216280937195, 0.7579091191291809, 0.7196427583694458, 0.6972743272781372, 0.6712248921394348, 0.6479134559631348, 0.6331872940063477, 0.6103395819664001, 0.6004927158355713, 0.5783679485321045, 0.5688369870185852, 0.5579732060432434, 0.5493081212043762, 0.5310683846473694, 0.5230399370193481, 0.5050555467605591, 0.5015731453895569, 0.4873039126396179, 0.48306408524513245, 0.4737320840358734, 0.46070602536201477, 0.45174816250801086, 0.44387826323509216, 0.4411112070083618, 0.4310378432273865, 0.4254072308540344, 0.41588741540908813, 0.41846758127212524, 0.40672993659973145, 0.40025264024734497, 0.39728811383247375, 0.396185964345932, 0.38340863585472107, 0.38147231936454773, 0.3779943585395813, 0.3764604926109314, 0.3682844340801239, 0.3677951395511627, 0.36175504326820374, 0.3548947870731354, 0.3488767147064209, 0.3526770770549774, 0.3439953625202179, 0.3395979106426239, 0.3390261232852936], 'accuracy': [0.3502500057220459, 0.5560833215713501, 0.6436874866485596, 0.6922083497047424, 0.7280833125114441, 0.745270848274231, 0.7629374861717224, 0.7788749933242798, 0.7874374985694885, 0.7969791889190674, 0.8088333606719971, 0.8149583339691162, 0.8232499957084656, 0.8275416493415833, 0.8358333110809326, 0.8385833501815796, 0.8442916870117188, 0.8474166393280029, 0.8520833253860474, 0.8560000061988831, 0.8617083430290222, 0.8630208373069763, 0.8683750033378601, 0.8709375262260437, 0.8727916479110718, 0.8764791488647461, 0.8817291855812073, 0.8822916746139526, 0.8840416669845581, 0.8876875042915344, 0.8882083296775818, 0.8894166946411133, 0.8902083039283752, 0.893625020980835, 0.8959791660308838, 0.8957708477973938, 0.8973333239555359, 0.9002916812896729, 0.9001458287239075, 0.9018333554267883, 0.9027708172798157, 0.9042083621025085, 0.9052708148956299, 0.9068750143051147, 0.9075416922569275, 0.9113333225250244, 0.9091249704360962, 0.9121666550636292, 0.9123958349227905, 0.9149374961853027], 'val_loss': [1.0042585134506226, 0.6355506181716919, 0.4867617189884186, 0.4215993285179138, 0.3781818449497223, 0.3534962236881256, 0.3357788622379303, 0.3197929561138153, 0.308162122964859, 0.2995615005493164, 0.29598093032836914, 0.2838948965072632, 0.27609366178512573, 0.269772469997406, 0.26391687989234924, 0.25673019886016846, 0.2534598708152771, 0.25083106756210327, 0.24190126359462738, 0.23894143104553223, 0.23175431787967682, 0.2276822030544281, 0.22549709677696228, 0.21706357598304749, 0.21401825547218323, 0.21569165587425232, 0.21020886301994324, 0.2090696543455124, 0.20424135029315948, 0.2023361623287201, 0.20161186158657074, 0.19171740114688873, 0.19193480908870697, 0.18860797584056854, 0.187997967004776, 0.1841883361339569, 0.18131045997142792, 0.18164123594760895, 0.17840641736984253, 0.17800207436084747, 0.17488007247447968, 0.17467421293258667, 0.17143668234348297, 0.16824913024902344, 0.173542320728302, 0.1672980785369873, 0.16196118295192719, 0.1645500659942627, 0.16760848462581635, 0.1619492471218109], 'val_accuracy': [0.737500011920929, 0.8443333506584167, 0.8766666650772095, 0.8871666789054871, 0.8969166874885559, 0.9039999842643738, 0.906416654586792, 0.9101666808128357, 0.9143333435058594, 0.9157500267028809, 0.9158333539962769, 0.9227499961853027, 0.9236666560173035, 0.9245833158493042, 0.9271666407585144, 0.9290000200271606, 0.9294166564941406, 0.9300000071525574, 0.9337499737739563, 0.9329166412353516, 0.9355833530426025, 0.9352499842643738, 0.9390833377838135, 0.9398333430290222, 0.9409166574478149, 0.9425833225250244, 0.9438333511352539, 0.9443333148956299, 0.9449999928474426, 0.9462500214576721, 0.9464166760444641, 0.9486666917800903, 0.9495833516120911, 0.9497500061988831, 0.9505000114440918, 0.9523333311080933, 0.9511666893959045, 0.953249990940094, 0.953416645526886, 0.9536666870117188, 0.9549166560173035, 0.9554166793823242, 0.956333339214325, 0.9553333520889282, 0.956250011920929, 0.9571666717529297, 0.9580000042915344, 0.9582499861717224, 0.9572499990463257, 0.9591666460037231]}\n",
      "{'loss': [2.6275875568389893, 2.461513042449951, 2.3834455013275146, 2.3484389781951904, 2.3274078369140625, 2.315577745437622, 2.3082616329193115, 2.304455518722534, 2.2997517585754395, 2.2949814796447754, 2.2917168140411377, 2.282553195953369, 2.2597970962524414, 2.2000036239624023, 2.1320393085479736, 2.0903208255767822, 2.0688536167144775, 2.055413246154785, 2.044408082962036, 2.0339105129241943, 2.0369396209716797, 2.0298728942871094, 2.0260961055755615, 2.0219006538391113, 2.0215883255004883, 2.018035411834717, 2.0170249938964844, 2.0162694454193115, 2.0120158195495605, 2.010089635848999, 2.007028579711914, 2.004851818084717, 2.0000715255737305, 1.9859102964401245, 1.9488844871520996, 1.8627171516418457, 1.7737641334533691, 1.7278598546981812, 1.6896724700927734, 1.6746848821640015, 1.6583821773529053, 1.6495375633239746, 1.6360102891921997, 1.6297305822372437, 1.6217557191848755, 1.614214301109314, 1.6105746030807495, 1.6021113395690918, 1.5965616703033447, 1.5935784578323364], 'accuracy': [0.09997916966676712, 0.10229166597127914, 0.10322916507720947, 0.10512500256299973, 0.1067083328962326, 0.10852083563804626, 0.11183333396911621, 0.1132291629910469, 0.11881250143051147, 0.12252083420753479, 0.1264375001192093, 0.1382291615009308, 0.15689583122730255, 0.18806250393390656, 0.20620833337306976, 0.21331250667572021, 0.21570833027362823, 0.2148125022649765, 0.21852083504199982, 0.2214999943971634, 0.2201458364725113, 0.22187499701976776, 0.2212499976158142, 0.22064583003520966, 0.2239374965429306, 0.22372916340827942, 0.22227083146572113, 0.22589583694934845, 0.22724999487400055, 0.22868749499320984, 0.2319166660308838, 0.2318125069141388, 0.23745833337306976, 0.2485833317041397, 0.2630625069141388, 0.28450000286102295, 0.29887500405311584, 0.3076041638851166, 0.31458333134651184, 0.31460416316986084, 0.31860417127609253, 0.3188541531562805, 0.3192708194255829, 0.3206041753292084, 0.3205416798591614, 0.32097917795181274, 0.3244999945163727, 0.32479166984558105, 0.3256041705608368, 0.3267291784286499], 'val_loss': [2.3158912658691406, 2.2726290225982666, 2.253765106201172, 2.254056453704834, 2.262380361557007, 2.2739033699035645, 2.275463819503784, 2.283588409423828, 2.29124116897583, 2.292654514312744, 2.244509696960449, 2.1115870475769043, 2.103224039077759, 2.7702512741088867, 3.06923508644104, 3.009080171585083, 2.9125754833221436, 2.9167590141296387, 2.9413530826568604, 2.9980475902557373, 3.0215888023376465, 3.1740970611572266, 3.279996633529663, 3.365142583847046, 3.332995653152466, 3.3689088821411133, 3.2929224967956543, 3.901477098464966, 4.1830668449401855, 4.535907745361328, 4.637190341949463, 5.396236419677734, 5.757994174957275, 5.920134544372559, 6.204260349273682, 7.155001163482666, 6.744478702545166, 7.3521928787231445, 7.124885559082031, 5.7860493659973145, 6.664148330688477, 6.795196533203125, 6.376821517944336, 7.596357345581055, 7.915394306182861, 7.139773368835449, 6.760319232940674, 8.906702995300293, 7.879856586456299, 7.552960395812988], 'val_accuracy': [0.10358333587646484, 0.10175000131130219, 0.1002499982714653, 0.09950000047683716, 0.11249999701976776, 0.15424999594688416, 0.15016666054725647, 0.1420833319425583, 0.13066667318344116, 0.10225000232458115, 0.12991666793823242, 0.17866666615009308, 0.20024999976158142, 0.20350000262260437, 0.20274999737739563, 0.2017499953508377, 0.2019166648387909, 0.2018333375453949, 0.2019166648387909, 0.2018333375453949, 0.2016666680574417, 0.2016666680574417, 0.20200000703334808, 0.20225000381469727, 0.20200000703334808, 0.2016666680574417, 0.20225000381469727, 0.20241667330265045, 0.20258332788944244, 0.20283333957195282, 0.20274999737739563, 0.20274999737739563, 0.20408333837985992, 0.21574999392032623, 0.2795833349227905, 0.30541667342185974, 0.312416672706604, 0.3097499907016754, 0.30691665410995483, 0.3233333230018616, 0.30691665410995483, 0.3160833418369293, 0.30666667222976685, 0.3070000112056732, 0.3062500059604645, 0.3070833384990692, 0.3071666657924652, 0.3058333396911621, 0.30674999952316284, 0.3075000047683716]}\n",
      "{'loss': [2.3016133308410645, 2.3004167079925537, 2.299733877182007, 2.2991340160369873, 2.2982516288757324, 2.2974462509155273, 2.296166181564331, 2.2942066192626953, 2.2907025814056396, 2.280318260192871, 2.2430217266082764, 2.168105363845825, 2.0805888175964355, 2.005061626434326, 1.9222923517227173, 1.8394312858581543, 1.7535020112991333, 1.657397985458374, 1.5545501708984375, 1.456815481185913, 1.3691458702087402, 1.299772024154663, 1.2378472089767456, 1.1758744716644287, 1.1342542171478271, 1.098314642906189, 1.0546374320983887, 1.021352767944336, 0.9910191893577576, 0.9655888676643372, 0.9440659284591675, 0.9202349185943604, 0.8920100927352905, 0.8768624663352966, 0.8507605195045471, 0.8363286256790161, 0.815780520439148, 0.7951684594154358, 0.776665449142456, 0.7705301642417908, 0.7522882223129272, 0.7317870855331421, 0.7150562405586243, 0.7006373405456543, 0.6970720887184143, 0.6812488436698914, 0.6703510880470276, 0.6615858674049377, 0.6383463740348816, 0.6395565271377563], 'accuracy': [0.11579166352748871, 0.11402083188295364, 0.11397916823625565, 0.11404166370630264, 0.11408333480358124, 0.1145000010728836, 0.11635416746139526, 0.1210208311676979, 0.13256250321865082, 0.16602084040641785, 0.19116666913032532, 0.19577082991600037, 0.21304166316986084, 0.24435417354106903, 0.2772291600704193, 0.30420833826065063, 0.3342916667461395, 0.3709999918937683, 0.40831249952316284, 0.445479154586792, 0.4829583466053009, 0.5131875276565552, 0.546541690826416, 0.5744583606719971, 0.5938541889190674, 0.6113749742507935, 0.6289583444595337, 0.6448333263397217, 0.6567916870117188, 0.6660000085830688, 0.6819375157356262, 0.6862708330154419, 0.7021874785423279, 0.7084583044052124, 0.7195833325386047, 0.7280416488647461, 0.7394583225250244, 0.7502291798591614, 0.7570833563804626, 0.7648958563804626, 0.7693541646003723, 0.7767916917800903, 0.7822708487510681, 0.7879791855812073, 0.7919374704360962, 0.7962083220481873, 0.7995833158493042, 0.8054375052452087, 0.8109999895095825, 0.8107916712760925], 'val_loss': [2.3014109134674072, 2.300845146179199, 2.3003089427948, 2.299636125564575, 2.298844814300537, 2.2977912425994873, 2.2962772846221924, 2.293882369995117, 2.288515090942383, 2.2669668197631836, 2.186232089996338, 2.0561325550079346, 1.9677088260650635, 1.8678985834121704, 1.7607628107070923, 1.6451795101165771, 1.5399166345596313, 1.4030539989471436, 1.2509442567825317, 1.1411734819412231, 1.054194450378418, 0.9824129343032837, 0.9245527386665344, 0.8733781576156616, 0.826055645942688, 0.7824751138687134, 0.7474665641784668, 0.7144334316253662, 0.6826857924461365, 0.6578965187072754, 0.6425139904022217, 0.6202571988105774, 0.5906887054443359, 0.5716518759727478, 0.5409496426582336, 0.5122790336608887, 0.4978448450565338, 0.4768705368041992, 0.4566945731639862, 0.4383634924888611, 0.43342843651771545, 0.4066638648509979, 0.39664220809936523, 0.39109835028648376, 0.38177230954170227, 0.3687479794025421, 0.37358078360557556, 0.3531720042228699, 0.3475837707519531, 0.34179410338401794], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10741666704416275, 0.12783333659172058, 0.1862500011920929, 0.19708333909511566, 0.20999999344348907, 0.22975000739097595, 0.28166666626930237, 0.35191667079925537, 0.3889999985694885, 0.44850000739097595, 0.5230000019073486, 0.5809166431427002, 0.6134166717529297, 0.6337500214576721, 0.6830000281333923, 0.706166684627533, 0.7348333597183228, 0.765583336353302, 0.7730833292007446, 0.7706666588783264, 0.7820000052452087, 0.8021666407585144, 0.815750002861023, 0.8215000033378601, 0.8319166898727417, 0.8475000262260437, 0.8655833601951599, 0.8787500262260437, 0.8917499780654907, 0.8926666378974915, 0.9020833373069763, 0.9018333554267883, 0.9079166650772095, 0.9044166803359985, 0.9125833511352539, 0.9166666865348816, 0.918666660785675, 0.918833315372467, 0.9227499961853027, 0.92166668176651, 0.9240833520889282, 0.9275000095367432, 0.9257500171661377]}\n",
      "{'loss': [2.3017120361328125, 2.3008711338043213, 2.3001604080200195, 2.2997395992279053, 2.2992489337921143, 2.298792600631714, 2.298091411590576, 2.2974321842193604, 2.296821117401123, 2.2957537174224854, 2.2945168018341064, 2.2927658557891846, 2.2904269695281982, 2.2863521575927734, 2.278873920440674, 2.2588107585906982, 2.1760222911834717, 2.0531532764434814, 1.9747934341430664, 1.9079147577285767, 1.8515598773956299, 1.7919747829437256, 1.733723759651184, 1.6484522819519043, 1.5570094585418701, 1.472244143486023, 1.40001380443573, 1.342889428138733, 1.2852702140808105, 1.2338827848434448, 1.186320185661316, 1.14266836643219, 1.1009979248046875, 1.0660805702209473, 1.0357235670089722, 1.0010392665863037, 0.9758946895599365, 0.9544873833656311, 0.9312496185302734, 0.9128792881965637, 0.8964616656303406, 0.8753697276115417, 0.8601163029670715, 0.8436983823776245, 0.8319779634475708, 0.8141525983810425, 0.8028615117073059, 0.7855076789855957, 0.7656194567680359, 0.7601045966148376], 'accuracy': [0.11762499809265137, 0.11397916823625565, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11406250298023224, 0.11431249976158142, 0.11502083390951157, 0.11837500333786011, 0.12733332812786102, 0.1547916680574417, 0.19031250476837158, 0.21254166960716248, 0.23791666328907013, 0.2708333432674408, 0.29785415530204773, 0.31854167580604553, 0.33899998664855957, 0.36639583110809326, 0.398458331823349, 0.42370831966400146, 0.45629167556762695, 0.4856666624546051, 0.5172083377838135, 0.5377916693687439, 0.5624374747276306, 0.5848125219345093, 0.6007708311080933, 0.6131874918937683, 0.6291249990463257, 0.6418541669845581, 0.6548541784286499, 0.6653333306312561, 0.6766250133514404, 0.6862083077430725, 0.6952916383743286, 0.7008333206176758, 0.7092499732971191, 0.715499997138977, 0.7277291417121887, 0.7337916493415833, 0.74239581823349, 0.749958336353302, 0.7523958086967468, 0.762583315372467, 0.7651666402816772], 'val_loss': [2.301661729812622, 2.3012101650238037, 2.3008272647857666, 2.300377368927002, 2.2999532222747803, 2.2994461059570312, 2.298827886581421, 2.298114538192749, 2.297172784805298, 2.296109437942505, 2.2947237491607666, 2.2926993370056152, 2.2896716594696045, 2.2843754291534424, 2.2732274532318115, 2.235212564468384, 2.059866428375244, 1.925005555152893, 1.8461041450500488, 1.7815697193145752, 1.7225475311279297, 1.6616922616958618, 1.5804983377456665, 1.4369648694992065, 1.3195899724960327, 1.2209866046905518, 1.1379480361938477, 1.0646216869354248, 0.9990717768669128, 0.9352518916130066, 0.8821631073951721, 0.8316432237625122, 0.7940658330917358, 0.7527838349342346, 0.7237874269485474, 0.697228193283081, 0.6728312969207764, 0.6517156362533569, 0.6344424486160278, 0.6154171228408813, 0.5997707843780518, 0.5838018655776978, 0.5678593516349792, 0.5503492951393127, 0.5343786478042603, 0.5196215510368347, 0.5054848790168762, 0.4870983958244324, 0.47522130608558655, 0.4580237567424774], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10608333349227905, 0.1145000010728836, 0.15583333373069763, 0.25041666626930237, 0.22716666758060455, 0.27024999260902405, 0.31450000405311584, 0.343583345413208, 0.3724166750907898, 0.40549999475479126, 0.484250009059906, 0.5172500014305115, 0.5537499785423279, 0.5897499918937683, 0.6289166808128357, 0.6647499799728394, 0.6924999952316284, 0.7211666703224182, 0.7425833344459534, 0.7519999742507935, 0.7631666660308838, 0.7789999842643738, 0.796833336353302, 0.7950000166893005, 0.8048333525657654, 0.8174999952316284, 0.8224999904632568, 0.8326666951179504, 0.8346666693687439, 0.8420833349227905, 0.8447499871253967, 0.8550000190734863, 0.8632500171661377, 0.8689166903495789, 0.8744999766349792, 0.8763333559036255, 0.8841666579246521, 0.8885833621025085]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "8depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
