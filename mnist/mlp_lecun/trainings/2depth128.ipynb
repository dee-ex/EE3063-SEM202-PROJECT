{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 817407,
     "status": "ok",
     "timestamp": 1627299165557,
     "user": {
      "displayName": "TRUNG Nguyễn Thành",
      "photoUrl": "",
      "userId": "02848241069421510082"
     },
     "user_tz": -420
    },
    "id": "JnHhSjZec4W6",
    "outputId": "74e646bf-7ced-4693-bf88-8a532f8b3f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 16s 5ms/step - loss: 2.5350 - accuracy: 0.1011 - val_loss: 2.2666 - val_accuracy: 0.1531\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3498 - accuracy: 0.1191 - val_loss: 2.2426 - val_accuracy: 0.1933\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2935 - accuracy: 0.1419 - val_loss: 2.2193 - val_accuracy: 0.3273\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2618 - accuracy: 0.1615 - val_loss: 2.1938 - val_accuracy: 0.4052\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2323 - accuracy: 0.1816 - val_loss: 2.1588 - val_accuracy: 0.4737\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1940 - accuracy: 0.2157 - val_loss: 2.1098 - val_accuracy: 0.5376\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1516 - accuracy: 0.2411 - val_loss: 2.0421 - val_accuracy: 0.5743\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0936 - accuracy: 0.2721 - val_loss: 1.9520 - val_accuracy: 0.5817\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0176 - accuracy: 0.3069 - val_loss: 1.8399 - val_accuracy: 0.6482\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.9198 - accuracy: 0.3488 - val_loss: 1.7116 - val_accuracy: 0.6517\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8153 - accuracy: 0.3818 - val_loss: 1.5775 - val_accuracy: 0.6733\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6972 - accuracy: 0.4224 - val_loss: 1.4438 - val_accuracy: 0.7005\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5852 - accuracy: 0.4604 - val_loss: 1.3230 - val_accuracy: 0.7278\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4816 - accuracy: 0.4928 - val_loss: 1.2169 - val_accuracy: 0.7320\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3845 - accuracy: 0.5224 - val_loss: 1.1256 - val_accuracy: 0.7517\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3210 - accuracy: 0.5483 - val_loss: 1.0498 - val_accuracy: 0.7632\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2383 - accuracy: 0.5757 - val_loss: 0.9856 - val_accuracy: 0.7694\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1785 - accuracy: 0.5935 - val_loss: 0.9309 - val_accuracy: 0.7794\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1249 - accuracy: 0.6148 - val_loss: 0.8822 - val_accuracy: 0.7895\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0823 - accuracy: 0.6310 - val_loss: 0.8422 - val_accuracy: 0.7932\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0423 - accuracy: 0.6476 - val_loss: 0.8058 - val_accuracy: 0.8019\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0025 - accuracy: 0.6636 - val_loss: 0.7736 - val_accuracy: 0.8087\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9769 - accuracy: 0.6725 - val_loss: 0.7449 - val_accuracy: 0.8186\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9358 - accuracy: 0.6871 - val_loss: 0.7167 - val_accuracy: 0.8227\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9136 - accuracy: 0.6943 - val_loss: 0.6929 - val_accuracy: 0.8262\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8933 - accuracy: 0.7021 - val_loss: 0.6712 - val_accuracy: 0.8298\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8673 - accuracy: 0.7116 - val_loss: 0.6506 - val_accuracy: 0.8345\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8506 - accuracy: 0.7202 - val_loss: 0.6323 - val_accuracy: 0.8365\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8240 - accuracy: 0.7308 - val_loss: 0.6140 - val_accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8028 - accuracy: 0.7371 - val_loss: 0.5984 - val_accuracy: 0.8429\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7942 - accuracy: 0.7419 - val_loss: 0.5836 - val_accuracy: 0.8470\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7749 - accuracy: 0.7477 - val_loss: 0.5706 - val_accuracy: 0.8491\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7637 - accuracy: 0.7529 - val_loss: 0.5582 - val_accuracy: 0.8512\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7429 - accuracy: 0.7605 - val_loss: 0.5465 - val_accuracy: 0.8544\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7318 - accuracy: 0.7649 - val_loss: 0.5361 - val_accuracy: 0.8562\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7156 - accuracy: 0.7668 - val_loss: 0.5261 - val_accuracy: 0.8573\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7144 - accuracy: 0.7705 - val_loss: 0.5172 - val_accuracy: 0.8595\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7021 - accuracy: 0.7761 - val_loss: 0.5094 - val_accuracy: 0.8602\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6860 - accuracy: 0.7806 - val_loss: 0.5004 - val_accuracy: 0.8632\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6775 - accuracy: 0.7815 - val_loss: 0.4929 - val_accuracy: 0.8638\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6638 - accuracy: 0.7892 - val_loss: 0.4863 - val_accuracy: 0.8650\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6489 - accuracy: 0.7936 - val_loss: 0.4793 - val_accuracy: 0.8675\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6509 - accuracy: 0.7957 - val_loss: 0.4731 - val_accuracy: 0.8695\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6444 - accuracy: 0.7956 - val_loss: 0.4683 - val_accuracy: 0.8697\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6384 - accuracy: 0.7985 - val_loss: 0.4625 - val_accuracy: 0.8711\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6331 - accuracy: 0.8011 - val_loss: 0.4569 - val_accuracy: 0.8731\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6183 - accuracy: 0.8052 - val_loss: 0.4520 - val_accuracy: 0.8749\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6184 - accuracy: 0.8060 - val_loss: 0.4471 - val_accuracy: 0.8746\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6109 - accuracy: 0.8043 - val_loss: 0.4426 - val_accuracy: 0.8777\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6036 - accuracy: 0.8106 - val_loss: 0.4384 - val_accuracy: 0.8779\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4847 - accuracy: 0.5401 - val_loss: 0.5406 - val_accuracy: 0.8695\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6201 - accuracy: 0.8235 - val_loss: 0.4133 - val_accuracy: 0.8888\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.8558 - val_loss: 0.3667 - val_accuracy: 0.8988\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4548 - accuracy: 0.8660 - val_loss: 0.3434 - val_accuracy: 0.9039\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4218 - accuracy: 0.8776 - val_loss: 0.3257 - val_accuracy: 0.9083\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - accuracy: 0.8819 - val_loss: 0.3145 - val_accuracy: 0.9124\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3829 - accuracy: 0.8896 - val_loss: 0.3061 - val_accuracy: 0.9128\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3842 - accuracy: 0.8885 - val_loss: 0.2990 - val_accuracy: 0.9152\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3711 - accuracy: 0.8895 - val_loss: 0.2924 - val_accuracy: 0.9176\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3681 - accuracy: 0.8927 - val_loss: 0.2888 - val_accuracy: 0.9179\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3550 - accuracy: 0.8964 - val_loss: 0.2843 - val_accuracy: 0.9179\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3529 - accuracy: 0.8945 - val_loss: 0.2801 - val_accuracy: 0.9200\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3511 - accuracy: 0.8992 - val_loss: 0.2767 - val_accuracy: 0.9202\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.9002 - val_loss: 0.2742 - val_accuracy: 0.9209\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3385 - accuracy: 0.8996 - val_loss: 0.2697 - val_accuracy: 0.9229\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.9029 - val_loss: 0.2681 - val_accuracy: 0.9224\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3266 - accuracy: 0.9035 - val_loss: 0.2653 - val_accuracy: 0.9242\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3259 - accuracy: 0.9053 - val_loss: 0.2635 - val_accuracy: 0.9242\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.9050 - val_loss: 0.2614 - val_accuracy: 0.9237\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.9040 - val_loss: 0.2590 - val_accuracy: 0.9244\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3163 - accuracy: 0.9068 - val_loss: 0.2573 - val_accuracy: 0.9261\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3127 - accuracy: 0.9099 - val_loss: 0.2558 - val_accuracy: 0.9261\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3092 - accuracy: 0.9087 - val_loss: 0.2526 - val_accuracy: 0.9277\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3095 - accuracy: 0.9111 - val_loss: 0.2514 - val_accuracy: 0.9281\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.9080 - val_loss: 0.2493 - val_accuracy: 0.9285\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.9118 - val_loss: 0.2485 - val_accuracy: 0.9288\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3040 - accuracy: 0.9121 - val_loss: 0.2466 - val_accuracy: 0.9291\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2998 - accuracy: 0.9117 - val_loss: 0.2454 - val_accuracy: 0.9293\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2975 - accuracy: 0.9137 - val_loss: 0.2432 - val_accuracy: 0.9293\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2896 - accuracy: 0.9141 - val_loss: 0.2423 - val_accuracy: 0.9304\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2915 - accuracy: 0.9153 - val_loss: 0.2405 - val_accuracy: 0.9308\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2970 - accuracy: 0.9136 - val_loss: 0.2398 - val_accuracy: 0.9307\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2868 - accuracy: 0.9176 - val_loss: 0.2368 - val_accuracy: 0.9323\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2979 - accuracy: 0.9124 - val_loss: 0.2354 - val_accuracy: 0.9327\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2880 - accuracy: 0.9152 - val_loss: 0.2337 - val_accuracy: 0.9328\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2820 - accuracy: 0.9176 - val_loss: 0.2329 - val_accuracy: 0.9327\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2757 - accuracy: 0.9204 - val_loss: 0.2321 - val_accuracy: 0.9337\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2818 - accuracy: 0.9172 - val_loss: 0.2305 - val_accuracy: 0.9333\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2787 - accuracy: 0.9183 - val_loss: 0.2293 - val_accuracy: 0.9343\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.9168 - val_loss: 0.2278 - val_accuracy: 0.9345\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2765 - accuracy: 0.9179 - val_loss: 0.2264 - val_accuracy: 0.9350\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2763 - accuracy: 0.9204 - val_loss: 0.2254 - val_accuracy: 0.9352\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2674 - accuracy: 0.9214 - val_loss: 0.2239 - val_accuracy: 0.9348\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2796 - accuracy: 0.9174 - val_loss: 0.2222 - val_accuracy: 0.9358\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2732 - accuracy: 0.9191 - val_loss: 0.2205 - val_accuracy: 0.9371\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2664 - accuracy: 0.9220 - val_loss: 0.2198 - val_accuracy: 0.9361\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2728 - accuracy: 0.9208 - val_loss: 0.2183 - val_accuracy: 0.9370\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2661 - accuracy: 0.9231 - val_loss: 0.2173 - val_accuracy: 0.9377\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.9230 - val_loss: 0.2163 - val_accuracy: 0.9370\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2595 - accuracy: 0.9257 - val_loss: 0.2144 - val_accuracy: 0.9387\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 1.9440 - accuracy: 0.3517 - val_loss: 0.7753 - val_accuracy: 0.8396\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8980 - accuracy: 0.7378 - val_loss: 0.4828 - val_accuracy: 0.8800\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6631 - accuracy: 0.8026 - val_loss: 0.3935 - val_accuracy: 0.8950\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5647 - accuracy: 0.8338 - val_loss: 0.3486 - val_accuracy: 0.9052\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4983 - accuracy: 0.8547 - val_loss: 0.3201 - val_accuracy: 0.9117\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4630 - accuracy: 0.8655 - val_loss: 0.2976 - val_accuracy: 0.9154\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4306 - accuracy: 0.8779 - val_loss: 0.2801 - val_accuracy: 0.9189\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4032 - accuracy: 0.8832 - val_loss: 0.2655 - val_accuracy: 0.9225\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3808 - accuracy: 0.8896 - val_loss: 0.2530 - val_accuracy: 0.9259\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3586 - accuracy: 0.8962 - val_loss: 0.2422 - val_accuracy: 0.9296\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3503 - accuracy: 0.8969 - val_loss: 0.2323 - val_accuracy: 0.9327\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3363 - accuracy: 0.9028 - val_loss: 0.2248 - val_accuracy: 0.9342\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3233 - accuracy: 0.9083 - val_loss: 0.2160 - val_accuracy: 0.9375\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3066 - accuracy: 0.9126 - val_loss: 0.2094 - val_accuracy: 0.9384\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2980 - accuracy: 0.9146 - val_loss: 0.2026 - val_accuracy: 0.9406\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2871 - accuracy: 0.9187 - val_loss: 0.1964 - val_accuracy: 0.9433\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2792 - accuracy: 0.9197 - val_loss: 0.1916 - val_accuracy: 0.9443\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2680 - accuracy: 0.9238 - val_loss: 0.1861 - val_accuracy: 0.9454\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2646 - accuracy: 0.9249 - val_loss: 0.1809 - val_accuracy: 0.9473\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2549 - accuracy: 0.9267 - val_loss: 0.1764 - val_accuracy: 0.9488\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2578 - accuracy: 0.9263 - val_loss: 0.1726 - val_accuracy: 0.9493\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2428 - accuracy: 0.9308 - val_loss: 0.1683 - val_accuracy: 0.9509\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2385 - accuracy: 0.9325 - val_loss: 0.1641 - val_accuracy: 0.9522\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2354 - accuracy: 0.9319 - val_loss: 0.1607 - val_accuracy: 0.9529\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2302 - accuracy: 0.9335 - val_loss: 0.1565 - val_accuracy: 0.9548\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2231 - accuracy: 0.9381 - val_loss: 0.1537 - val_accuracy: 0.9555\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2157 - accuracy: 0.9388 - val_loss: 0.1509 - val_accuracy: 0.9567\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2109 - accuracy: 0.9402 - val_loss: 0.1481 - val_accuracy: 0.9567\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2046 - accuracy: 0.9415 - val_loss: 0.1455 - val_accuracy: 0.9567\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2025 - accuracy: 0.9418 - val_loss: 0.1431 - val_accuracy: 0.9578\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2042 - accuracy: 0.9430 - val_loss: 0.1403 - val_accuracy: 0.9584\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1942 - accuracy: 0.9450 - val_loss: 0.1378 - val_accuracy: 0.9592\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1912 - accuracy: 0.9461 - val_loss: 0.1353 - val_accuracy: 0.9606\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1854 - accuracy: 0.9468 - val_loss: 0.1331 - val_accuracy: 0.9612\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1823 - accuracy: 0.9464 - val_loss: 0.1313 - val_accuracy: 0.9613\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1822 - accuracy: 0.9477 - val_loss: 0.1295 - val_accuracy: 0.9618\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1755 - accuracy: 0.9489 - val_loss: 0.1271 - val_accuracy: 0.9626\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1771 - accuracy: 0.9494 - val_loss: 0.1254 - val_accuracy: 0.9630\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1748 - accuracy: 0.9511 - val_loss: 0.1234 - val_accuracy: 0.9637\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1678 - accuracy: 0.9534 - val_loss: 0.1224 - val_accuracy: 0.9636\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1662 - accuracy: 0.9538 - val_loss: 0.1210 - val_accuracy: 0.9635\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1614 - accuracy: 0.9543 - val_loss: 0.1185 - val_accuracy: 0.9645\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1572 - accuracy: 0.9554 - val_loss: 0.1179 - val_accuracy: 0.9659\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1590 - accuracy: 0.9549 - val_loss: 0.1157 - val_accuracy: 0.9656\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1556 - accuracy: 0.9559 - val_loss: 0.1141 - val_accuracy: 0.9658\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1469 - accuracy: 0.9571 - val_loss: 0.1130 - val_accuracy: 0.9665\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1469 - accuracy: 0.9576 - val_loss: 0.1116 - val_accuracy: 0.9662\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1496 - accuracy: 0.9565 - val_loss: 0.1105 - val_accuracy: 0.9670\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1481 - accuracy: 0.9562 - val_loss: 0.1100 - val_accuracy: 0.9675\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1446 - accuracy: 0.9587 - val_loss: 0.1083 - val_accuracy: 0.9687\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 1.8307 - accuracy: 0.4089 - val_loss: 0.6945 - val_accuracy: 0.8518\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8113 - accuracy: 0.7628 - val_loss: 0.4589 - val_accuracy: 0.8872\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6007 - accuracy: 0.8240 - val_loss: 0.3856 - val_accuracy: 0.8963\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5293 - accuracy: 0.8458 - val_loss: 0.3467 - val_accuracy: 0.9044\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4777 - accuracy: 0.8591 - val_loss: 0.3213 - val_accuracy: 0.9114\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4418 - accuracy: 0.8721 - val_loss: 0.3047 - val_accuracy: 0.9157\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4188 - accuracy: 0.8784 - val_loss: 0.2896 - val_accuracy: 0.9191\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4002 - accuracy: 0.8852 - val_loss: 0.2782 - val_accuracy: 0.9229\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3761 - accuracy: 0.8937 - val_loss: 0.2670 - val_accuracy: 0.9252\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3628 - accuracy: 0.8976 - val_loss: 0.2576 - val_accuracy: 0.9276\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3417 - accuracy: 0.9027 - val_loss: 0.2501 - val_accuracy: 0.9293\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3365 - accuracy: 0.9021 - val_loss: 0.2429 - val_accuracy: 0.9312\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3224 - accuracy: 0.9056 - val_loss: 0.2360 - val_accuracy: 0.9330\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3173 - accuracy: 0.9078 - val_loss: 0.2306 - val_accuracy: 0.9343\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3079 - accuracy: 0.9113 - val_loss: 0.2237 - val_accuracy: 0.9363\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2979 - accuracy: 0.9134 - val_loss: 0.2185 - val_accuracy: 0.9377\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2903 - accuracy: 0.9163 - val_loss: 0.2136 - val_accuracy: 0.9395\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2800 - accuracy: 0.9190 - val_loss: 0.2084 - val_accuracy: 0.9407\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2733 - accuracy: 0.9199 - val_loss: 0.2050 - val_accuracy: 0.9425\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2661 - accuracy: 0.9233 - val_loss: 0.2005 - val_accuracy: 0.9432\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2726 - accuracy: 0.9217 - val_loss: 0.1959 - val_accuracy: 0.9454\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2601 - accuracy: 0.9222 - val_loss: 0.1920 - val_accuracy: 0.9463\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2551 - accuracy: 0.9271 - val_loss: 0.1887 - val_accuracy: 0.9473\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2461 - accuracy: 0.9302 - val_loss: 0.1854 - val_accuracy: 0.9486\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2444 - accuracy: 0.9304 - val_loss: 0.1821 - val_accuracy: 0.9493\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2369 - accuracy: 0.9316 - val_loss: 0.1787 - val_accuracy: 0.9498\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2353 - accuracy: 0.9296 - val_loss: 0.1753 - val_accuracy: 0.9513\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2295 - accuracy: 0.9331 - val_loss: 0.1721 - val_accuracy: 0.9525\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2255 - accuracy: 0.9346 - val_loss: 0.1698 - val_accuracy: 0.9534\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2223 - accuracy: 0.9379 - val_loss: 0.1673 - val_accuracy: 0.9531\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2200 - accuracy: 0.9375 - val_loss: 0.1652 - val_accuracy: 0.9542\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2115 - accuracy: 0.9396 - val_loss: 0.1622 - val_accuracy: 0.9551\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2179 - accuracy: 0.9373 - val_loss: 0.1594 - val_accuracy: 0.9560\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2104 - accuracy: 0.9398 - val_loss: 0.1571 - val_accuracy: 0.9560\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2017 - accuracy: 0.9405 - val_loss: 0.1562 - val_accuracy: 0.9567\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1990 - accuracy: 0.9429 - val_loss: 0.1536 - val_accuracy: 0.9563\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1992 - accuracy: 0.9434 - val_loss: 0.1510 - val_accuracy: 0.9576\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1945 - accuracy: 0.9445 - val_loss: 0.1492 - val_accuracy: 0.9581\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1904 - accuracy: 0.9431 - val_loss: 0.1475 - val_accuracy: 0.9580\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1869 - accuracy: 0.9447 - val_loss: 0.1453 - val_accuracy: 0.9584\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1908 - accuracy: 0.9453 - val_loss: 0.1436 - val_accuracy: 0.9592\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1839 - accuracy: 0.9456 - val_loss: 0.1421 - val_accuracy: 0.9592\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1806 - accuracy: 0.9479 - val_loss: 0.1401 - val_accuracy: 0.9604\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1798 - accuracy: 0.9479 - val_loss: 0.1395 - val_accuracy: 0.9605\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1770 - accuracy: 0.9488 - val_loss: 0.1376 - val_accuracy: 0.9602\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1732 - accuracy: 0.9506 - val_loss: 0.1364 - val_accuracy: 0.9604\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1746 - accuracy: 0.9492 - val_loss: 0.1346 - val_accuracy: 0.9613\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1692 - accuracy: 0.9518 - val_loss: 0.1335 - val_accuracy: 0.9611\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1671 - accuracy: 0.9513 - val_loss: 0.1318 - val_accuracy: 0.9622\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1670 - accuracy: 0.9525 - val_loss: 0.1308 - val_accuracy: 0.9622\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 1.5272 - accuracy: 0.5230 - val_loss: 0.5492 - val_accuracy: 0.8673\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6306 - accuracy: 0.8218 - val_loss: 0.4085 - val_accuracy: 0.8920\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5089 - accuracy: 0.8540 - val_loss: 0.3608 - val_accuracy: 0.9008\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4580 - accuracy: 0.8682 - val_loss: 0.3376 - val_accuracy: 0.9047\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4213 - accuracy: 0.8759 - val_loss: 0.3218 - val_accuracy: 0.9084\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4071 - accuracy: 0.8809 - val_loss: 0.3109 - val_accuracy: 0.9115\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3904 - accuracy: 0.8861 - val_loss: 0.3012 - val_accuracy: 0.9158\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3772 - accuracy: 0.8910 - val_loss: 0.2947 - val_accuracy: 0.9169\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3612 - accuracy: 0.8949 - val_loss: 0.2889 - val_accuracy: 0.9187\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3679 - accuracy: 0.8920 - val_loss: 0.2836 - val_accuracy: 0.9194\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3607 - accuracy: 0.8943 - val_loss: 0.2785 - val_accuracy: 0.9207\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3491 - accuracy: 0.8993 - val_loss: 0.2743 - val_accuracy: 0.9209\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3380 - accuracy: 0.9016 - val_loss: 0.2713 - val_accuracy: 0.9221\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3323 - accuracy: 0.9027 - val_loss: 0.2672 - val_accuracy: 0.9237\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3313 - accuracy: 0.9027 - val_loss: 0.2637 - val_accuracy: 0.9239\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3286 - accuracy: 0.9069 - val_loss: 0.2602 - val_accuracy: 0.9236\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3283 - accuracy: 0.9050 - val_loss: 0.2578 - val_accuracy: 0.9250\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3221 - accuracy: 0.9063 - val_loss: 0.2546 - val_accuracy: 0.9258\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3157 - accuracy: 0.9087 - val_loss: 0.2526 - val_accuracy: 0.9262\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3098 - accuracy: 0.9101 - val_loss: 0.2496 - val_accuracy: 0.9271\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2985 - accuracy: 0.9118 - val_loss: 0.2473 - val_accuracy: 0.9285\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3079 - accuracy: 0.9118 - val_loss: 0.2443 - val_accuracy: 0.9287\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2979 - accuracy: 0.9114 - val_loss: 0.2425 - val_accuracy: 0.9303\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2995 - accuracy: 0.9130 - val_loss: 0.2407 - val_accuracy: 0.9302\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3022 - accuracy: 0.9134 - val_loss: 0.2388 - val_accuracy: 0.9312\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2950 - accuracy: 0.9149 - val_loss: 0.2348 - val_accuracy: 0.9318\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2957 - accuracy: 0.9131 - val_loss: 0.2334 - val_accuracy: 0.9323\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2879 - accuracy: 0.9152 - val_loss: 0.2314 - val_accuracy: 0.9337\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2860 - accuracy: 0.9166 - val_loss: 0.2291 - val_accuracy: 0.9337\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2868 - accuracy: 0.9161 - val_loss: 0.2268 - val_accuracy: 0.9346\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2777 - accuracy: 0.9202 - val_loss: 0.2245 - val_accuracy: 0.9348\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2805 - accuracy: 0.9189 - val_loss: 0.2215 - val_accuracy: 0.9362\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2759 - accuracy: 0.9183 - val_loss: 0.2195 - val_accuracy: 0.9371\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2717 - accuracy: 0.9204 - val_loss: 0.2193 - val_accuracy: 0.9366\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2711 - accuracy: 0.9185 - val_loss: 0.2159 - val_accuracy: 0.9384\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2642 - accuracy: 0.9238 - val_loss: 0.2151 - val_accuracy: 0.9388\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2610 - accuracy: 0.9215 - val_loss: 0.2118 - val_accuracy: 0.9397\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2610 - accuracy: 0.9222 - val_loss: 0.2104 - val_accuracy: 0.9402\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2612 - accuracy: 0.9227 - val_loss: 0.2100 - val_accuracy: 0.9399\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2593 - accuracy: 0.9213 - val_loss: 0.2067 - val_accuracy: 0.9422\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2562 - accuracy: 0.9253 - val_loss: 0.2053 - val_accuracy: 0.9424\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2577 - accuracy: 0.9242 - val_loss: 0.2034 - val_accuracy: 0.9427\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2537 - accuracy: 0.9258 - val_loss: 0.2030 - val_accuracy: 0.9433\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2546 - accuracy: 0.9260 - val_loss: 0.2009 - val_accuracy: 0.9433\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2455 - accuracy: 0.9269 - val_loss: 0.1980 - val_accuracy: 0.9459\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2416 - accuracy: 0.9272 - val_loss: 0.1973 - val_accuracy: 0.9450\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2498 - accuracy: 0.9251 - val_loss: 0.1944 - val_accuracy: 0.9472\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2358 - accuracy: 0.9305 - val_loss: 0.1935 - val_accuracy: 0.9467\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2460 - accuracy: 0.9284 - val_loss: 0.1924 - val_accuracy: 0.9468\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2417 - accuracy: 0.9297 - val_loss: 0.1906 - val_accuracy: 0.9479\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.4767 - accuracy: 0.1808 - val_loss: 0.7304 - val_accuracy: 0.7630\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5350 - accuracy: 0.4659 - val_loss: 0.5919 - val_accuracy: 0.8158\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1556 - accuracy: 0.6062 - val_loss: 0.5489 - val_accuracy: 0.8453\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9628 - accuracy: 0.6783 - val_loss: 0.5477 - val_accuracy: 0.8578\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8490 - accuracy: 0.7221 - val_loss: 0.5450 - val_accuracy: 0.8676\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7752 - accuracy: 0.7502 - val_loss: 0.5358 - val_accuracy: 0.8752\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7191 - accuracy: 0.7684 - val_loss: 0.5343 - val_accuracy: 0.8791\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.7817 - val_loss: 0.5272 - val_accuracy: 0.8850\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6479 - accuracy: 0.7947 - val_loss: 0.5254 - val_accuracy: 0.8867\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6214 - accuracy: 0.8046 - val_loss: 0.5194 - val_accuracy: 0.8907\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6005 - accuracy: 0.8158 - val_loss: 0.5146 - val_accuracy: 0.8935\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5719 - accuracy: 0.8241 - val_loss: 0.5050 - val_accuracy: 0.8967\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5617 - accuracy: 0.8259 - val_loss: 0.5021 - val_accuracy: 0.8989\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5476 - accuracy: 0.8321 - val_loss: 0.4980 - val_accuracy: 0.9002\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5278 - accuracy: 0.8409 - val_loss: 0.4987 - val_accuracy: 0.9010\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5263 - accuracy: 0.8404 - val_loss: 0.4891 - val_accuracy: 0.9027\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5161 - accuracy: 0.8438 - val_loss: 0.4878 - val_accuracy: 0.9037\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4982 - accuracy: 0.8502 - val_loss: 0.4820 - val_accuracy: 0.9049\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4872 - accuracy: 0.8512 - val_loss: 0.4787 - val_accuracy: 0.9063\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4857 - accuracy: 0.8507 - val_loss: 0.4721 - val_accuracy: 0.9075\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4733 - accuracy: 0.8583 - val_loss: 0.4676 - val_accuracy: 0.9083\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4779 - accuracy: 0.8571 - val_loss: 0.4645 - val_accuracy: 0.9087\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4670 - accuracy: 0.8584 - val_loss: 0.4579 - val_accuracy: 0.9109\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4629 - accuracy: 0.8611 - val_loss: 0.4547 - val_accuracy: 0.9112\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4567 - accuracy: 0.8660 - val_loss: 0.4503 - val_accuracy: 0.9120\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4454 - accuracy: 0.8671 - val_loss: 0.4469 - val_accuracy: 0.9134\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4466 - accuracy: 0.8660 - val_loss: 0.4428 - val_accuracy: 0.9140\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4425 - accuracy: 0.8689 - val_loss: 0.4389 - val_accuracy: 0.9146\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4364 - accuracy: 0.8714 - val_loss: 0.4409 - val_accuracy: 0.9154\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4344 - accuracy: 0.8691 - val_loss: 0.4375 - val_accuracy: 0.9164\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4284 - accuracy: 0.8719 - val_loss: 0.4321 - val_accuracy: 0.9168\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4253 - accuracy: 0.8720 - val_loss: 0.4297 - val_accuracy: 0.9183\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4234 - accuracy: 0.8749 - val_loss: 0.4263 - val_accuracy: 0.9176\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4185 - accuracy: 0.8726 - val_loss: 0.4174 - val_accuracy: 0.9197\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4090 - accuracy: 0.8772 - val_loss: 0.4169 - val_accuracy: 0.9197\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4051 - accuracy: 0.8786 - val_loss: 0.4131 - val_accuracy: 0.9206\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4041 - accuracy: 0.8797 - val_loss: 0.4119 - val_accuracy: 0.9217\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3954 - accuracy: 0.8814 - val_loss: 0.4092 - val_accuracy: 0.9221\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3979 - accuracy: 0.8836 - val_loss: 0.4052 - val_accuracy: 0.9220\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3868 - accuracy: 0.8860 - val_loss: 0.4030 - val_accuracy: 0.9220\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3910 - accuracy: 0.8826 - val_loss: 0.4006 - val_accuracy: 0.9233\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3784 - accuracy: 0.8867 - val_loss: 0.3996 - val_accuracy: 0.9247\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3780 - accuracy: 0.8865 - val_loss: 0.3973 - val_accuracy: 0.9233\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3777 - accuracy: 0.8872 - val_loss: 0.3938 - val_accuracy: 0.9248\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3688 - accuracy: 0.8914 - val_loss: 0.3899 - val_accuracy: 0.9247\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3669 - accuracy: 0.8920 - val_loss: 0.3870 - val_accuracy: 0.9268\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3736 - accuracy: 0.8876 - val_loss: 0.3832 - val_accuracy: 0.9272\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3710 - accuracy: 0.8877 - val_loss: 0.3821 - val_accuracy: 0.9278\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3689 - accuracy: 0.8917 - val_loss: 0.3817 - val_accuracy: 0.9283\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3595 - accuracy: 0.8944 - val_loss: 0.3796 - val_accuracy: 0.9285\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.0595 - accuracy: 0.3333 - val_loss: 1.0448 - val_accuracy: 0.8019\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0302 - accuracy: 0.7097 - val_loss: 0.5675 - val_accuracy: 0.8677\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7139 - accuracy: 0.7912 - val_loss: 0.4497 - val_accuracy: 0.8856\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5881 - accuracy: 0.8294 - val_loss: 0.3941 - val_accuracy: 0.8962\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5336 - accuracy: 0.8445 - val_loss: 0.3613 - val_accuracy: 0.9050\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4822 - accuracy: 0.8606 - val_loss: 0.3396 - val_accuracy: 0.9088\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4586 - accuracy: 0.8691 - val_loss: 0.3222 - val_accuracy: 0.9117\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4256 - accuracy: 0.8791 - val_loss: 0.3086 - val_accuracy: 0.9146\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4111 - accuracy: 0.8808 - val_loss: 0.2967 - val_accuracy: 0.9162\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3972 - accuracy: 0.8843 - val_loss: 0.2851 - val_accuracy: 0.9193\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3811 - accuracy: 0.8911 - val_loss: 0.2763 - val_accuracy: 0.9222\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3722 - accuracy: 0.8948 - val_loss: 0.2668 - val_accuracy: 0.9238\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3577 - accuracy: 0.8973 - val_loss: 0.2591 - val_accuracy: 0.9251\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3450 - accuracy: 0.8997 - val_loss: 0.2516 - val_accuracy: 0.9279\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3362 - accuracy: 0.9032 - val_loss: 0.2447 - val_accuracy: 0.9295\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3311 - accuracy: 0.9033 - val_loss: 0.2386 - val_accuracy: 0.9316\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3158 - accuracy: 0.9081 - val_loss: 0.2334 - val_accuracy: 0.9334\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3066 - accuracy: 0.9127 - val_loss: 0.2281 - val_accuracy: 0.9342\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2959 - accuracy: 0.9127 - val_loss: 0.2230 - val_accuracy: 0.9364\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2975 - accuracy: 0.9154 - val_loss: 0.2181 - val_accuracy: 0.9376\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2917 - accuracy: 0.9161 - val_loss: 0.2122 - val_accuracy: 0.9393\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2865 - accuracy: 0.9176 - val_loss: 0.2079 - val_accuracy: 0.9407\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2759 - accuracy: 0.9194 - val_loss: 0.2037 - val_accuracy: 0.9416\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2731 - accuracy: 0.9215 - val_loss: 0.2003 - val_accuracy: 0.9429\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2706 - accuracy: 0.9202 - val_loss: 0.1968 - val_accuracy: 0.9444\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2598 - accuracy: 0.9261 - val_loss: 0.1925 - val_accuracy: 0.9445\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2538 - accuracy: 0.9270 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2504 - accuracy: 0.9286 - val_loss: 0.1859 - val_accuracy: 0.9469\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2397 - accuracy: 0.9299 - val_loss: 0.1826 - val_accuracy: 0.9475\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2416 - accuracy: 0.9313 - val_loss: 0.1792 - val_accuracy: 0.9482\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2393 - accuracy: 0.9304 - val_loss: 0.1765 - val_accuracy: 0.9496\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2325 - accuracy: 0.9336 - val_loss: 0.1741 - val_accuracy: 0.9503\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2286 - accuracy: 0.9323 - val_loss: 0.1713 - val_accuracy: 0.9510\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2255 - accuracy: 0.9363 - val_loss: 0.1686 - val_accuracy: 0.9518\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2185 - accuracy: 0.9364 - val_loss: 0.1665 - val_accuracy: 0.9519\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2233 - accuracy: 0.9358 - val_loss: 0.1641 - val_accuracy: 0.9532\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2214 - accuracy: 0.9364 - val_loss: 0.1614 - val_accuracy: 0.9536\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2141 - accuracy: 0.9360 - val_loss: 0.1595 - val_accuracy: 0.9547\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2046 - accuracy: 0.9401 - val_loss: 0.1571 - val_accuracy: 0.9553\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2058 - accuracy: 0.9415 - val_loss: 0.1550 - val_accuracy: 0.9561\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1977 - accuracy: 0.9416 - val_loss: 0.1532 - val_accuracy: 0.9561\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2025 - accuracy: 0.9405 - val_loss: 0.1521 - val_accuracy: 0.9567\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2040 - accuracy: 0.9419 - val_loss: 0.1498 - val_accuracy: 0.9567\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1985 - accuracy: 0.9420 - val_loss: 0.1480 - val_accuracy: 0.9577\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1930 - accuracy: 0.9430 - val_loss: 0.1460 - val_accuracy: 0.9579\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1847 - accuracy: 0.9468 - val_loss: 0.1441 - val_accuracy: 0.9582\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1915 - accuracy: 0.9443 - val_loss: 0.1426 - val_accuracy: 0.9592\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1859 - accuracy: 0.9455 - val_loss: 0.1409 - val_accuracy: 0.9593\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1775 - accuracy: 0.9493 - val_loss: 0.1398 - val_accuracy: 0.9601\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1836 - accuracy: 0.9450 - val_loss: 0.1378 - val_accuracy: 0.9603\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.1054 - accuracy: 0.3299 - val_loss: 1.3079 - val_accuracy: 0.7800\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2024 - accuracy: 0.6934 - val_loss: 0.6704 - val_accuracy: 0.8539\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7887 - accuracy: 0.7698 - val_loss: 0.5079 - val_accuracy: 0.8741\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6464 - accuracy: 0.8125 - val_loss: 0.4391 - val_accuracy: 0.8861\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5735 - accuracy: 0.8342 - val_loss: 0.4022 - val_accuracy: 0.8928\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5236 - accuracy: 0.8471 - val_loss: 0.3771 - val_accuracy: 0.8974\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4928 - accuracy: 0.8562 - val_loss: 0.3581 - val_accuracy: 0.9014\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4691 - accuracy: 0.8651 - val_loss: 0.3430 - val_accuracy: 0.9050\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4453 - accuracy: 0.8716 - val_loss: 0.3305 - val_accuracy: 0.9093\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4426 - accuracy: 0.8739 - val_loss: 0.3206 - val_accuracy: 0.9119\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4152 - accuracy: 0.8800 - val_loss: 0.3108 - val_accuracy: 0.9142\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4159 - accuracy: 0.8789 - val_loss: 0.3027 - val_accuracy: 0.9155\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3962 - accuracy: 0.8856 - val_loss: 0.2949 - val_accuracy: 0.9175\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3797 - accuracy: 0.8918 - val_loss: 0.2884 - val_accuracy: 0.9193\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3763 - accuracy: 0.8919 - val_loss: 0.2821 - val_accuracy: 0.9199\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3703 - accuracy: 0.8914 - val_loss: 0.2766 - val_accuracy: 0.9222\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3612 - accuracy: 0.8939 - val_loss: 0.2715 - val_accuracy: 0.9226\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3491 - accuracy: 0.8984 - val_loss: 0.2664 - val_accuracy: 0.9249\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3450 - accuracy: 0.8998 - val_loss: 0.2614 - val_accuracy: 0.9257\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3324 - accuracy: 0.9050 - val_loss: 0.2566 - val_accuracy: 0.9270\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3311 - accuracy: 0.9033 - val_loss: 0.2523 - val_accuracy: 0.9273\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3262 - accuracy: 0.9047 - val_loss: 0.2479 - val_accuracy: 0.9292\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3169 - accuracy: 0.9081 - val_loss: 0.2438 - val_accuracy: 0.9309\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3134 - accuracy: 0.9109 - val_loss: 0.2399 - val_accuracy: 0.9312\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3109 - accuracy: 0.9085 - val_loss: 0.2360 - val_accuracy: 0.9317\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3117 - accuracy: 0.9099 - val_loss: 0.2324 - val_accuracy: 0.9330\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2922 - accuracy: 0.9165 - val_loss: 0.2295 - val_accuracy: 0.9346\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2903 - accuracy: 0.9149 - val_loss: 0.2251 - val_accuracy: 0.9355\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2949 - accuracy: 0.9139 - val_loss: 0.2220 - val_accuracy: 0.9360\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2866 - accuracy: 0.9154 - val_loss: 0.2190 - val_accuracy: 0.9367\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2750 - accuracy: 0.9201 - val_loss: 0.2162 - val_accuracy: 0.9380\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2754 - accuracy: 0.9187 - val_loss: 0.2125 - val_accuracy: 0.9380\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2762 - accuracy: 0.9199 - val_loss: 0.2096 - val_accuracy: 0.9395\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2651 - accuracy: 0.9243 - val_loss: 0.2074 - val_accuracy: 0.9392\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2618 - accuracy: 0.9236 - val_loss: 0.2048 - val_accuracy: 0.9402\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2608 - accuracy: 0.9233 - val_loss: 0.2017 - val_accuracy: 0.9418\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2580 - accuracy: 0.9244 - val_loss: 0.1988 - val_accuracy: 0.9428\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2507 - accuracy: 0.9266 - val_loss: 0.1969 - val_accuracy: 0.9432\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2569 - accuracy: 0.9238 - val_loss: 0.1941 - val_accuracy: 0.9445\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2519 - accuracy: 0.9246 - val_loss: 0.1924 - val_accuracy: 0.9447\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2454 - accuracy: 0.9261 - val_loss: 0.1899 - val_accuracy: 0.9456\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2452 - accuracy: 0.9286 - val_loss: 0.1878 - val_accuracy: 0.9467\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2400 - accuracy: 0.9303 - val_loss: 0.1853 - val_accuracy: 0.9472\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2373 - accuracy: 0.9297 - val_loss: 0.1833 - val_accuracy: 0.9473\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2388 - accuracy: 0.9296 - val_loss: 0.1819 - val_accuracy: 0.9481\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2336 - accuracy: 0.9323 - val_loss: 0.1796 - val_accuracy: 0.9492\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2344 - accuracy: 0.9292 - val_loss: 0.1777 - val_accuracy: 0.9497\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2324 - accuracy: 0.9322 - val_loss: 0.1758 - val_accuracy: 0.9503\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2241 - accuracy: 0.9336 - val_loss: 0.1735 - val_accuracy: 0.9507\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2235 - accuracy: 0.9328 - val_loss: 0.1720 - val_accuracy: 0.9513\n",
      "{'loss': [2.4561057090759277, 2.3339791297912598, 2.2831547260284424, 2.2556376457214355, 2.223997116088867, 2.1838114261627197, 2.1364548206329346, 2.073190212249756, 1.9910621643066406, 1.8929075002670288, 1.7852729558944702, 1.667983055114746, 1.5585123300552368, 1.4588369131088257, 1.3638696670532227, 1.2917500734329224, 1.22535240650177, 1.1663970947265625, 1.1110241413116455, 1.0727002620697021, 1.032874345779419, 0.9995296001434326, 0.9703870415687561, 0.9338675737380981, 0.9083249568939209, 0.8851944804191589, 0.8616701364517212, 0.8439162373542786, 0.8202617168426514, 0.8045169115066528, 0.7868262529373169, 0.7709410190582275, 0.7538561224937439, 0.741377055644989, 0.7300823330879211, 0.7161762714385986, 0.7078986763954163, 0.6993390321731567, 0.6851537227630615, 0.6753706336021423, 0.6658725738525391, 0.6584656834602356, 0.6506569385528564, 0.6418734788894653, 0.6349642276763916, 0.6300394535064697, 0.6199014186859131, 0.6143635511398315, 0.6105974316596985, 0.6032897233963013], 'accuracy': [0.10527083277702332, 0.12258332967758179, 0.14495833218097687, 0.16479167342185974, 0.19077083468437195, 0.2237916737794876, 0.2513958215713501, 0.2841041684150696, 0.320499986410141, 0.35843750834465027, 0.3934583365917206, 0.4322291612625122, 0.4673750102519989, 0.5001875162124634, 0.5309791564941406, 0.5599583387374878, 0.5799999833106995, 0.5980416536331177, 0.6212291717529297, 0.6340833306312561, 0.648145854473114, 0.6644166707992554, 0.6726874709129333, 0.6886249780654907, 0.6963750123977661, 0.706083357334137, 0.7151666879653931, 0.7215208411216736, 0.7327291369438171, 0.7364166378974915, 0.742312490940094, 0.7485416531562805, 0.7552708387374878, 0.7601458430290222, 0.765791654586792, 0.7680208086967468, 0.7728750109672546, 0.7768333554267883, 0.7820624709129333, 0.7823958396911621, 0.7875624895095825, 0.7903541922569275, 0.793791651725769, 0.7962499856948853, 0.7988749742507935, 0.8008541464805603, 0.8056874871253967, 0.8066250085830688, 0.8069999814033508, 0.8098124861717224], 'val_loss': [2.266573429107666, 2.242588758468628, 2.2193350791931152, 2.193774461746216, 2.158845901489258, 2.109769344329834, 2.042053461074829, 1.9520182609558105, 1.8398672342300415, 1.7115647792816162, 1.577455997467041, 1.443842887878418, 1.3229669332504272, 1.2169244289398193, 1.1255545616149902, 1.0497915744781494, 0.9856085777282715, 0.9308645129203796, 0.8822218179702759, 0.8422497510910034, 0.8058024644851685, 0.7735785245895386, 0.744861900806427, 0.7167015671730042, 0.6928791403770447, 0.6712294816970825, 0.650561511516571, 0.6323469877243042, 0.6140284538269043, 0.5983712673187256, 0.5836158990859985, 0.5705883502960205, 0.5582190155982971, 0.546504020690918, 0.5360715389251709, 0.5261080861091614, 0.5171736478805542, 0.5093829035758972, 0.500407338142395, 0.4928906559944153, 0.4863262474536896, 0.4792746901512146, 0.4731462299823761, 0.4682929813861847, 0.4625045955181122, 0.4568995237350464, 0.45203691720962524, 0.44711005687713623, 0.4425819516181946, 0.4383563995361328], 'val_accuracy': [0.15308333933353424, 0.19333332777023315, 0.32733333110809326, 0.4051666557788849, 0.4737499952316284, 0.5375833511352539, 0.5743333101272583, 0.5816666483879089, 0.6482499837875366, 0.6516666412353516, 0.6732500195503235, 0.7005000114440918, 0.7277500033378601, 0.7319999933242798, 0.7517499923706055, 0.7631666660308838, 0.7694166898727417, 0.7794166803359985, 0.7894999980926514, 0.7931666374206543, 0.8019166588783264, 0.8087499737739563, 0.8185833096504211, 0.8227499723434448, 0.8261666893959045, 0.8297500014305115, 0.8345000147819519, 0.8364999890327454, 0.8399999737739563, 0.8429166674613953, 0.847000002861023, 0.8490833044052124, 0.8512499928474426, 0.8544166684150696, 0.856249988079071, 0.8573333621025085, 0.859499990940094, 0.8602499961853027, 0.8631666898727417, 0.8638333082199097, 0.8650000095367432, 0.8675000071525574, 0.8694999814033508, 0.8696666955947876, 0.8710833191871643, 0.8730833530426025, 0.874916672706604, 0.8745833039283752, 0.8776666522026062, 0.877916693687439]}\n",
      "{'loss': [1.06868314743042, 0.581410825252533, 0.48922425508499146, 0.4468476176261902, 0.4207611382007599, 0.4029097557067871, 0.3880760967731476, 0.38025957345962524, 0.3716473877429962, 0.3609927296638489, 0.35568639636039734, 0.35308367013931274, 0.3484228551387787, 0.34066158533096313, 0.33866649866104126, 0.33416154980659485, 0.32816383242607117, 0.32863062620162964, 0.32230815291404724, 0.3224537670612335, 0.3178899884223938, 0.3169977366924286, 0.3128461241722107, 0.3107312321662903, 0.30690035223960876, 0.3081798553466797, 0.30384573340415955, 0.30141550302505493, 0.30049929022789, 0.29500845074653625, 0.29506435990333557, 0.2933109402656555, 0.2916872799396515, 0.2913300096988678, 0.28735828399658203, 0.28549641370773315, 0.2840915322303772, 0.28149059414863586, 0.2792745530605316, 0.2797732651233673, 0.27679184079170227, 0.27756524085998535, 0.2735759913921356, 0.27216845750808716, 0.2735937833786011, 0.27223071455955505, 0.26928839087486267, 0.26514118909835815, 0.26515746116638184, 0.2612719237804413], 'accuracy': [0.6960208415985107, 0.8352708220481873, 0.8596041798591614, 0.8686249852180481, 0.8775416612625122, 0.8837500214576721, 0.8871041536331177, 0.8892291784286499, 0.8900208473205566, 0.8946250081062317, 0.8958541750907898, 0.8967083096504211, 0.8983333110809326, 0.9007291793823242, 0.9005625247955322, 0.9021041393280029, 0.9039583206176758, 0.9037916660308838, 0.9058333039283752, 0.9041875004768372, 0.9079375267028809, 0.9078541398048401, 0.9072291851043701, 0.9107083082199097, 0.9115625023841858, 0.9101666808128357, 0.9120208621025085, 0.9112083315849304, 0.9124166369438171, 0.9133750200271606, 0.913937509059906, 0.9149583578109741, 0.9160208106040955, 0.9143750071525574, 0.9154999852180481, 0.9168750047683716, 0.9175208210945129, 0.9177083373069763, 0.9191250205039978, 0.9187708497047424, 0.9189791679382324, 0.9196875095367432, 0.9206041693687439, 0.9199583530426025, 0.9194166660308838, 0.9200624823570251, 0.9216041564941406, 0.9227708578109741, 0.9229999780654907, 0.9241458177566528], 'val_loss': [0.5406051278114319, 0.4133417010307312, 0.36667802929878235, 0.34341901540756226, 0.32573503255844116, 0.3145025074481964, 0.30605804920196533, 0.298985093832016, 0.29238376021385193, 0.2888196110725403, 0.28427621722221375, 0.28006964921951294, 0.27668020129203796, 0.2742393910884857, 0.2697424590587616, 0.2680518627166748, 0.2653411328792572, 0.2635119557380676, 0.2613814175128937, 0.2589731514453888, 0.25726091861724854, 0.2557653486728668, 0.2526338994503021, 0.25135743618011475, 0.2493124008178711, 0.24850693345069885, 0.24661500751972198, 0.24535195529460907, 0.24319413304328918, 0.2423483282327652, 0.24047134816646576, 0.2397872656583786, 0.23683306574821472, 0.23535680770874023, 0.23372577130794525, 0.23293565213680267, 0.23211367428302765, 0.2304524928331375, 0.2293473780155182, 0.22780543565750122, 0.2263685166835785, 0.2253585159778595, 0.22392967343330383, 0.2222413867712021, 0.22048388421535492, 0.21984466910362244, 0.21826627850532532, 0.21729841828346252, 0.2163323312997818, 0.21440964937210083], 'val_accuracy': [0.8694999814033508, 0.8888333439826965, 0.8987500071525574, 0.9039166569709778, 0.9083333611488342, 0.9124166369438171, 0.9128333330154419, 0.9151666760444641, 0.9175833463668823, 0.9179166555404663, 0.9179166555404663, 0.9200000166893005, 0.9201666712760925, 0.9209166765213013, 0.9229166507720947, 0.9224166870117188, 0.9241666793823242, 0.9241666793823242, 0.9236666560173035, 0.9244166612625122, 0.9260833263397217, 0.9260833263397217, 0.9277499914169312, 0.9280833601951599, 0.9284999966621399, 0.9288333058357239, 0.9290833473205566, 0.9292500019073486, 0.9292500019073486, 0.9304166436195374, 0.9308333396911621, 0.9306666851043701, 0.9322500228881836, 0.9327499866485596, 0.9328333139419556, 0.9327499866485596, 0.9336666464805603, 0.9333333373069763, 0.934333324432373, 0.934499979019165, 0.9350000023841858, 0.9351666569709778, 0.9347500205039978, 0.9357500076293945, 0.9370833039283752, 0.9360833168029785, 0.9369999766349792, 0.937749981880188, 0.9369999766349792, 0.9386666417121887]}\n",
      "{'loss': [1.5757657289505005, 0.8196454048156738, 0.63041752576828, 0.5452873706817627, 0.4937322735786438, 0.452677458524704, 0.42633500695228577, 0.3977741003036499, 0.3775631785392761, 0.3583052158355713, 0.3464241921901703, 0.33187955617904663, 0.32124024629592896, 0.30734941363334656, 0.29831627011299133, 0.2892882227897644, 0.2809445858001709, 0.26954734325408936, 0.26004359126091003, 0.2552698850631714, 0.2500523626804352, 0.24224698543548584, 0.23682136833667755, 0.2313709706068039, 0.2256118357181549, 0.22201383113861084, 0.21540220081806183, 0.20994144678115845, 0.20583631098270416, 0.20502378046512604, 0.20062200725078583, 0.19462300837039948, 0.1890134960412979, 0.18605764210224152, 0.1807776838541031, 0.18025796115398407, 0.1763594001531601, 0.17487195134162903, 0.17287445068359375, 0.1673460155725479, 0.1651345193386078, 0.16353605687618256, 0.1608811467885971, 0.15883108973503113, 0.15536639094352722, 0.15190361440181732, 0.148508682847023, 0.14773517847061157, 0.1459330916404724, 0.14559389650821686], 'accuracy': [0.5174583196640015, 0.7589791417121887, 0.812833309173584, 0.8380625247955322, 0.8573750257492065, 0.8687916398048401, 0.8789791464805603, 0.8855833411216736, 0.890666663646698, 0.8967291712760925, 0.8996041417121887, 0.9041458368301392, 0.9086458086967468, 0.9113749861717224, 0.9144583344459534, 0.917312502861023, 0.918874979019165, 0.9229791760444641, 0.9256458282470703, 0.9272291660308838, 0.9281666874885559, 0.9311249852180481, 0.9317708611488342, 0.9332708120346069, 0.9347916841506958, 0.9367916584014893, 0.9383124709129333, 0.9405624866485596, 0.9411875009536743, 0.940833330154419, 0.9432083368301392, 0.9448750019073486, 0.9459375143051147, 0.9463333487510681, 0.9474166631698608, 0.9486874938011169, 0.9488541483879089, 0.9498124718666077, 0.9511666893959045, 0.9527708292007446, 0.953208327293396, 0.953125, 0.9545833468437195, 0.9549375176429749, 0.9557916522026062, 0.9554374814033508, 0.9569791555404663, 0.9573333263397217, 0.9569166898727417, 0.957770824432373], 'val_loss': [0.7752827405929565, 0.4827563762664795, 0.3934602737426758, 0.34857043623924255, 0.3200695514678955, 0.297614187002182, 0.28010159730911255, 0.265468031167984, 0.2529587745666504, 0.24222949147224426, 0.23228353261947632, 0.22480332851409912, 0.21601556241512299, 0.20941445231437683, 0.2026386260986328, 0.1963725984096527, 0.1915627270936966, 0.18611747026443481, 0.18085968494415283, 0.17637741565704346, 0.1726265847682953, 0.16827495396137238, 0.16409257054328918, 0.1607336550951004, 0.15652571618556976, 0.15370768308639526, 0.15085329115390778, 0.14807261526584625, 0.1455288529396057, 0.14312958717346191, 0.1402701884508133, 0.13780397176742554, 0.135271817445755, 0.13314707577228546, 0.13130652904510498, 0.12946298718452454, 0.1271340399980545, 0.12540729343891144, 0.12339393049478531, 0.12243037670850754, 0.12104477733373642, 0.11852994561195374, 0.11786235868930817, 0.11569851636886597, 0.11410146206617355, 0.11302747577428818, 0.11157112568616867, 0.11048094928264618, 0.10995040833950043, 0.108271524310112], 'val_accuracy': [0.8395833373069763, 0.8799999952316284, 0.8949999809265137, 0.9051666855812073, 0.9116666913032532, 0.9154166579246521, 0.918916642665863, 0.9225000143051147, 0.9259166717529297, 0.9295833110809326, 0.9327499866485596, 0.934249997138977, 0.9375, 0.9384166598320007, 0.940583348274231, 0.9432500004768372, 0.9443333148956299, 0.9454166889190674, 0.9472500085830688, 0.9488333463668823, 0.9493333101272583, 0.9509166479110718, 0.9521666765213013, 0.95291668176651, 0.9548333287239075, 0.9555000066757202, 0.9567499756813049, 0.9567499756813049, 0.9566666483879089, 0.9577500224113464, 0.9584166407585144, 0.9592499732971191, 0.9605833292007446, 0.9611666798591614, 0.9613333344459534, 0.9618333578109741, 0.9625833630561829, 0.9629999995231628, 0.9636666774749756, 0.9635833501815796, 0.9635000228881836, 0.9645000100135803, 0.9659166932106018, 0.965583324432373, 0.965833306312561, 0.9664999842643738, 0.9661666750907898, 0.9670000076293945, 0.9674999713897705, 0.968666672706604]}\n",
      "{'loss': [1.438740611076355, 0.7434502243995667, 0.5815925002098083, 0.5110917687416077, 0.4644355773925781, 0.43455785512924194, 0.4089335501194, 0.39078935980796814, 0.37172266840934753, 0.35748380422592163, 0.3458336293697357, 0.33540424704551697, 0.3250476121902466, 0.31336912512779236, 0.30421143770217896, 0.2934817373752594, 0.28937411308288574, 0.2822994887828827, 0.2749169170856476, 0.2696754038333893, 0.2626349925994873, 0.260056734085083, 0.2543223202228546, 0.24678190052509308, 0.2450047880411148, 0.2386142760515213, 0.2335953563451767, 0.22905361652374268, 0.22441522777080536, 0.22049736976623535, 0.21816419064998627, 0.21329404413700104, 0.2112714797258377, 0.20679084956645966, 0.20422618091106415, 0.20164638757705688, 0.1971287876367569, 0.19476540386676788, 0.19138208031654358, 0.18643589317798615, 0.18653690814971924, 0.18540553748607635, 0.1815098077058792, 0.18117661774158478, 0.17765647172927856, 0.1748971790075302, 0.17077754437923431, 0.17032888531684875, 0.1677192747592926, 0.1669926792383194], 'accuracy': [0.5747291445732117, 0.7827708125114441, 0.8303124904632568, 0.8519166707992554, 0.8649166822433472, 0.8741041421890259, 0.8817916512489319, 0.8866666555404663, 0.893875002861023, 0.8978958129882812, 0.9008541703224182, 0.9022083282470703, 0.905958354473114, 0.909500002861023, 0.9131041765213013, 0.9152291417121887, 0.9177916646003723, 0.918708324432373, 0.9211041927337646, 0.9231874942779541, 0.925125002861023, 0.9241250157356262, 0.9276458621025085, 0.9297083616256714, 0.929979145526886, 0.9314374923706055, 0.9322708249092102, 0.932937502861023, 0.9352499842643738, 0.9366666674613953, 0.9378958344459534, 0.9391250014305115, 0.9394583106040955, 0.940833330154419, 0.9403749704360962, 0.9423333406448364, 0.9436666369438171, 0.9443749785423279, 0.9436666369438171, 0.945479154586792, 0.9458958506584167, 0.9459166526794434, 0.9469791650772095, 0.9480208158493042, 0.9482083320617676, 0.9502500295639038, 0.9507708549499512, 0.9512291550636292, 0.9513124823570251, 0.9521666765213013], 'val_loss': [0.694532573223114, 0.45891278982162476, 0.3856157958507538, 0.346727579832077, 0.32132086157798767, 0.3046555519104004, 0.28960344195365906, 0.278231143951416, 0.2669873535633087, 0.2576294243335724, 0.2501140236854553, 0.24294012784957886, 0.23595349490642548, 0.23061023652553558, 0.223698690533638, 0.21850386261940002, 0.21361835300922394, 0.20844034850597382, 0.20499902963638306, 0.20046478509902954, 0.19591237604618073, 0.1919618397951126, 0.18865785002708435, 0.18541878461837769, 0.1821381151676178, 0.17872318625450134, 0.17534108459949493, 0.1721382588148117, 0.1698107272386551, 0.16726797819137573, 0.1652497798204422, 0.16224975883960724, 0.15944716334342957, 0.15708401799201965, 0.15617993474006653, 0.15359114110469818, 0.15102601051330566, 0.14921624958515167, 0.14747637510299683, 0.1452954113483429, 0.14358879625797272, 0.1421230584383011, 0.14012806117534637, 0.13949309289455414, 0.13761216402053833, 0.13640807569026947, 0.1346280574798584, 0.13353079557418823, 0.1318366527557373, 0.13082531094551086], 'val_accuracy': [0.8517500162124634, 0.8871666789054871, 0.8962500095367432, 0.9044166803359985, 0.9114166498184204, 0.9156666398048401, 0.9190833568572998, 0.9229166507720947, 0.9252499938011169, 0.9275833368301392, 0.9292500019073486, 0.9311666488647461, 0.9330000281333923, 0.934333324432373, 0.9363333582878113, 0.937666654586792, 0.9394999742507935, 0.940666675567627, 0.9424999952316284, 0.9431666731834412, 0.9454166889190674, 0.9462500214576721, 0.9473333358764648, 0.9485833048820496, 0.9493333101272583, 0.949833333492279, 0.9512500166893005, 0.9524999856948853, 0.953416645526886, 0.953083336353302, 0.9542499780654907, 0.9550833106040955, 0.9559999704360962, 0.9559999704360962, 0.9566666483879089, 0.956333339214325, 0.9575833082199097, 0.9580833315849304, 0.9580000042915344, 0.9584166407585144, 0.9591666460037231, 0.9591666460037231, 0.9604166746139526, 0.9605000019073486, 0.9601666927337646, 0.9604166746139526, 0.9612500071525574, 0.9610833525657654, 0.9622499942779541, 0.9621666669845581]}\n",
      "{'loss': [1.1137796640396118, 0.5922970771789551, 0.4901193082332611, 0.4499233663082123, 0.4204554557800293, 0.4027882516384125, 0.3883087933063507, 0.3794938027858734, 0.36630192399024963, 0.36085814237594604, 0.35567548871040344, 0.3457038104534149, 0.3429222106933594, 0.3355046510696411, 0.3316071331501007, 0.32640159130096436, 0.3237263262271881, 0.31981784105300903, 0.31721121072769165, 0.31154170632362366, 0.3063869774341583, 0.3074742555618286, 0.3010464012622833, 0.29900771379470825, 0.2952852249145508, 0.29341498017311096, 0.29054924845695496, 0.28705182671546936, 0.2853586971759796, 0.28550031781196594, 0.27980536222457886, 0.2777506709098816, 0.27443447709083557, 0.272122859954834, 0.2726461887359619, 0.2675686776638031, 0.2652852237224579, 0.26442772150039673, 0.26131853461265564, 0.26065412163734436, 0.25718605518341064, 0.25723737478256226, 0.2549761235713959, 0.2500525414943695, 0.249216690659523, 0.2465803623199463, 0.2442801296710968, 0.23886308073997498, 0.24245961010456085, 0.2403775006532669], 'accuracy': [0.6778958439826965, 0.8313124775886536, 0.8568541407585144, 0.8692083358764648, 0.8769999742507935, 0.8818333148956299, 0.8862291574478149, 0.8898958563804626, 0.8941249847412109, 0.893916666507721, 0.8959166407585144, 0.8999375104904175, 0.8997499942779541, 0.9023333191871643, 0.9022499918937683, 0.9059791564941406, 0.9057916402816772, 0.90645831823349, 0.9077708125114441, 0.9089166522026062, 0.9102500081062317, 0.9120000004768372, 0.9117083549499512, 0.9130416512489319, 0.9144166707992554, 0.9145625233650208, 0.9144999980926514, 0.9169166684150696, 0.9166250228881836, 0.9166250228881836, 0.9193958044052124, 0.9200624823570251, 0.9190000295639038, 0.9206458330154419, 0.9195208549499512, 0.9224374890327454, 0.9213958382606506, 0.9227499961853027, 0.9227708578109741, 0.921999990940094, 0.9247291684150696, 0.9245625138282776, 0.9246041774749756, 0.9275000095367432, 0.9257291555404663, 0.9269583225250244, 0.9277083277702332, 0.929937481880188, 0.9284583330154419, 0.9288750290870667], 'val_loss': [0.5492183566093445, 0.4084814488887787, 0.3608098030090332, 0.3376281261444092, 0.3218068778514862, 0.3108838200569153, 0.30115634202957153, 0.29465076327323914, 0.2889026403427124, 0.28362590074539185, 0.27850237488746643, 0.27429360151290894, 0.27134940028190613, 0.26723888516426086, 0.263723224401474, 0.2601647973060608, 0.2577657103538513, 0.25462180376052856, 0.25260403752326965, 0.24959108233451843, 0.24733969569206238, 0.24428746104240417, 0.2424907088279724, 0.2406574934720993, 0.23875445127487183, 0.23479969799518585, 0.23341785371303558, 0.23138785362243652, 0.22906506061553955, 0.2267588973045349, 0.22448065876960754, 0.22148706018924713, 0.21945913136005402, 0.2193492203950882, 0.21593932807445526, 0.21511545777320862, 0.2118016928434372, 0.21041801571846008, 0.21002162992954254, 0.20671185851097107, 0.2052614539861679, 0.20338527858257294, 0.20298299193382263, 0.20086167752742767, 0.1979694813489914, 0.19728438556194305, 0.19443215429782867, 0.1934562623500824, 0.1924000233411789, 0.19058333337306976], 'val_accuracy': [0.8673333525657654, 0.8920000195503235, 0.9008333086967468, 0.9046666622161865, 0.9084166884422302, 0.9114999771118164, 0.9157500267028809, 0.9169166684150696, 0.918666660785675, 0.9194166660308838, 0.9206666946411133, 0.9209166765213013, 0.92208331823349, 0.9237499833106995, 0.9239166378974915, 0.9235833287239075, 0.925000011920929, 0.9258333444595337, 0.9262499809265137, 0.9270833134651184, 0.9284999966621399, 0.9287499785423279, 0.9303333163261414, 0.9301666617393494, 0.9311666488647461, 0.9318333268165588, 0.9322500228881836, 0.9336666464805603, 0.9337499737739563, 0.934583306312561, 0.9347500205039978, 0.9362499713897705, 0.9370833039283752, 0.9365833401679993, 0.9384166598320007, 0.9387500286102295, 0.9396666884422302, 0.9402499794960022, 0.9399166703224182, 0.9421666860580444, 0.9424166679382324, 0.9426666498184204, 0.9432500004768372, 0.9433333277702332, 0.9459166526794434, 0.9449999928474426, 0.9471666812896729, 0.9467499852180481, 0.9468333125114441, 0.9479166865348816]}\n",
      "{'loss': [2.1626365184783936, 1.418826699256897, 1.1012781858444214, 0.9306759238243103, 0.8350219130516052, 0.7612451314926147, 0.7101898789405823, 0.6769634485244751, 0.6428220868110657, 0.6174589991569519, 0.5939528942108154, 0.574434757232666, 0.558666467666626, 0.5471262335777283, 0.5286052823066711, 0.5250476002693176, 0.5065675377845764, 0.49822473526000977, 0.4912542700767517, 0.4834883511066437, 0.47466135025024414, 0.4770418405532837, 0.4597313106060028, 0.4609973132610321, 0.4529360830783844, 0.44688814878463745, 0.4449000358581543, 0.438422292470932, 0.4301456809043884, 0.4239535331726074, 0.42463216185569763, 0.41736337542533875, 0.4152173697948456, 0.4159201979637146, 0.40567725896835327, 0.40357157588005066, 0.3990858495235443, 0.3939155638217926, 0.3954183757305145, 0.38838788866996765, 0.38644105195999146, 0.37964314222335815, 0.37882936000823975, 0.37582266330718994, 0.3742070198059082, 0.36841410398483276, 0.3714390993118286, 0.36789917945861816, 0.3663865029811859, 0.3603745996952057], 'accuracy': [0.26391667127609253, 0.5084999799728394, 0.6268541812896729, 0.6894999742507935, 0.7262916564941406, 0.754562497138977, 0.7721458077430725, 0.7848958373069763, 0.7972291707992554, 0.8052916526794434, 0.8171250224113464, 0.8227708339691162, 0.8273541927337646, 0.832895815372467, 0.8399375081062317, 0.8401458263397217, 0.8456458449363708, 0.8498958349227905, 0.8497916460037231, 0.8533958196640015, 0.8576458096504211, 0.8576666712760925, 0.8611249923706055, 0.862416684627533, 0.8663125038146973, 0.867270827293396, 0.867020845413208, 0.870437502861023, 0.8715416789054871, 0.8739374876022339, 0.8735625147819519, 0.8748541474342346, 0.8775208592414856, 0.8741666674613953, 0.8792499899864197, 0.879729151725769, 0.8815416693687439, 0.8833541870117188, 0.8827083110809326, 0.8850625157356262, 0.8846458196640015, 0.8873958587646484, 0.8874791860580444, 0.8875625133514404, 0.8894166946411133, 0.890666663646698, 0.8885625004768372, 0.8895208239555359, 0.8926041722297668, 0.8920000195503235], 'val_loss': [0.7304099202156067, 0.5918892025947571, 0.5489307641983032, 0.5477059483528137, 0.5449588894844055, 0.5357860326766968, 0.5342787504196167, 0.5271889567375183, 0.5253853797912598, 0.5194202065467834, 0.5146283507347107, 0.505017101764679, 0.5021365284919739, 0.49798068404197693, 0.4987122714519501, 0.4890783429145813, 0.4878461956977844, 0.4819898009300232, 0.4787227511405945, 0.47207504510879517, 0.4675635099411011, 0.46453768014907837, 0.45792829990386963, 0.4547114372253418, 0.45030948519706726, 0.44688937067985535, 0.4427657127380371, 0.43886831402778625, 0.4408850371837616, 0.4374537467956543, 0.43207257986068726, 0.42967870831489563, 0.4262983798980713, 0.4174034893512726, 0.4169299602508545, 0.4130743741989136, 0.4118662178516388, 0.4091542661190033, 0.40523046255111694, 0.40296924114227295, 0.40057629346847534, 0.39964696764945984, 0.3972833752632141, 0.3938310146331787, 0.3899043798446655, 0.38699576258659363, 0.3832208216190338, 0.38208428025245667, 0.38171976804733276, 0.3795572519302368], 'val_accuracy': [0.7630000114440918, 0.815750002861023, 0.8453333377838135, 0.8578333258628845, 0.8675833344459534, 0.875166654586792, 0.8790833353996277, 0.8849999904632568, 0.8867499828338623, 0.890749990940094, 0.8934999704360962, 0.8966666460037231, 0.8989166617393494, 0.9001666903495789, 0.9010000228881836, 0.9026666879653931, 0.9036666750907898, 0.9049166440963745, 0.906333327293396, 0.9075000286102295, 0.9083333611488342, 0.9086666703224182, 0.9109166860580444, 0.9112499952316284, 0.9120000004768372, 0.9134166836738586, 0.9139999747276306, 0.9145833253860474, 0.9154166579246521, 0.9164166450500488, 0.9168333411216736, 0.9182500243186951, 0.9175833463668823, 0.9196666479110718, 0.9196666479110718, 0.9205833077430725, 0.92166668176651, 0.92208331823349, 0.921999990940094, 0.921999990940094, 0.9232500195503235, 0.9246666431427002, 0.9233333468437195, 0.924833357334137, 0.9246666431427002, 0.9267500042915344, 0.9271666407585144, 0.9278333187103271, 0.9282500147819519, 0.9284999966621399]}\n",
      "{'loss': [1.7735105752944946, 0.919587254524231, 0.6739837527275085, 0.574832558631897, 0.523680567741394, 0.4806908369064331, 0.4508790373802185, 0.431184321641922, 0.40892887115478516, 0.39437663555145264, 0.37958288192749023, 0.3661348819732666, 0.3552965819835663, 0.34568628668785095, 0.3312453329563141, 0.3250361979007721, 0.31855207681655884, 0.3117341995239258, 0.3032093346118927, 0.29488903284072876, 0.28941503167152405, 0.2842397391796112, 0.2734668254852295, 0.2691669464111328, 0.26478713750839233, 0.25910595059394836, 0.2534811794757843, 0.25017204880714417, 0.24565765261650085, 0.24034921824932098, 0.2358858287334442, 0.23342181742191315, 0.22900116443634033, 0.22466355562210083, 0.22016122937202454, 0.21987786889076233, 0.2147013396024704, 0.21136339008808136, 0.20936909317970276, 0.20439453423023224, 0.20120596885681152, 0.20132212340831757, 0.1958855390548706, 0.19409531354904175, 0.19111143052577972, 0.1869974583387375, 0.18647751212120056, 0.18450883030891418, 0.18038229644298553, 0.18030403554439545], 'accuracy': [0.49306249618530273, 0.7339791655540466, 0.8022708296775818, 0.8329166769981384, 0.8484583497047424, 0.8616666793823242, 0.8705000281333923, 0.8759375214576721, 0.8829166889190674, 0.8856250047683716, 0.8893333077430725, 0.8957499861717224, 0.8978958129882812, 0.9004999995231628, 0.9045208096504211, 0.9054999947547913, 0.9073958396911621, 0.9106041789054871, 0.9123333096504211, 0.9150208234786987, 0.9168958067893982, 0.9180625081062317, 0.9207916855812073, 0.922249972820282, 0.9231458306312561, 0.9258750081062317, 0.9271875023841858, 0.9280624985694885, 0.9284999966621399, 0.9301666617393494, 0.9316666722297668, 0.9336041808128357, 0.9331250190734863, 0.9358749985694885, 0.9358541369438171, 0.9359583258628845, 0.9385833144187927, 0.9367499947547913, 0.9380624890327454, 0.9411458373069763, 0.9408541917800903, 0.9408958554267883, 0.9440833330154419, 0.9434791803359985, 0.9436458349227905, 0.945145845413208, 0.9457708597183228, 0.9455833435058594, 0.9480833411216736, 0.9468541741371155], 'val_loss': [1.0448460578918457, 0.5675250887870789, 0.44968974590301514, 0.3940851092338562, 0.3613477349281311, 0.33959200978279114, 0.3222135305404663, 0.308633416891098, 0.29668986797332764, 0.28514355421066284, 0.27630865573883057, 0.26684248447418213, 0.25913605093955994, 0.25155937671661377, 0.24472776055335999, 0.2386438399553299, 0.2333976775407791, 0.228099063038826, 0.22298137843608856, 0.21805371344089508, 0.21216292679309845, 0.2079264372587204, 0.20371446013450623, 0.20029865205287933, 0.1968240588903427, 0.19253644347190857, 0.18932969868183136, 0.18585066497325897, 0.1826324462890625, 0.17915233969688416, 0.17649123072624207, 0.17408590018749237, 0.17131578922271729, 0.1685941517353058, 0.1665017157793045, 0.1640760898590088, 0.1614394634962082, 0.15948732197284698, 0.15714891254901886, 0.15499110519886017, 0.15322934091091156, 0.15205754339694977, 0.14981339871883392, 0.14799636602401733, 0.14604255557060242, 0.1441415250301361, 0.14255349338054657, 0.1409434974193573, 0.13979966938495636, 0.13784682750701904], 'val_accuracy': [0.8019166588783264, 0.8677499890327454, 0.8855833411216736, 0.8961666822433472, 0.9049999713897705, 0.9088333249092102, 0.9116666913032532, 0.9145833253860474, 0.9161666631698608, 0.9192500114440918, 0.922166645526886, 0.9238333106040955, 0.925083339214325, 0.9279166460037231, 0.9294999837875366, 0.9315833449363708, 0.9334166646003723, 0.934249997138977, 0.9364166855812073, 0.937583327293396, 0.9393333196640015, 0.940666675567627, 0.9415833353996277, 0.9429166913032532, 0.9444166421890259, 0.9445000290870667, 0.9455000162124634, 0.9469166398048401, 0.9474999904632568, 0.9481666684150696, 0.9495833516120911, 0.9503333568572998, 0.9509999752044678, 0.9518333077430725, 0.9519166946411133, 0.953249990940094, 0.9535833597183228, 0.9546666741371155, 0.9553333520889282, 0.956083357334137, 0.956083357334137, 0.9567499756813049, 0.9567499756813049, 0.9576666951179504, 0.9579166769981384, 0.9582499861717224, 0.9591666460037231, 0.9593333601951599, 0.9600833058357239, 0.9602500200271606]}\n",
      "{'loss': [1.8783564567565918, 1.0540028810501099, 0.7413218021392822, 0.6236287951469421, 0.5575064420700073, 0.5175609588623047, 0.4857185482978821, 0.4640844762325287, 0.444766104221344, 0.4327254593372345, 0.4157392978668213, 0.40639737248420715, 0.38969308137893677, 0.3804685175418854, 0.3718121647834778, 0.36582979559898376, 0.3581368327140808, 0.349971204996109, 0.34186962246894836, 0.3367505967617035, 0.33337917923927307, 0.32510536909103394, 0.3185843527317047, 0.3122403919696808, 0.31200799345970154, 0.3046218156814575, 0.2999512255191803, 0.29207727313041687, 0.28910019993782043, 0.2866797149181366, 0.28272688388824463, 0.2753850221633911, 0.27341315150260925, 0.2717072069644928, 0.2676893472671509, 0.2643286883831024, 0.26175591349601746, 0.2555501163005829, 0.25371018052101135, 0.25229698419570923, 0.2480688840150833, 0.24454297125339508, 0.24081331491470337, 0.241230309009552, 0.2372497171163559, 0.23295898735523224, 0.23304612934589386, 0.22860082983970642, 0.22511987388134003, 0.22405554354190826], 'accuracy': [0.49158334732055664, 0.7174375057220459, 0.7829791903495789, 0.8175416588783264, 0.8382708430290222, 0.8491458296775818, 0.8594375252723694, 0.8666458129882812, 0.8709166646003723, 0.8762500286102295, 0.8803750276565552, 0.8832708597183228, 0.8886458277702332, 0.8917291760444641, 0.8923125267028809, 0.893666684627533, 0.8958333134651184, 0.8984375, 0.9007083177566528, 0.9028750061988831, 0.9035208225250244, 0.905875027179718, 0.9076458215713501, 0.9103749990463257, 0.9093124866485596, 0.9115625023841858, 0.9131875038146973, 0.9154375195503235, 0.9156249761581421, 0.9159791469573975, 0.9181666374206543, 0.9198750257492065, 0.9194583296775818, 0.9216874837875366, 0.921833336353302, 0.9225208163261414, 0.9234791398048401, 0.9255625009536743, 0.9246666431427002, 0.924875020980835, 0.9266250133514404, 0.929312527179718, 0.9296249747276306, 0.9280624985694885, 0.9297916889190674, 0.9315624833106995, 0.9309166669845581, 0.932770848274231, 0.9333124756813049, 0.9333333373069763], 'val_loss': [1.3078501224517822, 0.6704120635986328, 0.5078519582748413, 0.43905138969421387, 0.40220800042152405, 0.37705451250076294, 0.3580799102783203, 0.3429929316043854, 0.3305017054080963, 0.32060566544532776, 0.3108201026916504, 0.3026808500289917, 0.29489195346832275, 0.288381963968277, 0.28211572766304016, 0.2766211926937103, 0.2715207636356354, 0.2663829028606415, 0.2613966763019562, 0.2565642297267914, 0.25229135155677795, 0.24787084758281708, 0.24384582042694092, 0.23986861109733582, 0.23595216870307922, 0.23239253461360931, 0.22949714958667755, 0.2251022309064865, 0.22200427949428558, 0.21900366246700287, 0.2162068486213684, 0.2125312238931656, 0.20959654450416565, 0.20739330351352692, 0.20478321611881256, 0.2017095535993576, 0.19880889356136322, 0.19688232243061066, 0.1940954327583313, 0.19238106906414032, 0.18988272547721863, 0.1877923607826233, 0.18534420430660248, 0.18333686888217926, 0.18185342848300934, 0.17958679795265198, 0.17774638533592224, 0.17581093311309814, 0.1735261082649231, 0.17198307812213898], 'val_accuracy': [0.7799999713897705, 0.8539166450500488, 0.8740833401679993, 0.8860833048820496, 0.8927500247955322, 0.8974166512489319, 0.9014166593551636, 0.9049999713897705, 0.909333348274231, 0.9119166731834412, 0.9141666889190674, 0.9154999852180481, 0.9175000190734863, 0.9193333387374878, 0.9199166893959045, 0.922249972820282, 0.9225833415985107, 0.924916684627533, 0.9256666898727417, 0.9269999861717224, 0.9272500276565552, 0.9291666746139526, 0.9309166669845581, 0.9312499761581421, 0.9316666722297668, 0.9330000281333923, 0.934583306312561, 0.9355000257492065, 0.9359999895095825, 0.9366666674613953, 0.9380000233650208, 0.9380000233650208, 0.9394999742507935, 0.9391666650772095, 0.9401666522026062, 0.9418333172798157, 0.9428333044052124, 0.9431666731834412, 0.9445000290870667, 0.9446666836738586, 0.9455833435058594, 0.9466666579246521, 0.9471666812896729, 0.9472500085830688, 0.9480833411216736, 0.9491666555404663, 0.9496666789054871, 0.9503333568572998, 0.9507499933242798, 0.9513333439826965]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOEGH76HUH5p3fLXEAS78nh",
   "collapsed_sections": [],
   "name": "2depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
