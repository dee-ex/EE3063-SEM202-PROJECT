{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 724362,
     "status": "ok",
     "timestamp": 1627301082368,
     "user": {
      "displayName": "Trung Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjz3Gx8BE3WlqqWlg0FDtKUcK2DEtQ_rPNQD4mLTA=s64",
      "userId": "01683412142186761760"
     },
     "user_tz": -420
    },
    "id": "JnHhSjZec4W6",
    "outputId": "78aedbe1-266e-4599-8121-51fd8368d891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 16s 5ms/step - loss: 2.5156 - accuracy: 0.0971 - val_loss: 2.3038 - val_accuracy: 0.0995\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3865 - accuracy: 0.1000 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3595 - accuracy: 0.0988 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3403 - accuracy: 0.1026 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3356 - accuracy: 0.1012 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3303 - accuracy: 0.0987 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3234 - accuracy: 0.0988 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3206 - accuracy: 0.1038 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3193 - accuracy: 0.1004 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3132 - accuracy: 0.1022 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3129 - accuracy: 0.1035 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3112 - accuracy: 0.1050 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3123 - accuracy: 0.1015 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3086 - accuracy: 0.1073 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3089 - accuracy: 0.1045 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3085 - accuracy: 0.1059 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3074 - accuracy: 0.1059 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3076 - accuracy: 0.1048 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3073 - accuracy: 0.1054 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3060 - accuracy: 0.1093 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3053 - accuracy: 0.1070 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3068 - accuracy: 0.1046 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3052 - accuracy: 0.1081 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3051 - accuracy: 0.1059 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3047 - accuracy: 0.1084 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3038 - accuracy: 0.1097 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3058 - accuracy: 0.1060 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3038 - accuracy: 0.1065 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3051 - accuracy: 0.1057 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3044 - accuracy: 0.1052 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3038 - accuracy: 0.1078 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3028 - accuracy: 0.1117 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3038 - accuracy: 0.1087 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3028 - accuracy: 0.1122 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3034 - accuracy: 0.1098 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3035 - accuracy: 0.1100 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3029 - accuracy: 0.1099 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3038 - accuracy: 0.1111 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3032 - accuracy: 0.1085 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.1105 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3034 - accuracy: 0.1074 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3025 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3030 - accuracy: 0.1103 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3028 - accuracy: 0.1080 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3033 - accuracy: 0.1078 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3022 - accuracy: 0.1100 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3028 - accuracy: 0.1096 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3034 - accuracy: 0.1101 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3032 - accuracy: 0.1117 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3019 - accuracy: 0.1131 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.0205 - accuracy: 0.2696 - val_loss: 1.1015 - val_accuracy: 0.7666\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3885 - accuracy: 0.5410 - val_loss: 0.8104 - val_accuracy: 0.8369\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1729 - accuracy: 0.6254 - val_loss: 0.6596 - val_accuracy: 0.8572\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0442 - accuracy: 0.6751 - val_loss: 0.5660 - val_accuracy: 0.8703\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9605 - accuracy: 0.7051 - val_loss: 0.5046 - val_accuracy: 0.8794\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9004 - accuracy: 0.7207 - val_loss: 0.4624 - val_accuracy: 0.8861\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8547 - accuracy: 0.7428 - val_loss: 0.4280 - val_accuracy: 0.8901\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8195 - accuracy: 0.7526 - val_loss: 0.4040 - val_accuracy: 0.8933\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7759 - accuracy: 0.7697 - val_loss: 0.3863 - val_accuracy: 0.8942\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7494 - accuracy: 0.7775 - val_loss: 0.3707 - val_accuracy: 0.8980\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7309 - accuracy: 0.7856 - val_loss: 0.3578 - val_accuracy: 0.9019\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7241 - accuracy: 0.7919 - val_loss: 0.3461 - val_accuracy: 0.9042\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.7985 - val_loss: 0.3368 - val_accuracy: 0.9062\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6670 - accuracy: 0.8086 - val_loss: 0.3298 - val_accuracy: 0.9084\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6531 - accuracy: 0.8137 - val_loss: 0.3225 - val_accuracy: 0.9112\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6517 - accuracy: 0.8153 - val_loss: 0.3151 - val_accuracy: 0.9132\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6258 - accuracy: 0.8246 - val_loss: 0.3091 - val_accuracy: 0.9147\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6160 - accuracy: 0.8265 - val_loss: 0.3035 - val_accuracy: 0.9170\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6142 - accuracy: 0.8330 - val_loss: 0.2993 - val_accuracy: 0.9182\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5972 - accuracy: 0.8359 - val_loss: 0.2935 - val_accuracy: 0.9199\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5854 - accuracy: 0.8411 - val_loss: 0.2954 - val_accuracy: 0.9193\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5768 - accuracy: 0.8423 - val_loss: 0.2860 - val_accuracy: 0.9221\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5636 - accuracy: 0.8465 - val_loss: 0.2830 - val_accuracy: 0.9234\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5538 - accuracy: 0.8498 - val_loss: 0.2780 - val_accuracy: 0.9248\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5332 - accuracy: 0.8551 - val_loss: 0.2766 - val_accuracy: 0.9260\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5559 - accuracy: 0.8518 - val_loss: 0.2728 - val_accuracy: 0.9270\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5316 - accuracy: 0.8591 - val_loss: 0.2721 - val_accuracy: 0.9280\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.8549 - val_loss: 0.2678 - val_accuracy: 0.9292\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5199 - accuracy: 0.8632 - val_loss: 0.2644 - val_accuracy: 0.9304\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.8619 - val_loss: 0.2617 - val_accuracy: 0.9309\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5097 - accuracy: 0.8651 - val_loss: 0.2638 - val_accuracy: 0.9315\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8674 - val_loss: 0.2571 - val_accuracy: 0.9327\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.8696 - val_loss: 0.2564 - val_accuracy: 0.9333\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4990 - accuracy: 0.8724 - val_loss: 0.2555 - val_accuracy: 0.9336\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4928 - accuracy: 0.8741 - val_loss: 0.2501 - val_accuracy: 0.9352\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4862 - accuracy: 0.8739 - val_loss: 0.2492 - val_accuracy: 0.9363\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4768 - accuracy: 0.8769 - val_loss: 0.2461 - val_accuracy: 0.9358\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4727 - accuracy: 0.8769 - val_loss: 0.2451 - val_accuracy: 0.9379\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4666 - accuracy: 0.8780 - val_loss: 0.2430 - val_accuracy: 0.9388\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4526 - accuracy: 0.8837 - val_loss: 0.2406 - val_accuracy: 0.9394\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4575 - accuracy: 0.8795 - val_loss: 0.2416 - val_accuracy: 0.9381\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4569 - accuracy: 0.8830 - val_loss: 0.2372 - val_accuracy: 0.9396\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4564 - accuracy: 0.8814 - val_loss: 0.2335 - val_accuracy: 0.9403\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4413 - accuracy: 0.8878 - val_loss: 0.2298 - val_accuracy: 0.9426\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4434 - accuracy: 0.8841 - val_loss: 0.2294 - val_accuracy: 0.9424\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4403 - accuracy: 0.8864 - val_loss: 0.2263 - val_accuracy: 0.9434\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4362 - accuracy: 0.8891 - val_loss: 0.2269 - val_accuracy: 0.9433\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4265 - accuracy: 0.8912 - val_loss: 0.2252 - val_accuracy: 0.9437\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4381 - accuracy: 0.8872 - val_loss: 0.2227 - val_accuracy: 0.9444\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4300 - accuracy: 0.8897 - val_loss: 0.2215 - val_accuracy: 0.9455\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2965 - accuracy: 0.1160 - val_loss: 2.2202 - val_accuracy: 0.2656\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2281 - accuracy: 0.1765 - val_loss: 2.0223 - val_accuracy: 0.4217\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0960 - accuracy: 0.2331 - val_loss: 1.7905 - val_accuracy: 0.4647\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.9434 - accuracy: 0.2869 - val_loss: 1.5870 - val_accuracy: 0.5428\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8082 - accuracy: 0.3370 - val_loss: 1.3957 - val_accuracy: 0.5495\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6802 - accuracy: 0.3858 - val_loss: 1.2673 - val_accuracy: 0.5882\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5628 - accuracy: 0.4248 - val_loss: 1.1537 - val_accuracy: 0.6191\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4616 - accuracy: 0.4565 - val_loss: 1.0515 - val_accuracy: 0.6630\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3808 - accuracy: 0.4829 - val_loss: 0.9723 - val_accuracy: 0.7013\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3067 - accuracy: 0.5210 - val_loss: 0.9015 - val_accuracy: 0.7346\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2409 - accuracy: 0.5490 - val_loss: 0.8214 - val_accuracy: 0.7687\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1862 - accuracy: 0.5735 - val_loss: 0.7523 - val_accuracy: 0.7993\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1393 - accuracy: 0.5866 - val_loss: 0.6923 - val_accuracy: 0.8198\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0887 - accuracy: 0.6162 - val_loss: 0.6449 - val_accuracy: 0.8189\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0479 - accuracy: 0.6310 - val_loss: 0.5965 - val_accuracy: 0.8423\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0106 - accuracy: 0.6464 - val_loss: 0.5564 - val_accuracy: 0.8441\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9744 - accuracy: 0.6609 - val_loss: 0.5307 - val_accuracy: 0.8512\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9351 - accuracy: 0.6787 - val_loss: 0.4943 - val_accuracy: 0.8602\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9122 - accuracy: 0.6868 - val_loss: 0.4667 - val_accuracy: 0.8653\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8750 - accuracy: 0.7015 - val_loss: 0.4416 - val_accuracy: 0.8712\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8422 - accuracy: 0.7116 - val_loss: 0.4189 - val_accuracy: 0.8741\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8301 - accuracy: 0.7181 - val_loss: 0.3904 - val_accuracy: 0.8780\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7966 - accuracy: 0.7286 - val_loss: 0.3717 - val_accuracy: 0.8949\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7803 - accuracy: 0.7403 - val_loss: 0.3509 - val_accuracy: 0.8917\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7387 - accuracy: 0.7511 - val_loss: 0.3360 - val_accuracy: 0.9002\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7332 - accuracy: 0.7555 - val_loss: 0.3177 - val_accuracy: 0.9162\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7025 - accuracy: 0.7661 - val_loss: 0.3016 - val_accuracy: 0.9289\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6986 - accuracy: 0.7712 - val_loss: 0.2863 - val_accuracy: 0.9283\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6788 - accuracy: 0.7797 - val_loss: 0.2748 - val_accuracy: 0.9340\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6571 - accuracy: 0.7865 - val_loss: 0.2647 - val_accuracy: 0.9465\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6468 - accuracy: 0.7948 - val_loss: 0.2527 - val_accuracy: 0.9433\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6298 - accuracy: 0.8003 - val_loss: 0.2400 - val_accuracy: 0.9511\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6131 - accuracy: 0.8038 - val_loss: 0.2298 - val_accuracy: 0.9518\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6185 - accuracy: 0.8068 - val_loss: 0.2262 - val_accuracy: 0.9523\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5894 - accuracy: 0.8159 - val_loss: 0.2186 - val_accuracy: 0.9537\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5789 - accuracy: 0.8148 - val_loss: 0.2165 - val_accuracy: 0.9555\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5658 - accuracy: 0.8220 - val_loss: 0.2124 - val_accuracy: 0.9566\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5574 - accuracy: 0.8271 - val_loss: 0.1980 - val_accuracy: 0.9592\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5351 - accuracy: 0.8330 - val_loss: 0.1949 - val_accuracy: 0.9600\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5410 - accuracy: 0.8324 - val_loss: 0.1964 - val_accuracy: 0.9609\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5214 - accuracy: 0.8369 - val_loss: 0.1928 - val_accuracy: 0.9602\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5364 - accuracy: 0.8340 - val_loss: 0.1776 - val_accuracy: 0.9628\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4951 - accuracy: 0.8461 - val_loss: 0.1782 - val_accuracy: 0.9643\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5022 - accuracy: 0.8429 - val_loss: 0.1742 - val_accuracy: 0.9640\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.8456 - val_loss: 0.1679 - val_accuracy: 0.9641\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4809 - accuracy: 0.8507 - val_loss: 0.1703 - val_accuracy: 0.9648\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4713 - accuracy: 0.8510 - val_loss: 0.1658 - val_accuracy: 0.9656\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4793 - accuracy: 0.8514 - val_loss: 0.1678 - val_accuracy: 0.9657\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4598 - accuracy: 0.8554 - val_loss: 0.1649 - val_accuracy: 0.9675\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4607 - accuracy: 0.8556 - val_loss: 0.1595 - val_accuracy: 0.9666\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2990 - accuracy: 0.1201 - val_loss: 2.2328 - val_accuracy: 0.3457\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2138 - accuracy: 0.1991 - val_loss: 1.8633 - val_accuracy: 0.4582\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9198 - accuracy: 0.3098 - val_loss: 1.4214 - val_accuracy: 0.5535\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6404 - accuracy: 0.3985 - val_loss: 1.1832 - val_accuracy: 0.6146\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4466 - accuracy: 0.4658 - val_loss: 1.0414 - val_accuracy: 0.7049\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3098 - accuracy: 0.5200 - val_loss: 0.9299 - val_accuracy: 0.7333\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2083 - accuracy: 0.5609 - val_loss: 0.8200 - val_accuracy: 0.7791\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1164 - accuracy: 0.6086 - val_loss: 0.6990 - val_accuracy: 0.8242\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0249 - accuracy: 0.6484 - val_loss: 0.5980 - val_accuracy: 0.8449\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9478 - accuracy: 0.6876 - val_loss: 0.5267 - val_accuracy: 0.8691\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8788 - accuracy: 0.7173 - val_loss: 0.4660 - val_accuracy: 0.8848\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8239 - accuracy: 0.7389 - val_loss: 0.4241 - val_accuracy: 0.8955\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7650 - accuracy: 0.7594 - val_loss: 0.3903 - val_accuracy: 0.9043\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7223 - accuracy: 0.7745 - val_loss: 0.3565 - val_accuracy: 0.9133\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6844 - accuracy: 0.7921 - val_loss: 0.3297 - val_accuracy: 0.9163\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6574 - accuracy: 0.7992 - val_loss: 0.3069 - val_accuracy: 0.9227\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6187 - accuracy: 0.8161 - val_loss: 0.2884 - val_accuracy: 0.9270\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5995 - accuracy: 0.8228 - val_loss: 0.2737 - val_accuracy: 0.9309\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5590 - accuracy: 0.8339 - val_loss: 0.2570 - val_accuracy: 0.9341\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5510 - accuracy: 0.8386 - val_loss: 0.2462 - val_accuracy: 0.9338\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5290 - accuracy: 0.8455 - val_loss: 0.2311 - val_accuracy: 0.9395\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5141 - accuracy: 0.8535 - val_loss: 0.2217 - val_accuracy: 0.9403\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4874 - accuracy: 0.8591 - val_loss: 0.2113 - val_accuracy: 0.9426\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4740 - accuracy: 0.8635 - val_loss: 0.2078 - val_accuracy: 0.9426\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.8686 - val_loss: 0.1966 - val_accuracy: 0.9459\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4463 - accuracy: 0.8743 - val_loss: 0.1936 - val_accuracy: 0.9486\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4414 - accuracy: 0.8749 - val_loss: 0.1860 - val_accuracy: 0.9488\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.8815 - val_loss: 0.1764 - val_accuracy: 0.9523\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4123 - accuracy: 0.8836 - val_loss: 0.1744 - val_accuracy: 0.9535\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3996 - accuracy: 0.8863 - val_loss: 0.1675 - val_accuracy: 0.9532\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3853 - accuracy: 0.8906 - val_loss: 0.1662 - val_accuracy: 0.9544\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3815 - accuracy: 0.8942 - val_loss: 0.1630 - val_accuracy: 0.9557\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3679 - accuracy: 0.8971 - val_loss: 0.1571 - val_accuracy: 0.9567\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3696 - accuracy: 0.8989 - val_loss: 0.1549 - val_accuracy: 0.9589\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.9024 - val_loss: 0.1545 - val_accuracy: 0.9595\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.9031 - val_loss: 0.1502 - val_accuracy: 0.9587\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3421 - accuracy: 0.9012 - val_loss: 0.1468 - val_accuracy: 0.9604\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3311 - accuracy: 0.9054 - val_loss: 0.1438 - val_accuracy: 0.9614\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.9099 - val_loss: 0.1425 - val_accuracy: 0.9629\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3181 - accuracy: 0.9122 - val_loss: 0.1387 - val_accuracy: 0.9630\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3127 - accuracy: 0.9118 - val_loss: 0.1379 - val_accuracy: 0.9635\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2979 - accuracy: 0.9171 - val_loss: 0.1371 - val_accuracy: 0.9634\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2897 - accuracy: 0.9181 - val_loss: 0.1363 - val_accuracy: 0.9643\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2934 - accuracy: 0.9160 - val_loss: 0.1346 - val_accuracy: 0.9650\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.9231 - val_loss: 0.1356 - val_accuracy: 0.9652\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2852 - accuracy: 0.9211 - val_loss: 0.1335 - val_accuracy: 0.9640\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.9243 - val_loss: 0.1319 - val_accuracy: 0.9655\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2845 - accuracy: 0.9195 - val_loss: 0.1277 - val_accuracy: 0.9659\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2650 - accuracy: 0.9253 - val_loss: 0.1294 - val_accuracy: 0.9664\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2650 - accuracy: 0.9239 - val_loss: 0.1260 - val_accuracy: 0.9670\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.0444 - accuracy: 0.2683 - val_loss: 1.0255 - val_accuracy: 0.7761\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3534 - accuracy: 0.5336 - val_loss: 0.6876 - val_accuracy: 0.8432\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1367 - accuracy: 0.6146 - val_loss: 0.5498 - val_accuracy: 0.8670\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0008 - accuracy: 0.6671 - val_loss: 0.4756 - val_accuracy: 0.8829\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9192 - accuracy: 0.6981 - val_loss: 0.4267 - val_accuracy: 0.8924\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8440 - accuracy: 0.7319 - val_loss: 0.3975 - val_accuracy: 0.8973\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8115 - accuracy: 0.7418 - val_loss: 0.3687 - val_accuracy: 0.9027\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7706 - accuracy: 0.7607 - val_loss: 0.3479 - val_accuracy: 0.9068\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7368 - accuracy: 0.7727 - val_loss: 0.3342 - val_accuracy: 0.9065\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7161 - accuracy: 0.7804 - val_loss: 0.3183 - val_accuracy: 0.9109\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6907 - accuracy: 0.7894 - val_loss: 0.3071 - val_accuracy: 0.9133\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6577 - accuracy: 0.8010 - val_loss: 0.2975 - val_accuracy: 0.9158\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6514 - accuracy: 0.8072 - val_loss: 0.2868 - val_accuracy: 0.9187\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6378 - accuracy: 0.8095 - val_loss: 0.2768 - val_accuracy: 0.9206\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6172 - accuracy: 0.8189 - val_loss: 0.2738 - val_accuracy: 0.9217\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6051 - accuracy: 0.8248 - val_loss: 0.2642 - val_accuracy: 0.9255\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5957 - accuracy: 0.8318 - val_loss: 0.2564 - val_accuracy: 0.9260\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5830 - accuracy: 0.8330 - val_loss: 0.2512 - val_accuracy: 0.9298\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5729 - accuracy: 0.8332 - val_loss: 0.2490 - val_accuracy: 0.9308\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5524 - accuracy: 0.8425 - val_loss: 0.2454 - val_accuracy: 0.9301\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5445 - accuracy: 0.8460 - val_loss: 0.2370 - val_accuracy: 0.9337\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5304 - accuracy: 0.8473 - val_loss: 0.2345 - val_accuracy: 0.9334\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5291 - accuracy: 0.8538 - val_loss: 0.2315 - val_accuracy: 0.9336\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5094 - accuracy: 0.8563 - val_loss: 0.2261 - val_accuracy: 0.9367\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4955 - accuracy: 0.8629 - val_loss: 0.2189 - val_accuracy: 0.9377\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4895 - accuracy: 0.8608 - val_loss: 0.2195 - val_accuracy: 0.9376\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4880 - accuracy: 0.8641 - val_loss: 0.2146 - val_accuracy: 0.9389\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4816 - accuracy: 0.8663 - val_loss: 0.2105 - val_accuracy: 0.9399\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4787 - accuracy: 0.8689 - val_loss: 0.2097 - val_accuracy: 0.9415\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4629 - accuracy: 0.8722 - val_loss: 0.2060 - val_accuracy: 0.9426\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4689 - accuracy: 0.8704 - val_loss: 0.2059 - val_accuracy: 0.9417\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4610 - accuracy: 0.8727 - val_loss: 0.2012 - val_accuracy: 0.9445\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4467 - accuracy: 0.8778 - val_loss: 0.1987 - val_accuracy: 0.9438\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4416 - accuracy: 0.8781 - val_loss: 0.1942 - val_accuracy: 0.9465\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4333 - accuracy: 0.8814 - val_loss: 0.1949 - val_accuracy: 0.9460\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4380 - accuracy: 0.8834 - val_loss: 0.1907 - val_accuracy: 0.9464\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4310 - accuracy: 0.8818 - val_loss: 0.1899 - val_accuracy: 0.9472\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4060 - accuracy: 0.8915 - val_loss: 0.1887 - val_accuracy: 0.9477\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4167 - accuracy: 0.8868 - val_loss: 0.1835 - val_accuracy: 0.9496\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3964 - accuracy: 0.8934 - val_loss: 0.1814 - val_accuracy: 0.9498\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4127 - accuracy: 0.8884 - val_loss: 0.1799 - val_accuracy: 0.9505\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4055 - accuracy: 0.8895 - val_loss: 0.1774 - val_accuracy: 0.9507\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4030 - accuracy: 0.8932 - val_loss: 0.1761 - val_accuracy: 0.9502\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3962 - accuracy: 0.8950 - val_loss: 0.1744 - val_accuracy: 0.9516\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3944 - accuracy: 0.8952 - val_loss: 0.1726 - val_accuracy: 0.9523\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3814 - accuracy: 0.8987 - val_loss: 0.1721 - val_accuracy: 0.9520\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3759 - accuracy: 0.8993 - val_loss: 0.1701 - val_accuracy: 0.9528\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8967 - val_loss: 0.1685 - val_accuracy: 0.9534\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3803 - accuracy: 0.8980 - val_loss: 0.1715 - val_accuracy: 0.9528\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3722 - accuracy: 0.9006 - val_loss: 0.1656 - val_accuracy: 0.9543\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 5ms/step - loss: 2.7102 - accuracy: 0.1039 - val_loss: 2.2982 - val_accuracy: 0.2027\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4607 - accuracy: 0.1104 - val_loss: 2.2680 - val_accuracy: 0.1908\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3764 - accuracy: 0.1118 - val_loss: 2.2251 - val_accuracy: 0.1779\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3240 - accuracy: 0.1251 - val_loss: 2.1461 - val_accuracy: 0.1801\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2899 - accuracy: 0.1341 - val_loss: 1.9272 - val_accuracy: 0.2612\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2455 - accuracy: 0.1554 - val_loss: 1.5313 - val_accuracy: 0.4209\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1420 - accuracy: 0.1984 - val_loss: 1.7228 - val_accuracy: 0.4050\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9827 - accuracy: 0.2547 - val_loss: 2.0144 - val_accuracy: 0.4237\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8446 - accuracy: 0.2972 - val_loss: 2.2847 - val_accuracy: 0.4463\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7618 - accuracy: 0.3229 - val_loss: 2.4957 - val_accuracy: 0.4495\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6872 - accuracy: 0.3454 - val_loss: 2.5462 - val_accuracy: 0.4563\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6367 - accuracy: 0.3589 - val_loss: 2.6041 - val_accuracy: 0.4654\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6095 - accuracy: 0.3731 - val_loss: 2.6062 - val_accuracy: 0.4991\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5673 - accuracy: 0.3849 - val_loss: 2.6091 - val_accuracy: 0.4928\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5565 - accuracy: 0.3982 - val_loss: 2.6098 - val_accuracy: 0.4987\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5252 - accuracy: 0.4069 - val_loss: 2.5900 - val_accuracy: 0.5308\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5039 - accuracy: 0.4173 - val_loss: 2.5271 - val_accuracy: 0.5309\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4910 - accuracy: 0.4244 - val_loss: 2.4419 - val_accuracy: 0.5477\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4638 - accuracy: 0.4384 - val_loss: 2.3821 - val_accuracy: 0.5635\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4624 - accuracy: 0.4368 - val_loss: 2.4816 - val_accuracy: 0.5511\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4491 - accuracy: 0.4478 - val_loss: 2.4835 - val_accuracy: 0.5508\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4333 - accuracy: 0.4554 - val_loss: 2.4035 - val_accuracy: 0.5753\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4276 - accuracy: 0.4524 - val_loss: 2.2770 - val_accuracy: 0.5911\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4093 - accuracy: 0.4658 - val_loss: 2.3308 - val_accuracy: 0.5694\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3885 - accuracy: 0.4716 - val_loss: 2.2225 - val_accuracy: 0.5922\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3779 - accuracy: 0.4833 - val_loss: 2.3070 - val_accuracy: 0.5881\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3664 - accuracy: 0.4880 - val_loss: 2.3124 - val_accuracy: 0.5834\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3510 - accuracy: 0.4891 - val_loss: 2.3013 - val_accuracy: 0.5992\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3397 - accuracy: 0.4987 - val_loss: 2.3464 - val_accuracy: 0.5917\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3291 - accuracy: 0.5032 - val_loss: 2.2873 - val_accuracy: 0.6060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3034 - accuracy: 0.5152 - val_loss: 2.2816 - val_accuracy: 0.6010\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2800 - accuracy: 0.5227 - val_loss: 2.2570 - val_accuracy: 0.6083\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2761 - accuracy: 0.5286 - val_loss: 2.3883 - val_accuracy: 0.6203\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2593 - accuracy: 0.5412 - val_loss: 2.2853 - val_accuracy: 0.6320\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2416 - accuracy: 0.5406 - val_loss: 2.2697 - val_accuracy: 0.6301\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2401 - accuracy: 0.5394 - val_loss: 2.4791 - val_accuracy: 0.6043\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2301 - accuracy: 0.5493 - val_loss: 2.4137 - val_accuracy: 0.6250\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2064 - accuracy: 0.5668 - val_loss: 2.4617 - val_accuracy: 0.6243\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1954 - accuracy: 0.5715 - val_loss: 2.5069 - val_accuracy: 0.6334\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1686 - accuracy: 0.5750 - val_loss: 2.4917 - val_accuracy: 0.6250\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1662 - accuracy: 0.5847 - val_loss: 2.6104 - val_accuracy: 0.6266\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1512 - accuracy: 0.5954 - val_loss: 2.6959 - val_accuracy: 0.6382\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1498 - accuracy: 0.5956 - val_loss: 2.6166 - val_accuracy: 0.6453\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1262 - accuracy: 0.6064 - val_loss: 2.5198 - val_accuracy: 0.6621\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1120 - accuracy: 0.6113 - val_loss: 2.6998 - val_accuracy: 0.6686\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0973 - accuracy: 0.6154 - val_loss: 2.7387 - val_accuracy: 0.6696\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0834 - accuracy: 0.6249 - val_loss: 2.7571 - val_accuracy: 0.6568\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0866 - accuracy: 0.6291 - val_loss: 2.8039 - val_accuracy: 0.6664\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0714 - accuracy: 0.6322 - val_loss: 2.6932 - val_accuracy: 0.6663\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0601 - accuracy: 0.6390 - val_loss: 2.7917 - val_accuracy: 0.6571\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.3023 - accuracy: 0.1129 - val_loss: 2.2990 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2979 - accuracy: 0.1258 - val_loss: 2.2942 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2925 - accuracy: 0.1260 - val_loss: 2.2867 - val_accuracy: 0.1093\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2832 - accuracy: 0.1505 - val_loss: 2.2671 - val_accuracy: 0.1942\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2517 - accuracy: 0.2142 - val_loss: 2.1146 - val_accuracy: 0.3032\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1168 - accuracy: 0.2466 - val_loss: 1.8659 - val_accuracy: 0.3896\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9504 - accuracy: 0.2942 - val_loss: 1.6194 - val_accuracy: 0.5260\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7976 - accuracy: 0.3565 - val_loss: 1.4163 - val_accuracy: 0.6258\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6463 - accuracy: 0.4216 - val_loss: 1.2335 - val_accuracy: 0.6752\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5270 - accuracy: 0.4694 - val_loss: 1.0672 - val_accuracy: 0.7014\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3986 - accuracy: 0.5208 - val_loss: 0.9328 - val_accuracy: 0.7312\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2955 - accuracy: 0.5492 - val_loss: 0.8237 - val_accuracy: 0.7603\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2031 - accuracy: 0.5862 - val_loss: 0.7402 - val_accuracy: 0.7884\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1348 - accuracy: 0.6121 - val_loss: 0.6697 - val_accuracy: 0.8052\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0694 - accuracy: 0.6361 - val_loss: 0.6113 - val_accuracy: 0.8136\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0167 - accuracy: 0.6548 - val_loss: 0.5739 - val_accuracy: 0.8256\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9794 - accuracy: 0.6688 - val_loss: 0.5445 - val_accuracy: 0.8284\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9408 - accuracy: 0.6820 - val_loss: 0.5135 - val_accuracy: 0.8374\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9027 - accuracy: 0.7018 - val_loss: 0.4940 - val_accuracy: 0.8482\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8927 - accuracy: 0.7056 - val_loss: 0.4742 - val_accuracy: 0.8518\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8640 - accuracy: 0.7143 - val_loss: 0.4557 - val_accuracy: 0.8643\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8357 - accuracy: 0.7274 - val_loss: 0.4371 - val_accuracy: 0.8705\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8158 - accuracy: 0.7346 - val_loss: 0.4245 - val_accuracy: 0.8768\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7997 - accuracy: 0.7442 - val_loss: 0.4097 - val_accuracy: 0.8813\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7690 - accuracy: 0.7495 - val_loss: 0.3924 - val_accuracy: 0.8893\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7589 - accuracy: 0.7576 - val_loss: 0.3778 - val_accuracy: 0.8942\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7316 - accuracy: 0.7670 - val_loss: 0.3644 - val_accuracy: 0.8995\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7257 - accuracy: 0.7749 - val_loss: 0.3494 - val_accuracy: 0.9066\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7130 - accuracy: 0.7789 - val_loss: 0.3372 - val_accuracy: 0.9102\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6887 - accuracy: 0.7873 - val_loss: 0.3234 - val_accuracy: 0.9146\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6836 - accuracy: 0.7887 - val_loss: 0.3119 - val_accuracy: 0.9204\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6612 - accuracy: 0.7972 - val_loss: 0.2970 - val_accuracy: 0.9255\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6522 - accuracy: 0.7975 - val_loss: 0.2874 - val_accuracy: 0.9263\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6499 - accuracy: 0.7998 - val_loss: 0.2782 - val_accuracy: 0.9282\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6377 - accuracy: 0.8063 - val_loss: 0.2704 - val_accuracy: 0.9332\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6240 - accuracy: 0.8159 - val_loss: 0.2602 - val_accuracy: 0.9350\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6086 - accuracy: 0.8160 - val_loss: 0.2515 - val_accuracy: 0.9382\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5968 - accuracy: 0.8201 - val_loss: 0.2488 - val_accuracy: 0.9383\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5778 - accuracy: 0.8295 - val_loss: 0.2393 - val_accuracy: 0.9403\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5788 - accuracy: 0.8248 - val_loss: 0.2360 - val_accuracy: 0.9409\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.8266 - val_loss: 0.2291 - val_accuracy: 0.9420\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5591 - accuracy: 0.8294 - val_loss: 0.2257 - val_accuracy: 0.9437\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5598 - accuracy: 0.8356 - val_loss: 0.2181 - val_accuracy: 0.9442\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5462 - accuracy: 0.8331 - val_loss: 0.2150 - val_accuracy: 0.9473\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5390 - accuracy: 0.8379 - val_loss: 0.2113 - val_accuracy: 0.9472\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5257 - accuracy: 0.8416 - val_loss: 0.2089 - val_accuracy: 0.9488\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5161 - accuracy: 0.8441 - val_loss: 0.2041 - val_accuracy: 0.9498\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5143 - accuracy: 0.8479 - val_loss: 0.1997 - val_accuracy: 0.9502\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5100 - accuracy: 0.8445 - val_loss: 0.1970 - val_accuracy: 0.9506\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4991 - accuracy: 0.8536 - val_loss: 0.1991 - val_accuracy: 0.9505\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.3019 - accuracy: 0.1174 - val_loss: 2.2987 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2972 - accuracy: 0.1310 - val_loss: 2.2944 - val_accuracy: 0.1061\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2925 - accuracy: 0.1314 - val_loss: 2.2885 - val_accuracy: 0.1203\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2863 - accuracy: 0.1444 - val_loss: 2.2781 - val_accuracy: 0.1773\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2736 - accuracy: 0.1778 - val_loss: 2.2508 - val_accuracy: 0.2088\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2350 - accuracy: 0.2134 - val_loss: 2.1281 - val_accuracy: 0.2348\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1226 - accuracy: 0.2437 - val_loss: 1.9381 - val_accuracy: 0.3005\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.9793 - accuracy: 0.2933 - val_loss: 1.7351 - val_accuracy: 0.3796\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8453 - accuracy: 0.3407 - val_loss: 1.6075 - val_accuracy: 0.4389\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7549 - accuracy: 0.3735 - val_loss: 1.5011 - val_accuracy: 0.4988\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6606 - accuracy: 0.4236 - val_loss: 1.3854 - val_accuracy: 0.5587\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5683 - accuracy: 0.4586 - val_loss: 1.2638 - val_accuracy: 0.6164\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4797 - accuracy: 0.4956 - val_loss: 1.1337 - val_accuracy: 0.6633\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3732 - accuracy: 0.5325 - val_loss: 1.0273 - val_accuracy: 0.6971\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2876 - accuracy: 0.5595 - val_loss: 0.9376 - val_accuracy: 0.7181\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2128 - accuracy: 0.5836 - val_loss: 0.8658 - val_accuracy: 0.7545\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1528 - accuracy: 0.6077 - val_loss: 0.7998 - val_accuracy: 0.7763\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1055 - accuracy: 0.6281 - val_loss: 0.7462 - val_accuracy: 0.8009\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0515 - accuracy: 0.6517 - val_loss: 0.7010 - val_accuracy: 0.8192\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0121 - accuracy: 0.6669 - val_loss: 0.6656 - val_accuracy: 0.8339\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9869 - accuracy: 0.6824 - val_loss: 0.6313 - val_accuracy: 0.8430\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9530 - accuracy: 0.6938 - val_loss: 0.6045 - val_accuracy: 0.8564\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9326 - accuracy: 0.7088 - val_loss: 0.5743 - val_accuracy: 0.8634\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8995 - accuracy: 0.7184 - val_loss: 0.5541 - val_accuracy: 0.8659\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8804 - accuracy: 0.7253 - val_loss: 0.5356 - val_accuracy: 0.8728\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8586 - accuracy: 0.7326 - val_loss: 0.5192 - val_accuracy: 0.8763\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8356 - accuracy: 0.7377 - val_loss: 0.5017 - val_accuracy: 0.8821\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8175 - accuracy: 0.7453 - val_loss: 0.4847 - val_accuracy: 0.8863\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8066 - accuracy: 0.7561 - val_loss: 0.4707 - val_accuracy: 0.8897\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7921 - accuracy: 0.7562 - val_loss: 0.4552 - val_accuracy: 0.8923\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7525 - accuracy: 0.7719 - val_loss: 0.4428 - val_accuracy: 0.8950\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7491 - accuracy: 0.7720 - val_loss: 0.4317 - val_accuracy: 0.8970\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7355 - accuracy: 0.7752 - val_loss: 0.4209 - val_accuracy: 0.8998\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7209 - accuracy: 0.7839 - val_loss: 0.4100 - val_accuracy: 0.9028\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7209 - accuracy: 0.7849 - val_loss: 0.3982 - val_accuracy: 0.9045\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7080 - accuracy: 0.7865 - val_loss: 0.3889 - val_accuracy: 0.9075\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6851 - accuracy: 0.7936 - val_loss: 0.3806 - val_accuracy: 0.9076\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6702 - accuracy: 0.8006 - val_loss: 0.3718 - val_accuracy: 0.9110\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6781 - accuracy: 0.7929 - val_loss: 0.3650 - val_accuracy: 0.9133\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6552 - accuracy: 0.8027 - val_loss: 0.3537 - val_accuracy: 0.9165\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6483 - accuracy: 0.8072 - val_loss: 0.3481 - val_accuracy: 0.9162\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6405 - accuracy: 0.8117 - val_loss: 0.3372 - val_accuracy: 0.9202\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6241 - accuracy: 0.8191 - val_loss: 0.3308 - val_accuracy: 0.9213\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6223 - accuracy: 0.8156 - val_loss: 0.3229 - val_accuracy: 0.9230\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5954 - accuracy: 0.8243 - val_loss: 0.3146 - val_accuracy: 0.9253\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6006 - accuracy: 0.8247 - val_loss: 0.3111 - val_accuracy: 0.9260\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5823 - accuracy: 0.8279 - val_loss: 0.3062 - val_accuracy: 0.9278\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5835 - accuracy: 0.8274 - val_loss: 0.3001 - val_accuracy: 0.9284\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5733 - accuracy: 0.8337 - val_loss: 0.2938 - val_accuracy: 0.9303\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5643 - accuracy: 0.8341 - val_loss: 0.2876 - val_accuracy: 0.9307\n",
      "{'loss': [2.4552712440490723, 2.377751350402832, 2.354545831680298, 2.338608980178833, 2.333590269088745, 2.3275861740112305, 2.3228135108947754, 2.32083797454834, 2.316973924636841, 2.3137569427490234, 2.3133654594421387, 2.3110897541046143, 2.3119447231292725, 2.3086295127868652, 2.308899164199829, 2.3083858489990234, 2.3075246810913086, 2.3071980476379395, 2.3068125247955322, 2.305954933166504, 2.305030345916748, 2.3056704998016357, 2.3050284385681152, 2.304983377456665, 2.304659843444824, 2.3045997619628906, 2.3055193424224854, 2.3036704063415527, 2.30472469329834, 2.3042097091674805, 2.303597927093506, 2.303495407104492, 2.3040542602539062, 2.302673816680908, 2.303070545196533, 2.3033525943756104, 2.3029439449310303, 2.3033766746520996, 2.30307936668396, 2.302842855453491, 2.303269386291504, 2.302830457687378, 2.302966833114624, 2.302582263946533, 2.3029141426086426, 2.30204176902771, 2.3027453422546387, 2.3027377128601074, 2.302717685699463, 2.302300214767456], 'accuracy': [0.09987500309944153, 0.10052083432674408, 0.10116666555404663, 0.10464583337306976, 0.10125000029802322, 0.1027916669845581, 0.10147916525602341, 0.10256250202655792, 0.1027708351612091, 0.10258333384990692, 0.10235416889190674, 0.10502083599567413, 0.10193750262260437, 0.10585416853427887, 0.10593750327825546, 0.10750000178813934, 0.10527083277702332, 0.10656250268220901, 0.10572917014360428, 0.1080624982714653, 0.10662499815225601, 0.10664582997560501, 0.10772916674613953, 0.10693749785423279, 0.10897916555404663, 0.10929166525602341, 0.10697916895151138, 0.10750000178813934, 0.1068124994635582, 0.10585416853427887, 0.10743749886751175, 0.1106458306312561, 0.10697916895151138, 0.11018750071525574, 0.10956250131130219, 0.10922916978597641, 0.10895833373069763, 0.10993749648332596, 0.10897916555404663, 0.10960416495800018, 0.10852083563804626, 0.11122916638851166, 0.1106041669845581, 0.10987500101327896, 0.10927083343267441, 0.11143749952316284, 0.109354168176651, 0.11135416477918625, 0.11183333396911621, 0.11087500303983688], 'val_loss': [2.3038041591644287, 2.302002429962158, 2.3019816875457764, 2.3019843101501465, 2.301863670349121, 2.3019392490386963, 2.3019518852233887, 2.302011013031006, 2.3020529747009277, 2.3020334243774414, 2.302006244659424, 2.302030563354492, 2.302030086517334, 2.302053451538086, 2.302042245864868, 2.3020739555358887, 2.302090883255005, 2.3020823001861572, 2.3021230697631836, 2.3020737171173096, 2.302072525024414, 2.302048921585083, 2.3020591735839844, 2.302050828933716, 2.3020243644714355, 2.3020312786102295, 2.3020644187927246, 2.3020691871643066, 2.302088499069214, 2.3020870685577393, 2.302060604095459, 2.3020358085632324, 2.3020498752593994, 2.3020458221435547, 2.3020334243774414, 2.3020436763763428, 2.302058219909668, 2.3020620346069336, 2.3020570278167725, 2.3020594120025635, 2.3020713329315186, 2.3020846843719482, 2.302077531814575, 2.3020784854888916, 2.3020615577697754, 2.302060604095459, 2.302042245864868, 2.302056074142456, 2.302055835723877, 2.3020429611206055], 'val_accuracy': [0.09950000047683716, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [1.7763484716415405, 1.3184309005737305, 1.1398706436157227, 1.023374080657959, 0.9477788805961609, 0.8905115723609924, 0.8441676497459412, 0.8074955344200134, 0.7740625739097595, 0.7463091611862183, 0.7273861765861511, 0.7101669311523438, 0.6906905770301819, 0.6685678958892822, 0.653333306312561, 0.6417546272277832, 0.6299746036529541, 0.6164505481719971, 0.605421245098114, 0.5934572219848633, 0.5838640332221985, 0.5732977986335754, 0.5655205845832825, 0.5620558857917786, 0.5460085868835449, 0.5481518507003784, 0.533623456954956, 0.5305092930793762, 0.519936740398407, 0.5178589224815369, 0.5061941742897034, 0.5025216341018677, 0.4956023693084717, 0.4954448938369751, 0.48974189162254333, 0.48275619745254517, 0.4764997959136963, 0.4734075665473938, 0.470916211605072, 0.4623010754585266, 0.459888756275177, 0.4532662034034729, 0.44980913400650024, 0.4480213522911072, 0.4441881477832794, 0.4386427104473114, 0.43546855449676514, 0.43084245920181274, 0.4324248731136322, 0.43166327476501465], 'accuracy': [0.382750004529953, 0.5678125023841858, 0.6379166841506958, 0.6803333163261414, 0.7086874842643738, 0.7252083420753479, 0.745145857334137, 0.7583333253860474, 0.7692499756813049, 0.7788125276565552, 0.7870625257492065, 0.793708324432373, 0.800083339214325, 0.807854175567627, 0.8144999742507935, 0.8181458115577698, 0.8215416669845581, 0.8273125290870667, 0.8350625038146973, 0.8375625014305115, 0.8420624732971191, 0.844124972820282, 0.8464999794960022, 0.8481666445732117, 0.8525000214576721, 0.8538541793823242, 0.8577708601951599, 0.8586458563804626, 0.8616041541099548, 0.8618124723434448, 0.867104172706604, 0.8658124804496765, 0.8696666955947876, 0.8711041808128357, 0.8734583258628845, 0.8743125200271606, 0.8763958215713501, 0.874750018119812, 0.8775208592414856, 0.8799583315849304, 0.8804374933242798, 0.8833541870117188, 0.8817499876022339, 0.8852291703224182, 0.8852083086967468, 0.8869166374206543, 0.8878333568572998, 0.8899375200271606, 0.8889166712760925, 0.890583336353302], 'val_loss': [1.10145902633667, 0.8103588223457336, 0.6596038937568665, 0.5660228729248047, 0.5046409964561462, 0.46236395835876465, 0.42797186970710754, 0.40399259328842163, 0.3862837851047516, 0.3706933259963989, 0.3577585518360138, 0.3460521697998047, 0.3367789387702942, 0.32977959513664246, 0.32251664996147156, 0.31507211923599243, 0.30906182527542114, 0.3034810423851013, 0.29931825399398804, 0.29351603984832764, 0.2953735589981079, 0.2860189974308014, 0.2830488085746765, 0.2780357897281647, 0.2766284644603729, 0.2728178799152374, 0.27206283807754517, 0.26783180236816406, 0.2643851637840271, 0.26167529821395874, 0.2637910842895508, 0.2571342885494232, 0.25638169050216675, 0.2554601728916168, 0.25006574392318726, 0.24919405579566956, 0.2460712492465973, 0.2451210916042328, 0.24297672510147095, 0.24060127139091492, 0.241567000746727, 0.23721753060817719, 0.23345734179019928, 0.229765847325325, 0.2294258028268814, 0.2263391762971878, 0.226854607462883, 0.2252456396818161, 0.2226743996143341, 0.2215294986963272], 'val_accuracy': [0.7665833234786987, 0.8369166851043701, 0.8572499752044678, 0.8703333139419556, 0.8794166445732117, 0.8860833048820496, 0.8900833129882812, 0.8933333158493042, 0.8942499756813049, 0.8980000019073486, 0.9019166827201843, 0.9041666388511658, 0.906166672706604, 0.9084166884422302, 0.9111666679382324, 0.9131666421890259, 0.9146666526794434, 0.9169999957084656, 0.9181666374206543, 0.9199166893959045, 0.9193333387374878, 0.92208331823349, 0.9234166741371155, 0.924833357334137, 0.9259999990463257, 0.9269999861717224, 0.9279999732971191, 0.9291666746139526, 0.9304166436195374, 0.9309166669845581, 0.9315000176429749, 0.9326666593551636, 0.9333333373069763, 0.9335833191871643, 0.9351666569709778, 0.9363333582878113, 0.9358333349227905, 0.9379166960716248, 0.9388333559036255, 0.9394166469573975, 0.9380833506584167, 0.9395833611488342, 0.9403333067893982, 0.9425833225250244, 0.9424166679382324, 0.9434166550636292, 0.9433333277702332, 0.9436666369438171, 0.9444166421890259, 0.9455000162124634]}\n",
      "{'loss': [2.284996747970581, 2.1994552612304688, 2.0586371421813965, 1.9138528108596802, 1.7728334665298462, 1.6478725671768188, 1.5371997356414795, 1.4413033723831177, 1.3621132373809814, 1.2916347980499268, 1.2305996417999268, 1.1765910387039185, 1.1298327445983887, 1.077697515487671, 1.0447179079055786, 1.0018709897994995, 0.970170795917511, 0.9246600866317749, 0.905076265335083, 0.8729697465896606, 0.8386198878288269, 0.820127546787262, 0.7928571105003357, 0.7725210785865784, 0.7453691363334656, 0.7242223024368286, 0.706183671951294, 0.6867382526397705, 0.6743186712265015, 0.6566059589385986, 0.6475415229797363, 0.6324431300163269, 0.6135995984077454, 0.6096561551094055, 0.5905407071113586, 0.5787652730941772, 0.5643641352653503, 0.5502766966819763, 0.5413923859596252, 0.5363380312919617, 0.5201987028121948, 0.5190215110778809, 0.5012767314910889, 0.4987012445926666, 0.4954550862312317, 0.48179346323013306, 0.4787657558917999, 0.47397154569625854, 0.4606129825115204, 0.4629683792591095], 'accuracy': [0.12858332693576813, 0.19300000369548798, 0.2461041659116745, 0.29902082681655884, 0.34941667318344116, 0.39747917652130127, 0.43427082896232605, 0.4622708261013031, 0.492145836353302, 0.5250833630561829, 0.5527499914169312, 0.5769374966621399, 0.5935208201408386, 0.6183958053588867, 0.6336874961853027, 0.6506041884422302, 0.663729190826416, 0.6818958520889282, 0.6886875033378601, 0.7005833387374878, 0.7120624780654907, 0.7199375033378601, 0.7308541536331177, 0.742312490940094, 0.7514166831970215, 0.7602083086967468, 0.7655624747276306, 0.773354172706604, 0.7791875004768372, 0.7862083315849304, 0.7927916646003723, 0.7990000247955322, 0.8048750162124634, 0.8085833191871643, 0.815458357334137, 0.817062497138977, 0.8225625157356262, 0.8286041617393494, 0.8319583535194397, 0.8341041803359985, 0.8369791507720947, 0.8374166488647461, 0.8439375162124634, 0.8448125123977661, 0.8471249938011169, 0.8503749966621399, 0.8494166731834412, 0.8541666865348816, 0.8566458225250244, 0.8551874756813049], 'val_loss': [2.220238208770752, 2.022268533706665, 1.7905237674713135, 1.5869613885879517, 1.3957064151763916, 1.2673412561416626, 1.153719186782837, 1.051504135131836, 0.9723065495491028, 0.9015417695045471, 0.8214045166969299, 0.7523170709609985, 0.6923213601112366, 0.6448695659637451, 0.5965310335159302, 0.5564019680023193, 0.530672550201416, 0.49425169825553894, 0.4667322635650635, 0.44161954522132874, 0.41889533400535583, 0.3903876543045044, 0.3716580271720886, 0.3508642911911011, 0.3360043168067932, 0.31773412227630615, 0.3015799820423126, 0.28626516461372375, 0.27481934428215027, 0.2646818161010742, 0.252655565738678, 0.2400471568107605, 0.22979268431663513, 0.2262086719274521, 0.2185850292444229, 0.21649165451526642, 0.21235528588294983, 0.1979915350675583, 0.1949375420808792, 0.19637778401374817, 0.19280388951301575, 0.17757461965084076, 0.17815189063549042, 0.1742122769355774, 0.16791360080242157, 0.17033222317695618, 0.16579166054725647, 0.16781267523765564, 0.16491979360580444, 0.1594521552324295], 'val_accuracy': [0.265583336353302, 0.4216666519641876, 0.4646666646003723, 0.5427500009536743, 0.5494999885559082, 0.5881666541099548, 0.6190833449363708, 0.6629999876022339, 0.7012500166893005, 0.73458331823349, 0.768666684627533, 0.7992500066757202, 0.8198333382606506, 0.8189166784286499, 0.8423333168029785, 0.844083309173584, 0.8511666655540466, 0.8601666688919067, 0.8653333187103271, 0.8712499737739563, 0.8740833401679993, 0.878000020980835, 0.8949166536331177, 0.8917499780654907, 0.9001666903495789, 0.9161666631698608, 0.9289166927337646, 0.9282500147819519, 0.9340000152587891, 0.9465000033378601, 0.9432500004768372, 0.9510833621025085, 0.9518333077430725, 0.9522500038146973, 0.9536666870117188, 0.9555000066757202, 0.9565833210945129, 0.9592499732971191, 0.9599999785423279, 0.9609166383743286, 0.9601666927337646, 0.9627500176429749, 0.9643333554267883, 0.9639999866485596, 0.9640833139419556, 0.9648333191871643, 0.965583324432373, 0.965666651725769, 0.9674999713897705, 0.9665833115577698]}\n",
      "{'loss': [2.2878754138946533, 2.1552281379699707, 1.844133973121643, 1.5890281200408936, 1.4121215343475342, 1.283984899520874, 1.1825088262557983, 1.0913608074188232, 1.0015941858291626, 0.9285265207290649, 0.8556140661239624, 0.8094077110290527, 0.7533583045005798, 0.7187930345535278, 0.6833350658416748, 0.6499255299568176, 0.6194008588790894, 0.5950700044631958, 0.5687389373779297, 0.5495397448539734, 0.5167456865310669, 0.5073140263557434, 0.4879071116447449, 0.47677701711654663, 0.45584484934806824, 0.44497358798980713, 0.4343808889389038, 0.42121216654777527, 0.40705931186676025, 0.3942089378833771, 0.3862017095088959, 0.37496182322502136, 0.36945149302482605, 0.362985759973526, 0.3485943078994751, 0.3436001241207123, 0.33515313267707825, 0.3261401057243347, 0.32471218705177307, 0.3162904977798462, 0.31110647320747375, 0.3001132607460022, 0.2959052622318268, 0.2933647930622101, 0.28447994589805603, 0.28145402669906616, 0.28063613176345825, 0.27686625719070435, 0.26874732971191406, 0.2646966874599457], 'accuracy': [0.13827084004878998, 0.226645827293396, 0.3329375088214874, 0.4167291522026062, 0.4793125092983246, 0.5286458134651184, 0.5726458430290222, 0.6187083125114441, 0.6601458191871643, 0.6925625205039978, 0.7234583497047424, 0.7409166693687439, 0.762708306312561, 0.7793333530426025, 0.7905625104904175, 0.8034166693687439, 0.8145833611488342, 0.8228541612625122, 0.8335208296775818, 0.8392500281333923, 0.8500624895095825, 0.8542291522026062, 0.8590624928474426, 0.8644583225250244, 0.8697291612625122, 0.8752708435058594, 0.8766458630561829, 0.8809999823570251, 0.8849166631698608, 0.8886666893959045, 0.8914583325386047, 0.8945624828338623, 0.8970208168029785, 0.8989375233650208, 0.9011250138282776, 0.9040833115577698, 0.9038333296775818, 0.9082083106040955, 0.9098125100135803, 0.9115833044052124, 0.9130208492279053, 0.9165208339691162, 0.9176250100135803, 0.9168124794960022, 0.9203125238418579, 0.9205625057220459, 0.9230833053588867, 0.921833336353302, 0.9247291684150696, 0.9258541464805603], 'val_loss': [2.2327771186828613, 1.8632606267929077, 1.4214309453964233, 1.1832207441329956, 1.041357398033142, 0.9299135804176331, 0.8199710249900818, 0.6990278959274292, 0.5980480909347534, 0.5267485976219177, 0.46601325273513794, 0.4241480231285095, 0.39029473066329956, 0.35650435090065, 0.3297029137611389, 0.3069332540035248, 0.2883976399898529, 0.273657888174057, 0.2569555640220642, 0.24620544910430908, 0.2311468869447708, 0.22171777486801147, 0.2112935334444046, 0.20782552659511566, 0.19656704366207123, 0.1936122179031372, 0.1859685629606247, 0.17644444108009338, 0.17439331114292145, 0.1674889475107193, 0.16616162657737732, 0.16299590468406677, 0.15714439749717712, 0.15491361916065216, 0.1544617861509323, 0.15024176239967346, 0.14675819873809814, 0.1437903195619583, 0.14249981939792633, 0.13868550956249237, 0.1378881186246872, 0.1370859444141388, 0.1363063007593155, 0.13457044959068298, 0.13564760982990265, 0.13345955312252045, 0.13192668557167053, 0.12774629890918732, 0.12941600382328033, 0.126047745347023], 'val_accuracy': [0.34566667675971985, 0.4581666588783264, 0.5534999966621399, 0.6145833134651184, 0.7049166560173035, 0.7333333492279053, 0.7790833115577698, 0.8241666555404663, 0.8449166417121887, 0.8690833449363708, 0.8847500085830688, 0.8955000042915344, 0.9043333530426025, 0.9132500290870667, 0.9163333177566528, 0.9226666688919067, 0.9269999861717224, 0.9309166669845581, 0.9340833425521851, 0.9338333606719971, 0.9394999742507935, 0.9403333067893982, 0.9425833225250244, 0.9425833225250244, 0.9459166526794434, 0.9485833048820496, 0.9488333463668823, 0.9523333311080933, 0.953499972820282, 0.953166663646698, 0.9544166922569275, 0.9557499885559082, 0.9567499756813049, 0.9589166641235352, 0.9595000147819519, 0.9586666822433472, 0.9604166746139526, 0.9614166617393494, 0.9629166722297668, 0.9629999995231628, 0.9635000228881836, 0.9634166955947876, 0.9643333554267883, 0.9649999737739563, 0.9651666879653931, 0.9639999866485596, 0.965499997138977, 0.9659166932106018, 0.9664166569709778, 0.9670000076293945]}\n",
      "{'loss': [1.7949204444885254, 1.2882540225982666, 1.0971717834472656, 0.9794802069664001, 0.9020864367485046, 0.8403223752975464, 0.8039490580558777, 0.7647174596786499, 0.7329593896865845, 0.7115104794502258, 0.6869924068450928, 0.6625503897666931, 0.6493184566497803, 0.6298269629478455, 0.6173030734062195, 0.6041431427001953, 0.5811632871627808, 0.5778276920318604, 0.5661756992340088, 0.5510788559913635, 0.5482305288314819, 0.5271556377410889, 0.525292158126831, 0.5154345035552979, 0.5011316537857056, 0.49283984303474426, 0.48911547660827637, 0.4830264151096344, 0.47912919521331787, 0.4626363515853882, 0.4606349766254425, 0.45624682307243347, 0.4470979869365692, 0.438932865858078, 0.42988723516464233, 0.43305152654647827, 0.42500680685043335, 0.4181957542896271, 0.4167094826698303, 0.4090936779975891, 0.4129750430583954, 0.40776321291923523, 0.40160641074180603, 0.39267778396606445, 0.3945517838001251, 0.380189448595047, 0.3801611661911011, 0.37817642092704773, 0.37536540627479553, 0.37213337421417236], 'accuracy': [0.36937499046325684, 0.5587916374206543, 0.6301875114440918, 0.6767916679382324, 0.7041249871253967, 0.7331041693687439, 0.7448541522026062, 0.7623124718666077, 0.7741666436195374, 0.7824583053588867, 0.7919999957084656, 0.8009583353996277, 0.807604193687439, 0.8128958344459534, 0.8183958530426025, 0.8257291913032532, 0.8333125114440918, 0.8341041803359985, 0.835604190826416, 0.8419791460037231, 0.8442708253860474, 0.8499791622161865, 0.8530416488647461, 0.8556041717529297, 0.8612291812896729, 0.8608541488647461, 0.8638333082199097, 0.8664166927337646, 0.8683750033378601, 0.8722291588783264, 0.8730208277702332, 0.8738124966621399, 0.878166675567627, 0.8796666860580444, 0.8818125128746033, 0.8836666941642761, 0.8845416903495789, 0.8880000114440918, 0.8866666555404663, 0.8898749947547913, 0.8885416388511658, 0.8892916440963745, 0.8941249847412109, 0.8970833420753479, 0.895104169845581, 0.8972291946411133, 0.8988541960716248, 0.8973333239555359, 0.8996041417121887, 0.9006875157356262], 'val_loss': [1.0254700183868408, 0.6876040101051331, 0.5498213171958923, 0.4756086766719818, 0.4267275035381317, 0.3974533975124359, 0.36866897344589233, 0.3479234278202057, 0.33416256308555603, 0.31828224658966064, 0.3071175515651703, 0.29746121168136597, 0.28681546449661255, 0.2767593264579773, 0.2737623453140259, 0.2641853988170624, 0.25642815232276917, 0.25124379992485046, 0.24900828301906586, 0.24536415934562683, 0.23696686327457428, 0.23450234532356262, 0.23150034248828888, 0.22607716917991638, 0.2188778519630432, 0.21954157948493958, 0.2146340161561966, 0.21054328978061676, 0.20970633625984192, 0.2060428112745285, 0.205868199467659, 0.20124483108520508, 0.1987486630678177, 0.19422706961631775, 0.1948905885219574, 0.19074545800685883, 0.18986055254936218, 0.1887245625257492, 0.18350747227668762, 0.18139855563640594, 0.17985257506370544, 0.17736287415027618, 0.17610947787761688, 0.17442232370376587, 0.1726176142692566, 0.172115296125412, 0.17010298371315002, 0.16852541267871857, 0.17150425910949707, 0.1655997782945633], 'val_accuracy': [0.7760833501815796, 0.8432499766349792, 0.8669999837875366, 0.8829166889190674, 0.8924166560173035, 0.8973333239555359, 0.9026666879653931, 0.9068333506584167, 0.906499981880188, 0.9109166860580444, 0.9132500290870667, 0.9157500267028809, 0.918666660785675, 0.9205833077430725, 0.92166668176651, 0.9254999756813049, 0.9259999990463257, 0.9298333525657654, 0.9307500123977661, 0.9300833344459534, 0.9337499737739563, 0.9334166646003723, 0.9335833191871643, 0.9367499947547913, 0.937666654586792, 0.937583327293396, 0.9389166831970215, 0.9399166703224182, 0.9415000081062317, 0.9425833225250244, 0.9417499899864197, 0.9445000290870667, 0.9438333511352539, 0.9465000033378601, 0.9459999799728394, 0.9464166760444641, 0.9471666812896729, 0.9476666450500488, 0.9495833516120911, 0.949833333492279, 0.9505000114440918, 0.9506666660308838, 0.950166642665863, 0.9515833258628845, 0.9522500038146973, 0.9520000219345093, 0.952750027179718, 0.953416645526886, 0.952750027179718, 0.9543333053588867]}\n",
      "{'loss': [2.635934829711914, 2.43802809715271, 2.362800359725952, 2.315422773361206, 2.2823703289031982, 2.2255356311798096, 2.102160930633545, 1.945828914642334, 1.8182421922683716, 1.7401028871536255, 1.6755746603012085, 1.6262081861495972, 1.5945732593536377, 1.5651954412460327, 1.5480022430419922, 1.5188027620315552, 1.5095654726028442, 1.4891666173934937, 1.4702410697937012, 1.4598289728164673, 1.4448696374893188, 1.428676962852478, 1.4217686653137207, 1.400547981262207, 1.3872836828231812, 1.370821475982666, 1.3591229915618896, 1.3419997692108154, 1.3304580450057983, 1.3180915117263794, 1.3015711307525635, 1.2862331867218018, 1.2726057767868042, 1.2585259675979614, 1.2415298223495483, 1.2314237356185913, 1.21998131275177, 1.2061423063278198, 1.1933845281600952, 1.1718659400939941, 1.1624552011489868, 1.1503163576126099, 1.1420565843582153, 1.1288635730743408, 1.1107628345489502, 1.1035809516906738, 1.0918031930923462, 1.0781643390655518, 1.0710664987564087, 1.0618692636489868], 'accuracy': [0.10520832985639572, 0.10993749648332596, 0.11339583247900009, 0.12716667354106903, 0.13879166543483734, 0.1655624955892563, 0.21329165995121002, 0.2643333375453949, 0.3049166798591614, 0.32858332991600037, 0.34827083349227905, 0.3636458218097687, 0.3775624930858612, 0.3903333246707916, 0.40312498807907104, 0.4097708463668823, 0.4181458353996277, 0.4268958270549774, 0.4361875057220459, 0.4398333430290222, 0.4488541781902313, 0.4567083418369293, 0.4584999978542328, 0.46777084469795227, 0.4735833406448364, 0.4854791760444641, 0.49037501215934753, 0.4933750033378601, 0.5010625123977661, 0.5083958506584167, 0.515291690826416, 0.5205833315849304, 0.5300208330154419, 0.539020836353302, 0.5420833230018616, 0.5459583401679993, 0.5523124933242798, 0.5629166960716248, 0.5726875066757202, 0.5790416598320007, 0.585604190826416, 0.5930416584014893, 0.5979791879653931, 0.606291651725769, 0.6158333420753479, 0.6182083487510681, 0.6259791851043701, 0.6307291388511658, 0.6322916746139526, 0.6400416493415833], 'val_loss': [2.2981693744659424, 2.2679686546325684, 2.225083827972412, 2.1461455821990967, 1.9272361993789673, 1.5312923192977905, 1.7227903604507446, 2.0143942832946777, 2.2847347259521484, 2.495650291442871, 2.5461642742156982, 2.6041159629821777, 2.6061856746673584, 2.6091389656066895, 2.6097607612609863, 2.590015172958374, 2.527125835418701, 2.441866874694824, 2.382103681564331, 2.4815587997436523, 2.483513593673706, 2.4034605026245117, 2.2770018577575684, 2.3307952880859375, 2.2225215435028076, 2.3069770336151123, 2.3123791217803955, 2.301300525665283, 2.346360445022583, 2.287278890609741, 2.2815918922424316, 2.257005453109741, 2.38834547996521, 2.2852768898010254, 2.269717216491699, 2.4790730476379395, 2.413728713989258, 2.461655378341675, 2.5069191455841064, 2.4916508197784424, 2.6104111671447754, 2.695937395095825, 2.6165733337402344, 2.5197813510894775, 2.699763774871826, 2.7387373447418213, 2.7571280002593994, 2.8038814067840576, 2.6931960582733154, 2.7917087078094482], 'val_accuracy': [0.20274999737739563, 0.19075000286102295, 0.17791666090488434, 0.18008333444595337, 0.26124998927116394, 0.42091667652130127, 0.4050000011920929, 0.42366665601730347, 0.4463333189487457, 0.4494999945163727, 0.45625001192092896, 0.46541666984558105, 0.49908334016799927, 0.49283334612846375, 0.4986666738986969, 0.5308333039283752, 0.530916690826416, 0.5476666688919067, 0.5634999871253967, 0.5510833263397217, 0.5508333444595337, 0.5752500295639038, 0.5910833477973938, 0.5694166421890259, 0.5922499895095825, 0.5880833268165588, 0.5834166407585144, 0.5991666913032532, 0.5916666388511658, 0.6060000061988831, 0.6010000109672546, 0.6082500219345093, 0.6203333139419556, 0.6320000290870667, 0.6300833225250244, 0.6042500138282776, 0.625, 0.6243333220481873, 0.6334166526794434, 0.625, 0.6265833377838135, 0.6382499933242798, 0.6452500224113464, 0.6620833277702332, 0.668583333492279, 0.6695833206176758, 0.6568333506584167, 0.6664166450500488, 0.6663333177566528, 0.6570833325386047]}\n",
      "{'loss': [2.3011059761047363, 2.2966675758361816, 2.2907748222351074, 2.279263973236084, 2.2263872623443604, 2.075623035430908, 1.9127801656723022, 1.7613706588745117, 1.6254371404647827, 1.4966026544570923, 1.3747878074645996, 1.2650846242904663, 1.1882545948028564, 1.1174765825271606, 1.053736686706543, 1.0027233362197876, 0.9672463536262512, 0.9306681156158447, 0.902250349521637, 0.8772090673446655, 0.8544133305549622, 0.8308295011520386, 0.8094137907028198, 0.7987534403800964, 0.7660611271858215, 0.7591814994812012, 0.7328364253044128, 0.7228142023086548, 0.7080334424972534, 0.6949453949928284, 0.6798022985458374, 0.6643396019935608, 0.6531528830528259, 0.6374125480651855, 0.632474958896637, 0.6188088655471802, 0.5997223258018494, 0.5972433686256409, 0.5801138281822205, 0.580881655216217, 0.5728179812431335, 0.5614992380142212, 0.5497429370880127, 0.5461690425872803, 0.5380825400352478, 0.5271468162536621, 0.5161987543106079, 0.5136208534240723, 0.5056061744689941, 0.5025849342346191], 'accuracy': [0.12312500178813934, 0.12575000524520874, 0.13102082908153534, 0.164124995470047, 0.22699999809265137, 0.2536250054836273, 0.3140625059604645, 0.37160417437553406, 0.43277081847190857, 0.4815624952316284, 0.5266666412353516, 0.5599791407585144, 0.5882916450500488, 0.6169999837875366, 0.6399999856948853, 0.6603333353996277, 0.6747291684150696, 0.6874791383743286, 0.7018125057220459, 0.7092708349227905, 0.7172708511352539, 0.7284583449363708, 0.7373958230018616, 0.7434375286102295, 0.7529374957084656, 0.7567708492279053, 0.7660208344459534, 0.7735000252723694, 0.7801250219345093, 0.7847708463668823, 0.7903541922569275, 0.7980208396911621, 0.7991874814033508, 0.8040000200271606, 0.8083750009536743, 0.8146458268165588, 0.817312479019165, 0.8196458220481873, 0.8272916674613953, 0.8242291808128357, 0.8264583349227905, 0.8297500014305115, 0.8365833163261414, 0.8354166746139526, 0.8402500152587891, 0.8409374952316284, 0.843416690826416, 0.8481458425521851, 0.8470208048820496, 0.8515833616256714], 'val_loss': [2.2989652156829834, 2.294198989868164, 2.2867074012756348, 2.267091751098633, 2.1145882606506348, 1.865881323814392, 1.6193748712539673, 1.4162507057189941, 1.2335280179977417, 1.0671837329864502, 0.9328168034553528, 0.8237273097038269, 0.740209698677063, 0.6697298288345337, 0.6112829446792603, 0.5739247798919678, 0.5445249676704407, 0.5134645700454712, 0.49400562047958374, 0.47416049242019653, 0.4556911289691925, 0.4371001422405243, 0.42449215054512024, 0.40965011715888977, 0.3923933804035187, 0.37777507305145264, 0.3643650710582733, 0.3494173288345337, 0.33720633387565613, 0.32340267300605774, 0.31192782521247864, 0.29697486758232117, 0.28741538524627686, 0.27824345231056213, 0.2703722417354584, 0.2601751685142517, 0.25152790546417236, 0.24884480237960815, 0.23934513330459595, 0.23597991466522217, 0.22914497554302216, 0.22569754719734192, 0.21809181571006775, 0.21504156291484833, 0.21132725477218628, 0.20894858241081238, 0.20412561297416687, 0.19970914721488953, 0.19698059558868408, 0.19914668798446655], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10925000160932541, 0.1941666603088379, 0.3031666576862335, 0.3895833194255829, 0.5260000228881836, 0.6258333325386047, 0.675166666507721, 0.7014166712760925, 0.731166660785675, 0.7603333592414856, 0.7884166836738586, 0.8052499890327454, 0.8135833144187927, 0.8255833387374878, 0.828416645526886, 0.8374166488647461, 0.8481666445732117, 0.8518333435058594, 0.8643333315849304, 0.8705000281333923, 0.8768333196640015, 0.8812500238418579, 0.8893333077430725, 0.8941666483879089, 0.8995000123977661, 0.906583309173584, 0.9101666808128357, 0.9145833253860474, 0.9204166531562805, 0.9254999756813049, 0.9263333082199097, 0.9281666874885559, 0.9331666827201843, 0.9350000023841858, 0.9381666779518127, 0.9382500052452087, 0.9403333067893982, 0.9409166574478149, 0.9419999718666077, 0.9436666369438171, 0.9442499876022339, 0.9472500085830688, 0.9471666812896729, 0.9488333463668823, 0.9497500061988831, 0.950166642665863, 0.9505833387374878, 0.9505000114440918]}\n",
      "{'loss': [2.300837993621826, 2.296245574951172, 2.291292667388916, 2.2837138175964355, 2.26719331741333, 2.2125120162963867, 2.0896198749542236, 1.9399076700210571, 1.8195314407348633, 1.7296704053878784, 1.641869306564331, 1.5464648008346558, 1.4518438577651978, 1.349029302597046, 1.267364740371704, 1.199826955795288, 1.1430448293685913, 1.0901215076446533, 1.039795994758606, 1.0049188137054443, 0.976510226726532, 0.9436128735542297, 0.9132013916969299, 0.8948984146118164, 0.8767259120941162, 0.8529355525970459, 0.8335141539573669, 0.8136452436447144, 0.796628475189209, 0.7777627110481262, 0.7597869634628296, 0.753564715385437, 0.7383328676223755, 0.7263292670249939, 0.7170119881629944, 0.7067807912826538, 0.6884266138076782, 0.6809093952178955, 0.673717200756073, 0.6551116108894348, 0.6390298008918762, 0.636038601398468, 0.6249492168426514, 0.6195940971374512, 0.5990766882896423, 0.5938122272491455, 0.5842452049255371, 0.5808929204940796, 0.5729743838310242, 0.5620355010032654], 'accuracy': [0.12556250393390656, 0.12672916054725647, 0.13258333504199982, 0.15412500500679016, 0.18922916054725647, 0.22304166853427887, 0.25470831990242004, 0.3102291524410248, 0.3489583432674408, 0.3865000009536743, 0.43016666173934937, 0.4673541784286499, 0.503125011920929, 0.5383958220481873, 0.5660833120346069, 0.5907291769981384, 0.6127708554267883, 0.6319791674613953, 0.6552916765213013, 0.6710833311080933, 0.6845208406448364, 0.6978750228881836, 0.7101666927337646, 0.7186874747276306, 0.726437509059906, 0.7339583039283752, 0.7405416369438171, 0.7489374876022339, 0.7557083368301392, 0.7617083191871643, 0.7683125138282776, 0.7717499732971191, 0.7744583487510681, 0.7822499871253967, 0.7852916717529297, 0.7877083420753479, 0.7928749918937683, 0.7955833077430725, 0.7963125109672546, 0.8025624752044678, 0.8090624809265137, 0.8117708563804626, 0.8143749833106995, 0.8168541789054871, 0.823395848274231, 0.8245208263397217, 0.8283125162124634, 0.8277083039283752, 0.8330416679382324, 0.8351458311080933], 'val_loss': [2.2987499237060547, 2.294382333755493, 2.2884745597839355, 2.2781214714050293, 2.2508223056793213, 2.128143787384033, 1.9381145238876343, 1.7350788116455078, 1.6074527502059937, 1.501083493232727, 1.3853915929794312, 1.2638283967971802, 1.1337016820907593, 1.0272791385650635, 0.9376165270805359, 0.865804135799408, 0.7998262643814087, 0.7461962103843689, 0.7009645104408264, 0.6656463146209717, 0.6313138604164124, 0.6044511198997498, 0.5743467211723328, 0.5540823936462402, 0.5356378555297852, 0.5191916227340698, 0.5017035007476807, 0.48472079634666443, 0.470681369304657, 0.45518067479133606, 0.44276052713394165, 0.43165451288223267, 0.4208943247795105, 0.41004183888435364, 0.3982090353965759, 0.3889012336730957, 0.38057100772857666, 0.37178197503089905, 0.36497586965560913, 0.3537115752696991, 0.34814563393592834, 0.3371948301792145, 0.33081188797950745, 0.3229430019855499, 0.3146314322948456, 0.31113293766975403, 0.30617719888687134, 0.3000872731208801, 0.29381096363067627, 0.287609726190567], 'val_accuracy': [0.10599999874830246, 0.10608333349227905, 0.12033333629369736, 0.17733334004878998, 0.20883333683013916, 0.23483332991600037, 0.3005000054836273, 0.37958332896232605, 0.4389166533946991, 0.4987500011920929, 0.5586666464805603, 0.6164166927337646, 0.6633333563804626, 0.6970833539962769, 0.7180833220481873, 0.7544999718666077, 0.7763333320617676, 0.8009166717529297, 0.8191666603088379, 0.8339166641235352, 0.8429999947547913, 0.856416642665863, 0.8634166717529297, 0.8659166693687439, 0.8728333115577698, 0.8763333559036255, 0.8820833563804626, 0.8863333463668823, 0.8896666765213013, 0.8922500014305115, 0.8949999809265137, 0.8970000147819519, 0.8998333215713501, 0.9028333425521851, 0.9045000076293945, 0.9075000286102295, 0.9075833559036255, 0.9110000133514404, 0.9132500290870667, 0.9164999723434448, 0.9162499904632568, 0.9201666712760925, 0.9213333129882812, 0.9229999780654907, 0.9253333210945129, 0.9259999990463257, 0.9278333187103271, 0.9284166693687439, 0.9303333163261414, 0.9306666851043701]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(16, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "6depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
