{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 678735,
     "status": "ok",
     "timestamp": 1627300881741,
     "user": {
      "displayName": "TRUNG Nguyễn Thành",
      "photoUrl": "",
      "userId": "02848241069421510082"
     },
     "user_tz": -420
    },
    "id": "JnHhSjZec4W6",
    "outputId": "8c053723-ce16-45fb-a54a-bbe314930be1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 16s 5ms/step - loss: 2.4835 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3951 - accuracy: 0.1027 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3638 - accuracy: 0.1003 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3489 - accuracy: 0.1001 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3361 - accuracy: 0.1015 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3313 - accuracy: 0.1028 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3219 - accuracy: 0.1048 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3224 - accuracy: 0.1005 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3187 - accuracy: 0.1002 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3162 - accuracy: 0.1023 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3146 - accuracy: 0.1044 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3109 - accuracy: 0.1050 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3104 - accuracy: 0.1061 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3091 - accuracy: 0.1042 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3089 - accuracy: 0.1058 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3081 - accuracy: 0.1051 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3086 - accuracy: 0.1044 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3068 - accuracy: 0.1066 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3063 - accuracy: 0.1095 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3071 - accuracy: 0.1062 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3054 - accuracy: 0.1079 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3055 - accuracy: 0.1090 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3042 - accuracy: 0.1084 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3048 - accuracy: 0.1105 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3058 - accuracy: 0.1084 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3047 - accuracy: 0.1081 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3047 - accuracy: 0.1052 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3041 - accuracy: 0.1079 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3046 - accuracy: 0.1058 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3033 - accuracy: 0.1083 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3035 - accuracy: 0.1107 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3041 - accuracy: 0.1032 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3031 - accuracy: 0.1113 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3034 - accuracy: 0.1050 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3039 - accuracy: 0.1067 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3029 - accuracy: 0.1092 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3034 - accuracy: 0.1067 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3034 - accuracy: 0.1064 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3032 - accuracy: 0.1073 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3027 - accuracy: 0.1075 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3034 - accuracy: 0.1076 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3017 - accuracy: 0.1149 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3031 - accuracy: 0.1078 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.1136 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3028 - accuracy: 0.1084 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3021 - accuracy: 0.1104 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3028 - accuracy: 0.1104 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3025 - accuracy: 0.1095 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3017 - accuracy: 0.1135 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 1.8135 - accuracy: 0.3760 - val_loss: 0.7249 - val_accuracy: 0.8418\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9910 - accuracy: 0.6942 - val_loss: 0.5085 - val_accuracy: 0.8758\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7892 - accuracy: 0.7621 - val_loss: 0.4205 - val_accuracy: 0.8890\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7019 - accuracy: 0.7888 - val_loss: 0.3759 - val_accuracy: 0.8957\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6406 - accuracy: 0.8143 - val_loss: 0.3488 - val_accuracy: 0.9002\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5998 - accuracy: 0.8252 - val_loss: 0.3291 - val_accuracy: 0.9062\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5770 - accuracy: 0.8321 - val_loss: 0.3121 - val_accuracy: 0.9107\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5458 - accuracy: 0.8437 - val_loss: 0.3027 - val_accuracy: 0.9112\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5344 - accuracy: 0.8489 - val_loss: 0.2960 - val_accuracy: 0.9139\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5189 - accuracy: 0.8501 - val_loss: 0.2881 - val_accuracy: 0.9157\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4959 - accuracy: 0.8573 - val_loss: 0.2800 - val_accuracy: 0.9183\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4843 - accuracy: 0.8629 - val_loss: 0.2743 - val_accuracy: 0.9191\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4775 - accuracy: 0.8636 - val_loss: 0.2713 - val_accuracy: 0.9197\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4641 - accuracy: 0.8678 - val_loss: 0.2648 - val_accuracy: 0.9222\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4594 - accuracy: 0.8722 - val_loss: 0.2630 - val_accuracy: 0.9221\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.8737 - val_loss: 0.2594 - val_accuracy: 0.9231\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4465 - accuracy: 0.8758 - val_loss: 0.2571 - val_accuracy: 0.9240\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4370 - accuracy: 0.8787 - val_loss: 0.2525 - val_accuracy: 0.9261\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4207 - accuracy: 0.8825 - val_loss: 0.2480 - val_accuracy: 0.9265\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4179 - accuracy: 0.8823 - val_loss: 0.2467 - val_accuracy: 0.9260\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8842 - val_loss: 0.2451 - val_accuracy: 0.9266\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4085 - accuracy: 0.8860 - val_loss: 0.2422 - val_accuracy: 0.9283\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4040 - accuracy: 0.8884 - val_loss: 0.2387 - val_accuracy: 0.9297\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3933 - accuracy: 0.8901 - val_loss: 0.2347 - val_accuracy: 0.9323\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3950 - accuracy: 0.8930 - val_loss: 0.2379 - val_accuracy: 0.9309\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3873 - accuracy: 0.8939 - val_loss: 0.2338 - val_accuracy: 0.9308\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3880 - accuracy: 0.8938 - val_loss: 0.2276 - val_accuracy: 0.9334\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3855 - accuracy: 0.8943 - val_loss: 0.2258 - val_accuracy: 0.9341\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3714 - accuracy: 0.8991 - val_loss: 0.2268 - val_accuracy: 0.9337\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3727 - accuracy: 0.8977 - val_loss: 0.2231 - val_accuracy: 0.9342\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.9033 - val_loss: 0.2226 - val_accuracy: 0.9358\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3635 - accuracy: 0.9028 - val_loss: 0.2182 - val_accuracy: 0.9364\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.9021 - val_loss: 0.2191 - val_accuracy: 0.9360\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3449 - accuracy: 0.9063 - val_loss: 0.2182 - val_accuracy: 0.9366\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3561 - accuracy: 0.9030 - val_loss: 0.2130 - val_accuracy: 0.9388\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3445 - accuracy: 0.9064 - val_loss: 0.2126 - val_accuracy: 0.9385\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3388 - accuracy: 0.9076 - val_loss: 0.2098 - val_accuracy: 0.9387\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.9092 - val_loss: 0.2080 - val_accuracy: 0.9403\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.9068 - val_loss: 0.2062 - val_accuracy: 0.9413\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3368 - accuracy: 0.9085 - val_loss: 0.2056 - val_accuracy: 0.9408\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3297 - accuracy: 0.9108 - val_loss: 0.2034 - val_accuracy: 0.9427\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.9104 - val_loss: 0.2018 - val_accuracy: 0.9423\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.9113 - val_loss: 0.1988 - val_accuracy: 0.9428\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3233 - accuracy: 0.9135 - val_loss: 0.2012 - val_accuracy: 0.9432\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.9115 - val_loss: 0.1961 - val_accuracy: 0.9445\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.9144 - val_loss: 0.1947 - val_accuracy: 0.9455\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3151 - accuracy: 0.9143 - val_loss: 0.1921 - val_accuracy: 0.9461\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3118 - accuracy: 0.9175 - val_loss: 0.1901 - val_accuracy: 0.9469\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3044 - accuracy: 0.9164 - val_loss: 0.1911 - val_accuracy: 0.9463\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.9190 - val_loss: 0.1860 - val_accuracy: 0.9486\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2941 - accuracy: 0.1293 - val_loss: 2.1199 - val_accuracy: 0.3781\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1123 - accuracy: 0.2491 - val_loss: 1.6314 - val_accuracy: 0.6258\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7600 - accuracy: 0.3901 - val_loss: 1.1343 - val_accuracy: 0.7205\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4244 - accuracy: 0.4982 - val_loss: 0.8262 - val_accuracy: 0.7872\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1853 - accuracy: 0.5900 - val_loss: 0.6378 - val_accuracy: 0.8338\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0176 - accuracy: 0.6558 - val_loss: 0.5218 - val_accuracy: 0.8629\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8976 - accuracy: 0.7041 - val_loss: 0.4492 - val_accuracy: 0.8839\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8177 - accuracy: 0.7399 - val_loss: 0.3934 - val_accuracy: 0.9007\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7442 - accuracy: 0.7658 - val_loss: 0.3502 - val_accuracy: 0.9094\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6850 - accuracy: 0.7908 - val_loss: 0.3166 - val_accuracy: 0.9183\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6375 - accuracy: 0.8094 - val_loss: 0.2859 - val_accuracy: 0.9267\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5829 - accuracy: 0.8299 - val_loss: 0.2631 - val_accuracy: 0.9319\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5534 - accuracy: 0.8405 - val_loss: 0.2405 - val_accuracy: 0.9378\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5263 - accuracy: 0.8492 - val_loss: 0.2252 - val_accuracy: 0.9400\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4935 - accuracy: 0.8610 - val_loss: 0.2099 - val_accuracy: 0.9441\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4667 - accuracy: 0.8665 - val_loss: 0.1991 - val_accuracy: 0.9473\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4477 - accuracy: 0.8766 - val_loss: 0.1871 - val_accuracy: 0.9503\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4248 - accuracy: 0.8827 - val_loss: 0.1794 - val_accuracy: 0.9522\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4135 - accuracy: 0.8866 - val_loss: 0.1731 - val_accuracy: 0.9538\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3847 - accuracy: 0.8926 - val_loss: 0.1660 - val_accuracy: 0.9553\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3674 - accuracy: 0.8982 - val_loss: 0.1593 - val_accuracy: 0.9571\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3674 - accuracy: 0.8994 - val_loss: 0.1544 - val_accuracy: 0.9582\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.9071 - val_loss: 0.1502 - val_accuracy: 0.9591\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3394 - accuracy: 0.9071 - val_loss: 0.1454 - val_accuracy: 0.9605\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3184 - accuracy: 0.9139 - val_loss: 0.1405 - val_accuracy: 0.9623\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3181 - accuracy: 0.9146 - val_loss: 0.1376 - val_accuracy: 0.9621\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2997 - accuracy: 0.9209 - val_loss: 0.1341 - val_accuracy: 0.9638\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2882 - accuracy: 0.9235 - val_loss: 0.1340 - val_accuracy: 0.9632\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.9262 - val_loss: 0.1308 - val_accuracy: 0.9653\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.9284 - val_loss: 0.1291 - val_accuracy: 0.9657\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2597 - accuracy: 0.9280 - val_loss: 0.1248 - val_accuracy: 0.9666\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2572 - accuracy: 0.9325 - val_loss: 0.1243 - val_accuracy: 0.9676\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2536 - accuracy: 0.9340 - val_loss: 0.1214 - val_accuracy: 0.9682\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2477 - accuracy: 0.9348 - val_loss: 0.1204 - val_accuracy: 0.9693\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2444 - accuracy: 0.9333 - val_loss: 0.1209 - val_accuracy: 0.9674\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2270 - accuracy: 0.9387 - val_loss: 0.1188 - val_accuracy: 0.9695\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2274 - accuracy: 0.9407 - val_loss: 0.1178 - val_accuracy: 0.9685\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2252 - accuracy: 0.9383 - val_loss: 0.1156 - val_accuracy: 0.9698\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2172 - accuracy: 0.9407 - val_loss: 0.1159 - val_accuracy: 0.9693\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9425 - val_loss: 0.1151 - val_accuracy: 0.9707\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9460 - val_loss: 0.1127 - val_accuracy: 0.9709\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9463 - val_loss: 0.1129 - val_accuracy: 0.9716\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1929 - accuracy: 0.9490 - val_loss: 0.1120 - val_accuracy: 0.9713\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1940 - accuracy: 0.9492 - val_loss: 0.1114 - val_accuracy: 0.9722\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1906 - accuracy: 0.9482 - val_loss: 0.1091 - val_accuracy: 0.9719\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1905 - accuracy: 0.9480 - val_loss: 0.1100 - val_accuracy: 0.9719\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1772 - accuracy: 0.9517 - val_loss: 0.1097 - val_accuracy: 0.9720\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1782 - accuracy: 0.9515 - val_loss: 0.1092 - val_accuracy: 0.9721\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1718 - accuracy: 0.9544 - val_loss: 0.1090 - val_accuracy: 0.9725\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9555 - val_loss: 0.1090 - val_accuracy: 0.9732\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2571 - accuracy: 0.1585 - val_loss: 1.8387 - val_accuracy: 0.6137\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8211 - accuracy: 0.3769 - val_loss: 1.0390 - val_accuracy: 0.7640\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2935 - accuracy: 0.5597 - val_loss: 0.6798 - val_accuracy: 0.8306\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0143 - accuracy: 0.6604 - val_loss: 0.5149 - val_accuracy: 0.8664\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8530 - accuracy: 0.7274 - val_loss: 0.4231 - val_accuracy: 0.8867\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7342 - accuracy: 0.7741 - val_loss: 0.3677 - val_accuracy: 0.8977\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6562 - accuracy: 0.8014 - val_loss: 0.3348 - val_accuracy: 0.9053\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6013 - accuracy: 0.8236 - val_loss: 0.3066 - val_accuracy: 0.9127\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5444 - accuracy: 0.8437 - val_loss: 0.2843 - val_accuracy: 0.9179\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5143 - accuracy: 0.8561 - val_loss: 0.2674 - val_accuracy: 0.9223\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4823 - accuracy: 0.8669 - val_loss: 0.2526 - val_accuracy: 0.9261\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4541 - accuracy: 0.8766 - val_loss: 0.2384 - val_accuracy: 0.9307\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4365 - accuracy: 0.8837 - val_loss: 0.2268 - val_accuracy: 0.9346\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4148 - accuracy: 0.8866 - val_loss: 0.2188 - val_accuracy: 0.9368\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3981 - accuracy: 0.8922 - val_loss: 0.2098 - val_accuracy: 0.9379\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3823 - accuracy: 0.8956 - val_loss: 0.1991 - val_accuracy: 0.9423\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.9032 - val_loss: 0.1919 - val_accuracy: 0.9442\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3449 - accuracy: 0.9094 - val_loss: 0.1864 - val_accuracy: 0.9467\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.9107 - val_loss: 0.1794 - val_accuracy: 0.9473\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3250 - accuracy: 0.9148 - val_loss: 0.1761 - val_accuracy: 0.9486\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3186 - accuracy: 0.9164 - val_loss: 0.1707 - val_accuracy: 0.9489\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2988 - accuracy: 0.9190 - val_loss: 0.1661 - val_accuracy: 0.9515\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.9263 - val_loss: 0.1602 - val_accuracy: 0.9530\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2843 - accuracy: 0.9233 - val_loss: 0.1574 - val_accuracy: 0.9531\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2778 - accuracy: 0.9283 - val_loss: 0.1541 - val_accuracy: 0.9539\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2670 - accuracy: 0.9296 - val_loss: 0.1512 - val_accuracy: 0.9547\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2593 - accuracy: 0.9337 - val_loss: 0.1465 - val_accuracy: 0.9564\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2559 - accuracy: 0.9348 - val_loss: 0.1453 - val_accuracy: 0.9581\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2511 - accuracy: 0.9347 - val_loss: 0.1453 - val_accuracy: 0.9571\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2338 - accuracy: 0.9367 - val_loss: 0.1392 - val_accuracy: 0.9598\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2323 - accuracy: 0.9390 - val_loss: 0.1385 - val_accuracy: 0.9597\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2257 - accuracy: 0.9424 - val_loss: 0.1369 - val_accuracy: 0.9610\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2249 - accuracy: 0.9426 - val_loss: 0.1340 - val_accuracy: 0.9607\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9428 - val_loss: 0.1317 - val_accuracy: 0.9613\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9454 - val_loss: 0.1312 - val_accuracy: 0.9611\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9457 - val_loss: 0.1282 - val_accuracy: 0.9651\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9474 - val_loss: 0.1287 - val_accuracy: 0.9647\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9467 - val_loss: 0.1268 - val_accuracy: 0.9647\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1941 - accuracy: 0.9511 - val_loss: 0.1253 - val_accuracy: 0.9652\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1866 - accuracy: 0.9532 - val_loss: 0.1234 - val_accuracy: 0.9649\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1932 - accuracy: 0.9517 - val_loss: 0.1229 - val_accuracy: 0.9656\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1859 - accuracy: 0.9521 - val_loss: 0.1204 - val_accuracy: 0.9666\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1823 - accuracy: 0.9522 - val_loss: 0.1211 - val_accuracy: 0.9668\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1755 - accuracy: 0.9535 - val_loss: 0.1187 - val_accuracy: 0.9677\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1765 - accuracy: 0.9535 - val_loss: 0.1180 - val_accuracy: 0.9671\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1717 - accuracy: 0.9557 - val_loss: 0.1188 - val_accuracy: 0.9672\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1698 - accuracy: 0.9566 - val_loss: 0.1184 - val_accuracy: 0.9687\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1666 - accuracy: 0.9576 - val_loss: 0.1179 - val_accuracy: 0.9679\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1647 - accuracy: 0.9564 - val_loss: 0.1143 - val_accuracy: 0.9690\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1611 - accuracy: 0.9591 - val_loss: 0.1152 - val_accuracy: 0.9678\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 1.8446 - accuracy: 0.3626 - val_loss: 0.6996 - val_accuracy: 0.8263\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9677 - accuracy: 0.6864 - val_loss: 0.4764 - val_accuracy: 0.8743\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7753 - accuracy: 0.7553 - val_loss: 0.3955 - val_accuracy: 0.8892\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.7897 - val_loss: 0.3584 - val_accuracy: 0.8987\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6125 - accuracy: 0.8137 - val_loss: 0.3297 - val_accuracy: 0.9039\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5849 - accuracy: 0.8248 - val_loss: 0.3133 - val_accuracy: 0.9072\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5489 - accuracy: 0.8348 - val_loss: 0.2983 - val_accuracy: 0.9110\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5338 - accuracy: 0.8430 - val_loss: 0.2875 - val_accuracy: 0.9144\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5154 - accuracy: 0.8472 - val_loss: 0.2760 - val_accuracy: 0.9170\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.8556 - val_loss: 0.2679 - val_accuracy: 0.9214\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4709 - accuracy: 0.8644 - val_loss: 0.2597 - val_accuracy: 0.9233\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4628 - accuracy: 0.8651 - val_loss: 0.2543 - val_accuracy: 0.9243\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.8730 - val_loss: 0.2476 - val_accuracy: 0.9258\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.8763 - val_loss: 0.2432 - val_accuracy: 0.9274\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4258 - accuracy: 0.8792 - val_loss: 0.2370 - val_accuracy: 0.9300\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4207 - accuracy: 0.8798 - val_loss: 0.2302 - val_accuracy: 0.9317\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8835 - val_loss: 0.2276 - val_accuracy: 0.9311\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4049 - accuracy: 0.8850 - val_loss: 0.2208 - val_accuracy: 0.9354\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3893 - accuracy: 0.8900 - val_loss: 0.2172 - val_accuracy: 0.9363\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3904 - accuracy: 0.8893 - val_loss: 0.2131 - val_accuracy: 0.9380\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3813 - accuracy: 0.8923 - val_loss: 0.2104 - val_accuracy: 0.9386\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3685 - accuracy: 0.8965 - val_loss: 0.2047 - val_accuracy: 0.9413\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8991 - val_loss: 0.2021 - val_accuracy: 0.9413\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3529 - accuracy: 0.9004 - val_loss: 0.1984 - val_accuracy: 0.9438\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.8974 - val_loss: 0.1950 - val_accuracy: 0.9443\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3452 - accuracy: 0.9020 - val_loss: 0.1934 - val_accuracy: 0.9450\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.9039 - val_loss: 0.1903 - val_accuracy: 0.9457\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3294 - accuracy: 0.9066 - val_loss: 0.1845 - val_accuracy: 0.9473\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.9057 - val_loss: 0.1818 - val_accuracy: 0.9487\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3194 - accuracy: 0.9109 - val_loss: 0.1809 - val_accuracy: 0.9488\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.9090 - val_loss: 0.1775 - val_accuracy: 0.9508\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3095 - accuracy: 0.9143 - val_loss: 0.1730 - val_accuracy: 0.9512\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3150 - accuracy: 0.9125 - val_loss: 0.1739 - val_accuracy: 0.9520\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3058 - accuracy: 0.9144 - val_loss: 0.1705 - val_accuracy: 0.9515\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3006 - accuracy: 0.9173 - val_loss: 0.1693 - val_accuracy: 0.9525\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2978 - accuracy: 0.9163 - val_loss: 0.1667 - val_accuracy: 0.9528\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2840 - accuracy: 0.9201 - val_loss: 0.1664 - val_accuracy: 0.9532\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2914 - accuracy: 0.9175 - val_loss: 0.1641 - val_accuracy: 0.9537\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2914 - accuracy: 0.9196 - val_loss: 0.1602 - val_accuracy: 0.9548\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.9183 - val_loss: 0.1588 - val_accuracy: 0.9561\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2789 - accuracy: 0.9208 - val_loss: 0.1589 - val_accuracy: 0.9555\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2797 - accuracy: 0.9234 - val_loss: 0.1547 - val_accuracy: 0.9566\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2799 - accuracy: 0.9220 - val_loss: 0.1535 - val_accuracy: 0.9569\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2701 - accuracy: 0.9243 - val_loss: 0.1521 - val_accuracy: 0.9572\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2690 - accuracy: 0.9256 - val_loss: 0.1520 - val_accuracy: 0.9575\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2692 - accuracy: 0.9251 - val_loss: 0.1497 - val_accuracy: 0.9576\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2648 - accuracy: 0.9241 - val_loss: 0.1500 - val_accuracy: 0.9573\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2566 - accuracy: 0.9293 - val_loss: 0.1480 - val_accuracy: 0.9584\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2532 - accuracy: 0.9294 - val_loss: 0.1474 - val_accuracy: 0.9586\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2560 - accuracy: 0.9285 - val_loss: 0.1452 - val_accuracy: 0.9592\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.7894 - accuracy: 0.1054 - val_loss: 2.2588 - val_accuracy: 0.1220\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4524 - accuracy: 0.1187 - val_loss: 2.1934 - val_accuracy: 0.1082\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3167 - accuracy: 0.1367 - val_loss: 1.9429 - val_accuracy: 0.2777\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2052 - accuracy: 0.1818 - val_loss: 1.5212 - val_accuracy: 0.3887\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.0107 - accuracy: 0.2595 - val_loss: 1.7648 - val_accuracy: 0.4243\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8002 - accuracy: 0.3320 - val_loss: 1.7954 - val_accuracy: 0.5079\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6420 - accuracy: 0.3838 - val_loss: 1.6736 - val_accuracy: 0.5742\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5158 - accuracy: 0.4357 - val_loss: 1.5635 - val_accuracy: 0.6333\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4073 - accuracy: 0.4893 - val_loss: 1.5565 - val_accuracy: 0.6628\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.3031 - accuracy: 0.5284 - val_loss: 1.5518 - val_accuracy: 0.6932\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2278 - accuracy: 0.5633 - val_loss: 1.6133 - val_accuracy: 0.7156\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1558 - accuracy: 0.5898 - val_loss: 1.6485 - val_accuracy: 0.7237\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1024 - accuracy: 0.6169 - val_loss: 1.7329 - val_accuracy: 0.7290\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0724 - accuracy: 0.6298 - val_loss: 1.7370 - val_accuracy: 0.7402\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0334 - accuracy: 0.6481 - val_loss: 1.7738 - val_accuracy: 0.7468\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0066 - accuracy: 0.6569 - val_loss: 1.7209 - val_accuracy: 0.7574\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9915 - accuracy: 0.6642 - val_loss: 1.8342 - val_accuracy: 0.7524\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9719 - accuracy: 0.6781 - val_loss: 1.8299 - val_accuracy: 0.7623\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9348 - accuracy: 0.6911 - val_loss: 1.8627 - val_accuracy: 0.7629\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9291 - accuracy: 0.6939 - val_loss: 1.8432 - val_accuracy: 0.7688\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9144 - accuracy: 0.7021 - val_loss: 1.9129 - val_accuracy: 0.7703\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9014 - accuracy: 0.7038 - val_loss: 1.7816 - val_accuracy: 0.7852\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8836 - accuracy: 0.7142 - val_loss: 1.8378 - val_accuracy: 0.7839\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8625 - accuracy: 0.7207 - val_loss: 1.9243 - val_accuracy: 0.7834\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8512 - accuracy: 0.7275 - val_loss: 1.8575 - val_accuracy: 0.7915\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8459 - accuracy: 0.7310 - val_loss: 1.8281 - val_accuracy: 0.7994\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8349 - accuracy: 0.7358 - val_loss: 1.9826 - val_accuracy: 0.7959\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8242 - accuracy: 0.7430 - val_loss: 1.8290 - val_accuracy: 0.8097\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8089 - accuracy: 0.7449 - val_loss: 1.9007 - val_accuracy: 0.8115\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7961 - accuracy: 0.7533 - val_loss: 1.8306 - val_accuracy: 0.8186\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7859 - accuracy: 0.7558 - val_loss: 1.8052 - val_accuracy: 0.8217\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7824 - accuracy: 0.7540 - val_loss: 1.8604 - val_accuracy: 0.8213\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7691 - accuracy: 0.7612 - val_loss: 1.8439 - val_accuracy: 0.8294\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7523 - accuracy: 0.7685 - val_loss: 1.7897 - val_accuracy: 0.8347\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7613 - accuracy: 0.7663 - val_loss: 1.7631 - val_accuracy: 0.8357\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7441 - accuracy: 0.7717 - val_loss: 1.7322 - val_accuracy: 0.8396\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7321 - accuracy: 0.7789 - val_loss: 1.8222 - val_accuracy: 0.8354\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7240 - accuracy: 0.7816 - val_loss: 1.8501 - val_accuracy: 0.8347\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7251 - accuracy: 0.7799 - val_loss: 1.6914 - val_accuracy: 0.8483\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7125 - accuracy: 0.7874 - val_loss: 1.6811 - val_accuracy: 0.8497\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7094 - accuracy: 0.7926 - val_loss: 1.7001 - val_accuracy: 0.8476\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6867 - accuracy: 0.7961 - val_loss: 1.7877 - val_accuracy: 0.8452\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6949 - accuracy: 0.7963 - val_loss: 1.6951 - val_accuracy: 0.8569\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6861 - accuracy: 0.7987 - val_loss: 1.6934 - val_accuracy: 0.8604\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6797 - accuracy: 0.8015 - val_loss: 1.6621 - val_accuracy: 0.8562\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6767 - accuracy: 0.8036 - val_loss: 1.6546 - val_accuracy: 0.8633\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6726 - accuracy: 0.8038 - val_loss: 1.5967 - val_accuracy: 0.8694\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6580 - accuracy: 0.8096 - val_loss: 1.6465 - val_accuracy: 0.8614\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6583 - accuracy: 0.8103 - val_loss: 1.7149 - val_accuracy: 0.8608\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6462 - accuracy: 0.8134 - val_loss: 1.6659 - val_accuracy: 0.8725\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 2.2976 - accuracy: 0.1351 - val_loss: 2.2822 - val_accuracy: 0.2649\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2750 - accuracy: 0.2384 - val_loss: 2.2383 - val_accuracy: 0.4435\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2084 - accuracy: 0.3155 - val_loss: 1.9441 - val_accuracy: 0.4943\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8993 - accuracy: 0.3971 - val_loss: 1.3813 - val_accuracy: 0.5995\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5275 - accuracy: 0.4791 - val_loss: 1.0146 - val_accuracy: 0.7168\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2615 - accuracy: 0.5700 - val_loss: 0.7995 - val_accuracy: 0.7882\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0663 - accuracy: 0.6457 - val_loss: 0.6520 - val_accuracy: 0.8364\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9432 - accuracy: 0.6967 - val_loss: 0.5536 - val_accuracy: 0.8560\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8487 - accuracy: 0.7376 - val_loss: 0.4890 - val_accuracy: 0.8738\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7700 - accuracy: 0.7680 - val_loss: 0.4387 - val_accuracy: 0.8867\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7115 - accuracy: 0.7879 - val_loss: 0.4033 - val_accuracy: 0.8941\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6756 - accuracy: 0.8037 - val_loss: 0.3728 - val_accuracy: 0.9007\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6314 - accuracy: 0.8184 - val_loss: 0.3483 - val_accuracy: 0.9060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5976 - accuracy: 0.8298 - val_loss: 0.3297 - val_accuracy: 0.9096\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5685 - accuracy: 0.8385 - val_loss: 0.3122 - val_accuracy: 0.9128\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5578 - accuracy: 0.8432 - val_loss: 0.2980 - val_accuracy: 0.9178\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5248 - accuracy: 0.8538 - val_loss: 0.2827 - val_accuracy: 0.9204\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5102 - accuracy: 0.8632 - val_loss: 0.2712 - val_accuracy: 0.9240\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4855 - accuracy: 0.8663 - val_loss: 0.2594 - val_accuracy: 0.9273\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4590 - accuracy: 0.8730 - val_loss: 0.2497 - val_accuracy: 0.9288\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4669 - accuracy: 0.8748 - val_loss: 0.2402 - val_accuracy: 0.9317\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4378 - accuracy: 0.8801 - val_loss: 0.2316 - val_accuracy: 0.9349\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4151 - accuracy: 0.8877 - val_loss: 0.2247 - val_accuracy: 0.9362\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4062 - accuracy: 0.8885 - val_loss: 0.2157 - val_accuracy: 0.9390\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3957 - accuracy: 0.8957 - val_loss: 0.2105 - val_accuracy: 0.9406\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3853 - accuracy: 0.8971 - val_loss: 0.2026 - val_accuracy: 0.9423\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3843 - accuracy: 0.8975 - val_loss: 0.1974 - val_accuracy: 0.9446\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3638 - accuracy: 0.9024 - val_loss: 0.1933 - val_accuracy: 0.9456\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3470 - accuracy: 0.9100 - val_loss: 0.1867 - val_accuracy: 0.9474\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3403 - accuracy: 0.9099 - val_loss: 0.1805 - val_accuracy: 0.9503\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3300 - accuracy: 0.9145 - val_loss: 0.1767 - val_accuracy: 0.9493\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3275 - accuracy: 0.9129 - val_loss: 0.1733 - val_accuracy: 0.9513\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3312 - accuracy: 0.9118 - val_loss: 0.1687 - val_accuracy: 0.9517\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3086 - accuracy: 0.9176 - val_loss: 0.1660 - val_accuracy: 0.9525\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3010 - accuracy: 0.9194 - val_loss: 0.1621 - val_accuracy: 0.9545\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3035 - accuracy: 0.9221 - val_loss: 0.1600 - val_accuracy: 0.9547\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2981 - accuracy: 0.9209 - val_loss: 0.1565 - val_accuracy: 0.9548\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2924 - accuracy: 0.9247 - val_loss: 0.1533 - val_accuracy: 0.9556\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2851 - accuracy: 0.9248 - val_loss: 0.1505 - val_accuracy: 0.9580\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2754 - accuracy: 0.9291 - val_loss: 0.1489 - val_accuracy: 0.9572\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2732 - accuracy: 0.9305 - val_loss: 0.1468 - val_accuracy: 0.9582\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2709 - accuracy: 0.9298 - val_loss: 0.1434 - val_accuracy: 0.9589\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2608 - accuracy: 0.9323 - val_loss: 0.1426 - val_accuracy: 0.9598\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2523 - accuracy: 0.9337 - val_loss: 0.1391 - val_accuracy: 0.9607\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2509 - accuracy: 0.9352 - val_loss: 0.1392 - val_accuracy: 0.9611\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2416 - accuracy: 0.9371 - val_loss: 0.1346 - val_accuracy: 0.9613\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2512 - accuracy: 0.9360 - val_loss: 0.1354 - val_accuracy: 0.9622\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2486 - accuracy: 0.9357 - val_loss: 0.1333 - val_accuracy: 0.9628\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2413 - accuracy: 0.9371 - val_loss: 0.1295 - val_accuracy: 0.9632\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2402 - accuracy: 0.9388 - val_loss: 0.1298 - val_accuracy: 0.9638\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 2.2988 - accuracy: 0.1247 - val_loss: 2.2853 - val_accuracy: 0.1738\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2801 - accuracy: 0.2075 - val_loss: 2.2605 - val_accuracy: 0.2776\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2518 - accuracy: 0.2822 - val_loss: 2.1983 - val_accuracy: 0.4233\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.1604 - accuracy: 0.3476 - val_loss: 1.8882 - val_accuracy: 0.4268\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8741 - accuracy: 0.3849 - val_loss: 1.3882 - val_accuracy: 0.6378\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5057 - accuracy: 0.4883 - val_loss: 0.9937 - val_accuracy: 0.7485\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2429 - accuracy: 0.5820 - val_loss: 0.7913 - val_accuracy: 0.7953\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0591 - accuracy: 0.6513 - val_loss: 0.6629 - val_accuracy: 0.8269\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9412 - accuracy: 0.6959 - val_loss: 0.5764 - val_accuracy: 0.8453\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8571 - accuracy: 0.7282 - val_loss: 0.5095 - val_accuracy: 0.8656\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7947 - accuracy: 0.7538 - val_loss: 0.4685 - val_accuracy: 0.8741\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7319 - accuracy: 0.7789 - val_loss: 0.4350 - val_accuracy: 0.8829\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6972 - accuracy: 0.7905 - val_loss: 0.4057 - val_accuracy: 0.8898\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6578 - accuracy: 0.8038 - val_loss: 0.3838 - val_accuracy: 0.8953\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6249 - accuracy: 0.8176 - val_loss: 0.3692 - val_accuracy: 0.8985\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.8244 - val_loss: 0.3502 - val_accuracy: 0.9013\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5802 - accuracy: 0.8312 - val_loss: 0.3336 - val_accuracy: 0.9062\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5531 - accuracy: 0.8421 - val_loss: 0.3224 - val_accuracy: 0.9088\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5350 - accuracy: 0.8503 - val_loss: 0.3125 - val_accuracy: 0.9114\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5151 - accuracy: 0.8560 - val_loss: 0.3022 - val_accuracy: 0.9146\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5061 - accuracy: 0.8570 - val_loss: 0.2938 - val_accuracy: 0.9157\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5028 - accuracy: 0.8633 - val_loss: 0.2842 - val_accuracy: 0.9195\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4838 - accuracy: 0.8630 - val_loss: 0.2762 - val_accuracy: 0.9208\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4730 - accuracy: 0.8707 - val_loss: 0.2686 - val_accuracy: 0.9227\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4469 - accuracy: 0.8778 - val_loss: 0.2626 - val_accuracy: 0.9241\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4445 - accuracy: 0.8760 - val_loss: 0.2556 - val_accuracy: 0.9260\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4414 - accuracy: 0.8798 - val_loss: 0.2482 - val_accuracy: 0.9292\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4213 - accuracy: 0.8838 - val_loss: 0.2425 - val_accuracy: 0.9303\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4193 - accuracy: 0.8857 - val_loss: 0.2361 - val_accuracy: 0.9327\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4120 - accuracy: 0.8895 - val_loss: 0.2309 - val_accuracy: 0.9345\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4022 - accuracy: 0.8908 - val_loss: 0.2273 - val_accuracy: 0.9356\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3823 - accuracy: 0.8950 - val_loss: 0.2232 - val_accuracy: 0.9362\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3777 - accuracy: 0.8957 - val_loss: 0.2169 - val_accuracy: 0.9367\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3759 - accuracy: 0.9006 - val_loss: 0.2134 - val_accuracy: 0.9389\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3733 - accuracy: 0.8992 - val_loss: 0.2080 - val_accuracy: 0.9410\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3624 - accuracy: 0.8998 - val_loss: 0.2045 - val_accuracy: 0.9418\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.9067 - val_loss: 0.2012 - val_accuracy: 0.9421\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.9046 - val_loss: 0.1976 - val_accuracy: 0.9428\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3403 - accuracy: 0.9085 - val_loss: 0.1943 - val_accuracy: 0.9439\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3398 - accuracy: 0.9095 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3268 - accuracy: 0.9119 - val_loss: 0.1874 - val_accuracy: 0.9454\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3271 - accuracy: 0.9128 - val_loss: 0.1852 - val_accuracy: 0.9467\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3144 - accuracy: 0.9150 - val_loss: 0.1838 - val_accuracy: 0.9470\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3122 - accuracy: 0.9164 - val_loss: 0.1789 - val_accuracy: 0.9488\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3064 - accuracy: 0.9180 - val_loss: 0.1764 - val_accuracy: 0.9503\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2986 - accuracy: 0.9205 - val_loss: 0.1737 - val_accuracy: 0.9507\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3016 - accuracy: 0.9183 - val_loss: 0.1711 - val_accuracy: 0.9513\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2958 - accuracy: 0.9198 - val_loss: 0.1697 - val_accuracy: 0.9518\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.9237 - val_loss: 0.1664 - val_accuracy: 0.9523\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2873 - accuracy: 0.9215 - val_loss: 0.1640 - val_accuracy: 0.9538\n",
      "{'loss': [2.44187331199646, 2.384675979614258, 2.3605122566223145, 2.3462624549865723, 2.3332841396331787, 2.3292407989501953, 2.3220314979553223, 2.3206961154937744, 2.3180296421051025, 2.3152427673339844, 2.3133387565612793, 2.3119657039642334, 2.310129165649414, 2.3089842796325684, 2.308361530303955, 2.3086040019989014, 2.308403730392456, 2.306546926498413, 2.30629301071167, 2.3063547611236572, 2.3056535720825195, 2.30564022064209, 2.304553985595703, 2.30472731590271, 2.305601119995117, 2.3042984008789062, 2.304262161254883, 2.304232120513916, 2.3040339946746826, 2.3032963275909424, 2.3032116889953613, 2.303710699081421, 2.3036131858825684, 2.303507089614868, 2.303030014038086, 2.3034002780914307, 2.3024909496307373, 2.3028228282928467, 2.303184747695923, 2.302839517593384, 2.3026371002197266, 2.303130626678467, 2.302910089492798, 2.3026397228240967, 2.302706480026245, 2.302459478378296, 2.302314043045044, 2.3025193214416504, 2.302185535430908, 2.3022658824920654], 'accuracy': [0.09993749856948853, 0.10135416686534882, 0.09993749856948853, 0.10081250220537186, 0.10366666316986084, 0.10241666436195374, 0.10483333468437195, 0.10143750160932541, 0.10108333081007004, 0.10106249898672104, 0.10485416650772095, 0.10324999690055847, 0.10525000095367432, 0.10597916692495346, 0.10497916489839554, 0.1054166629910469, 0.10372916609048843, 0.10535416752099991, 0.10774999856948853, 0.10710416734218597, 0.10662499815225601, 0.10691666603088379, 0.10795833170413971, 0.10927083343267441, 0.10754166543483734, 0.10849999636411667, 0.10718750208616257, 0.10710416734218597, 0.1081458330154419, 0.11029166728258133, 0.11016666889190674, 0.10654166340827942, 0.10956250131130219, 0.10641666501760483, 0.1105833351612091, 0.10958333313465118, 0.1107499971985817, 0.10927083343267441, 0.10772916674613953, 0.10945833474397659, 0.10885416716337204, 0.10881250351667404, 0.11183333396911621, 0.10927083343267441, 0.11227083206176758, 0.10970833152532578, 0.11091666668653488, 0.11131250113248825, 0.1120000034570694, 0.1119583323597908], 'val_loss': [2.3027422428131104, 2.302281141281128, 2.302260160446167, 2.302215814590454, 2.3021748065948486, 2.3020973205566406, 2.3021156787872314, 2.302161931991577, 2.3020899295806885, 2.302125930786133, 2.3020315170288086, 2.302079677581787, 2.302076578140259, 2.3020431995391846, 2.302034854888916, 2.302016019821167, 2.3020129203796387, 2.302028179168701, 2.302046298980713, 2.302062511444092, 2.3021011352539062, 2.3021109104156494, 2.302133560180664, 2.3021059036254883, 2.3020832538604736, 2.3021726608276367, 2.3021047115325928, 2.3020613193511963, 2.302082061767578, 2.3020949363708496, 2.302065849304199, 2.3021047115325928, 2.302060604095459, 2.302028179168701, 2.302112579345703, 2.3020925521850586, 2.3021132946014404, 2.302063465118408, 2.3020951747894287, 2.3020200729370117, 2.3021349906921387, 2.3021838665008545, 2.302098035812378, 2.3020784854888916, 2.302021026611328, 2.302041530609131, 2.302077531814575, 2.3020846843719482, 2.3020575046539307, 2.3020691871643066], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [1.477480173110962, 0.9290904998779297, 0.7661207914352417, 0.6831769943237305, 0.6308020949363708, 0.5947656631469727, 0.5679216980934143, 0.5406777262687683, 0.5283336043357849, 0.5119089484214783, 0.49553388357162476, 0.4837898313999176, 0.4712861180305481, 0.4661179482936859, 0.45624569058418274, 0.4463980197906494, 0.4403088390827179, 0.43388888239860535, 0.42995548248291016, 0.42058300971984863, 0.41448280215263367, 0.410026490688324, 0.4014703631401062, 0.4004960060119629, 0.3927190899848938, 0.3871510326862335, 0.3856060802936554, 0.3821309506893158, 0.3732615113258362, 0.3755084276199341, 0.36665117740631104, 0.3625246584415436, 0.3596881031990051, 0.3533731698989868, 0.3529319763183594, 0.3455321192741394, 0.3463684618473053, 0.33887070417404175, 0.3383196294307709, 0.333993136882782, 0.3301101326942444, 0.32889604568481445, 0.3262535333633423, 0.3238945007324219, 0.3218213617801666, 0.3160269558429718, 0.3109753131866455, 0.31281235814094543, 0.3064161241054535, 0.3065747320652008], 'accuracy': [0.5156875252723694, 0.7158958315849304, 0.7714375257492065, 0.7948333621025085, 0.8175208568572998, 0.8264583349227905, 0.8352500200271606, 0.8460833430290222, 0.8486250042915344, 0.8527083396911621, 0.8582708239555359, 0.8629999756813049, 0.8666666746139526, 0.8683124780654907, 0.8717291951179504, 0.8743125200271606, 0.8778958320617676, 0.8791249990463257, 0.8806041479110718, 0.8829583525657654, 0.8841249942779541, 0.8863333463668823, 0.8888958096504211, 0.8890833258628845, 0.8931666612625122, 0.8940833210945129, 0.8953750133514404, 0.8956249952316284, 0.898687481880188, 0.8974583148956299, 0.9006249904632568, 0.9019166827201843, 0.9007708430290222, 0.9041041731834412, 0.9042916893959045, 0.906583309173584, 0.9054375290870667, 0.9073125123977661, 0.9081875085830688, 0.9091249704360962, 0.9106875061988831, 0.9103541374206543, 0.9110416769981384, 0.9135833382606506, 0.913729190826416, 0.9140416383743286, 0.9159583449363708, 0.9156875014305115, 0.9165833592414856, 0.917020857334137], 'val_loss': [0.7248504757881165, 0.5085260272026062, 0.42051219940185547, 0.3758638799190521, 0.34883031249046326, 0.32905635237693787, 0.3120940923690796, 0.30269670486450195, 0.2960171699523926, 0.2881467342376709, 0.27998220920562744, 0.2743181586265564, 0.2712516188621521, 0.26482537388801575, 0.26302841305732727, 0.2593889832496643, 0.25711789727211, 0.2524847090244293, 0.24797135591506958, 0.24666786193847656, 0.2451450377702713, 0.2422201782464981, 0.23871761560440063, 0.23472128808498383, 0.23791036009788513, 0.23377439379692078, 0.22756241261959076, 0.22583502531051636, 0.22675614058971405, 0.22312065958976746, 0.22264550626277924, 0.21824634075164795, 0.21908512711524963, 0.21819667518138885, 0.21304801106452942, 0.21255247294902802, 0.20978349447250366, 0.2079744189977646, 0.20616580545902252, 0.20562687516212463, 0.20336395502090454, 0.20177075266838074, 0.19878314435482025, 0.20115557312965393, 0.19613206386566162, 0.19467952847480774, 0.1921474188566208, 0.19010381400585175, 0.19106800854206085, 0.18596090376377106], 'val_accuracy': [0.8418333530426025, 0.8758333325386047, 0.8889999985694885, 0.8957499861717224, 0.9001666903495789, 0.90625, 0.9106666445732117, 0.9112499952316284, 0.9139166474342346, 0.9156666398048401, 0.9183333516120911, 0.9190833568572998, 0.9197499752044678, 0.922249972820282, 0.92208331823349, 0.9230833053588867, 0.9240000247955322, 0.9260833263397217, 0.9265000224113464, 0.9259999990463257, 0.9265833497047424, 0.9282500147819519, 0.9296666383743286, 0.9323333501815796, 0.9309166669845581, 0.9308333396911621, 0.9334166646003723, 0.9340833425521851, 0.9337499737739563, 0.934249997138977, 0.9358333349227905, 0.9364166855812073, 0.9359999895095825, 0.9365833401679993, 0.9388333559036255, 0.9384999871253967, 0.9386666417121887, 0.9403333067893982, 0.9413333535194397, 0.940833330154419, 0.9426666498184204, 0.9423333406448364, 0.9428333044052124, 0.9431666731834412, 0.9445000290870667, 0.9455000162124634, 0.9460833072662354, 0.9469166398048401, 0.9462500214576721, 0.9485833048820496]}\n",
      "{'loss': [2.265859603881836, 2.0325090885162354, 1.668044090270996, 1.3598880767822266, 1.1405189037322998, 0.9860473871231079, 0.8787409067153931, 0.7960225343704224, 0.7284860014915466, 0.6749487519264221, 0.6276525259017944, 0.5808711051940918, 0.5395693182945251, 0.5163525938987732, 0.486703485250473, 0.4683270752429962, 0.44095247983932495, 0.4222659468650818, 0.40245434641838074, 0.38669610023498535, 0.3636898696422577, 0.35957974195480347, 0.34007054567337036, 0.3291997015476227, 0.321382075548172, 0.3117145001888275, 0.30081725120544434, 0.2910830080509186, 0.2771143317222595, 0.2706867456436157, 0.2616890072822571, 0.255153626203537, 0.2513126730918884, 0.24390122294425964, 0.24108339846134186, 0.23171421885490417, 0.22670744359493256, 0.22047384083271027, 0.21140746772289276, 0.21047930419445038, 0.20636694133281708, 0.19922617077827454, 0.19714446365833282, 0.19496960937976837, 0.1916051059961319, 0.18760952353477478, 0.18092462420463562, 0.17835797369480133, 0.17344175279140472, 0.16952061653137207], 'accuracy': [0.16052083671092987, 0.2827708423137665, 0.4204791784286499, 0.5211458206176758, 0.6054166555404663, 0.6686041951179504, 0.711104154586792, 0.7476875185966492, 0.7725625038146973, 0.7947291731834412, 0.8141875267028809, 0.8309583067893982, 0.8448749780654907, 0.8525624871253967, 0.862625002861023, 0.8670416474342346, 0.8776666522026062, 0.8827499747276306, 0.8886874914169312, 0.8933749794960022, 0.9013749957084656, 0.901604175567627, 0.9075208306312561, 0.9118124842643738, 0.9142916798591614, 0.9166250228881836, 0.9201666712760925, 0.9225000143051147, 0.9256666898727417, 0.9283124804496765, 0.929562509059906, 0.9325000047683716, 0.9330416917800903, 0.9366458058357239, 0.9348333477973938, 0.9387916922569275, 0.9406458139419556, 0.9399999976158142, 0.9433333277702332, 0.9437916874885559, 0.9448124766349792, 0.9469583630561829, 0.9473124742507935, 0.9490416646003723, 0.948437511920929, 0.9493749737739563, 0.9510833621025085, 0.9511458277702332, 0.9539583325386047, 0.9546458125114441], 'val_loss': [2.119882822036743, 1.6313543319702148, 1.1342869997024536, 0.8262317776679993, 0.6377725601196289, 0.5218232274055481, 0.4491734206676483, 0.393403559923172, 0.35020360350608826, 0.3165868818759918, 0.2859472632408142, 0.26306477189064026, 0.24047161638736725, 0.22523748874664307, 0.20987051725387573, 0.19910424947738647, 0.1870737373828888, 0.17940205335617065, 0.17309145629405975, 0.16598136723041534, 0.15929603576660156, 0.15442276000976562, 0.15022602677345276, 0.14544454216957092, 0.14047876000404358, 0.13756150007247925, 0.13413457572460175, 0.13395147025585175, 0.13080212473869324, 0.12905657291412354, 0.12479034066200256, 0.12434950470924377, 0.12139149755239487, 0.12036845833063126, 0.12093573808670044, 0.11878499388694763, 0.11779724061489105, 0.11562436074018478, 0.11586242914199829, 0.11506234854459763, 0.11268124729394913, 0.11288614571094513, 0.11202184855937958, 0.11136744171380997, 0.10907503217458725, 0.10998618602752686, 0.10973680764436722, 0.1091814711689949, 0.10903488844633102, 0.10901982337236404], 'val_accuracy': [0.37808331847190857, 0.6257500052452087, 0.7204999923706055, 0.7871666550636292, 0.8337500095367432, 0.8629166483879089, 0.8839166760444641, 0.9007499814033508, 0.909416675567627, 0.9183333516120911, 0.9266666769981384, 0.9319166541099548, 0.937833309173584, 0.9399999976158142, 0.9440833330154419, 0.9472500085830688, 0.9503333568572998, 0.9521666765213013, 0.9538333415985107, 0.9553333520889282, 0.9570833444595337, 0.9581666588783264, 0.9590833187103271, 0.9605000019073486, 0.9623333215713501, 0.9620833396911621, 0.9637500047683716, 0.9632499814033508, 0.9652500152587891, 0.965749979019165, 0.9665833115577698, 0.9675833582878113, 0.9682499766349792, 0.9693333506584167, 0.9674166440963745, 0.9695000052452087, 0.968500018119812, 0.9698333144187927, 0.9693333506584167, 0.9707499742507935, 0.9709166884422302, 0.9715833067893982, 0.9713333249092102, 0.9722499847412109, 0.971916675567627, 0.971916675567627, 0.972000002861023, 0.972083330154419, 0.9725000262260437, 0.9732499718666077]}\n",
      "{'loss': [2.182529926300049, 1.6745301485061646, 1.2102192640304565, 0.9661511182785034, 0.8184525370597839, 0.7126346230506897, 0.6394774317741394, 0.5841522216796875, 0.5389620065689087, 0.5102007389068604, 0.4791888892650604, 0.4505274295806885, 0.430775910615921, 0.4073292315006256, 0.39560070633888245, 0.3772488534450531, 0.3571121394634247, 0.343116819858551, 0.33292117714881897, 0.3171980082988739, 0.3092735707759857, 0.2976355254650116, 0.2845856845378876, 0.2789287269115448, 0.27188900113105774, 0.265351802110672, 0.2572230100631714, 0.25203245878219604, 0.2447599470615387, 0.2374681830406189, 0.23474177718162537, 0.2270394116640091, 0.22253349423408508, 0.21478739380836487, 0.2090829610824585, 0.20998381078243256, 0.20481441915035248, 0.20390260219573975, 0.19332168996334076, 0.1892445683479309, 0.19048887491226196, 0.18503427505493164, 0.18146134912967682, 0.178004652261734, 0.17844201624393463, 0.17172838747501373, 0.1662062555551529, 0.16760623455047607, 0.1611594408750534, 0.16220980882644653], 'accuracy': [0.21402083337306976, 0.42745834589004517, 0.5898749828338623, 0.6807500123977661, 0.7403749823570251, 0.7823958396911621, 0.8106041550636292, 0.8285416960716248, 0.8461250066757202, 0.8557708263397217, 0.8687291741371155, 0.8779791593551636, 0.8835208415985107, 0.8891458511352539, 0.8934583067893982, 0.8978333473205566, 0.9033958315849304, 0.9091874957084656, 0.9123541712760925, 0.9169999957084656, 0.9190000295639038, 0.9204999804496765, 0.925083339214325, 0.9259999990463257, 0.9289166927337646, 0.929937481880188, 0.9324583411216736, 0.9354791641235352, 0.9362916946411133, 0.9366666674613953, 0.9385416507720947, 0.9411249756813049, 0.9431250095367432, 0.9438750147819519, 0.9452499747276306, 0.945604145526886, 0.9474583268165588, 0.9471458196640015, 0.949916660785675, 0.9521874785423279, 0.9512708187103271, 0.9522708058357239, 0.952875018119812, 0.9526666402816772, 0.9533541798591614, 0.9552500247955322, 0.9567916393280029, 0.9569166898727417, 0.9573541879653931, 0.9589999914169312], 'val_loss': [1.8387023210525513, 1.0389975309371948, 0.6797509789466858, 0.5148815512657166, 0.4231354296207428, 0.36774304509162903, 0.33477187156677246, 0.3066118359565735, 0.2843271493911743, 0.2673957347869873, 0.25264501571655273, 0.23840688169002533, 0.22681760787963867, 0.21878457069396973, 0.20984987914562225, 0.19909131526947021, 0.19194330275058746, 0.18644055724143982, 0.17939715087413788, 0.1760702133178711, 0.17066597938537598, 0.1660628318786621, 0.1601715385913849, 0.1574212610721588, 0.15407513082027435, 0.15123941004276276, 0.14651045203208923, 0.1452634036540985, 0.14528366923332214, 0.1391901671886444, 0.13848917186260223, 0.13692164421081543, 0.13399769365787506, 0.13166695833206177, 0.1312064379453659, 0.12823353707790375, 0.12873610854148865, 0.12681584060192108, 0.12528853118419647, 0.12344689667224884, 0.1229051798582077, 0.12043441832065582, 0.1211346760392189, 0.11874767392873764, 0.11797171831130981, 0.11877020448446274, 0.1184481605887413, 0.11786916851997375, 0.11431725323200226, 0.11521420627832413], 'val_accuracy': [0.6137499809265137, 0.7639999985694885, 0.8305833339691162, 0.8664166927337646, 0.8867499828338623, 0.8976666927337646, 0.9052500128746033, 0.9126666784286499, 0.9179166555404663, 0.9223333597183228, 0.9260833263397217, 0.9306666851043701, 0.934583306312561, 0.9368333220481873, 0.9379166960716248, 0.9423333406448364, 0.9441666603088379, 0.9466666579246521, 0.9473333358764648, 0.9485833048820496, 0.9489166736602783, 0.9514999985694885, 0.953000009059906, 0.953083336353302, 0.9539166688919067, 0.9546666741371155, 0.956416666507721, 0.9580833315849304, 0.9570833444595337, 0.9598333239555359, 0.9597499966621399, 0.9610000252723694, 0.9606666564941406, 0.9612500071525574, 0.9610833525657654, 0.9650833606719971, 0.9646666646003723, 0.9646666646003723, 0.9651666879653931, 0.9649166464805603, 0.965583324432373, 0.9665833115577698, 0.9667500257492065, 0.9676666855812073, 0.9670833349227905, 0.9672499895095825, 0.968666672706604, 0.9679166674613953, 0.968999981880188, 0.9678333401679993]}\n",
      "{'loss': [1.4971638917922974, 0.9023767113685608, 0.7391549348831177, 0.6610601544380188, 0.6083945035934448, 0.5754273533821106, 0.5498573184013367, 0.5265703797340393, 0.502798855304718, 0.4885222911834717, 0.4674646854400635, 0.4586217999458313, 0.44853588938713074, 0.43190819025039673, 0.42685168981552124, 0.4206296503543854, 0.40640801191329956, 0.4009280204772949, 0.3917005658149719, 0.3843167722225189, 0.3796460032463074, 0.37050992250442505, 0.3615186810493469, 0.35337138175964355, 0.3533703088760376, 0.34647929668426514, 0.3401699364185333, 0.33571353554725647, 0.333024263381958, 0.3265330195426941, 0.3150753080844879, 0.31360146403312683, 0.3121507465839386, 0.3073076605796814, 0.30123409628868103, 0.29881808161735535, 0.2879103422164917, 0.2885281443595886, 0.28765684366226196, 0.28731250762939453, 0.27843964099884033, 0.27853700518608093, 0.2775244116783142, 0.2715083360671997, 0.2711571156978607, 0.26498857140541077, 0.26189959049224854, 0.25805360078811646, 0.2539246678352356, 0.2600037157535553], 'accuracy': [0.5012500286102295, 0.7088541388511658, 0.7664166688919067, 0.7957708239555359, 0.8158125281333923, 0.828208327293396, 0.8355000019073486, 0.8460833430290222, 0.8533958196640015, 0.8561458587646484, 0.8652083277702332, 0.8667708039283752, 0.8721666932106018, 0.8756666779518127, 0.878250002861023, 0.8793958425521851, 0.8839374780654907, 0.886020839214325, 0.8878333568572998, 0.8890208601951599, 0.8927708268165588, 0.8958541750907898, 0.8970416784286499, 0.8993541598320007, 0.8994166851043701, 0.903083324432373, 0.9043124914169312, 0.9063541889190674, 0.9067291617393494, 0.9084374904632568, 0.9107916951179504, 0.9127708077430725, 0.9122499823570251, 0.9142083525657654, 0.9149583578109741, 0.9166458249092102, 0.9193958044052124, 0.9189375042915344, 0.9202708601951599, 0.9191250205039978, 0.921916663646698, 0.9234166741371155, 0.9226666688919067, 0.9233333468437195, 0.9241666793823242, 0.9261041879653931, 0.9260208606719971, 0.9287499785423279, 0.9291666746139526, 0.9281666874885559], 'val_loss': [0.6995992064476013, 0.4764367341995239, 0.3954589366912842, 0.3583816587924957, 0.32965680956840515, 0.3132697343826294, 0.2983476221561432, 0.28746721148490906, 0.27604562044143677, 0.26787078380584717, 0.2596702575683594, 0.25432661175727844, 0.2475980967283249, 0.24319997429847717, 0.23696106672286987, 0.23022061586380005, 0.2275618463754654, 0.22079694271087646, 0.21719883382320404, 0.21307556331157684, 0.21037329733371735, 0.204668328166008, 0.20209576189517975, 0.19835110008716583, 0.1950284242630005, 0.19335398077964783, 0.19029347598552704, 0.18447652459144592, 0.18175974488258362, 0.1809285432100296, 0.17749609053134918, 0.17304858565330505, 0.17391633987426758, 0.17051656544208527, 0.1692512482404709, 0.16672582924365997, 0.16641409695148468, 0.16414237022399902, 0.1601746678352356, 0.15881143510341644, 0.15893331170082092, 0.15470658242702484, 0.15353985130786896, 0.15206372737884521, 0.15201134979724884, 0.14967411756515503, 0.1499663144350052, 0.14795105159282684, 0.14744675159454346, 0.14518950879573822], 'val_accuracy': [0.8263333439826965, 0.8743333220481873, 0.8892499804496765, 0.8986666798591614, 0.9039166569709778, 0.9071666598320007, 0.9110000133514404, 0.9144166707992554, 0.9169999957084656, 0.9214166402816772, 0.9233333468437195, 0.9243333339691162, 0.9257500171661377, 0.9274166822433472, 0.9300000071525574, 0.9316666722297668, 0.9310833215713501, 0.9354166388511658, 0.9363333582878113, 0.9380000233650208, 0.9385833144187927, 0.9412500262260437, 0.9413333535194397, 0.9437500238418579, 0.9443333148956299, 0.9449999928474426, 0.9456666707992554, 0.9472500085830688, 0.9486666917800903, 0.9487500190734863, 0.9508333206176758, 0.9511666893959045, 0.9520000219345093, 0.9514999985694885, 0.9524999856948853, 0.952750027179718, 0.953249990940094, 0.9536666870117188, 0.9548333287239075, 0.956083357334137, 0.9555000066757202, 0.9565833210945129, 0.9569166898727417, 0.9571666717529297, 0.9574999809265137, 0.9575833082199097, 0.9573333263397217, 0.9584166407585144, 0.9585833549499512, 0.9592499732971191]}\n",
      "{'loss': [2.6798033714294434, 2.414320230484009, 2.29229736328125, 2.162355899810791, 1.9492979049682617, 1.7565940618515015, 1.6112172603607178, 1.4880361557006836, 1.3772802352905273, 1.2759013175964355, 1.205534815788269, 1.14669668674469, 1.0968371629714966, 1.062059760093689, 1.024153470993042, 1.0028038024902344, 0.9839504957199097, 0.9624651670455933, 0.9364020228385925, 0.924582302570343, 0.9061247706413269, 0.8922765254974365, 0.8843153715133667, 0.8648000359535217, 0.8519548177719116, 0.8416988849639893, 0.8256372213363647, 0.8197253346443176, 0.8036973476409912, 0.7964181900024414, 0.78934645652771, 0.7750946283340454, 0.768589198589325, 0.7567635178565979, 0.7566688060760498, 0.7435452342033386, 0.7362688183784485, 0.7310181260108948, 0.7267683744430542, 0.7179338932037354, 0.7113907933235168, 0.7004961967468262, 0.690285861492157, 0.6795698404312134, 0.6772655844688416, 0.673333466053009, 0.6720485687255859, 0.6621399521827698, 0.6543142199516296, 0.6497886776924133], 'accuracy': [0.10772916674613953, 0.1223333328962326, 0.14564582705497742, 0.20268750190734863, 0.2822916805744171, 0.3463124930858612, 0.39772915840148926, 0.4489166736602783, 0.49904167652130127, 0.5422083139419556, 0.5727291703224182, 0.5956249833106995, 0.6192083358764648, 0.6354374885559082, 0.6507916450500488, 0.6602708101272583, 0.6701041460037231, 0.6792291402816772, 0.6884375214576721, 0.6953333616256714, 0.703208327293396, 0.7088958621025085, 0.7144583463668823, 0.7201874852180481, 0.7272499799728394, 0.7335000038146973, 0.7378125190734863, 0.7425000071525574, 0.7477499842643738, 0.7534583210945129, 0.7548333406448364, 0.7583958506584167, 0.7621250152587891, 0.7696458101272583, 0.7717291712760925, 0.77322918176651, 0.7795624732971191, 0.7809374928474426, 0.7825624942779541, 0.7867708206176758, 0.7897708415985107, 0.7945208549499512, 0.7962708473205566, 0.8006250262260437, 0.8024791479110718, 0.8041041493415833, 0.8033958077430725, 0.8090000152587891, 0.8117499947547913, 0.8118333220481873], 'val_loss': [2.2587575912475586, 2.193369150161743, 1.9428863525390625, 1.5212419033050537, 1.764767050743103, 1.795417308807373, 1.673595666885376, 1.563538908958435, 1.5565136671066284, 1.5518330335617065, 1.6132962703704834, 1.648545742034912, 1.732908010482788, 1.7370134592056274, 1.7738441228866577, 1.7209275960922241, 1.8342435359954834, 1.8299022912979126, 1.8627004623413086, 1.843198299407959, 1.9129247665405273, 1.7816181182861328, 1.837769865989685, 1.9242932796478271, 1.8575465679168701, 1.8280750513076782, 1.9826477766036987, 1.828961968421936, 1.9006600379943848, 1.8306010961532593, 1.8052231073379517, 1.8604191541671753, 1.8439342975616455, 1.7896567583084106, 1.7631394863128662, 1.7321593761444092, 1.8221668004989624, 1.850095272064209, 1.6913566589355469, 1.6811420917510986, 1.7001054286956787, 1.7877241373062134, 1.6951342821121216, 1.6934270858764648, 1.6621408462524414, 1.6545506715774536, 1.596699595451355, 1.6465421915054321, 1.714863896369934, 1.6658506393432617], 'val_accuracy': [0.12200000137090683, 0.10824999958276749, 0.2776666581630707, 0.38866665959358215, 0.4242500066757202, 0.5079166889190674, 0.5742499828338623, 0.6333333253860474, 0.6627500057220459, 0.6931666731834412, 0.715583324432373, 0.7236666679382324, 0.7289999723434448, 0.7402499914169312, 0.746833324432373, 0.7574166655540466, 0.7524166703224182, 0.7622500061988831, 0.7629166841506958, 0.768750011920929, 0.7703333497047424, 0.7851666808128357, 0.7839166522026062, 0.7834166884422302, 0.7914999723434448, 0.7994166612625122, 0.7959166765213013, 0.8096666932106018, 0.8115000128746033, 0.8185833096504211, 0.8217499852180481, 0.8213333487510681, 0.8294166922569275, 0.8346666693687439, 0.8356666564941406, 0.8395833373069763, 0.8354166746139526, 0.8346666693687439, 0.8483333587646484, 0.8497499823570251, 0.8475833535194397, 0.8451666831970215, 0.8569166660308838, 0.8604166507720947, 0.856249988079071, 0.8632500171661377, 0.8694166541099548, 0.8614166378974915, 0.8608333468437195, 0.8725000023841858]}\n",
      "{'loss': [2.292764186859131, 2.2662594318389893, 2.157824993133545, 1.792412281036377, 1.4533629417419434, 1.2157025337219238, 1.0359246730804443, 0.9158285856246948, 0.8245954513549805, 0.7540875673294067, 0.7028517127037048, 0.6624400615692139, 0.6236379146575928, 0.5936080813407898, 0.5656986236572266, 0.5435346364974976, 0.5178706645965576, 0.5025591254234314, 0.4789048135280609, 0.46051159501075745, 0.45213061571121216, 0.4340459108352661, 0.41767793893814087, 0.40499529242515564, 0.39529767632484436, 0.38146013021469116, 0.37596407532691956, 0.36071300506591797, 0.3523483872413635, 0.3442530035972595, 0.33104002475738525, 0.3286384344100952, 0.3221111595630646, 0.31407180428504944, 0.30782148241996765, 0.3008664846420288, 0.29496240615844727, 0.2906825542449951, 0.28699302673339844, 0.2784443497657776, 0.27553626894950867, 0.2696259915828705, 0.2634720504283905, 0.2558755576610565, 0.25002142786979675, 0.24720852077007294, 0.24590079486370087, 0.24436067044734955, 0.23627367615699768, 0.23637241125106812], 'accuracy': [0.16870833933353424, 0.25833332538604736, 0.3324374854564667, 0.4176041781902313, 0.5019583106040955, 0.5869791507720947, 0.6585624814033508, 0.7087708115577698, 0.7459999918937683, 0.7717499732971191, 0.7916041612625122, 0.8100000023841858, 0.8211666941642761, 0.8306458592414856, 0.8411874771118164, 0.8476250171661377, 0.8583333492279053, 0.8645625114440918, 0.8693749904632568, 0.8736875057220459, 0.8791041374206543, 0.8823541402816772, 0.8877708315849304, 0.8907708525657654, 0.895354151725769, 0.8987500071525574, 0.9006249904632568, 0.9035208225250244, 0.9073958396911621, 0.9090625047683716, 0.9129791855812073, 0.9135208129882812, 0.9147499799728394, 0.9163749814033508, 0.9183750152587891, 0.921833336353302, 0.9224374890327454, 0.9246875047683716, 0.9253541827201843, 0.9282083511352539, 0.9294583201408386, 0.929604172706604, 0.9330000281333923, 0.9333333373069763, 0.9353125095367432, 0.9367708563804626, 0.9373124837875366, 0.937125027179718, 0.9392083287239075, 0.9395624995231628], 'val_loss': [2.282176971435547, 2.238269329071045, 1.9441274404525757, 1.381343126296997, 1.0146267414093018, 0.7995333671569824, 0.6519741415977478, 0.5536066889762878, 0.4890192449092865, 0.43870067596435547, 0.40333932638168335, 0.3727627694606781, 0.34826505184173584, 0.3297334909439087, 0.31223782896995544, 0.298003226518631, 0.2827291488647461, 0.2712394893169403, 0.25942376255989075, 0.2497188150882721, 0.24023419618606567, 0.23155808448791504, 0.22465582191944122, 0.21574875712394714, 0.21048414707183838, 0.2026440054178238, 0.19740574061870575, 0.19334284961223602, 0.18665200471878052, 0.1805388182401657, 0.17666999995708466, 0.17325365543365479, 0.16874068975448608, 0.16595032811164856, 0.16213007271289825, 0.16000396013259888, 0.1565166860818863, 0.1533428430557251, 0.15046052634716034, 0.14894481003284454, 0.146779403090477, 0.14344558119773865, 0.14264129102230072, 0.13909953832626343, 0.1391521543264389, 0.13463591039180756, 0.13544979691505432, 0.13326145708560944, 0.1295199692249298, 0.1298285871744156], 'val_accuracy': [0.26491665840148926, 0.44350001215934753, 0.49433332681655884, 0.5995000004768372, 0.7168333530426025, 0.7881666421890259, 0.8364166617393494, 0.8560000061988831, 0.8738333582878113, 0.8867499828338623, 0.8940833210945129, 0.9007499814033508, 0.906000018119812, 0.909583330154419, 0.9128333330154419, 0.9178333282470703, 0.9204166531562805, 0.9240000247955322, 0.9272500276565552, 0.9288333058357239, 0.9316666722297668, 0.9349166750907898, 0.9361666440963745, 0.9390000104904175, 0.940583348274231, 0.9423333406448364, 0.9445833563804626, 0.9455833435058594, 0.9474166631698608, 0.9503333568572998, 0.9493333101272583, 0.9512500166893005, 0.9516666531562805, 0.9524999856948853, 0.9545000195503235, 0.9546666741371155, 0.9547500014305115, 0.9555833339691162, 0.9580000042915344, 0.9572499990463257, 0.9581666588783264, 0.9589166641235352, 0.9598333239555359, 0.9606666564941406, 0.9610833525657654, 0.9613333344459534, 0.9621666669845581, 0.9628333449363708, 0.9632499814033508, 0.9637500047683716]}\n",
      "{'loss': [2.294379949569702, 2.274707078933716, 2.238367795944214, 2.1019017696380615, 1.7852065563201904, 1.4343581199645996, 1.1884138584136963, 1.026493787765503, 0.9160712957382202, 0.8329970836639404, 0.7759537100791931, 0.7222797274589539, 0.6828628778457642, 0.6471250653266907, 0.6238048672676086, 0.5930674076080322, 0.5765914916992188, 0.5553997755050659, 0.5334410071372986, 0.5187774300575256, 0.5055757761001587, 0.4929134249687195, 0.4779725670814514, 0.46973156929016113, 0.4471786320209503, 0.44006726145744324, 0.4333139955997467, 0.42366939783096313, 0.4164283573627472, 0.40986764430999756, 0.3951091766357422, 0.38695645332336426, 0.37800341844558716, 0.37103015184402466, 0.36760830879211426, 0.3559494614601135, 0.35055017471313477, 0.35062989592552185, 0.33683767914772034, 0.33624133467674255, 0.329388290643692, 0.3220672905445099, 0.31535962224006653, 0.31239646673202515, 0.31269457936286926, 0.30042725801467896, 0.2990065813064575, 0.2927792966365814, 0.2869632840156555, 0.28724217414855957], 'accuracy': [0.15314583480358124, 0.2199583351612091, 0.3023958206176758, 0.3564375042915344, 0.4098958373069763, 0.5118749737739563, 0.6021875143051147, 0.6643333435058594, 0.7073333263397217, 0.737291693687439, 0.7602499723434448, 0.7810624837875366, 0.7943750023841858, 0.807854175567627, 0.8197500109672546, 0.8270833492279053, 0.8334791660308838, 0.8414583206176758, 0.8493958115577698, 0.8547083139419556, 0.8584374785423279, 0.8654791712760925, 0.8661249876022339, 0.8707708120346069, 0.8771250247955322, 0.8785625100135803, 0.8823541402816772, 0.8837708234786987, 0.8865833282470703, 0.8883958458900452, 0.8922708630561829, 0.8945624828338623, 0.8960624933242798, 0.901354193687439, 0.9008333086967468, 0.9023125171661377, 0.9048749804496765, 0.905875027179718, 0.9089166522026062, 0.9097499847412109, 0.9102500081062317, 0.913979172706604, 0.9151041507720947, 0.9163125157356262, 0.9178333282470703, 0.9200833439826965, 0.9194999933242798, 0.9207708239555359, 0.9230208396911621, 0.9223333597183228], 'val_loss': [2.2852656841278076, 2.2605409622192383, 2.198340654373169, 1.888222336769104, 1.3882286548614502, 0.9936923980712891, 0.7913180589675903, 0.6629035472869873, 0.576352059841156, 0.5094907283782959, 0.46848204731941223, 0.4350297152996063, 0.4056890904903412, 0.38375696539878845, 0.36917582154273987, 0.3501950800418854, 0.3336336612701416, 0.32242435216903687, 0.3125461935997009, 0.3021934926509857, 0.29380640387535095, 0.2842308282852173, 0.2761707901954651, 0.2685716152191162, 0.2625594735145569, 0.25561800599098206, 0.24822954833507538, 0.24250297248363495, 0.2361426055431366, 0.23088830709457397, 0.2272711843252182, 0.22315381467342377, 0.2169177383184433, 0.21342729032039642, 0.20803026854991913, 0.2045249491930008, 0.20115305483341217, 0.19757062196731567, 0.19426560401916504, 0.19171860814094543, 0.18742763996124268, 0.18517622351646423, 0.18378235399723053, 0.17887990176677704, 0.17641080915927887, 0.17367950081825256, 0.1711129993200302, 0.1696551889181137, 0.16638128459453583, 0.16399827599525452], 'val_accuracy': [0.17383334040641785, 0.2775833308696747, 0.4233333468437195, 0.4268333315849304, 0.6377500295639038, 0.7484999895095825, 0.7953333258628845, 0.8269166946411133, 0.8453333377838135, 0.8655833601951599, 0.8740833401679993, 0.8829166889190674, 0.8897500038146973, 0.8953333497047424, 0.8985000252723694, 0.9012500047683716, 0.90625, 0.9088333249092102, 0.9114166498184204, 0.9145833253860474, 0.9156666398048401, 0.9194999933242798, 0.9208333492279053, 0.9226666688919067, 0.9240833520889282, 0.9259999990463257, 0.9291666746139526, 0.9303333163261414, 0.9326666593551636, 0.934499979019165, 0.9355833530426025, 0.9361666440963745, 0.9367499947547913, 0.9389166831970215, 0.9409999847412109, 0.9418333172798157, 0.9420833587646484, 0.9428333044052124, 0.9439166784286499, 0.9449999928474426, 0.9454166889190674, 0.9467499852180481, 0.9470000267028809, 0.9487500190734863, 0.9503333568572998, 0.9506666660308838, 0.9513333439826965, 0.9518333077430725, 0.9522500038146973, 0.9537500143051147]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    input_shape = (28 * 28,)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(512, activation=activation, input_shape=input_shape, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(256, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['sigmoid', 'tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5depth128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
