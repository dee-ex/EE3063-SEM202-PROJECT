{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "98d6e936-4897-4a69-d33b-bdfa2229e2ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 63s 50ms/step - loss: 1.3045 - accuracy: 0.6165 - val_loss: 0.2561 - val_accuracy: 0.9330\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.2267 - accuracy: 0.9409 - val_loss: 0.1526 - val_accuracy: 0.9583\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.1552 - accuracy: 0.9575 - val_loss: 0.1137 - val_accuracy: 0.9684\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 0.1136 - accuracy: 0.9678 - val_loss: 0.0933 - val_accuracy: 0.9740\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 0.0943 - accuracy: 0.9724 - val_loss: 0.0842 - val_accuracy: 0.9762\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 0.0801 - accuracy: 0.9777 - val_loss: 0.0785 - val_accuracy: 0.9775\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0682 - accuracy: 0.9796 - val_loss: 0.0652 - val_accuracy: 0.9825\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.0600 - val_accuracy: 0.9827\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0565 - accuracy: 0.9839 - val_loss: 0.0571 - val_accuracy: 0.9837\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0517 - accuracy: 0.9852 - val_loss: 0.0544 - val_accuracy: 0.9839\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 0.0555 - val_accuracy: 0.9834\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0396 - accuracy: 0.9893 - val_loss: 0.0504 - val_accuracy: 0.9854\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0386 - accuracy: 0.9894 - val_loss: 0.0497 - val_accuracy: 0.9855\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.0467 - val_accuracy: 0.9858\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 0.0484 - val_accuracy: 0.9856\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.0465 - val_accuracy: 0.9862\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0292 - accuracy: 0.9925 - val_loss: 0.0458 - val_accuracy: 0.9868\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0423 - val_accuracy: 0.9872\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0279 - accuracy: 0.9925 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0256 - accuracy: 0.9939 - val_loss: 0.0411 - val_accuracy: 0.9879\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.0406 - val_accuracy: 0.9874\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.0435 - val_accuracy: 0.9877\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 0.0399 - val_accuracy: 0.9890\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.0398 - val_accuracy: 0.9883\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.0527 - val_accuracy: 0.9846\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0172 - accuracy: 0.9965 - val_loss: 0.0423 - val_accuracy: 0.9876\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.0386 - val_accuracy: 0.9888\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.0389 - val_accuracy: 0.9886\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.0416 - val_accuracy: 0.9882\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.0372 - val_accuracy: 0.9887\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.0377 - val_accuracy: 0.9889\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.0386 - val_accuracy: 0.9892\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 0.0437 - val_accuracy: 0.9869\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0398 - val_accuracy: 0.9883\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.0394 - val_accuracy: 0.9887\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.0380 - val_accuracy: 0.9887\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0369 - val_accuracy: 0.9893\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.0376 - val_accuracy: 0.9898\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.0429 - val_accuracy: 0.9879\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.0391 - val_accuracy: 0.9889\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.0384 - val_accuracy: 0.9894\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.0412 - val_accuracy: 0.9886\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.0387 - val_accuracy: 0.9893\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0402 - val_accuracy: 0.9889\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.0382 - val_accuracy: 0.9893\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0382 - val_accuracy: 0.9896\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.0442 - val_accuracy: 0.9877\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.0387 - val_accuracy: 0.9891\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0372 - val_accuracy: 0.9896\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0388 - val_accuracy: 0.9889\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 19s 45ms/step - loss: 2.3022 - accuracy: 0.1094 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.2998 - accuracy: 0.1136 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.2985 - accuracy: 0.1143 - val_loss: 2.2963 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.2928 - accuracy: 0.1131 - val_loss: 2.2729 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.1192 - accuracy: 0.2431 - val_loss: 0.9838 - val_accuracy: 0.6803\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.8300 - accuracy: 0.7284 - val_loss: 0.2602 - val_accuracy: 0.9238\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.2611 - accuracy: 0.9183 - val_loss: 0.2039 - val_accuracy: 0.9383\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.1626 - accuracy: 0.9493 - val_loss: 0.1192 - val_accuracy: 0.9650\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.1147 - accuracy: 0.9634 - val_loss: 0.1008 - val_accuracy: 0.9696\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0960 - accuracy: 0.9708 - val_loss: 0.0912 - val_accuracy: 0.9722\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0766 - accuracy: 0.9764 - val_loss: 0.0849 - val_accuracy: 0.9751\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0652 - accuracy: 0.9796 - val_loss: 0.0797 - val_accuracy: 0.9759\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0546 - accuracy: 0.9823 - val_loss: 0.0846 - val_accuracy: 0.9772\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.0699 - val_accuracy: 0.9805\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0404 - accuracy: 0.9881 - val_loss: 0.0743 - val_accuracy: 0.9787\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 0.0645 - val_accuracy: 0.9808\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.0647 - val_accuracy: 0.9822\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.0772 - val_accuracy: 0.9787\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.0616 - val_accuracy: 0.9811\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0678 - val_accuracy: 0.9808\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.0632 - val_accuracy: 0.9820\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0844 - val_accuracy: 0.9821\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0791 - val_accuracy: 0.9777\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0732 - val_accuracy: 0.9818\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0790 - val_accuracy: 0.9827\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0727 - val_accuracy: 0.9818\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0680 - val_accuracy: 0.9829\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0771 - val_accuracy: 0.9809\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.0888 - val_accuracy: 0.9821\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0712 - val_accuracy: 0.9827\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0753 - val_accuracy: 0.9833\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0745 - val_accuracy: 0.9848\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.1093 - val_accuracy: 0.9793\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0866 - val_accuracy: 0.9823\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0797 - val_accuracy: 0.9835\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0940 - val_accuracy: 0.9847\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0776 - val_accuracy: 0.9853\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0847 - val_accuracy: 0.9837\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0840 - val_accuracy: 0.9834\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1008 - val_accuracy: 0.9851\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1130 - val_accuracy: 0.9850\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 1.1168e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9852\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 4.1478e-05 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9858\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 5.3165e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9857\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 8.7374e-04 - accuracy: 0.9998 - val_loss: 0.0898 - val_accuracy: 0.9840\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0966 - val_accuracy: 0.9843\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 5.9696e-04 - accuracy: 0.9999 - val_loss: 0.1066 - val_accuracy: 0.9850\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 5.1276e-05 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9847\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.4074e-05 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9847\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 23s 52ms/step - loss: 2.3020 - accuracy: 0.1122 - val_loss: 2.3018 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.3009 - accuracy: 0.1121 - val_loss: 2.3016 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.3004 - accuracy: 0.1129 - val_loss: 2.3009 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.3001 - accuracy: 0.1108 - val_loss: 2.2993 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.2977 - accuracy: 0.1133 - val_loss: 2.2940 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.2882 - accuracy: 0.1142 - val_loss: 2.2394 - val_accuracy: 0.2342\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.8108 - accuracy: 0.4798 - val_loss: 0.3583 - val_accuracy: 0.8875\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.3504 - accuracy: 0.8882 - val_loss: 0.1638 - val_accuracy: 0.9502\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.1620 - accuracy: 0.9501 - val_loss: 0.1614 - val_accuracy: 0.9453\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.1099 - accuracy: 0.9659 - val_loss: 0.1110 - val_accuracy: 0.9653\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0856 - accuracy: 0.9719 - val_loss: 0.0761 - val_accuracy: 0.9769\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0665 - accuracy: 0.9796 - val_loss: 0.0803 - val_accuracy: 0.9758\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0575 - accuracy: 0.9823 - val_loss: 0.0716 - val_accuracy: 0.9787\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 0.0636 - val_accuracy: 0.9812\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.0629 - val_accuracy: 0.9826\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.0616 - val_accuracy: 0.9817\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.0684 - val_accuracy: 0.9804\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.0657 - val_accuracy: 0.9814\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0592 - val_accuracy: 0.9843\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0625 - val_accuracy: 0.9837\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0575 - val_accuracy: 0.9843\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0636 - val_accuracy: 0.9837\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0609 - val_accuracy: 0.9850\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0669 - val_accuracy: 0.9852\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0705 - val_accuracy: 0.9846\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0651 - val_accuracy: 0.9844\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0695 - val_accuracy: 0.9831\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0719 - val_accuracy: 0.9838\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0770 - val_accuracy: 0.9846\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0989 - val_accuracy: 0.9779\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0836 - val_accuracy: 0.9827\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.0788 - val_accuracy: 0.9843\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0841 - val_accuracy: 0.9856\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1022 - val_accuracy: 0.9826\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0672 - val_accuracy: 0.9841\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0737 - val_accuracy: 0.9857\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0763 - val_accuracy: 0.9865\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0849 - val_accuracy: 0.9864\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.8670e-04 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9865\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 6.7005e-05 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9867\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 3.0651e-05 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9868\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 2.6620e-05 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9867\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.0065e-05 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9868\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 1.9147e-05 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9865\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.5646e-05 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9867\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.3159e-05 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9865\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 1.1975e-05 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9865\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.1890e-05 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9865\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 9.5759e-06 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9865\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 9.8372e-06 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9865\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 21s 50ms/step - loss: 1.3639 - accuracy: 0.5678 - val_loss: 0.1854 - val_accuracy: 0.9398\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.1670 - accuracy: 0.9483 - val_loss: 0.0980 - val_accuracy: 0.9699\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0986 - accuracy: 0.9690 - val_loss: 0.0741 - val_accuracy: 0.9772\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0704 - accuracy: 0.9783 - val_loss: 0.0728 - val_accuracy: 0.9771\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.0614 - val_accuracy: 0.9801\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.0576 - val_accuracy: 0.9821\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.0532 - val_accuracy: 0.9843\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.0526 - val_accuracy: 0.9841\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.0694 - val_accuracy: 0.9789\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.0475 - val_accuracy: 0.9863\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.0488 - val_accuracy: 0.9862\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0528 - val_accuracy: 0.9844\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0574 - val_accuracy: 0.9843\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0620 - val_accuracy: 0.9830\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0515 - val_accuracy: 0.9873\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0711 - val_accuracy: 0.9812\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0778 - val_accuracy: 0.9808\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.0491 - val_accuracy: 0.9870\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0492 - val_accuracy: 0.9872\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0522 - val_accuracy: 0.9875\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0564 - val_accuracy: 0.9877\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0571 - val_accuracy: 0.9879\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.1172 - val_accuracy: 0.9657\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.0436 - val_accuracy: 0.9872\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.0478 - val_accuracy: 0.9868\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0530 - val_accuracy: 0.9858\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0542 - val_accuracy: 0.9867\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0557 - val_accuracy: 0.9879\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 8.7254e-04 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9878\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 6.5641e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9883\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 4.9515e-04 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9881\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 3.7904e-04 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9880\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 3.1671e-04 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9881\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.6859e-04 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9879\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.2277e-04 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9880\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.9703e-04 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9883\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.7113e-04 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 0.9881\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 1.5978e-04 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9878\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.4993e-04 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9881\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 1.2386e-04 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9879\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.2037e-04 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9879\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 1.0312e-04 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9879\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 9.9968e-05 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9879\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 9.3614e-05 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9878\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 8.7881e-05 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9878\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 8.0847e-05 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9880\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 7.1631e-05 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9878\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 6.9060e-05 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9877\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 6.5122e-05 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9880\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 6.1115e-05 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9877\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 20s 48ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0952 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0995 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0959 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0958 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0960 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: nan - accuracy: 0.0967 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.1015 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: nan - accuracy: 0.0965 - val_loss: nan - val_accuracy: 0.0995\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 35s 85ms/step - loss: 2.3022 - accuracy: 0.1122 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 33s 87ms/step - loss: 2.3014 - accuracy: 0.1133 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3012 - accuracy: 0.1133 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3016 - accuracy: 0.1108 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 2.3008 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3011 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3011 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3008 - accuracy: 0.1160 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3010 - accuracy: 0.1150 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3010 - accuracy: 0.1144 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3011 - accuracy: 0.1145 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3009 - accuracy: 0.1159 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3011 - accuracy: 0.1135 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3010 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3014 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3014 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.3010 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3014 - accuracy: 0.1107 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3008 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3004 - accuracy: 0.1185 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3008 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3010 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3006 - accuracy: 0.1163 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3013 - accuracy: 0.1122 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3008 - accuracy: 0.1159 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3013 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3010 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3011 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3008 - accuracy: 0.1168 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 33s 88ms/step - loss: 2.3004 - accuracy: 0.1154 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.3010 - accuracy: 0.1131 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 33s 88ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3011 - accuracy: 0.1111 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.3006 - accuracy: 0.1159 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3005 - accuracy: 0.1162 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 33s 88ms/step - loss: 2.3007 - accuracy: 0.1146 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3007 - accuracy: 0.1160 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 31s 81ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3007 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3007 - accuracy: 0.1162 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 30s 81ms/step - loss: 2.3009 - accuracy: 0.1155 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 26s 61ms/step - loss: 2.3023 - accuracy: 0.1104 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3011 - accuracy: 0.1146 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3006 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3008 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3008 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3011 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3009 - accuracy: 0.1158 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3009 - accuracy: 0.1145 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3014 - accuracy: 0.1118 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3007 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3007 - accuracy: 0.1167 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3011 - accuracy: 0.1129 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3009 - accuracy: 0.1152 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 2.3008 - accuracy: 0.1156 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3011 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3008 - accuracy: 0.1155 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3008 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3008 - accuracy: 0.1166 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3008 - accuracy: 0.1156 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3015 - accuracy: 0.1113 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3013 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3007 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3007 - accuracy: 0.1154 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3007 - accuracy: 0.1152 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3007 - accuracy: 0.1150 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3008 - accuracy: 0.1145 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3007 - accuracy: 0.1146 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3012 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3011 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3008 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 2.3012 - accuracy: 0.1136 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3009 - accuracy: 0.1165 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3005 - accuracy: 0.1172 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3007 - accuracy: 0.1154 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3011 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3012 - accuracy: 0.1145 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3012 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.3008 - accuracy: 0.1155 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.3011 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3005 - accuracy: 0.1165 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "{'loss': [0.7442235350608826, 0.20340120792388916, 0.14501041173934937, 0.10929639637470245, 0.09131063520908356, 0.07819099724292755, 0.06928366422653198, 0.06133826822042465, 0.05486937612295151, 0.05060963332653046, 0.04644341394305229, 0.042243074625730515, 0.03950333595275879, 0.0368758961558342, 0.03836580738425255, 0.031939513981342316, 0.0297806728631258, 0.028371762484312057, 0.026854069903492928, 0.024472124874591827, 0.023497868329286575, 0.022158604115247726, 0.020533272996544838, 0.020038658753037453, 0.018407797440886497, 0.017055561766028404, 0.01586053892970085, 0.015993066132068634, 0.014752577058970928, 0.013297731056809425, 0.012805551290512085, 0.012707705609500408, 0.011262508109211922, 0.010642442852258682, 0.009957178495824337, 0.008886069990694523, 0.00899483636021614, 0.008022474125027657, 0.0075147999450564384, 0.007330229505896568, 0.0064815375953912735, 0.005960687063634396, 0.005548861809074879, 0.005536044016480446, 0.005107223521918058, 0.0046005696058273315, 0.02220950648188591, 0.0076384455896914005, 0.00502435676753521, 0.004161822609603405], 'accuracy': [0.7977291941642761, 0.945395827293396, 0.9598125219345093, 0.968916654586792, 0.9738333225250244, 0.9781666398048401, 0.9797916412353516, 0.9825416803359985, 0.9843124747276306, 0.9855208396911621, 0.9867500066757202, 0.9879583120346069, 0.9890833497047424, 0.9901041388511658, 0.9892500042915344, 0.9916041493415833, 0.992145836353302, 0.992354154586792, 0.9929999709129333, 0.9937916398048401, 0.9940208196640015, 0.9943749904632568, 0.9950208067893982, 0.9953333139419556, 0.995437502861023, 0.9961458444595337, 0.9965208172798157, 0.9963750243186951, 0.9965624809265137, 0.9971458315849304, 0.9973333477973938, 0.9971666932106018, 0.9977083206176758, 0.9980624914169312, 0.9981458187103271, 0.9985833168029785, 0.9983124732971191, 0.9988541603088379, 0.9988124966621399, 0.9988958239555359, 0.9991666674613953, 0.9992291927337646, 0.9994791746139526, 0.9993958473205566, 0.9993749856948853, 0.9996458292007446, 0.995270848274231, 0.9986458420753479, 0.9993333220481873, 0.9996041655540466], 'val_loss': [0.2560741603374481, 0.15256167948246002, 0.11374460905790329, 0.09334680438041687, 0.08421342819929123, 0.07853477448225021, 0.0651606023311615, 0.059957459568977356, 0.05712030455470085, 0.05438956245779991, 0.055546052753925323, 0.05041644722223282, 0.04970887675881386, 0.04674931988120079, 0.048406485468149185, 0.04645175859332085, 0.04577863961458206, 0.04227496683597565, 0.04322312772274017, 0.04111204296350479, 0.040568139404058456, 0.04348162189126015, 0.03989935293793678, 0.03981209918856621, 0.05271020904183388, 0.04225119948387146, 0.038616955280303955, 0.03887559100985527, 0.04157361760735512, 0.03717605769634247, 0.037665411829948425, 0.03861436992883682, 0.04374762997031212, 0.03977179527282715, 0.03936360776424408, 0.03804410621523857, 0.03688616305589676, 0.03755122050642967, 0.04285632446408272, 0.03911009803414345, 0.03838156536221504, 0.04122810438275337, 0.03869318217039108, 0.040234412997961044, 0.038181740790605545, 0.0381912887096405, 0.04419635981321335, 0.03874911740422249, 0.037206318229436874, 0.038810454308986664], 'val_accuracy': [0.9330000281333923, 0.9583333134651184, 0.968416690826416, 0.9739999771118164, 0.9761666655540466, 0.9775000214576721, 0.9825000166893005, 0.9826666712760925, 0.9837499856948853, 0.9839166402816772, 0.9834166765213013, 0.9854166507720947, 0.9854999780654907, 0.9858333468437195, 0.9855833053588867, 0.9861666560173035, 0.9867500066757202, 0.9872499704360962, 0.9869166612625122, 0.9879166483879089, 0.987416684627533, 0.987666666507721, 0.9890000224113464, 0.9883333444595337, 0.98458331823349, 0.987583339214325, 0.9888333082199097, 0.9885833263397217, 0.9881666898727417, 0.9886666536331177, 0.9889166951179504, 0.9891666769981384, 0.9869166612625122, 0.9882500171661377, 0.9887499809265137, 0.9886666536331177, 0.9893333315849304, 0.9897500276565552, 0.9879166483879089, 0.9889166951179504, 0.9894166588783264, 0.9885833263397217, 0.9893333315849304, 0.9889166951179504, 0.9892500042915344, 0.9895833134651184, 0.9877499938011169, 0.9890833497047424, 0.9895833134651184, 0.9889166951179504]}\n",
      "{'loss': [2.301670789718628, 2.300640344619751, 2.2997989654541016, 2.297635316848755, 2.288071870803833, 1.7796047925949097, 0.6089199781417847, 0.22909767925739288, 0.14785261452198029, 0.11193747073411942, 0.08998197317123413, 0.07528714090585709, 0.0639984980225563, 0.0554068386554718, 0.04954652488231659, 0.04253542423248291, 0.03810998424887657, 0.03328891098499298, 0.028955938294529915, 0.02759883552789688, 0.02386724390089512, 0.02230757102370262, 0.01836507022380829, 0.0185311920940876, 0.014564295299351215, 0.012996861711144447, 0.012035515159368515, 0.011000271886587143, 0.010642826557159424, 0.007311755325645208, 0.007821108214557171, 0.007319044321775436, 0.007088875398039818, 0.008592357859015465, 0.005193490069359541, 0.005664775148034096, 0.005066487472504377, 0.005574179347604513, 0.007370153907686472, 0.0031720444094389677, 0.0007168963202275336, 0.0007295098039321601, 9.680289076641202e-05, 9.841116116149351e-05, 0.0001823573256842792, 0.0033994349651038647, 0.0024750730954110622, 0.00040847272612154484, 4.4732609239872545e-05, 2.3146702005760744e-05], 'accuracy': [0.11314583569765091, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.4000833332538605, 0.8037499785423279, 0.9288333058357239, 0.9537291526794434, 0.9647291898727417, 0.9717708230018616, 0.9767083525657654, 0.979604184627533, 0.9823541641235352, 0.9844791889190674, 0.9869999885559082, 0.987541675567627, 0.9895625114440918, 0.9903333187103271, 0.9909999966621399, 0.9921875, 0.992437481880188, 0.9938541650772095, 0.9937083125114441, 0.9949374794960022, 0.9955624938011169, 0.9960208535194397, 0.9961249828338623, 0.9966874718666077, 0.9976666569709778, 0.9973124861717224, 0.9977291822433472, 0.9977291822433472, 0.9971666932106018, 0.9982500076293945, 0.9980000257492065, 0.9983124732971191, 0.9982291460037231, 0.9972708225250244, 0.9989583492279053, 0.999875009059906, 0.99979168176651, 1.0, 0.9999791383743286, 0.9999374747276306, 0.9990416765213013, 0.9992499947547913, 0.9999374747276306, 1.0, 1.0], 'val_loss': [2.301654577255249, 2.3010921478271484, 2.3000824451446533, 2.296255350112915, 2.2729475498199463, 0.9837923049926758, 0.2601838707923889, 0.20390371978282928, 0.11921803653240204, 0.10075467824935913, 0.0912303552031517, 0.08490611612796783, 0.07968678325414658, 0.08463989943265915, 0.06987551599740982, 0.07429002225399017, 0.06451468169689178, 0.06466507166624069, 0.07722336053848267, 0.06163827329874039, 0.06775704026222229, 0.06323977559804916, 0.08440329879522324, 0.07910232245922089, 0.07316149026155472, 0.07896002382040024, 0.07270915061235428, 0.06802308559417725, 0.07713506370782852, 0.08884844928979874, 0.07117670029401779, 0.0752926617860794, 0.07452090084552765, 0.1092686578631401, 0.08664586395025253, 0.07972346246242523, 0.09397921711206436, 0.07762238383293152, 0.0847267359495163, 0.08401577919721603, 0.10083962976932526, 0.1130405142903328, 0.11367402970790863, 0.1141485869884491, 0.11578330397605896, 0.08981292694807053, 0.09661968797445297, 0.10660790652036667, 0.1128571406006813, 0.11693785339593887], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.6803333163261414, 0.9238333106040955, 0.9382500052452087, 0.9649999737739563, 0.9695833325386047, 0.9722499847412109, 0.9750833511352539, 0.9759166836738586, 0.9771666526794434, 0.9804999828338623, 0.9786666631698608, 0.9808333516120911, 0.9821666479110718, 0.9787499904632568, 0.981083333492279, 0.9807500243186951, 0.9819999933242798, 0.9820833206176758, 0.9776666760444641, 0.9818333387374878, 0.9826666712760925, 0.9817500114440918, 0.9829166531562805, 0.9809166789054871, 0.9820833206176758, 0.9827499985694885, 0.9833333492279053, 0.9848333597183228, 0.9793333411216736, 0.9823333621025085, 0.9835000038146973, 0.984749972820282, 0.9853333234786987, 0.9837499856948853, 0.9834166765213013, 0.9850833415985107, 0.9850000143051147, 0.9852499961853027, 0.9857500195503235, 0.9856666922569275, 0.984000027179718, 0.984250009059906, 0.9850000143051147, 0.984749972820282, 0.984666645526886]}\n",
      "{'loss': [2.3015923500061035, 2.300718307495117, 2.3001182079315186, 2.299055576324463, 2.2961387634277344, 2.2791740894317627, 1.268249750137329, 0.28051289916038513, 0.14751729369163513, 0.10519743710756302, 0.08173565566539764, 0.06631464511156082, 0.05629444867372513, 0.04650652036070824, 0.04176473245024681, 0.03641074523329735, 0.03024815395474434, 0.02739047259092331, 0.023256264626979828, 0.020339708775281906, 0.018507767468690872, 0.01578516699373722, 0.013820789754390717, 0.01251349225640297, 0.009221186861395836, 0.009332237765192986, 0.010793721303343773, 0.005551785230636597, 0.005755625199526548, 0.0050898222252726555, 0.0069955443032085896, 0.005676953587681055, 0.005720228422433138, 0.003469576593488455, 0.006314457394182682, 0.003880706150084734, 0.0025895056314766407, 0.0009567119413986802, 0.00016531735309399664, 5.134049933985807e-05, 3.166629176121205e-05, 2.4782453692751005e-05, 2.07091561605921e-05, 1.7595210010767914e-05, 1.543465805298183e-05, 1.3625266547023784e-05, 1.2251281077624299e-05, 1.1142421499243937e-05, 1.0157338692806661e-05, 9.37451477511786e-06], 'accuracy': [0.11349999904632568, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.12033333629369736, 0.6196249723434448, 0.9102916717529297, 0.9546458125114441, 0.9668958187103271, 0.9738333225250244, 0.9794374704360962, 0.9824374914169312, 0.9853749871253967, 0.9867083430290222, 0.9886041879653931, 0.9904375076293945, 0.9911041855812073, 0.992229163646698, 0.9933541417121887, 0.9939583539962769, 0.9947291612625122, 0.9952083230018616, 0.9960625171661377, 0.997041642665863, 0.9968125224113464, 0.9965000152587891, 0.9982291460037231, 0.9981666803359985, 0.9984583258628845, 0.9975208044052124, 0.9978541731834412, 0.9981666803359985, 0.9987499713897705, 0.9981666803359985, 0.9990208148956299, 0.9992916584014893, 0.9997708201408386, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.3017983436584473, 2.3015856742858887, 2.3008737564086914, 2.2992870807647705, 2.2939655780792236, 2.239436626434326, 0.35833844542503357, 0.16376282274723053, 0.161357581615448, 0.1109696552157402, 0.07607750594615936, 0.08030815422534943, 0.07157716155052185, 0.06359048187732697, 0.06294935196638107, 0.061614781618118286, 0.06841697543859482, 0.06571780145168304, 0.05918207764625549, 0.06249046325683594, 0.05750546231865883, 0.06361567974090576, 0.060871098190546036, 0.06691800802946091, 0.0704968199133873, 0.06514477729797363, 0.06950245052576065, 0.07192899286746979, 0.07702666521072388, 0.09893868118524551, 0.08355042338371277, 0.07880242168903351, 0.08406563103199005, 0.1022275984287262, 0.06716490536928177, 0.07367074489593506, 0.07628129422664642, 0.0848899856209755, 0.09290524572134018, 0.09525894373655319, 0.0984036773443222, 0.10105963796377182, 0.10293655097484589, 0.10478208214044571, 0.10648374259471893, 0.10782963782548904, 0.10922365635633469, 0.11050713807344437, 0.11161500960588455, 0.11268100142478943], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.23416666686534882, 0.887499988079071, 0.950166642665863, 0.9453333616256714, 0.9653333425521851, 0.9769166707992554, 0.9758333563804626, 0.9786666631698608, 0.981249988079071, 0.9825833439826965, 0.9816666841506958, 0.9804166555404663, 0.981416642665863, 0.984333336353302, 0.9836666584014893, 0.984250009059906, 0.9836666584014893, 0.9850000143051147, 0.9852499961853027, 0.98458331823349, 0.984416663646698, 0.9830833077430725, 0.9838333129882812, 0.98458331823349, 0.9779166579246521, 0.9826666712760925, 0.984250009059906, 0.9855833053588867, 0.9825833439826965, 0.984083354473114, 0.9856666922569275, 0.9865000247955322, 0.9864166378974915, 0.9865000247955322, 0.9866666793823242, 0.9867500066757202, 0.9866666793823242, 0.9867500066757202, 0.9865000247955322, 0.9866666793823242, 0.9865000247955322, 0.9865000247955322, 0.9865000247955322, 0.9865000247955322, 0.9865000247955322]}\n",
      "{'loss': [0.7303270697593689, 0.14579008519649506, 0.0927787572145462, 0.06896789371967316, 0.054537251591682434, 0.04590145871043205, 0.03891654312610626, 0.03237498551607132, 0.027407173067331314, 0.02384377084672451, 0.019188866019248962, 0.01661141775548458, 0.014156577177345753, 0.01116579957306385, 0.00915560033172369, 0.007824099622666836, 0.0059793866239488125, 0.01798292063176632, 0.00574045954272151, 0.0034476900473237038, 0.002206584205850959, 0.0015587015077471733, 0.03629760444164276, 0.02592494525015354, 0.007926222868263721, 0.003740787273272872, 0.0019630673341453075, 0.0012328590964898467, 0.0008638417930342257, 0.0006071425741538405, 0.00047893222654238343, 0.00037246374995447695, 0.0003101381880696863, 0.0002656620927155018, 0.00022661499679088593, 0.0002012165350606665, 0.0001752753887558356, 0.00015684228856116533, 0.00014258039300329983, 0.0001285141916014254, 0.00011687773803714663, 0.00010739288700278848, 9.825646702665836e-05, 9.129857062362134e-05, 8.426959539065138e-05, 7.933227607281879e-05, 7.37431546440348e-05, 6.847616896266118e-05, 6.544939242303371e-05, 6.143652717582881e-05], 'accuracy': [0.7758333086967468, 0.9546874761581421, 0.9707291722297668, 0.9782291650772095, 0.9829791784286499, 0.9854583144187927, 0.987458348274231, 0.9894791841506958, 0.9916874766349792, 0.9927291870117188, 0.9942916631698608, 0.9947291612625122, 0.9958541393280029, 0.9964583516120911, 0.9975208044052124, 0.9979166388511658, 0.9986249804496765, 0.9954583048820496, 0.9986666440963745, 0.9992708563804626, 0.9995833039283752, 0.9998124837875366, 0.9942708611488342, 0.9916874766349792, 0.9981666803359985, 0.9994583129882812, 0.999833345413208, 0.999916672706604, 0.9999791383743286, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.18536244332790375, 0.09799698740243912, 0.07412488013505936, 0.07275190949440002, 0.06135537847876549, 0.05764422193169594, 0.053187206387519836, 0.05261857435107231, 0.06940055638551712, 0.04750201478600502, 0.04883355274796486, 0.052764151245355606, 0.05740118399262428, 0.0619734562933445, 0.051491476595401764, 0.07111994177103043, 0.07775144279003143, 0.04908837750554085, 0.04924953728914261, 0.052156463265419006, 0.05640104040503502, 0.05712907016277313, 0.11717833578586578, 0.04361579939723015, 0.04781144857406616, 0.05303774029016495, 0.05422867834568024, 0.055730387568473816, 0.05885912477970123, 0.0606207475066185, 0.06375916302204132, 0.06519148498773575, 0.06775565445423126, 0.0689629465341568, 0.07099881768226624, 0.07158283144235611, 0.07319202274084091, 0.07423286139965057, 0.07566214352846146, 0.07688246667385101, 0.07779446244239807, 0.07873759418725967, 0.08003805577754974, 0.08074743300676346, 0.08136734366416931, 0.08208295702934265, 0.08284498751163483, 0.08332628756761551, 0.08449740707874298, 0.08545275032520294], 'val_accuracy': [0.9397500157356262, 0.9699166417121887, 0.9771666526794434, 0.9770833253860474, 0.9800833463668823, 0.9820833206176758, 0.984250009059906, 0.984083354473114, 0.9789166450500488, 0.9863333106040955, 0.9861666560173035, 0.984416663646698, 0.984250009059906, 0.9829999804496765, 0.987333357334137, 0.981249988079071, 0.9807500243186951, 0.9869999885559082, 0.9872499704360962, 0.987500011920929, 0.987666666507721, 0.9879166483879089, 0.965666651725769, 0.9872499704360962, 0.9868333339691162, 0.9857500195503235, 0.9866666793823242, 0.9879166483879089, 0.9878333210945129, 0.9882500171661377, 0.9880833625793457, 0.9879999756813049, 0.9880833625793457, 0.9879166483879089, 0.9879999756813049, 0.9883333444595337, 0.9880833625793457, 0.9878333210945129, 0.9880833625793457, 0.9879166483879089, 0.9879166483879089, 0.9879166483879089, 0.9879166483879089, 0.9878333210945129, 0.9878333210945129, 0.9879999756813049, 0.9878333210945129, 0.9877499938011169, 0.9879999756813049, 0.9877499938011169]}\n",
      "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'accuracy': [0.09827083349227905, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823], 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_accuracy': [0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716]}\n",
      "{'loss': [2.3018927574157715, 2.3012266159057617, 2.3010613918304443, 2.301020383834839, 2.301013946533203, 2.301008701324463, 2.3010103702545166, 2.301011085510254, 2.301008939743042, 2.3010075092315674, 2.301008701324463, 2.301011085510254, 2.3010077476501465, 2.3010096549987793, 2.301006555557251, 2.301006555557251, 2.3010060787200928, 2.3010122776031494, 2.3010094165802, 2.3010056018829346, 2.301010847091675, 2.3010072708129883, 2.3010122776031494, 2.301006317138672, 2.3010101318359375, 2.301008701324463, 2.301010847091675, 2.3010106086730957, 2.3010101318359375, 2.30100417137146, 2.301007032394409, 2.3010077476501465, 2.3010106086730957, 2.301008939743042, 2.301009178161621, 2.3010075092315674, 2.3010072708129883, 2.301006555557251, 2.3010060787200928, 2.301011085510254, 2.3010051250457764, 2.3010056018829346, 2.3010072708129883, 2.301009178161621, 2.3010072708129883, 2.3010106086730957, 2.3010103702545166, 2.3010077476501465, 2.301009178161621, 2.301006317138672], 'accuracy': [0.11356250196695328, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3019516468048096, 2.3019375801086426, 2.302006483078003, 2.3020670413970947, 2.3020834922790527, 2.3020925521850586, 2.3020949363708496, 2.3020966053009033, 2.30208420753479, 2.302083969116211, 2.3020694255828857, 2.3020787239074707, 2.302079200744629, 2.3020973205566406, 2.3021178245544434, 2.3021092414855957, 2.3021156787872314, 2.3021140098571777, 2.3020858764648438, 2.3021042346954346, 2.30210542678833, 2.302126169204712, 2.3021321296691895, 2.3021180629730225, 2.302096366882324, 2.3021068572998047, 2.3021090030670166, 2.3021044731140137, 2.302119016647339, 2.3020987510681152, 2.3020668029785156, 2.3020551204681396, 2.3020639419555664, 2.3020846843719482, 2.3020780086517334, 2.3020896911621094, 2.3020784854888916, 2.3020787239074707, 2.3020894527435303, 2.30210280418396, 2.3021109104156494, 2.3020923137664795, 2.3020899295806885, 2.302091121673584, 2.3021023273468018, 2.3021011352539062, 2.3021035194396973, 2.3021035194396973, 2.302076816558838, 2.302110433578491], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [2.301905870437622, 2.301241159439087, 2.3010706901550293, 2.3010241985321045, 2.301016330718994, 2.3010120391845703, 2.30100417137146, 2.3010106086730957, 2.301008701324463, 2.3010025024414062, 2.301006555557251, 2.3010025024414062, 2.3010072708129883, 2.301011085510254, 2.3010010719299316, 2.301003932952881, 2.3010058403015137, 2.3010051250457764, 2.3010072708129883, 2.3010094165802, 2.3010060787200928, 2.3010077476501465, 2.3010077476501465, 2.301010847091675, 2.301007032394409, 2.301008462905884, 2.3010098934173584, 2.301007032394409, 2.3010051250457764, 2.3010075092315674, 2.3010072708129883, 2.301008939743042, 2.301009178161621, 2.3010082244873047, 2.3010077476501465, 2.3010101318359375, 2.301007032394409, 2.3009963035583496, 2.3010072708129883, 2.3010082244873047, 2.3010082244873047, 2.3010058403015137, 2.301008939743042, 2.301006555557251, 2.3010096549987793, 2.301008701324463, 2.301010847091675, 2.3010096549987793, 2.3010060787200928, 2.3010001182556152], 'accuracy': [0.11337500065565109, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.301933765411377, 2.3019156455993652, 2.301966667175293, 2.3020260334014893, 2.3020591735839844, 2.3020877838134766, 2.302107334136963, 2.302093029022217, 2.3020944595336914, 2.30210280418396, 2.3020873069763184, 2.3021090030670166, 2.30210280418396, 2.302103042602539, 2.302100419998169, 2.302081823348999, 2.3021044731140137, 2.3020877838134766, 2.3020944595336914, 2.3020761013031006, 2.3020851612091064, 2.3020873069763184, 2.3020918369293213, 2.3020975589752197, 2.302100658416748, 2.3021113872528076, 2.302102565765381, 2.3020992279052734, 2.3020834922790527, 2.302072048187256, 2.30210280418396, 2.302119731903076, 2.3021299839019775, 2.3020975589752197, 2.3020873069763184, 2.3020927906036377, 2.302100896835327, 2.302095413208008, 2.302088975906372, 2.3020927906036377, 2.302091121673584, 2.3020987510681152, 2.302112102508545, 2.3020944595336914, 2.3021225929260254, 2.3021137714385986, 2.3021230697631836, 2.3021047115325928, 2.302112579345703, 2.3021092414855957], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "noise_24cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
