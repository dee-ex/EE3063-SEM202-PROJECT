{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noise_12cnn_selulecun.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnHhSjZec4W6",
        "outputId": "bef759c1-90fa-47b7-edcc-517585170911"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "    input_shape = (28, 28, 1)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    sample = GaussianNoise(0.2)\n",
        "    x_train = sample(x_train/255, training=True)\n",
        "    x_test = sample(x_test/255, training=True)\n",
        "    \n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test= to_categorical(y_test)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
        "\n",
        "def build_cnn(activation,\n",
        "              dropout_rate,\n",
        "              optimizer):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal', input_shape=input_shape))\n",
        "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same', kernel_initializer='lecun_normal'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation=activation))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=optimizer, \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'gelu': Activation(gelu)})\n",
        "\n",
        "def swish(x):\n",
        "    return x * tf.sigmoid(x)\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
        "\n",
        "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
        "act_func = ['selu']\n",
        "\n",
        "result = []\n",
        "\n",
        "\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    \n",
        "    model = build_cnn(activation=activation,\n",
        "                      dropout_rate=0.2,\n",
        "                      optimizer=SGD())\n",
        "    \n",
        "    history = model.fit(x_train, y_train,\n",
        "          validation_split=0.20,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "    \n",
        "    result.append(history)\n",
        "    \n",
        "    K.clear_session()\n",
        "    del model\n",
        "\n",
        "for r in result:\n",
        "    print(r.history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "11501568/11490434 [==============================] - 1s 0us/step\n",
            "\n",
            "Training with -->selu<-- activation function\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 65s 56ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0965 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 21s 55ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 21s 56ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0995 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0955 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0961 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0955 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 20s 52ms/step - loss: nan - accuracy: 0.0955 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0995\n",
            "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'accuracy': [0.09966666996479034, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823], 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_accuracy': [0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}