{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "e94f67b0-a4cd-4809-ecc8-202eea42b149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 37s 55ms/step - loss: 1.4127 - accuracy: 0.5840 - val_loss: 0.3204 - val_accuracy: 0.9156\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.2997 - accuracy: 0.9167 - val_loss: 0.1908 - val_accuracy: 0.9485\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.1852 - accuracy: 0.9477 - val_loss: 0.1457 - val_accuracy: 0.9588\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.1409 - accuracy: 0.9600 - val_loss: 0.1199 - val_accuracy: 0.9640\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.1126 - accuracy: 0.9681 - val_loss: 0.1081 - val_accuracy: 0.9675\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0976 - accuracy: 0.9727 - val_loss: 0.0975 - val_accuracy: 0.9711\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0868 - accuracy: 0.9753 - val_loss: 0.0845 - val_accuracy: 0.9751\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0757 - accuracy: 0.9775 - val_loss: 0.0808 - val_accuracy: 0.9760\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0685 - accuracy: 0.9812 - val_loss: 0.0729 - val_accuracy: 0.9780\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0650 - accuracy: 0.9819 - val_loss: 0.0703 - val_accuracy: 0.9785\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0592 - accuracy: 0.9830 - val_loss: 0.0653 - val_accuracy: 0.9790\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0549 - accuracy: 0.9842 - val_loss: 0.0639 - val_accuracy: 0.9802\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0512 - accuracy: 0.9851 - val_loss: 0.0621 - val_accuracy: 0.9802\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.0572 - val_accuracy: 0.9833\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0454 - accuracy: 0.9872 - val_loss: 0.0544 - val_accuracy: 0.9841\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0442 - accuracy: 0.9874 - val_loss: 0.0532 - val_accuracy: 0.9842\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.0528 - val_accuracy: 0.9834\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 0.0507 - val_accuracy: 0.9854\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0362 - accuracy: 0.9897 - val_loss: 0.0486 - val_accuracy: 0.9857\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0340 - accuracy: 0.9905 - val_loss: 0.0477 - val_accuracy: 0.9868\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0320 - accuracy: 0.9918 - val_loss: 0.0465 - val_accuracy: 0.9862\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0304 - accuracy: 0.9925 - val_loss: 0.0500 - val_accuracy: 0.9850\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0309 - accuracy: 0.9917 - val_loss: 0.0441 - val_accuracy: 0.9876\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0286 - accuracy: 0.9922 - val_loss: 0.0435 - val_accuracy: 0.9874\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0273 - accuracy: 0.9934 - val_loss: 0.0438 - val_accuracy: 0.9874\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0264 - accuracy: 0.9932 - val_loss: 0.0434 - val_accuracy: 0.9876\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0418 - val_accuracy: 0.9883\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 0.0408 - val_accuracy: 0.9884\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0220 - accuracy: 0.9946 - val_loss: 0.0409 - val_accuracy: 0.9880\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 0.0422 - val_accuracy: 0.9877\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.0430 - val_accuracy: 0.9875\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0398 - val_accuracy: 0.9877\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.0386 - val_accuracy: 0.9888\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.0393 - val_accuracy: 0.9885\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0165 - accuracy: 0.9968 - val_loss: 0.0382 - val_accuracy: 0.9893\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: 0.0375 - val_accuracy: 0.9893\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 0.0416 - val_accuracy: 0.9871\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.0375 - val_accuracy: 0.9893\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0370 - val_accuracy: 0.9896\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.0380 - val_accuracy: 0.9890\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.0366 - val_accuracy: 0.9898\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.0363 - val_accuracy: 0.9899\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.0365 - val_accuracy: 0.9896\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.0375 - val_accuracy: 0.9881\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.0363 - val_accuracy: 0.9901\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0358 - val_accuracy: 0.9897\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.0374 - val_accuracy: 0.9886\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0354 - val_accuracy: 0.9897\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.0361 - val_accuracy: 0.9897\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 21s 50ms/step - loss: 2.3013 - accuracy: 0.1224 - val_loss: 2.2986 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.2960 - accuracy: 0.1150 - val_loss: 2.2813 - val_accuracy: 0.1472\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.9655 - accuracy: 0.3468 - val_loss: 0.3053 - val_accuracy: 0.9003\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.2495 - accuracy: 0.9235 - val_loss: 0.1628 - val_accuracy: 0.9474\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.1428 - accuracy: 0.9538 - val_loss: 0.1181 - val_accuracy: 0.9617\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.1019 - accuracy: 0.9681 - val_loss: 0.1236 - val_accuracy: 0.9605\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0838 - accuracy: 0.9731 - val_loss: 0.1042 - val_accuracy: 0.9685\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0676 - accuracy: 0.9782 - val_loss: 0.0848 - val_accuracy: 0.9728\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0531 - accuracy: 0.9828 - val_loss: 0.0760 - val_accuracy: 0.9768\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0485 - accuracy: 0.9859 - val_loss: 0.0829 - val_accuracy: 0.9740\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.0767 - val_accuracy: 0.9775\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0819 - val_accuracy: 0.9761\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.0847 - val_accuracy: 0.9743\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0837 - val_accuracy: 0.9775\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0820 - val_accuracy: 0.9788\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0799 - val_accuracy: 0.9793\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0816 - val_accuracy: 0.9791\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0894 - val_accuracy: 0.9793\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0889 - val_accuracy: 0.9792\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0979 - val_accuracy: 0.9790\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0995 - val_accuracy: 0.9801\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0978 - val_accuracy: 0.9801\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1003 - val_accuracy: 0.9815\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1036 - val_accuracy: 0.9787\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1023 - val_accuracy: 0.9818\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1071 - val_accuracy: 0.9815\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0963 - val_accuracy: 0.9823\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.1013 - val_accuracy: 0.9829\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1052 - val_accuracy: 0.9834\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.6748e-04 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9838\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 1.0791e-04 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9837\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 9.0513e-05 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9839\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 7.5425e-05 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9837\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 6.3750e-05 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9841\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 5.2288e-05 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9842\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 5.2163e-05 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9841\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 4.1512e-05 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9841\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 3.7703e-05 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9841\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 3.8705e-05 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9839\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 3.5630e-05 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9841\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 3.2630e-05 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9842\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.7903e-05 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9839\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.5793e-05 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9837\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.7475e-05 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9840\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.4022e-05 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9841\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.5091e-05 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9838\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.0978e-05 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9839\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 2.0773e-05 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9841\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 1.9988e-05 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9837\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 24s 57ms/step - loss: 2.3002 - accuracy: 0.1168 - val_loss: 2.2915 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 2.1512 - accuracy: 0.2127 - val_loss: 0.3793 - val_accuracy: 0.8791\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.3202 - accuracy: 0.8999 - val_loss: 0.1675 - val_accuracy: 0.9481\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.1493 - accuracy: 0.9532 - val_loss: 0.1386 - val_accuracy: 0.9591\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.1059 - accuracy: 0.9669 - val_loss: 0.1043 - val_accuracy: 0.9688\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0781 - accuracy: 0.9741 - val_loss: 0.0865 - val_accuracy: 0.9736\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0614 - accuracy: 0.9803 - val_loss: 0.0948 - val_accuracy: 0.9717\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.0803 - val_accuracy: 0.9764\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.0840 - val_accuracy: 0.9753\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0397 - accuracy: 0.9860 - val_loss: 0.0789 - val_accuracy: 0.9775\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 0.0810 - val_accuracy: 0.9781\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.0291 - accuracy: 0.9900 - val_loss: 0.0811 - val_accuracy: 0.9785\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0790 - val_accuracy: 0.9780\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.0902 - val_accuracy: 0.9772\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0943 - val_accuracy: 0.9742\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0947 - val_accuracy: 0.9758\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0902 - val_accuracy: 0.9806\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0952 - val_accuracy: 0.9796\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0995 - val_accuracy: 0.9797\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1145 - val_accuracy: 0.9787\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.0785 - val_accuracy: 0.9809\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0868 - val_accuracy: 0.9812\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9829\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 4.5649e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9822\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 2.8371e-04 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9821\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 2.1676e-04 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9830\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 1.6534e-04 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9827\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 1.3270e-04 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9827\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 1.1420e-04 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9823\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 9.6616e-05 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9827\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 8.5393e-05 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9827\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 7.3118e-05 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9823\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 7.2486e-05 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9825\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 6.1550e-05 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9827\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 5.6745e-05 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9824\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 5.0320e-05 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9827\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 5.2056e-05 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9825\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 4.3721e-05 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9826\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 4.2819e-05 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9827\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 4.1866e-05 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9826\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 3.9288e-05 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9828\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 3.7001e-05 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9827\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 3.2276e-05 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9827\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 2.8253e-05 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9827\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 3.0665e-05 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9828\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 2.7965e-05 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9827\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 2.7281e-05 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9824\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 2.7204e-05 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9826\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 23s 56ms/step - loss: 1.4017 - accuracy: 0.5807 - val_loss: 0.1698 - val_accuracy: 0.9451\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.1561 - accuracy: 0.9499 - val_loss: 0.1117 - val_accuracy: 0.9653\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0937 - accuracy: 0.9703 - val_loss: 0.1039 - val_accuracy: 0.9662\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0693 - accuracy: 0.9790 - val_loss: 0.0708 - val_accuracy: 0.9786\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0548 - accuracy: 0.9823 - val_loss: 0.0706 - val_accuracy: 0.9783\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.0632 - val_accuracy: 0.9801\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0367 - accuracy: 0.9889 - val_loss: 0.0762 - val_accuracy: 0.9772\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 0.0679 - val_accuracy: 0.9800\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.0540 - val_accuracy: 0.9826\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.0575 - val_accuracy: 0.9822\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.0633 - val_accuracy: 0.9816\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.0629 - val_accuracy: 0.9842\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0600 - val_accuracy: 0.9822\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0703 - val_accuracy: 0.9797\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0620 - val_accuracy: 0.9835\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0793 - accuracy: 0.9900 - val_loss: 0.0834 - val_accuracy: 0.9748\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0637 - accuracy: 0.9815 - val_loss: 0.0595 - val_accuracy: 0.9807\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 0.0524 - val_accuracy: 0.9830\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0303 - accuracy: 0.9918 - val_loss: 0.0492 - val_accuracy: 0.9850\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0464 - val_accuracy: 0.9853\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0473 - val_accuracy: 0.9850\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.0463 - val_accuracy: 0.9853\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0461 - val_accuracy: 0.9855\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.0459 - val_accuracy: 0.9858\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.0472 - val_accuracy: 0.9865\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 0.0470 - val_accuracy: 0.9863\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0485 - val_accuracy: 0.9861\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0488 - val_accuracy: 0.9861\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0508 - val_accuracy: 0.9862\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0513 - val_accuracy: 0.9858\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0523 - val_accuracy: 0.9863\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0534 - val_accuracy: 0.9862\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0543 - val_accuracy: 0.9859\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9859\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9861\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 8.9156e-04 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9862\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 7.7215e-04 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 0.9865\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 6.7283e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9863\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 5.8264e-04 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9863\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 5.7716e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9861\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 5.4788e-04 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9865\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 4.7233e-04 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9863\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 4.3561e-04 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9862\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 4.1594e-04 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9863\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 3.5600e-04 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9864\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 3.3935e-04 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9865\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 3.0825e-04 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9864\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 2.7981e-04 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9864\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 2.7813e-04 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9862\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 2.4435e-04 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9864\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 22s 55ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0968 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0964 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0953 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 21s 56ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0968 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 21s 57ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 20s 53ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 20s 54ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0995\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 35s 86ms/step - loss: 2.3023 - accuracy: 0.1096 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3014 - accuracy: 0.1129 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3006 - accuracy: 0.1154 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3007 - accuracy: 0.1146 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3013 - accuracy: 0.1115 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3012 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1138 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 34s 90ms/step - loss: 2.3014 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3012 - accuracy: 0.1129 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3011 - accuracy: 0.1146 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3008 - accuracy: 0.1145 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3013 - accuracy: 0.1127 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3012 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3014 - accuracy: 0.1108 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3017 - accuracy: 0.1106 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3006 - accuracy: 0.1158 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3002 - accuracy: 0.1180 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3010 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 34s 90ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 34s 90ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3011 - accuracy: 0.1138 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3014 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3007 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1145 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3007 - accuracy: 0.1144 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3014 - accuracy: 0.1109 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3012 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3004 - accuracy: 0.1149 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3007 - accuracy: 0.1156 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3009 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3012 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3012 - accuracy: 0.1101 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3007 - accuracy: 0.1176 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3009 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1135 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1156 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3012 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3010 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 2.3010 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3008 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 2.3009 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 27s 66ms/step - loss: 2.3022 - accuracy: 0.1117 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3015 - accuracy: 0.1118 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3010 - accuracy: 0.1147 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3017 - accuracy: 0.1107 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3009 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3011 - accuracy: 0.1149 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3013 - accuracy: 0.1118 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3013 - accuracy: 0.1121 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3006 - accuracy: 0.1160 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3005 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3007 - accuracy: 0.1157 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3009 - accuracy: 0.1147 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 2.3012 - accuracy: 0.1110 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3009 - accuracy: 0.1152 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3012 - accuracy: 0.1147 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3012 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3008 - accuracy: 0.1147 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3009 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3007 - accuracy: 0.1161 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3005 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3012 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3005 - accuracy: 0.1163 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3016 - accuracy: 0.1118 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 25s 67ms/step - loss: 2.3011 - accuracy: 0.1152 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3006 - accuracy: 0.1166 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3013 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3011 - accuracy: 0.1119 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3009 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3010 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3008 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3011 - accuracy: 0.1155 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3013 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3011 - accuracy: 0.1159 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3006 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3011 - accuracy: 0.1127 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3009 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3010 - accuracy: 0.1147 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3013 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3004 - accuracy: 0.1169 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3011 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3009 - accuracy: 0.1159 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 2.3013 - accuracy: 0.1120 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.3003 - accuracy: 0.1178 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "{'loss': [0.8425115346908569, 0.26011621952056885, 0.17309938371181488, 0.13354435563087463, 0.11077836900949478, 0.09548207372426987, 0.08459039032459259, 0.075473353266716, 0.06863405555486679, 0.06290513277053833, 0.05825335532426834, 0.054141025990247726, 0.050427746027708054, 0.04782687500119209, 0.04429958015680313, 0.042459242045879364, 0.039753418415784836, 0.037922441959381104, 0.03607291355729103, 0.03410732001066208, 0.03273427486419678, 0.03094872087240219, 0.029741112142801285, 0.02842406928539276, 0.027137281373143196, 0.025889843702316284, 0.025441203266382217, 0.023890510201454163, 0.02308124303817749, 0.02178584598004818, 0.021246496587991714, 0.02023405022919178, 0.019583815708756447, 0.01897149346768856, 0.018144696950912476, 0.017240649089217186, 0.016600655391812325, 0.016299543902277946, 0.015481448732316494, 0.014886308461427689, 0.014415755867958069, 0.01395087968558073, 0.013503095135092735, 0.012910529971122742, 0.01239973958581686, 0.012036449275910854, 0.011549068614840508, 0.01101125217974186, 0.01062753051519394, 0.010090782307088375], 'accuracy': [0.7716666460037231, 0.9284374713897705, 0.9514791369438171, 0.9625416398048401, 0.9680416584014893, 0.9727708101272583, 0.9757500290870667, 0.9784374833106995, 0.9803333282470703, 0.9823958277702332, 0.9831458330154419, 0.984333336353302, 0.9854166507720947, 0.9862499833106995, 0.9875208139419556, 0.987625002861023, 0.989062488079071, 0.9891666769981384, 0.9899583458900452, 0.9904999732971191, 0.9911875128746033, 0.9920833110809326, 0.992145836353302, 0.9922916889190674, 0.9931666851043701, 0.9933541417121887, 0.9935208559036255, 0.9939791560173035, 0.9938541650772095, 0.9947916865348816, 0.9949374794960022, 0.9952083230018616, 0.9955000281333923, 0.995479166507721, 0.9959375262260437, 0.9963750243186951, 0.9963124990463257, 0.9966041445732117, 0.9968541860580444, 0.9970625042915344, 0.997041642665863, 0.9972708225250244, 0.9975000023841858, 0.9975625276565552, 0.9976666569709778, 0.9977708458900452, 0.9978958368301392, 0.9979791641235352, 0.9982708096504211, 0.9984166622161865], 'val_loss': [0.32038819789886475, 0.19080296158790588, 0.14571520686149597, 0.11986004561185837, 0.10811860114336014, 0.09750431030988693, 0.08451914042234421, 0.08078205585479736, 0.07288462668657303, 0.0703074261546135, 0.0652783066034317, 0.0638727992773056, 0.06206554174423218, 0.05718806013464928, 0.05436338111758232, 0.05323722958564758, 0.05284135788679123, 0.050693344324827194, 0.04863106831908226, 0.04770501330494881, 0.046519745141267776, 0.050039198249578476, 0.044077109545469284, 0.043480128049850464, 0.04379425570368767, 0.04339633136987686, 0.041802745312452316, 0.04077558219432831, 0.040871512144804, 0.03962661325931549, 0.04219863563776016, 0.042970020323991776, 0.03982563316822052, 0.038622770458459854, 0.03928930312395096, 0.03818376734852791, 0.03754742816090584, 0.04157702252268791, 0.03751417249441147, 0.03699459135532379, 0.03799891471862793, 0.03660174831748009, 0.03631177917122841, 0.03654632717370987, 0.037482645362615585, 0.03626566007733345, 0.03580827638506889, 0.03744896873831749, 0.03541736677289009, 0.036101922392845154], 'val_accuracy': [0.9155833125114441, 0.9484999775886536, 0.9588333368301392, 0.9639999866485596, 0.9674999713897705, 0.9710833430290222, 0.9750833511352539, 0.9760000109672546, 0.9779999852180481, 0.9785000085830688, 0.9789999723434448, 0.9801666736602783, 0.9801666736602783, 0.9832500219345093, 0.984083354473114, 0.98416668176651, 0.9834166765213013, 0.9854166507720947, 0.9856666922569275, 0.9868333339691162, 0.9862499833106995, 0.9850000143051147, 0.987583339214325, 0.987416684627533, 0.987416684627533, 0.987583339214325, 0.9883333444595337, 0.9884166717529297, 0.9879999756813049, 0.9884999990463257, 0.987666666507721, 0.987500011920929, 0.987666666507721, 0.9888333082199097, 0.9884999990463257, 0.9893333315849304, 0.9893333315849304, 0.9870833158493042, 0.9892500042915344, 0.9895833134651184, 0.9890000224113464, 0.9898333549499512, 0.9899166822433472, 0.9895833134651184, 0.9880833625793457, 0.9900833368301392, 0.9896666407585144, 0.9885833263397217, 0.9896666407585144, 0.9896666407585144]}\n",
      "{'loss': [2.3002376556396484, 2.292710065841675, 1.3371491432189941, 0.21213693916797638, 0.1342134326696396, 0.09966698288917542, 0.08174191415309906, 0.0673135295510292, 0.056745558977127075, 0.05033443123102188, 0.04128314182162285, 0.036403678357601166, 0.029544556513428688, 0.025017425417900085, 0.025333043187856674, 0.01735793612897396, 0.016262425109744072, 0.013263183645904064, 0.013275759294629097, 0.01190935168415308, 0.008733888156712055, 0.008112684823572636, 0.005715044215321541, 0.003997085150331259, 0.006139029283076525, 0.003583453129976988, 0.004924444947391748, 0.009633082896471024, 0.003371079685166478, 0.0009445859468542039, 0.00022426285431720316, 0.00011191707017133012, 8.702190825715661e-05, 7.208858733065426e-05, 6.208903505466878e-05, 5.416525891632773e-05, 4.848894968745299e-05, 4.375224307295866e-05, 3.989629112766124e-05, 3.660407310235314e-05, 3.372482387931086e-05, 3.148262476315722e-05, 2.9374350560829043e-05, 2.7599029635894112e-05, 2.58933832810726e-05, 2.4495875550201163e-05, 2.3230571969179437e-05, 2.208414844062645e-05, 2.1019481209805235e-05, 2.0074276108061895e-05], 'accuracy': [0.11804166436195374, 0.11783333122730255, 0.5749375224113464, 0.934291660785675, 0.9574375152587891, 0.9692916870117188, 0.9737708568572998, 0.9783333539962769, 0.9817500114440918, 0.984666645526886, 0.9865416884422302, 0.9878958463668823, 0.9897708296775818, 0.9917083382606506, 0.9914166927337646, 0.9941666722297668, 0.9945416450500488, 0.9955624938011169, 0.9955833554267883, 0.9960208535194397, 0.997041642665863, 0.9976249933242798, 0.9981666803359985, 0.9987916946411133, 0.9979791641235352, 0.9989583492279053, 0.9985833168029785, 0.9965624809265137, 0.9989166855812073, 0.9998124837875366, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.298649549484253, 2.281348705291748, 0.3052888810634613, 0.1628224104642868, 0.11809699237346649, 0.12363127619028091, 0.10418949276208878, 0.0848383978009224, 0.07603088021278381, 0.08292044699192047, 0.07674767822027206, 0.08186734467744827, 0.08469437807798386, 0.08369316905736923, 0.08202850073575974, 0.07986891269683838, 0.08163933455944061, 0.08941765129566193, 0.08893465995788574, 0.09789630025625229, 0.09945132583379745, 0.09911169111728668, 0.09781596064567566, 0.10026773810386658, 0.10364175587892532, 0.10225429385900497, 0.10707151144742966, 0.09629958122968674, 0.10125122219324112, 0.10519323498010635, 0.10672347247600555, 0.10984934121370316, 0.1123683899641037, 0.11453978717327118, 0.11611704528331757, 0.11763563752174377, 0.11922068148851395, 0.12065982818603516, 0.121673583984375, 0.12281224876642227, 0.12419456988573074, 0.124965138733387, 0.12581264972686768, 0.12667912244796753, 0.1275612711906433, 0.12837086617946625, 0.1290620118379593, 0.12977217137813568, 0.13049067556858063, 0.1311214566230774], 'val_accuracy': [0.10599999874830246, 0.1471666693687439, 0.9003333449363708, 0.9474166631698608, 0.9617499709129333, 0.9605000019073486, 0.968500018119812, 0.9728333353996277, 0.9768333435058594, 0.9739999771118164, 0.9775000214576721, 0.9760833382606506, 0.9742500185966492, 0.9775000214576721, 0.9788333177566528, 0.9793333411216736, 0.9790833592414856, 0.9793333411216736, 0.9791666865348816, 0.9789999723434448, 0.9800833463668823, 0.9798333048820496, 0.9800833463668823, 0.9815000295639038, 0.9786666631698608, 0.9818333387374878, 0.9815000295639038, 0.9823333621025085, 0.9829166531562805, 0.9834166765213013, 0.9838333129882812, 0.9837499856948853, 0.9839166402816772, 0.9836666584014893, 0.984083354473114, 0.98416668176651, 0.984083354473114, 0.984083354473114, 0.984083354473114, 0.9839166402816772, 0.984083354473114, 0.98416668176651, 0.9839166402816772, 0.9837499856948853, 0.984000027179718, 0.984083354473114, 0.9838333129882812, 0.9839166402816772, 0.984083354473114, 0.9837499856948853]}\n",
      "{'loss': [2.2979350090026855, 1.6737054586410522, 0.25477078557014465, 0.13888059556484222, 0.09989514946937561, 0.07942242175340652, 0.06573818624019623, 0.054654840379953384, 0.04665788635611534, 0.04068031162023544, 0.03314921632409096, 0.03112788312137127, 0.025058086961507797, 0.022472495213150978, 0.019206805154681206, 0.015662260353565216, 0.014091095887124538, 0.014172215946018696, 0.011151080019772053, 0.006616287864744663, 0.009456808678805828, 0.008455075323581696, 0.02413775958120823, 0.0034760774578899145, 0.0011258124141022563, 0.0005126509349793196, 0.00029370535048656166, 0.00021095012198202312, 0.00015929141954984516, 0.00013326095358934253, 0.00011255450954195112, 9.691388549981639e-05, 8.614942635176703e-05, 7.694248051848263e-05, 6.888879579491913e-05, 6.284899427555501e-05, 5.7426863349974155e-05, 5.271058398648165e-05, 4.912744407192804e-05, 4.537112545222044e-05, 4.2362087697256356e-05, 3.986136653111316e-05, 3.754063800442964e-05, 3.533402195898816e-05, 3.331325569888577e-05, 3.167626346112229e-05, 3.008393287018407e-05, 2.8677008231170475e-05, 2.7365198548068292e-05, 2.6150450139539316e-05], 'accuracy': [0.11387500166893005, 0.4247708320617676, 0.9203958511352539, 0.956375002861023, 0.9682916402816772, 0.9743750095367432, 0.9788333177566528, 0.9819791913032532, 0.9849583506584167, 0.9863958358764648, 0.989145815372467, 0.9894166588783264, 0.9919583201408386, 0.9921666383743286, 0.9937083125114441, 0.9951249957084656, 0.995395839214325, 0.9954166412353516, 0.9963958263397217, 0.9980624914169312, 0.9972083568572998, 0.9971666932106018, 0.9944791793823242, 0.9991041421890259, 0.9998958110809326, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.291513442993164, 0.37925729155540466, 0.16748011112213135, 0.138551265001297, 0.10428844392299652, 0.08651771396398544, 0.09481990337371826, 0.08030199259519577, 0.0840054452419281, 0.07894087582826614, 0.0809723436832428, 0.08106367290019989, 0.07902601361274719, 0.09021193534135818, 0.09432312846183777, 0.08749016374349594, 0.09115723520517349, 0.094749815762043, 0.09019791334867477, 0.09521495550870895, 0.0995144173502922, 0.1145465224981308, 0.07848309725522995, 0.0867903009057045, 0.09472624957561493, 0.09822811186313629, 0.10331670939922333, 0.10750292241573334, 0.11065532267093658, 0.11256839334964752, 0.1149248331785202, 0.1174001395702362, 0.1188584491610527, 0.12066566944122314, 0.12205274403095245, 0.12352105975151062, 0.12517917156219482, 0.12633462250232697, 0.12736791372299194, 0.12832927703857422, 0.12957271933555603, 0.13062602281570435, 0.13151460886001587, 0.1325562447309494, 0.13350754976272583, 0.13431823253631592, 0.13513357937335968, 0.1357450634241104, 0.1365053653717041, 0.13716010749340057], 'val_accuracy': [0.10599999874830246, 0.8790833353996277, 0.9480833411216736, 0.9590833187103271, 0.968833327293396, 0.9735833406448364, 0.971666693687439, 0.9764166474342346, 0.9752500057220459, 0.9775000214576721, 0.9780833125114441, 0.9785000085830688, 0.9779999852180481, 0.9771666526794434, 0.9741666913032532, 0.9777500033378601, 0.9777500033378601, 0.9757500290870667, 0.9805833101272583, 0.9795833230018616, 0.9796666502952576, 0.9786666631698608, 0.9809166789054871, 0.981249988079071, 0.9829166531562805, 0.9822499752044678, 0.9820833206176758, 0.9829999804496765, 0.9826666712760925, 0.9826666712760925, 0.9823333621025085, 0.9826666712760925, 0.9826666712760925, 0.9823333621025085, 0.9825000166893005, 0.9826666712760925, 0.9824166893959045, 0.9827499985694885, 0.9825000166893005, 0.9825833439826965, 0.9827499985694885, 0.9825833439826965, 0.9828333258628845, 0.9827499985694885, 0.9826666712760925, 0.9827499985694885, 0.9828333258628845, 0.9827499985694885, 0.9824166893959045, 0.9825833439826965]}\n",
      "{'loss': [0.738448977470398, 0.13371360301971436, 0.087688148021698, 0.06852976232767105, 0.056255873292684555, 0.046026285737752914, 0.038284435868263245, 0.03238321840763092, 0.027956677600741386, 0.022376928478479385, 0.01907464861869812, 0.016180770471692085, 0.012031498365104198, 0.009830016642808914, 0.00723935104906559, 0.15752017498016357, 0.056595589965581894, 0.03784167766571045, 0.02851071208715439, 0.022748488932847977, 0.0180331040173769, 0.014450597576797009, 0.011425248347222805, 0.009462009184062481, 0.007491999305784702, 0.006132814567536116, 0.004906157031655312, 0.004019108135253191, 0.0032801085617393255, 0.0025722242426127195, 0.002221700269728899, 0.0018076825654134154, 0.0014835066394880414, 0.0012445340398699045, 0.0010898567270487547, 0.0009381368872709572, 0.0008120383135974407, 0.0007255178061313927, 0.0006378850666806102, 0.000573755067307502, 0.0005203624023124576, 0.000473707914352417, 0.000426755374064669, 0.0003959803143516183, 0.0003666537522803992, 0.00033365306444466114, 0.0003117924206890166, 0.0002896905643865466, 0.00027084164321422577, 0.00025284907314926386], 'accuracy': [0.7886041402816772, 0.9575208425521851, 0.972000002861023, 0.9789999723434448, 0.9821458458900452, 0.9854375123977661, 0.9879999756813049, 0.9898750185966492, 0.9916458129882812, 0.9932916760444641, 0.9942499995231628, 0.9950416684150696, 0.9964374899864197, 0.9973958134651184, 0.9980000257492065, 0.9771875143051147, 0.9833333492279053, 0.9886249899864197, 0.9916874766349792, 0.9936249852180481, 0.9948958158493042, 0.9960416555404663, 0.9973333477973938, 0.9980624914169312, 0.9988124966621399, 0.9991875290870667, 0.9994166493415833, 0.9993958473205566, 0.9997291564941406, 0.9998958110809326, 0.999833345413208, 0.9998541474342346, 0.999916672706604, 1.0, 0.9999791383743286, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.16976810991764069, 0.11174219846725464, 0.10394901782274246, 0.07082537561655045, 0.07056599855422974, 0.063173308968544, 0.07624516636133194, 0.06787312030792236, 0.05402637645602226, 0.05754141882061958, 0.06330674886703491, 0.06292114406824112, 0.05999304726719856, 0.07031479477882385, 0.062009297311306, 0.08335195481777191, 0.059548478573560715, 0.0524417869746685, 0.049216378480196, 0.04639573022723198, 0.04728304594755173, 0.046258170157670975, 0.04609732702374458, 0.04588406905531883, 0.04716048017144203, 0.046970728784799576, 0.048514943569898605, 0.048828426748514175, 0.05076305568218231, 0.051328469067811966, 0.05227431654930115, 0.053394488990306854, 0.054314762353897095, 0.054037902504205704, 0.055819474160671234, 0.05625022202730179, 0.05698951333761215, 0.05822555720806122, 0.059161972254514694, 0.05977225676178932, 0.06047595664858818, 0.06135616451501846, 0.06171124428510666, 0.06290709227323532, 0.06347514688968658, 0.0641980916261673, 0.06454320251941681, 0.06493036448955536, 0.0658067911863327, 0.06600524485111237], 'val_accuracy': [0.9450833201408386, 0.9653333425521851, 0.9661666750907898, 0.9785833358764648, 0.9782500267028809, 0.9800833463668823, 0.9771666526794434, 0.9800000190734863, 0.9825833439826965, 0.9821666479110718, 0.9815833568572998, 0.98416668176651, 0.9822499752044678, 0.9796666502952576, 0.9835000038146973, 0.9748333096504211, 0.9806666374206543, 0.9829999804496765, 0.9850000143051147, 0.9853333234786987, 0.9850000143051147, 0.9853333234786987, 0.9854999780654907, 0.9857500195503235, 0.9865000247955322, 0.9863333106040955, 0.9860833287239075, 0.9860833287239075, 0.9862499833106995, 0.9858333468437195, 0.9863333106040955, 0.9861666560173035, 0.9859166741371155, 0.9859166741371155, 0.9860833287239075, 0.9861666560173035, 0.9865000247955322, 0.9863333106040955, 0.9863333106040955, 0.9860833287239075, 0.9865000247955322, 0.9863333106040955, 0.9862499833106995, 0.9863333106040955, 0.9864166378974915, 0.9865000247955322, 0.9864166378974915, 0.9864166378974915, 0.9862499833106995, 0.9864166378974915]}\n",
      "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'accuracy': [0.09862499684095383, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823], 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_accuracy': [0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716]}\n",
      "{'loss': [2.3018863201141357, 2.3012232780456543, 2.3010613918304443, 2.3010220527648926, 2.3010077476501465, 2.3010025024414062, 2.3009984493255615, 2.300999164581299, 2.300999402999878, 2.3009984493255615, 2.3009955883026123, 2.3009982109069824, 2.300995111465454, 2.3010010719299316, 2.300997018814087, 2.300999402999878, 2.3009963035583496, 2.3009965419769287, 2.300992727279663, 2.300990581512451, 2.3009979724884033, 2.300997018814087, 2.300995349884033, 2.300997018814087, 2.300995349884033, 2.300994873046875, 2.3009958267211914, 2.3009965419769287, 2.300992250442505, 2.300999164581299, 2.3009936809539795, 2.3009958267211914, 2.3009963035583496, 2.3009936809539795, 2.3009982109069824, 2.3009939193725586, 2.300992965698242, 2.300994396209717, 2.300995349884033, 2.3009958267211914, 2.300995349884033, 2.3009908199310303, 2.3009917736053467, 2.3009963035583496, 2.3009934425354004, 2.300994873046875, 2.3009979724884033, 2.3009979724884033, 2.300995349884033, 2.3009934425354004], 'accuracy': [0.1133333370089531, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3019394874572754, 2.30191707611084, 2.301980495452881, 2.301999807357788, 2.302051305770874, 2.302074670791626, 2.302053451538086, 2.3020787239074707, 2.302083969116211, 2.3020811080932617, 2.302109956741333, 2.302107810974121, 2.3020944595336914, 2.302079200744629, 2.302091121673584, 2.302109718322754, 2.302103281021118, 2.3021204471588135, 2.3021249771118164, 2.302095890045166, 2.302079677581787, 2.3020801544189453, 2.3020453453063965, 2.302053213119507, 2.3020644187927246, 2.3020756244659424, 2.3020713329315186, 2.3020644187927246, 2.3020689487457275, 2.3020803928375244, 2.3020823001861572, 2.302103042602539, 2.302095890045166, 2.3020846843719482, 2.3020663261413574, 2.3020739555358887, 2.3020880222320557, 2.3021180629730225, 2.3021225929260254, 2.302107095718384, 2.302064895629883, 2.3021016120910645, 2.3020899295806885, 2.302110433578491, 2.302079677581787, 2.3021063804626465, 2.3021080493927, 2.3021063804626465, 2.302102565765381, 2.302095651626587], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [2.3019134998321533, 2.301239490509033, 2.301065683364868, 2.3010127544403076, 2.30100417137146, 2.3010010719299316, 2.3010001182556152, 2.301004648208618, 2.301004648208618, 2.300996780395508, 2.3010005950927734, 2.3009965419769287, 2.3010005950927734, 2.300997734069824, 2.300999164581299, 2.300996780395508, 2.300997734069824, 2.3010010719299316, 2.3009932041168213, 2.3009989261627197, 2.300999402999878, 2.3009979724884033, 2.3009955883026123, 2.3009986877441406, 2.3009941577911377, 2.300994396209717, 2.3009960651397705, 2.300997018814087, 2.30098819732666, 2.3009979724884033, 2.300994396209717, 2.3009917736053467, 2.300995349884033, 2.3009986877441406, 2.3009934425354004, 2.300995349884033, 2.3009955883026123, 2.300992488861084, 2.300994873046875, 2.3009912967681885, 2.300992250442505, 2.300995111465454, 2.300992012023926, 2.3009965419769287, 2.3009939193725586, 2.300992727279663, 2.3009915351867676, 2.3009984493255615, 2.300992250442505, 2.300992727279663], 'accuracy': [0.11337500065565109, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3019771575927734, 2.30196213722229, 2.301995277404785, 2.302077293395996, 2.302096128463745, 2.3020856380462646, 2.3021011352539062, 2.3021061420440674, 2.302088975906372, 2.3020904064178467, 2.302100896835327, 2.3020946979522705, 2.302056074142456, 2.302061080932617, 2.3020763397216797, 2.3021066188812256, 2.3021130561828613, 2.3021113872528076, 2.302060604095459, 2.302070379257202, 2.3020846843719482, 2.302107334136963, 2.3020761013031006, 2.3020994663238525, 2.302093982696533, 2.30210018157959, 2.302104949951172, 2.3020739555358887, 2.3020832538604736, 2.3020853996276855, 2.3020660877227783, 2.302056312561035, 2.3020942211151123, 2.30208158493042, 2.3020882606506348, 2.302091360092163, 2.302069664001465, 2.3021068572998047, 2.3020851612091064, 2.302065134048462, 2.3021020889282227, 2.302088737487793, 2.302076816558838, 2.302095651626587, 2.302075147628784, 2.3020949363708496, 2.3020894527435303, 2.3020811080932617, 2.3021111488342285, 2.3020920753479004], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "noise_12cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
