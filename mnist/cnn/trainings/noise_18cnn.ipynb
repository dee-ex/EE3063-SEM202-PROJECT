{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnHhSjZec4W6",
    "outputId": "2425ede9-5b71-48ad-b843-7078a07e1839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with -->tanh<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 29s 37ms/step - loss: 1.3248 - accuracy: 0.6119 - val_loss: 0.2553 - val_accuracy: 0.9327\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.2361 - accuracy: 0.9382 - val_loss: 0.1501 - val_accuracy: 0.9564\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.1492 - accuracy: 0.9582 - val_loss: 0.1172 - val_accuracy: 0.9662\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.1138 - accuracy: 0.9678 - val_loss: 0.1025 - val_accuracy: 0.9711\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0974 - accuracy: 0.9731 - val_loss: 0.0886 - val_accuracy: 0.9744\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0798 - accuracy: 0.9771 - val_loss: 0.0780 - val_accuracy: 0.9767\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0689 - accuracy: 0.9812 - val_loss: 0.0745 - val_accuracy: 0.9778\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0668 - accuracy: 0.9811 - val_loss: 0.0698 - val_accuracy: 0.9779\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0593 - accuracy: 0.9830 - val_loss: 0.0660 - val_accuracy: 0.9806\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: 0.0602 - val_accuracy: 0.9813\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0520 - accuracy: 0.9856 - val_loss: 0.0575 - val_accuracy: 0.9827\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0461 - accuracy: 0.9874 - val_loss: 0.0532 - val_accuracy: 0.9835\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0415 - accuracy: 0.9888 - val_loss: 0.0537 - val_accuracy: 0.9843\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0476 - accuracy: 0.9865 - val_loss: 0.0526 - val_accuracy: 0.9837\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0411 - accuracy: 0.9884 - val_loss: 0.0486 - val_accuracy: 0.9848\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0375 - accuracy: 0.9898 - val_loss: 0.0471 - val_accuracy: 0.9857\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0350 - accuracy: 0.9906 - val_loss: 0.0474 - val_accuracy: 0.9852\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0347 - accuracy: 0.9905 - val_loss: 0.0455 - val_accuracy: 0.9861\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.0434 - val_accuracy: 0.9870\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0293 - accuracy: 0.9925 - val_loss: 0.0442 - val_accuracy: 0.9867\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0272 - accuracy: 0.9934 - val_loss: 0.0414 - val_accuracy: 0.9875\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0266 - accuracy: 0.9930 - val_loss: 0.0421 - val_accuracy: 0.9877\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0247 - accuracy: 0.9944 - val_loss: 0.0422 - val_accuracy: 0.9880\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0247 - accuracy: 0.9935 - val_loss: 0.0398 - val_accuracy: 0.9887\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.0412 - val_accuracy: 0.9879\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 0.0388 - val_accuracy: 0.9888\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.0381 - val_accuracy: 0.9893\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0187 - accuracy: 0.9955 - val_loss: 0.0410 - val_accuracy: 0.9881\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.0415 - val_accuracy: 0.9870\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 0.0382 - val_accuracy: 0.9883\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.0382 - val_accuracy: 0.9885\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.0375 - val_accuracy: 0.9891\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0159 - accuracy: 0.9966 - val_loss: 0.0402 - val_accuracy: 0.9883\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.0360 - val_accuracy: 0.9893\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.0360 - val_accuracy: 0.9892\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.0355 - val_accuracy: 0.9895\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0375 - val_accuracy: 0.9885\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0345 - val_accuracy: 0.9895\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.0346 - val_accuracy: 0.9899\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 0.0363 - val_accuracy: 0.9894\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.0350 - val_accuracy: 0.9893\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.0364 - val_accuracy: 0.9890\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.0339 - val_accuracy: 0.9898\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.0380 - val_accuracy: 0.9886\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 0.0346 - val_accuracy: 0.9898\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0343 - val_accuracy: 0.9902\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 0.0360 - val_accuracy: 0.9893\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.0349 - val_accuracy: 0.9899\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.0342 - val_accuracy: 0.9897\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0335 - val_accuracy: 0.9905\n",
      "\n",
      "Training with -->relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 15s 34ms/step - loss: 2.3020 - accuracy: 0.1116 - val_loss: 2.3017 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.3011 - accuracy: 0.1135 - val_loss: 2.3014 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.3003 - accuracy: 0.1147 - val_loss: 2.3010 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 2.3000 - accuracy: 0.1135 - val_loss: 2.3001 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.2984 - accuracy: 0.1160 - val_loss: 2.2982 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.2959 - accuracy: 0.1153 - val_loss: 2.2925 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.2871 - accuracy: 0.1149 - val_loss: 2.2462 - val_accuracy: 0.1950\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 1.6526 - accuracy: 0.4554 - val_loss: 0.2747 - val_accuracy: 0.9106\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2448 - accuracy: 0.9216 - val_loss: 0.1715 - val_accuracy: 0.9471\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.1359 - accuracy: 0.9575 - val_loss: 0.1324 - val_accuracy: 0.9571\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0979 - accuracy: 0.9679 - val_loss: 0.1099 - val_accuracy: 0.9652\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0761 - accuracy: 0.9759 - val_loss: 0.0909 - val_accuracy: 0.9724\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0622 - accuracy: 0.9798 - val_loss: 0.0907 - val_accuracy: 0.9722\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0517 - accuracy: 0.9828 - val_loss: 0.0810 - val_accuracy: 0.9756\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.0911 - val_accuracy: 0.9721\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 0.0799 - val_accuracy: 0.9765\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0292 - accuracy: 0.9901 - val_loss: 0.0899 - val_accuracy: 0.9762\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.0906 - val_accuracy: 0.9753\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0914 - val_accuracy: 0.9747\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.1215 - val_accuracy: 0.9703\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0938 - val_accuracy: 0.9762\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0887 - val_accuracy: 0.9791\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0959 - val_accuracy: 0.9787\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0908 - val_accuracy: 0.9795\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0958 - val_accuracy: 0.9801\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0992 - val_accuracy: 0.9803\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.1052 - val_accuracy: 0.9796\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0963 - val_accuracy: 0.9790\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.1028 - val_accuracy: 0.9787\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0845 - val_accuracy: 0.9803\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1046 - val_accuracy: 0.9802\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.1211 - val_accuracy: 0.9777\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1283 - val_accuracy: 0.9797\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1429 - val_accuracy: 0.9761\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.1032 - val_accuracy: 0.9803\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1109 - val_accuracy: 0.9826\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.4089e-04 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9809\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 3.8346e-04 - accuracy: 0.9999 - val_loss: 0.1330 - val_accuracy: 0.9801\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1311 - val_accuracy: 0.9817\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.1079 - val_accuracy: 0.9815\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 6.4620e-04 - accuracy: 0.9999 - val_loss: 0.1195 - val_accuracy: 0.9815\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 1.3459e-04 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9824\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 5.6539e-05 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9822\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 3.3518e-05 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9825\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 3.0320e-05 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9822\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.1604e-05 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9823\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0691e-05 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9823\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 1.6339e-05 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9823\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 1.5382e-05 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9823\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 1.3037e-05 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9824\n",
      "\n",
      "Training with -->leaky-relu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 17s 39ms/step - loss: 2.3019 - accuracy: 0.1140 - val_loss: 2.3013 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 2.3003 - accuracy: 0.1149 - val_loss: 2.3003 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 2.2989 - accuracy: 0.1134 - val_loss: 2.2961 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 2.2891 - accuracy: 0.1280 - val_loss: 2.2018 - val_accuracy: 0.2048\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.7095 - accuracy: 0.4270 - val_loss: 0.3284 - val_accuracy: 0.8963\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.2731 - accuracy: 0.9148 - val_loss: 0.1568 - val_accuracy: 0.9488\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.1458 - accuracy: 0.9537 - val_loss: 0.1360 - val_accuracy: 0.9562\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.1048 - accuracy: 0.9672 - val_loss: 0.1081 - val_accuracy: 0.9655\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0794 - accuracy: 0.9737 - val_loss: 0.0826 - val_accuracy: 0.9732\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0617 - accuracy: 0.9808 - val_loss: 0.0802 - val_accuracy: 0.9758\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.0740 - val_accuracy: 0.9777\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.0844 - val_accuracy: 0.9737\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.0756 - val_accuracy: 0.9781\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0801 - val_accuracy: 0.9782\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.0803 - val_accuracy: 0.9785\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0870 - val_accuracy: 0.9771\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0998 - val_accuracy: 0.9759\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0919 - val_accuracy: 0.9803\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0827 - val_accuracy: 0.9814\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0961 - val_accuracy: 0.9780\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0939 - val_accuracy: 0.9812\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1099 - val_accuracy: 0.9795\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0939 - val_accuracy: 0.9798\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1006 - val_accuracy: 0.9783\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1102 - val_accuracy: 0.9805\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0898 - val_accuracy: 0.9787\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0968 - val_accuracy: 0.9822\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0996 - val_accuracy: 0.9823\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0991 - val_accuracy: 0.9820\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1029 - val_accuracy: 0.9828\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 4.1564e-04 - accuracy: 0.9999 - val_loss: 0.1082 - val_accuracy: 0.9827\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.0377e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9824\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 6.8471e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9830\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 5.0279e-05 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9829\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 4.8607e-05 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9831\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 3.6187e-05 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9830\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 3.0901e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9831\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 3.1670e-05 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9828\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 2.7160e-05 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9830\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 2.2207e-05 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9830\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.9749e-05 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9828\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 2.0756e-05 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9830\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.7507e-05 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9829\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.5666e-05 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9830\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.4022e-05 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9830\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.5013e-05 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9830\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.2419e-05 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9831\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.2280e-05 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9831\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.1520e-05 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9831\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.1490e-05 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9830\n",
      "\n",
      "Training with -->elu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 16s 37ms/step - loss: 1.3374 - accuracy: 0.5908 - val_loss: 0.1615 - val_accuracy: 0.9488\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.1464 - accuracy: 0.9526 - val_loss: 0.1025 - val_accuracy: 0.9653\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0919 - accuracy: 0.9725 - val_loss: 0.0755 - val_accuracy: 0.9754\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0659 - accuracy: 0.9787 - val_loss: 0.0779 - val_accuracy: 0.9742\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 0.0647 - val_accuracy: 0.9804\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.0569 - val_accuracy: 0.9811\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 0.0566 - val_accuracy: 0.9816\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.0551 - val_accuracy: 0.9831\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0571 - val_accuracy: 0.9832\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.0518 - val_accuracy: 0.9846\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.0515 - val_accuracy: 0.9852\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0529 - val_accuracy: 0.9849\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.0587 - val_accuracy: 0.9835\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0666 - val_accuracy: 0.9825\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0588 - val_accuracy: 0.9846\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0609 - val_accuracy: 0.9837\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0598 - val_accuracy: 0.9856\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0647 - val_accuracy: 0.9850\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 8.5630e-04 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9848\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 4.8914e-04 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9850\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 3.3747e-04 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 0.9849\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 2.8444e-04 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9852\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 2.2426e-04 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9852\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 1.9485e-04 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9848\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.6702e-04 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9852\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.4944e-04 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9849\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 1.3249e-04 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9847\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.2257e-04 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9845\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 1.0331e-04 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9846\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 9.6443e-05 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9851\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 9.1945e-05 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9850\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 8.9922e-05 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9851\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 7.9416e-05 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9851\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 6.9700e-05 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9848\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 7.3802e-05 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9848\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 5.9138e-05 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9846\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 5.8355e-05 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9847\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 5.5798e-05 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9851\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 5.0603e-05 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9846\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 5.1596e-05 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9847\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 4.6573e-05 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9847\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 4.3704e-05 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9847\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 4.1251e-05 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9849\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 4.0773e-05 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9846\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 3.8258e-05 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9846\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 3.7767e-05 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9845\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 3.4654e-05 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9847\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 3.4003e-05 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9844\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 3.3094e-05 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9846\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 3.0317e-05 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9845\n",
      "\n",
      "Training with -->selu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 15s 37ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0969 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0982 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 13s 34ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0960 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0955 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.1020 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0964 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0961 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0959 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0971 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 13s 35ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0995\n",
      "\n",
      "Training with -->gelu<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 27s 64ms/step - loss: 2.3022 - accuracy: 0.1094 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 2.3014 - accuracy: 0.1138 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3007 - accuracy: 0.1156 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3012 - accuracy: 0.1142 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 23s 63ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3004 - accuracy: 0.1162 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3008 - accuracy: 0.1167 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3009 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3007 - accuracy: 0.1154 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3012 - accuracy: 0.1129 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3010 - accuracy: 0.1146 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3009 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3012 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3010 - accuracy: 0.1144 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3013 - accuracy: 0.1115 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3007 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3012 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3006 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3011 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3018 - accuracy: 0.1115 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3007 - accuracy: 0.1178 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3012 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3012 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3008 - accuracy: 0.1154 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3010 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3016 - accuracy: 0.1118 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3009 - accuracy: 0.1138 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 2.3008 - accuracy: 0.1168 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3007 - accuracy: 0.1157 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3008 - accuracy: 0.1145 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3006 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3009 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3014 - accuracy: 0.1117 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3007 - accuracy: 0.1158 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3015 - accuracy: 0.1112 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3014 - accuracy: 0.1128 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3011 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3007 - accuracy: 0.1150 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 23s 63ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.3010 - accuracy: 0.1137 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "\n",
      "Training with -->swish<-- activation function\n",
      "\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 20s 46ms/step - loss: 2.3021 - accuracy: 0.1138 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3013 - accuracy: 0.1141 - val_loss: 2.3019 - val_accuracy: 0.1060\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3008 - accuracy: 0.1151 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3012 - accuracy: 0.1149 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3008 - accuracy: 0.1141 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3007 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3010 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3005 - accuracy: 0.1172 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 2.3008 - accuracy: 0.1159 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 17s 47ms/step - loss: 2.3013 - accuracy: 0.1144 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3013 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3010 - accuracy: 0.1144 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3016 - accuracy: 0.1113 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3010 - accuracy: 0.1149 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3008 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3012 - accuracy: 0.1133 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3009 - accuracy: 0.1147 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3009 - accuracy: 0.1134 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 2.3012 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3007 - accuracy: 0.1146 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 17s 47ms/step - loss: 2.3006 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3011 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 17s 47ms/step - loss: 2.3010 - accuracy: 0.1115 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3010 - accuracy: 0.1150 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 2.3007 - accuracy: 0.1152 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3011 - accuracy: 0.1127 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3013 - accuracy: 0.1135 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3016 - accuracy: 0.1104 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3008 - accuracy: 0.1155 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3004 - accuracy: 0.1167 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3010 - accuracy: 0.1147 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3011 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3011 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3007 - accuracy: 0.1152 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3009 - accuracy: 0.1154 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3010 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3007 - accuracy: 0.1153 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 2.3009 - accuracy: 0.1138 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 2.3015 - accuracy: 0.1092 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3007 - accuracy: 0.1144 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.3004 - accuracy: 0.1162 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 2.3012 - accuracy: 0.1127 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.3011 - accuracy: 0.1130 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "{'loss': [0.7535043954849243, 0.20564621686935425, 0.14072729647159576, 0.11118079721927643, 0.09347189217805862, 0.0815083235502243, 0.0724647045135498, 0.06540168076753616, 0.06033477187156677, 0.05569303408265114, 0.05067988112568855, 0.04739966243505478, 0.043621089309453964, 0.0482771098613739, 0.03958703204989433, 0.03697831928730011, 0.03465433791279793, 0.03291594237089157, 0.031136374920606613, 0.029318789020180702, 0.027583768591284752, 0.027176180854439735, 0.025079714134335518, 0.024288490414619446, 0.02293081395328045, 0.02202759124338627, 0.021161573007702827, 0.01999044232070446, 0.0190086979418993, 0.018246697261929512, 0.01760052889585495, 0.016811810433864594, 0.015891937538981438, 0.015164478681981564, 0.014226510189473629, 0.013690878637135029, 0.013055716641247272, 0.012332363054156303, 0.011893329210579395, 0.011344227939844131, 0.010768260806798935, 0.010153728537261486, 0.009885254316031933, 0.009354730136692524, 0.00879134051501751, 0.008526604622602463, 0.0080422880128026, 0.007754380349069834, 0.007289327215403318, 0.006987016648054123], 'accuracy': [0.7964583039283752, 0.9446458220481873, 0.9600208401679993, 0.968458354473114, 0.9742083549499512, 0.9765833616256714, 0.9795416593551636, 0.9811458587646484, 0.9825624823570251, 0.9842708110809326, 0.9857291579246521, 0.9863749742507935, 0.9881250262260437, 0.9865208268165588, 0.989145815372467, 0.9897291660308838, 0.9909374713897705, 0.9914374947547913, 0.9918749928474426, 0.9919999837875366, 0.9931041598320007, 0.9928749799728394, 0.9938750267028809, 0.9936666488647461, 0.9942916631698608, 0.9946666955947876, 0.9946249723434448, 0.9951666593551636, 0.9955000281333923, 0.9959166646003723, 0.9959791898727417, 0.9961458444595337, 0.9966458082199097, 0.9964374899864197, 0.997041642665863, 0.9970208406448364, 0.9972500205039978, 0.9973541498184204, 0.9977083206176758, 0.9976875185966492, 0.9980833530426025, 0.9982291460037231, 0.9981250166893005, 0.9982291460037231, 0.9986458420753479, 0.9987916946411133, 0.9988750219345093, 0.9988541603088379, 0.9990000128746033, 0.9991041421890259], 'val_loss': [0.25528445839881897, 0.1501101553440094, 0.11717096716165543, 0.10248300433158875, 0.08861842006444931, 0.07803884148597717, 0.07453789561986923, 0.06980986893177032, 0.06603439152240753, 0.06022945046424866, 0.05748191475868225, 0.05318966507911682, 0.05368407815694809, 0.05255686119198799, 0.04857369512319565, 0.047068022191524506, 0.04738819971680641, 0.04554927721619606, 0.04344070330262184, 0.04417338967323303, 0.04140489548444748, 0.042131271213293076, 0.04219535365700722, 0.03983493894338608, 0.04116232693195343, 0.03876297175884247, 0.03805346041917801, 0.04102405160665512, 0.04150739684700966, 0.038238633424043655, 0.038228970021009445, 0.03753132000565529, 0.040190622210502625, 0.03602460399270058, 0.03596606105566025, 0.03550108149647713, 0.03752977401018143, 0.03451741114258766, 0.034574978053569794, 0.036325760185718536, 0.034955382347106934, 0.03641987964510918, 0.03386779502034187, 0.03800392150878906, 0.034615132957696915, 0.03431819751858711, 0.03602990135550499, 0.034863077104091644, 0.03420797362923622, 0.033452991396188736], 'val_accuracy': [0.9327499866485596, 0.956416666507721, 0.9661666750907898, 0.9710833430290222, 0.9744166731834412, 0.9766666889190674, 0.9778333306312561, 0.9779166579246521, 0.9805833101272583, 0.981333315372467, 0.9827499985694885, 0.9835000038146973, 0.984333336353302, 0.9836666584014893, 0.9848333597183228, 0.9856666922569275, 0.9852499961853027, 0.9860833287239075, 0.9869999885559082, 0.9866666793823242, 0.987500011920929, 0.9877499938011169, 0.9879999756813049, 0.9886666536331177, 0.9879166483879089, 0.9888333082199097, 0.9892500042915344, 0.9880833625793457, 0.9869999885559082, 0.9883333444595337, 0.9884999990463257, 0.9890833497047424, 0.9882500171661377, 0.9893333315849304, 0.9891666769981384, 0.9894999861717224, 0.9884999990463257, 0.9894999861717224, 0.9899166822433472, 0.9894166588783264, 0.9893333315849304, 0.9890000224113464, 0.9897500276565552, 0.9885833263397217, 0.9898333549499512, 0.9901666641235352, 0.9893333315849304, 0.9899166822433472, 0.9896666407585144, 0.9904999732971191]}\n",
      "{'loss': [2.301624059677124, 2.300786018371582, 2.300320625305176, 2.2996342182159424, 2.2983081340789795, 2.294969081878662, 2.2788093090057373, 1.011056661605835, 0.213714137673378, 0.12807288765907288, 0.0941038429737091, 0.07468543201684952, 0.061876535415649414, 0.052892573177814484, 0.043635811656713486, 0.038309045135974884, 0.032218270003795624, 0.027942093089222908, 0.024043167009949684, 0.019993819296360016, 0.019656525924801826, 0.017487889155745506, 0.012660644948482513, 0.013733239844441414, 0.010445346124470234, 0.008299288339912891, 0.008857513777911663, 0.007878934033215046, 0.010140147991478443, 0.014263675548136234, 0.005918518640100956, 0.0033004770521074533, 0.0025936244055628777, 0.003098627319559455, 0.008124314248561859, 0.0015194239094853401, 0.00023795870947651565, 0.0011703725904226303, 0.0020915342029184103, 0.007990608923137188, 0.0006841827998869121, 0.00011604798783082515, 4.966373307979666e-05, 3.437646591919474e-05, 2.7077667255070992e-05, 2.2342355805449188e-05, 1.9027233065571636e-05, 1.6567886632401496e-05, 1.4646539057139307e-05, 1.315193367190659e-05], 'accuracy': [0.1133333370089531, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.12250000238418579, 0.6721875071525574, 0.9325000047683716, 0.9600625038146973, 0.9696875214576721, 0.9763333201408386, 0.979687511920929, 0.9827291369438171, 0.9858541488647461, 0.9869583249092102, 0.9893749952316284, 0.9910208582878113, 0.992270827293396, 0.9934999942779541, 0.9934999942779541, 0.9941250085830688, 0.9956458210945129, 0.995145857334137, 0.9965833425521851, 0.9970625042915344, 0.996916651725769, 0.9976249933242798, 0.9967291951179504, 0.9966041445732117, 0.9980000257492065, 0.9988541603088379, 0.9992499947547913, 0.9990000128746033, 0.9974583387374878, 0.9995833039283752, 0.999958336353302, 0.9996041655540466, 0.9992708563804626, 0.9977291822433472, 0.9998958110809326, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.3016626834869385, 2.3014161586761475, 2.3010292053222656, 2.3001296520233154, 2.2981886863708496, 2.292477607727051, 2.2461986541748047, 0.27466902136802673, 0.17148393392562866, 0.1323615312576294, 0.10986325889825821, 0.09091131389141083, 0.09072725474834442, 0.08101475238800049, 0.0911220982670784, 0.07985556870698929, 0.08994583785533905, 0.0905904769897461, 0.09144791960716248, 0.1215062364935875, 0.09382936358451843, 0.08865498751401901, 0.09590127319097519, 0.09080230444669724, 0.09579981118440628, 0.09915951639413834, 0.10517843812704086, 0.09627020359039307, 0.10283806174993515, 0.08451340347528458, 0.10460715740919113, 0.12111374735832214, 0.12831896543502808, 0.14287973940372467, 0.10315322130918503, 0.1109464019536972, 0.1280154287815094, 0.13301868736743927, 0.13106968998908997, 0.10793048143386841, 0.11952711641788483, 0.12549391388893127, 0.12990924715995789, 0.13351695239543915, 0.13639292120933533, 0.13882599771022797, 0.1409100741147995, 0.14275994896888733, 0.1445055603981018, 0.14595618844032288], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.19499999284744263, 0.9105833172798157, 0.9470833539962769, 0.9570833444595337, 0.9651666879653931, 0.9724166393280029, 0.9722499847412109, 0.9755833148956299, 0.972083330154419, 0.9764999747276306, 0.9761666655540466, 0.9752500057220459, 0.9746666550636292, 0.9702500104904175, 0.9762499928474426, 0.9790833592414856, 0.9787499904632568, 0.9794999957084656, 0.9800833463668823, 0.9802500009536743, 0.9795833230018616, 0.9789999723434448, 0.9787499904632568, 0.9803333282470703, 0.9801666736602783, 0.9776666760444641, 0.9796666502952576, 0.9760833382606506, 0.9802500009536743, 0.9825833439826965, 0.9809166789054871, 0.9800833463668823, 0.9816666841506958, 0.9815000295639038, 0.9815000295639038, 0.9824166893959045, 0.9822499752044678, 0.9825000166893005, 0.9822499752044678, 0.9823333621025085, 0.9823333621025085, 0.9823333621025085, 0.9823333621025085, 0.9824166893959045]}\n",
      "{'loss': [2.301360845565796, 2.300050735473633, 2.297811269760132, 2.2747604846954346, 1.139879584312439, 0.23044830560684204, 0.13728860020637512, 0.09862560033798218, 0.07968395203351974, 0.06107178330421448, 0.05241754651069641, 0.04411747679114342, 0.03746047616004944, 0.030589891597628593, 0.027451319620013237, 0.02174401842057705, 0.01930958405137062, 0.017811313271522522, 0.01374607440084219, 0.012172849848866463, 0.010316113941371441, 0.007707166485488415, 0.009714974090456963, 0.008335944265127182, 0.003285276936367154, 0.008306227624416351, 0.004045749548822641, 0.004968854598701, 0.007843627594411373, 0.0024540377780795097, 0.00029778972384519875, 0.00010139177175005898, 6.946249050088227e-05, 5.395910193328746e-05, 4.410045949043706e-05, 3.715835191542283e-05, 3.2227890187641606e-05, 2.7965059416601434e-05, 2.532140388211701e-05, 2.2705791707267053e-05, 2.0598630726453848e-05, 1.8867118342313915e-05, 1.7408425264875405e-05, 1.61591378855519e-05, 1.5002784493844956e-05, 1.4020014532434288e-05, 1.3153939107724e-05, 1.2372461242193822e-05, 1.167166465165792e-05, 1.1023500519513618e-05], 'accuracy': [0.11397916823625565, 0.11395833641290665, 0.11395833641290665, 0.16764582693576813, 0.6301249861717224, 0.9275208115577698, 0.9570833444595337, 0.9686874747276306, 0.9737083315849304, 0.9806874990463257, 0.9832500219345093, 0.9852083325386047, 0.9880416393280029, 0.9899791479110718, 0.9908541440963745, 0.9928125143051147, 0.9936458468437195, 0.9941041469573975, 0.995270848274231, 0.9959375262260437, 0.9965833425521851, 0.9973541498184204, 0.997041642665863, 0.9972916841506958, 0.9989374876022339, 0.9974374771118164, 0.9988333582878113, 0.9983749985694885, 0.9973958134651184, 0.9994583129882812, 0.9999791383743286, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.301283597946167, 2.3003041744232178, 2.296121120452881, 2.201833486557007, 0.32841289043426514, 0.15682674944400787, 0.136047825217247, 0.1081143468618393, 0.08258094638586044, 0.08023671805858612, 0.07399239391088486, 0.08435428142547607, 0.07555244863033295, 0.08009698241949081, 0.08031292259693146, 0.08700317144393921, 0.09978242963552475, 0.09193919599056244, 0.08270315825939178, 0.09611845016479492, 0.09386061877012253, 0.10993919521570206, 0.09392406046390533, 0.10060412436723709, 0.11018694192171097, 0.089780792593956, 0.0967877060174942, 0.09963446855545044, 0.09907364845275879, 0.1029251292347908, 0.10823912918567657, 0.11237359791994095, 0.11581986397504807, 0.11883111298084259, 0.12133903801441193, 0.12349214404821396, 0.12542708218097687, 0.1274169683456421, 0.128799170255661, 0.13021361827850342, 0.13169102370738983, 0.13291342556476593, 0.13422583043575287, 0.13538281619548798, 0.13641804456710815, 0.13750992715358734, 0.1384965181350708, 0.13940882682800293, 0.1403162181377411, 0.14116205275058746], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.20475000143051147, 0.8962500095367432, 0.9487500190734863, 0.956166684627533, 0.965499997138977, 0.9732499718666077, 0.9757500290870667, 0.9776666760444641, 0.9737499952316284, 0.9780833125114441, 0.9781666398048401, 0.9785000085830688, 0.9770833253860474, 0.9759166836738586, 0.9803333282470703, 0.981416642665863, 0.9779999852180481, 0.981249988079071, 0.9794999957084656, 0.9798333048820496, 0.9783333539962769, 0.9804999828338623, 0.9786666631698608, 0.9822499752044678, 0.9823333621025085, 0.9819999933242798, 0.9828333258628845, 0.9827499985694885, 0.9824166893959045, 0.9829999804496765, 0.9829166531562805, 0.9830833077430725, 0.9829999804496765, 0.9830833077430725, 0.9828333258628845, 0.9829999804496765, 0.9829999804496765, 0.9828333258628845, 0.9829999804496765, 0.9829166531562805, 0.9829999804496765, 0.9829999804496765, 0.9829999804496765, 0.9830833077430725, 0.9830833077430725, 0.9830833077430725, 0.9829999804496765]}\n",
      "{'loss': [0.686800479888916, 0.13010311126708984, 0.0865410640835762, 0.06558620184659958, 0.05223498120903969, 0.0422450453042984, 0.03520553186535835, 0.028653772547841072, 0.02324242889881134, 0.018135929480195045, 0.015518390573561192, 0.01329783909022808, 0.009356905706226826, 0.007591086905449629, 0.004409336484968662, 0.0035474528558552265, 0.0024579635355621576, 0.0014219243312254548, 0.0007999822846613824, 0.00048531711217947304, 0.0003581634082365781, 0.0002874530619010329, 0.00023650159710086882, 0.00019703569705598056, 0.00016877194866538048, 0.00014941841072868556, 0.00013549394498113543, 0.0001209884649142623, 0.00010948782437480986, 9.98727700789459e-05, 9.244403918273747e-05, 8.478540257783607e-05, 7.813957199687138e-05, 7.266516331583261e-05, 6.826509343227372e-05, 6.364431465044618e-05, 6.0016165662091225e-05, 5.6435412261635065e-05, 5.3034826123621315e-05, 5.012907422496937e-05, 4.7503028326900676e-05, 4.4929340219823644e-05, 4.273853846825659e-05, 4.1312498069601133e-05, 3.9492722862632945e-05, 3.7534664443228394e-05, 3.575528535293415e-05, 3.429321805015206e-05, 3.310656393296085e-05, 3.1785035389475524e-05], 'accuracy': [0.7996249794960022, 0.9582291841506958, 0.9729375243186951, 0.9792500138282776, 0.9835208058357239, 0.987291693687439, 0.9889583587646484, 0.9912499785423279, 0.9927291870117188, 0.9944999814033508, 0.9954166412353516, 0.9960625171661377, 0.9972916841506958, 0.9979166388511658, 0.9992083311080933, 0.9993333220481873, 0.9994375109672546, 0.9998124837875366, 0.9999374747276306, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.1614932119846344, 0.10252208262681961, 0.07546241581439972, 0.07792110741138458, 0.06468602269887924, 0.05685801804065704, 0.05660022050142288, 0.055090077221393585, 0.0571301132440567, 0.051811445504426956, 0.051474325358867645, 0.05287674441933632, 0.05867885425686836, 0.06661800295114517, 0.05883190780878067, 0.06090794503688812, 0.05979510396718979, 0.06469283252954483, 0.06738381087779999, 0.06971734017133713, 0.07182445377111435, 0.07353361696004868, 0.07570132613182068, 0.07651626318693161, 0.07865125685930252, 0.07998518645763397, 0.08096030354499817, 0.0827280655503273, 0.08344288170337677, 0.0852321907877922, 0.08562803268432617, 0.08655981719493866, 0.08796003460884094, 0.08888600021600723, 0.08946339786052704, 0.09037037938833237, 0.0910000428557396, 0.09171944856643677, 0.09274718910455704, 0.0930974930524826, 0.09423306584358215, 0.09469111263751984, 0.09553822875022888, 0.09603046625852585, 0.09689173102378845, 0.0972982794046402, 0.09778202325105667, 0.09838813543319702, 0.09885567426681519, 0.09965922683477402], 'val_accuracy': [0.9488333463668823, 0.9653333425521851, 0.9754166603088379, 0.9741666913032532, 0.9804166555404663, 0.981083333492279, 0.9815833568572998, 0.9830833077430725, 0.9831666946411133, 0.98458331823349, 0.9852499961853027, 0.9849166870117188, 0.9835000038146973, 0.9825000166893005, 0.98458331823349, 0.9836666584014893, 0.9855833053588867, 0.9850000143051147, 0.9848333597183228, 0.9850000143051147, 0.9849166870117188, 0.9852499961853027, 0.9852499961853027, 0.9848333597183228, 0.9852499961853027, 0.9849166870117188, 0.984749972820282, 0.984499990940094, 0.98458331823349, 0.9850833415985107, 0.9850000143051147, 0.9850833415985107, 0.9850833415985107, 0.9848333597183228, 0.9848333597183228, 0.98458331823349, 0.984666645526886, 0.9850833415985107, 0.98458331823349, 0.984749972820282, 0.984749972820282, 0.984749972820282, 0.9849166870117188, 0.98458331823349, 0.98458331823349, 0.984499990940094, 0.984666645526886, 0.984416663646698, 0.98458331823349, 0.984499990940094]}\n",
      "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'accuracy': [0.09825000166893005, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823, 0.09852083027362823], 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_accuracy': [0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716, 0.09950000047683716]}\n",
      "{'loss': [2.3019373416900635, 2.3012759685516357, 2.301088333129883, 2.3010337352752686, 2.301017999649048, 2.301008701324463, 2.3010096549987793, 2.301008462905884, 2.3010122776031494, 2.3010106086730957, 2.301008939743042, 2.301004409790039, 2.3010127544403076, 2.3010082244873047, 2.301006555557251, 2.3010098934173584, 2.3010072708129883, 2.3010077476501465, 2.301009178161621, 2.301006555557251, 2.3010098934173584, 2.3010127544403076, 2.301004648208618, 2.30100679397583, 2.3010056018829346, 2.3010013103485107, 2.3010120391845703, 2.3010082244873047, 2.301009178161621, 2.3010079860687256, 2.30100679397583, 2.3010075092315674, 2.3010075092315674, 2.3010060787200928, 2.301010847091675, 2.301006555557251, 2.3010096549987793, 2.3010075092315674, 2.3010072708129883, 2.301009178161621, 2.301008462905884, 2.301009178161621, 2.301008939743042, 2.301008701324463, 2.3010103702545166, 2.3010075092315674, 2.3010029792785645, 2.3010082244873047, 2.301008939743042, 2.3010106086730957], 'accuracy': [0.11310416460037231, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.3019940853118896, 2.301931858062744, 2.3019790649414062, 2.3020098209381104, 2.3020386695861816, 2.302065134048462, 2.3020546436309814, 2.3020403385162354, 2.3020694255828857, 2.302064895629883, 2.3020713329315186, 2.302091121673584, 2.3021180629730225, 2.3020927906036377, 2.3020784854888916, 2.3021035194396973, 2.3021068572998047, 2.302093505859375, 2.3021023273468018, 2.3021178245544434, 2.3021140098571777, 2.302109718322754, 2.3021137714385986, 2.302123785018921, 2.3021340370178223, 2.3020660877227783, 2.3021111488342285, 2.302102565765381, 2.3021156787872314, 2.302111864089966, 2.3021059036254883, 2.3021256923675537, 2.302110433578491, 2.302112340927124, 2.3021068572998047, 2.3020899295806885, 2.3020973205566406, 2.3020782470703125, 2.302084445953369, 2.3020801544189453, 2.3021016120910645, 2.30210280418396, 2.3021206855773926, 2.3021137714385986, 2.302110433578491, 2.302117109298706, 2.302107095718384, 2.3021023273468018, 2.3021082878112793, 2.3021116256713867], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n",
      "{'loss': [2.301912784576416, 2.3012497425079346, 2.301071882247925, 2.3010246753692627, 2.301013231277466, 2.3010072708129883, 2.3010072708129883, 2.3010048866271973, 2.301011085510254, 2.3010058403015137, 2.301011323928833, 2.3010053634643555, 2.3010082244873047, 2.3010122776031494, 2.3010036945343018, 2.301011800765991, 2.3010051250457764, 2.301010847091675, 2.3010125160217285, 2.301008701324463, 2.301008462905884, 2.3010103702545166, 2.3010096549987793, 2.3010082244873047, 2.3010072708129883, 2.3010082244873047, 2.30100679397583, 2.3010075092315674, 2.301009178161621, 2.3010025024414062, 2.3010075092315674, 2.3010082244873047, 2.301008939743042, 2.3010106086730957, 2.301011323928833, 2.3010072708129883, 2.301007032394409, 2.3010056018829346, 2.3010034561157227, 2.30100679397583, 2.3010079860687256, 2.3010075092315674, 2.3010072708129883, 2.301008939743042, 2.301011562347412, 2.30100417137146, 2.301009178161621, 2.3010029792785645, 2.3010082244873047, 2.3010082244873047], 'accuracy': [0.11341666430234909, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665, 0.11395833641290665], 'val_loss': [2.301903009414673, 2.301884889602661, 2.3019652366638184, 2.302018642425537, 2.302051067352295, 2.302060842514038, 2.302090883255005, 2.3020997047424316, 2.3020827770233154, 2.302072525024414, 2.302072763442993, 2.3020739555358887, 2.302079200744629, 2.3020880222320557, 2.3021206855773926, 2.302107810974121, 2.302107572555542, 2.3020968437194824, 2.302097797393799, 2.3021059036254883, 2.3021183013916016, 2.302114963531494, 2.302114963531494, 2.3021035194396973, 2.302114725112915, 2.3021154403686523, 2.3021016120910645, 2.3021318912506104, 2.302126169204712, 2.302107810974121, 2.302086353302002, 2.3021116256713867, 2.3021128177642822, 2.3021059036254883, 2.3021366596221924, 2.302093505859375, 2.3020858764648438, 2.302072048187256, 2.3021302223205566, 2.3021011352539062, 2.3020987510681152, 2.302093982696533, 2.3020992279052734, 2.3021047115325928, 2.302093982696533, 2.302119731903076, 2.3021340370178223, 2.3020737171173096, 2.3020997047424316, 2.302123785018921], 'val_accuracy': [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def preprocess_mnist(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    sample = GaussianNoise(0.2)\n",
    "    x_train = sample(x_train/255, training=True)\n",
    "    x_test = sample(x_test/255, training=True)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test= to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, input_shape\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def build_cnn(activation,\n",
    "              dropout_rate,\n",
    "              optimizer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=SGD())\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "          validation_split=0.20,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "for r in result:\n",
    "    print(r.history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "noise_18cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
