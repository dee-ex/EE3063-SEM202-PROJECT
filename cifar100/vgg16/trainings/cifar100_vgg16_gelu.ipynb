{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WljAm5f0fKkw",
    "outputId": "219b636c-13d7-44e2-9f07-6b37c750457c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 4s 0us/step\n",
      "169017344/169001437 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "a2acb51d-15ba-417b-9dae-020c9858de9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "14d75fea-62e5-4733-e623-d2c6226d4aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 45s 124ms/step - loss: 7.8841 - accuracy: 0.0111 - top3_acc: 0.0312 - top_k_categorical_accuracy: 0.0513 - val_loss: 6.8109 - val_accuracy: 0.0089 - val_top3_acc: 0.0319 - val_top_k_categorical_accuracy: 0.0521\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 7.2872 - accuracy: 0.0171 - top3_acc: 0.0506 - top_k_categorical_accuracy: 0.0786 - val_loss: 6.7590 - val_accuracy: 0.0185 - val_top3_acc: 0.0475 - val_top_k_categorical_accuracy: 0.0772\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 6.9972 - accuracy: 0.0298 - top3_acc: 0.0801 - top_k_categorical_accuracy: 0.1229 - val_loss: 6.6728 - val_accuracy: 0.0230 - val_top3_acc: 0.0579 - val_top_k_categorical_accuracy: 0.0986\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 6.8520 - accuracy: 0.0372 - top3_acc: 0.0980 - top_k_categorical_accuracy: 0.1495 - val_loss: 6.5896 - val_accuracy: 0.0277 - val_top3_acc: 0.0771 - val_top_k_categorical_accuracy: 0.1274\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 6.7184 - accuracy: 0.0419 - top3_acc: 0.1116 - top_k_categorical_accuracy: 0.1727 - val_loss: 6.5045 - val_accuracy: 0.0296 - val_top3_acc: 0.0942 - val_top_k_categorical_accuracy: 0.1540\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 6.6018 - accuracy: 0.0494 - top3_acc: 0.1302 - top_k_categorical_accuracy: 0.1973 - val_loss: 6.4458 - val_accuracy: 0.0336 - val_top3_acc: 0.1007 - val_top_k_categorical_accuracy: 0.1604\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 6.5181 - accuracy: 0.0569 - top3_acc: 0.1486 - top_k_categorical_accuracy: 0.2206 - val_loss: 6.3081 - val_accuracy: 0.0536 - val_top3_acc: 0.1349 - val_top_k_categorical_accuracy: 0.2041\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 6.4250 - accuracy: 0.0627 - top3_acc: 0.1598 - top_k_categorical_accuracy: 0.2383 - val_loss: 6.3143 - val_accuracy: 0.0501 - val_top3_acc: 0.1342 - val_top_k_categorical_accuracy: 0.2070\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 6.3559 - accuracy: 0.0705 - top3_acc: 0.1740 - top_k_categorical_accuracy: 0.2528 - val_loss: 6.3054 - val_accuracy: 0.0586 - val_top3_acc: 0.1499 - val_top_k_categorical_accuracy: 0.2326\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 6.2942 - accuracy: 0.0748 - top3_acc: 0.1810 - top_k_categorical_accuracy: 0.2675 - val_loss: 6.2105 - val_accuracy: 0.0601 - val_top3_acc: 0.1601 - val_top_k_categorical_accuracy: 0.2390\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 6.2104 - accuracy: 0.0799 - top3_acc: 0.1907 - top_k_categorical_accuracy: 0.2758 - val_loss: 6.2475 - val_accuracy: 0.0720 - val_top3_acc: 0.1750 - val_top_k_categorical_accuracy: 0.2474\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 6.1399 - accuracy: 0.0839 - top3_acc: 0.2063 - top_k_categorical_accuracy: 0.2945 - val_loss: 6.1828 - val_accuracy: 0.0701 - val_top3_acc: 0.1712 - val_top_k_categorical_accuracy: 0.2558\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 6.0883 - accuracy: 0.0909 - top3_acc: 0.2205 - top_k_categorical_accuracy: 0.3102 - val_loss: 6.2374 - val_accuracy: 0.0668 - val_top3_acc: 0.1655 - val_top_k_categorical_accuracy: 0.2420\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 6.0160 - accuracy: 0.0975 - top3_acc: 0.2324 - top_k_categorical_accuracy: 0.3257 - val_loss: 6.0475 - val_accuracy: 0.0791 - val_top3_acc: 0.1972 - val_top_k_categorical_accuracy: 0.2797\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 5.9933 - accuracy: 0.1013 - top3_acc: 0.2410 - top_k_categorical_accuracy: 0.3351 - val_loss: 6.2582 - val_accuracy: 0.0660 - val_top3_acc: 0.1666 - val_top_k_categorical_accuracy: 0.2437\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 5.9462 - accuracy: 0.1087 - top3_acc: 0.2463 - top_k_categorical_accuracy: 0.3440 - val_loss: 5.9726 - val_accuracy: 0.0918 - val_top3_acc: 0.2159 - val_top_k_categorical_accuracy: 0.2973\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 5.8724 - accuracy: 0.1139 - top3_acc: 0.2570 - top_k_categorical_accuracy: 0.3552 - val_loss: 5.9014 - val_accuracy: 0.1147 - val_top3_acc: 0.2595 - val_top_k_categorical_accuracy: 0.3529\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 5.7829 - accuracy: 0.1241 - top3_acc: 0.2738 - top_k_categorical_accuracy: 0.3781 - val_loss: 6.1040 - val_accuracy: 0.0981 - val_top3_acc: 0.2229 - val_top_k_categorical_accuracy: 0.3097\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 5.7538 - accuracy: 0.1278 - top3_acc: 0.2858 - top_k_categorical_accuracy: 0.3851 - val_loss: 5.8431 - val_accuracy: 0.1219 - val_top3_acc: 0.2633 - val_top_k_categorical_accuracy: 0.3498\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 5.6801 - accuracy: 0.1342 - top3_acc: 0.2962 - top_k_categorical_accuracy: 0.4006 - val_loss: 5.9643 - val_accuracy: 0.1181 - val_top3_acc: 0.2591 - val_top_k_categorical_accuracy: 0.3495\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 5.6397 - accuracy: 0.1414 - top3_acc: 0.3016 - top_k_categorical_accuracy: 0.4068 - val_loss: 5.7397 - val_accuracy: 0.1257 - val_top3_acc: 0.2697 - val_top_k_categorical_accuracy: 0.3637\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 5.5512 - accuracy: 0.1512 - top3_acc: 0.3182 - top_k_categorical_accuracy: 0.4259 - val_loss: 5.7829 - val_accuracy: 0.1201 - val_top3_acc: 0.2634 - val_top_k_categorical_accuracy: 0.3515\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 5.4899 - accuracy: 0.1534 - top3_acc: 0.3305 - top_k_categorical_accuracy: 0.4419 - val_loss: 6.0396 - val_accuracy: 0.1063 - val_top3_acc: 0.2429 - val_top_k_categorical_accuracy: 0.3294\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 5.4354 - accuracy: 0.1640 - top3_acc: 0.3397 - top_k_categorical_accuracy: 0.4529 - val_loss: 5.8160 - val_accuracy: 0.1594 - val_top3_acc: 0.3256 - val_top_k_categorical_accuracy: 0.4267\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 5.3772 - accuracy: 0.1701 - top3_acc: 0.3535 - top_k_categorical_accuracy: 0.4653 - val_loss: 5.6513 - val_accuracy: 0.1696 - val_top3_acc: 0.3346 - val_top_k_categorical_accuracy: 0.4363\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 5.3301 - accuracy: 0.1741 - top3_acc: 0.3618 - top_k_categorical_accuracy: 0.4721 - val_loss: 6.1516 - val_accuracy: 0.1566 - val_top3_acc: 0.3127 - val_top_k_categorical_accuracy: 0.4113\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 5.2654 - accuracy: 0.1851 - top3_acc: 0.3737 - top_k_categorical_accuracy: 0.4879 - val_loss: 5.9798 - val_accuracy: 0.1319 - val_top3_acc: 0.2693 - val_top_k_categorical_accuracy: 0.3591\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 5.2163 - accuracy: 0.1893 - top3_acc: 0.3805 - top_k_categorical_accuracy: 0.4981 - val_loss: 5.5093 - val_accuracy: 0.1853 - val_top3_acc: 0.3576 - val_top_k_categorical_accuracy: 0.4581\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 5.1397 - accuracy: 0.2009 - top3_acc: 0.4013 - top_k_categorical_accuracy: 0.5145 - val_loss: 5.6512 - val_accuracy: 0.1861 - val_top3_acc: 0.3597 - val_top_k_categorical_accuracy: 0.4564\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 5.0977 - accuracy: 0.2046 - top3_acc: 0.4039 - top_k_categorical_accuracy: 0.5174 - val_loss: 5.7070 - val_accuracy: 0.2140 - val_top3_acc: 0.3966 - val_top_k_categorical_accuracy: 0.5017\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 5.0487 - accuracy: 0.2172 - top3_acc: 0.4124 - top_k_categorical_accuracy: 0.5285 - val_loss: 5.8993 - val_accuracy: 0.1717 - val_top3_acc: 0.3343 - val_top_k_categorical_accuracy: 0.4286\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 4.9908 - accuracy: 0.2232 - top3_acc: 0.4268 - top_k_categorical_accuracy: 0.5387 - val_loss: 5.4566 - val_accuracy: 0.2119 - val_top3_acc: 0.3936 - val_top_k_categorical_accuracy: 0.4905\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.9387 - accuracy: 0.2289 - top3_acc: 0.4373 - top_k_categorical_accuracy: 0.5501 - val_loss: 5.5175 - val_accuracy: 0.2154 - val_top3_acc: 0.3934 - val_top_k_categorical_accuracy: 0.4890\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 4.8615 - accuracy: 0.2425 - top3_acc: 0.4514 - top_k_categorical_accuracy: 0.5668 - val_loss: 5.3631 - val_accuracy: 0.2280 - val_top3_acc: 0.4206 - val_top_k_categorical_accuracy: 0.5238\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.8170 - accuracy: 0.2508 - top3_acc: 0.4619 - top_k_categorical_accuracy: 0.5759 - val_loss: 5.6170 - val_accuracy: 0.2118 - val_top3_acc: 0.3896 - val_top_k_categorical_accuracy: 0.4875\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.7761 - accuracy: 0.2529 - top3_acc: 0.4692 - top_k_categorical_accuracy: 0.5879 - val_loss: 5.1815 - val_accuracy: 0.2543 - val_top3_acc: 0.4479 - val_top_k_categorical_accuracy: 0.5534\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 4.6990 - accuracy: 0.2623 - top3_acc: 0.4868 - top_k_categorical_accuracy: 0.6012 - val_loss: 5.0140 - val_accuracy: 0.2794 - val_top3_acc: 0.4831 - val_top_k_categorical_accuracy: 0.5897\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 4.6592 - accuracy: 0.2723 - top3_acc: 0.4907 - top_k_categorical_accuracy: 0.6081 - val_loss: 5.0833 - val_accuracy: 0.2782 - val_top3_acc: 0.4763 - val_top_k_categorical_accuracy: 0.5795\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 4.5911 - accuracy: 0.2853 - top3_acc: 0.5052 - top_k_categorical_accuracy: 0.6163 - val_loss: 4.8684 - val_accuracy: 0.2898 - val_top3_acc: 0.4951 - val_top_k_categorical_accuracy: 0.5962\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 4.5591 - accuracy: 0.2859 - top3_acc: 0.5118 - top_k_categorical_accuracy: 0.6248 - val_loss: 4.9659 - val_accuracy: 0.2800 - val_top3_acc: 0.4857 - val_top_k_categorical_accuracy: 0.5895\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 4.5124 - accuracy: 0.2940 - top3_acc: 0.5191 - top_k_categorical_accuracy: 0.6295 - val_loss: 4.8836 - val_accuracy: 0.2966 - val_top3_acc: 0.5101 - val_top_k_categorical_accuracy: 0.6082\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 4.4757 - accuracy: 0.3018 - top3_acc: 0.5248 - top_k_categorical_accuracy: 0.6356 - val_loss: 5.0130 - val_accuracy: 0.2900 - val_top3_acc: 0.4975 - val_top_k_categorical_accuracy: 0.6006\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.4185 - accuracy: 0.3073 - top3_acc: 0.5365 - top_k_categorical_accuracy: 0.6461 - val_loss: 4.6524 - val_accuracy: 0.3246 - val_top3_acc: 0.5392 - val_top_k_categorical_accuracy: 0.6435\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.3556 - accuracy: 0.3122 - top3_acc: 0.5448 - top_k_categorical_accuracy: 0.6553 - val_loss: 4.6275 - val_accuracy: 0.3258 - val_top3_acc: 0.5511 - val_top_k_categorical_accuracy: 0.6480\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.2791 - accuracy: 0.3252 - top3_acc: 0.5549 - top_k_categorical_accuracy: 0.6641 - val_loss: 4.5840 - val_accuracy: 0.3348 - val_top3_acc: 0.5605 - val_top_k_categorical_accuracy: 0.6663\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.2343 - accuracy: 0.3332 - top3_acc: 0.5654 - top_k_categorical_accuracy: 0.6733 - val_loss: 4.9190 - val_accuracy: 0.3151 - val_top3_acc: 0.5215 - val_top_k_categorical_accuracy: 0.6194\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 4.1941 - accuracy: 0.3404 - top3_acc: 0.5724 - top_k_categorical_accuracy: 0.6794 - val_loss: 4.7269 - val_accuracy: 0.3321 - val_top3_acc: 0.5482 - val_top_k_categorical_accuracy: 0.6528\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 4.1357 - accuracy: 0.3463 - top3_acc: 0.5811 - top_k_categorical_accuracy: 0.6898 - val_loss: 4.7664 - val_accuracy: 0.3324 - val_top3_acc: 0.5442 - val_top_k_categorical_accuracy: 0.6476\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 4.0655 - accuracy: 0.3629 - top3_acc: 0.6012 - top_k_categorical_accuracy: 0.7033 - val_loss: 4.5757 - val_accuracy: 0.3508 - val_top3_acc: 0.5591 - val_top_k_categorical_accuracy: 0.6628\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.0309 - accuracy: 0.3651 - top3_acc: 0.5987 - top_k_categorical_accuracy: 0.7062 - val_loss: 4.6002 - val_accuracy: 0.3495 - val_top3_acc: 0.5687 - val_top_k_categorical_accuracy: 0.6695\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('gelu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "62df86e6-c864-44fa-ac5e-cca930905b21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [7.67201566696167, 7.2097063064575195, 6.9503607749938965, 6.8054351806640625, 6.675176620483398, 6.57338285446167, 6.493958950042725, 6.403574466705322, 6.3328776359558105, 6.268405437469482, 6.196023464202881, 6.131565570831299, 6.0729169845581055, 6.001755714416504, 5.976963043212891, 5.913079261779785, 5.841590881347656, 5.770167350769043, 5.733740329742432, 5.663923263549805, 5.610350608825684, 5.53655481338501, 5.490584850311279, 5.430843830108643, 5.363954067230225, 5.310644626617432, 5.2514543533325195, 5.196191310882568, 5.140029430389404, 5.0798516273498535, 5.035109519958496, 4.9788432121276855, 4.918978214263916, 4.860324382781982, 4.838574409484863, 4.768493175506592, 4.703679084777832, 4.65272331237793, 4.595791816711426, 4.54779052734375, 4.501707553863525, 4.4523797035217285, 4.403788089752197, 4.336930751800537, 4.279697418212891, 4.231776714324951, 4.185236930847168, 4.126057147979736, 4.086338996887207, 4.047345161437988], 'accuracy': [0.012024999596178532, 0.01977499946951866, 0.03189999982714653, 0.038075000047683716, 0.044599998742341995, 0.05139999836683273, 0.05887499824166298, 0.06472499668598175, 0.07107499986886978, 0.07689999788999557, 0.08065000176429749, 0.08687499910593033, 0.09319999814033508, 0.0989999994635582, 0.10100000351667404, 0.11015000194311142, 0.11580000072717667, 0.12492500245571136, 0.12987500429153442, 0.13650000095367432, 0.14214999973773956, 0.15109999477863312, 0.1537500023841858, 0.16522499918937683, 0.17104999721050262, 0.17790000140666962, 0.18632499873638153, 0.19439999759197235, 0.2011750042438507, 0.20935000479221344, 0.21584999561309814, 0.2249249964952469, 0.23385000228881836, 0.24207499623298645, 0.249099999666214, 0.25562500953674316, 0.26292499899864197, 0.2737250030040741, 0.2829749882221222, 0.28769999742507935, 0.29785001277923584, 0.3051750063896179, 0.30970001220703125, 0.31542500853538513, 0.3240250051021576, 0.3331499993801117, 0.3422499895095825, 0.35234999656677246, 0.3598249852657318, 0.3634999990463257], 'top3_acc': [0.03384999930858612, 0.057999998331069946, 0.08662500232458115, 0.10239999741315842, 0.1158749982714653, 0.13459999859333038, 0.15232500433921814, 0.16509999334812164, 0.17602500319480896, 0.18527500331401825, 0.19522500038146973, 0.2091750055551529, 0.2206750065088272, 0.23520000278949738, 0.24085000157356262, 0.2502500116825104, 0.2633500099182129, 0.2776249945163727, 0.286175012588501, 0.2981500029563904, 0.30720001459121704, 0.32225000858306885, 0.3294749855995178, 0.3384000062942505, 0.354449987411499, 0.3666499853134155, 0.37584999203681946, 0.38690000772476196, 0.39662501215934753, 0.40755000710487366, 0.41819998621940613, 0.42989999055862427, 0.43959999084472656, 0.4516499936580658, 0.45787501335144043, 0.47099998593330383, 0.484250009059906, 0.49357500672340393, 0.5045499801635742, 0.5141249895095825, 0.522599995136261, 0.5305500030517578, 0.5390250086784363, 0.5457749962806702, 0.5544000267982483, 0.5633000135421753, 0.5730249881744385, 0.5857499837875366, 0.5940750241279602, 0.5967249870300293], 'top_k_categorical_accuracy': [0.05587499961256981, 0.09017500281333923, 0.13384999334812164, 0.15832500159740448, 0.180075004696846, 0.2019750028848648, 0.22527499496936798, 0.24404999613761902, 0.25722500681877136, 0.27162501215934753, 0.2819499969482422, 0.2988249957561493, 0.3119249939918518, 0.3287000060081482, 0.3354499936103821, 0.34975001215934753, 0.3621000051498413, 0.3797000050544739, 0.3880999982357025, 0.4038749933242798, 0.413875013589859, 0.43149998784065247, 0.4403499960899353, 0.4507499933242798, 0.46697500348091125, 0.47872498631477356, 0.4916999936103821, 0.5008000135421753, 0.5119749903678894, 0.5184000134468079, 0.5332000255584717, 0.543524980545044, 0.5523250102996826, 0.5677750110626221, 0.5720999836921692, 0.5885000228881836, 0.5994250178337097, 0.609749972820282, 0.6147750020027161, 0.6277999877929688, 0.6334999799728394, 0.6419500112533569, 0.6483500003814697, 0.6578500270843506, 0.663224995136261, 0.6724500060081482, 0.6814749836921692, 0.6916999816894531, 0.6982499957084656, 0.7045750021934509], 'val_loss': [6.810850143432617, 6.759047508239746, 6.672830581665039, 6.589637279510498, 6.504520893096924, 6.445835113525391, 6.308140754699707, 6.314268589019775, 6.305403709411621, 6.210517883300781, 6.2474846839904785, 6.182802677154541, 6.237361431121826, 6.047455310821533, 6.258215427398682, 5.972568035125732, 5.901411533355713, 6.103962421417236, 5.843090057373047, 5.964300632476807, 5.739661693572998, 5.782914161682129, 6.039581298828125, 5.815988063812256, 5.651278018951416, 6.151566028594971, 5.9798078536987305, 5.509285926818848, 5.651162147521973, 5.706999778747559, 5.899272918701172, 5.456636905670166, 5.517459869384766, 5.363093376159668, 5.6170244216918945, 5.181496620178223, 5.013988971710205, 5.083284378051758, 4.868411064147949, 4.96589469909668, 4.883616924285889, 5.013009071350098, 4.652408123016357, 4.627455711364746, 4.583988189697266, 4.918989658355713, 4.726898670196533, 4.766439914703369, 4.575740814208984, 4.600203990936279], 'val_accuracy': [0.008899999782443047, 0.01850000023841858, 0.023000000044703484, 0.027699999511241913, 0.029600000008940697, 0.03359999880194664, 0.053599998354911804, 0.05009999871253967, 0.05860000103712082, 0.060100000351667404, 0.07199999690055847, 0.07010000199079514, 0.06679999828338623, 0.07909999787807465, 0.06599999964237213, 0.09179999679327011, 0.11469999700784683, 0.09809999912977219, 0.12189999967813492, 0.11810000240802765, 0.1256999969482422, 0.1200999990105629, 0.1062999963760376, 0.15940000116825104, 0.1695999950170517, 0.1565999984741211, 0.13189999759197235, 0.18529999256134033, 0.18610000610351562, 0.21400000154972076, 0.17170000076293945, 0.211899995803833, 0.21539999544620514, 0.2280000001192093, 0.2117999941110611, 0.25429999828338623, 0.2793999910354614, 0.2782000005245209, 0.2897999882698059, 0.2800000011920929, 0.29660001397132874, 0.28999999165534973, 0.3246000111103058, 0.32580000162124634, 0.33480000495910645, 0.3151000142097473, 0.3321000039577484, 0.33239999413490295, 0.3508000075817108, 0.34950000047683716], 'val_top3_acc': [0.03189999982714653, 0.04749999940395355, 0.05790000036358833, 0.0771000012755394, 0.094200000166893, 0.1006999984383583, 0.13490000367164612, 0.13420000672340393, 0.14990000426769257, 0.16009999811649323, 0.17499999701976776, 0.1712000072002411, 0.1655000001192093, 0.1972000002861023, 0.16660000383853912, 0.2159000039100647, 0.25949999690055847, 0.22290000319480896, 0.26330000162124634, 0.2590999901294708, 0.26969999074935913, 0.26339998841285706, 0.24289999902248383, 0.3255999982357025, 0.3346000015735626, 0.3127000033855438, 0.26930001378059387, 0.35760000348091125, 0.3596999943256378, 0.39660000801086426, 0.3343000113964081, 0.3935999870300293, 0.39340001344680786, 0.4205999970436096, 0.38960000872612, 0.4478999972343445, 0.4830999970436096, 0.4763000011444092, 0.4950999915599823, 0.48570001125335693, 0.5101000070571899, 0.4975000023841858, 0.5392000079154968, 0.5511000156402588, 0.5605000257492065, 0.5214999914169312, 0.5482000112533569, 0.5442000031471252, 0.5590999722480774, 0.5687000155448914], 'val_top_k_categorical_accuracy': [0.05209999904036522, 0.07720000296831131, 0.09860000014305115, 0.1273999959230423, 0.15399999916553497, 0.16040000319480896, 0.20409999787807465, 0.2070000022649765, 0.23260000348091125, 0.23899999260902405, 0.24740000069141388, 0.2558000087738037, 0.24199999868869781, 0.27970001101493835, 0.24369999766349792, 0.2973000109195709, 0.3528999984264374, 0.30970001220703125, 0.3497999906539917, 0.34950000047683716, 0.3637000024318695, 0.351500004529953, 0.3294000029563904, 0.42669999599456787, 0.43630000948905945, 0.41130000352859497, 0.35910001397132874, 0.45809999108314514, 0.4564000070095062, 0.5016999840736389, 0.428600013256073, 0.49050000309944153, 0.48899999260902405, 0.5238000154495239, 0.48750001192092896, 0.5533999800682068, 0.5896999835968018, 0.5795000195503235, 0.5961999893188477, 0.5895000100135803, 0.6082000136375427, 0.600600004196167, 0.6434999704360962, 0.6480000019073486, 0.6662999987602234, 0.6194000244140625, 0.6528000235557556, 0.647599995136261, 0.6628000140190125, 0.6694999933242798]}\n",
      "313/313 [==============================] - 6s 14ms/step - loss: 4.5056 - accuracy: 0.3547 - top3_acc: 0.5733 - top_k_categorical_accuracy: 0.6712\n",
      "[4.5056233406066895, 0.3546999990940094, 0.5733000040054321, 0.6711999773979187]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_vgg16_gelu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
