{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WljAm5f0fKkw",
    "outputId": "219b636c-13d7-44e2-9f07-6b37c750457c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 4s 0us/step\n",
      "169017344/169001437 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "a2acb51d-15ba-417b-9dae-020c9858de9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "9f132aa8-0c58-4c2a-e2b2-d331acd1c550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 84s 107ms/step - loss: 8.1008 - accuracy: 0.0147 - top3_acc: 0.0422 - top_k_categorical_accuracy: 0.0669 - val_loss: 7.0747 - val_accuracy: 0.0274 - val_top3_acc: 0.0761 - val_top_k_categorical_accuracy: 0.1173\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 7.2995 - accuracy: 0.0324 - top3_acc: 0.0892 - top_k_categorical_accuracy: 0.1339 - val_loss: 6.8987 - val_accuracy: 0.0374 - val_top3_acc: 0.1008 - val_top_k_categorical_accuracy: 0.1499\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 6.9010 - accuracy: 0.0481 - top3_acc: 0.1224 - top_k_categorical_accuracy: 0.1820 - val_loss: 6.7186 - val_accuracy: 0.0412 - val_top3_acc: 0.0999 - val_top_k_categorical_accuracy: 0.1476\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 6.6390 - accuracy: 0.0618 - top3_acc: 0.1525 - top_k_categorical_accuracy: 0.2211 - val_loss: 6.7111 - val_accuracy: 0.0610 - val_top3_acc: 0.1293 - val_top_k_categorical_accuracy: 0.1870\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 6.4298 - accuracy: 0.0763 - top3_acc: 0.1781 - top_k_categorical_accuracy: 0.2542 - val_loss: 6.4693 - val_accuracy: 0.0699 - val_top3_acc: 0.1672 - val_top_k_categorical_accuracy: 0.2426\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 6.2970 - accuracy: 0.0770 - top3_acc: 0.1926 - top_k_categorical_accuracy: 0.2756 - val_loss: 6.5605 - val_accuracy: 0.0735 - val_top3_acc: 0.1621 - val_top_k_categorical_accuracy: 0.2248\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 6.1727 - accuracy: 0.0916 - top3_acc: 0.2141 - top_k_categorical_accuracy: 0.3011 - val_loss: 6.4320 - val_accuracy: 0.0731 - val_top3_acc: 0.1689 - val_top_k_categorical_accuracy: 0.2429\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 6.0451 - accuracy: 0.1016 - top3_acc: 0.2346 - top_k_categorical_accuracy: 0.3291 - val_loss: 6.6383 - val_accuracy: 0.0634 - val_top3_acc: 0.1545 - val_top_k_categorical_accuracy: 0.2208\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 5.9324 - accuracy: 0.1097 - top3_acc: 0.2524 - top_k_categorical_accuracy: 0.3506 - val_loss: 6.3621 - val_accuracy: 0.0934 - val_top3_acc: 0.2036 - val_top_k_categorical_accuracy: 0.2866\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 5.8250 - accuracy: 0.1237 - top3_acc: 0.2769 - top_k_categorical_accuracy: 0.3761 - val_loss: 6.7873 - val_accuracy: 0.0723 - val_top3_acc: 0.1594 - val_top_k_categorical_accuracy: 0.2256\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 5.7301 - accuracy: 0.1335 - top3_acc: 0.2927 - top_k_categorical_accuracy: 0.3978 - val_loss: 6.6783 - val_accuracy: 0.0824 - val_top3_acc: 0.1829 - val_top_k_categorical_accuracy: 0.2630\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 5.6549 - accuracy: 0.1419 - top3_acc: 0.3032 - top_k_categorical_accuracy: 0.4123 - val_loss: 6.2604 - val_accuracy: 0.0999 - val_top3_acc: 0.2165 - val_top_k_categorical_accuracy: 0.3057\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 5.5644 - accuracy: 0.1527 - top3_acc: 0.3230 - top_k_categorical_accuracy: 0.4333 - val_loss: 6.9455 - val_accuracy: 0.0815 - val_top3_acc: 0.1827 - val_top_k_categorical_accuracy: 0.2545\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 5.4745 - accuracy: 0.1608 - top3_acc: 0.3383 - top_k_categorical_accuracy: 0.4454 - val_loss: 7.0715 - val_accuracy: 0.0820 - val_top3_acc: 0.1799 - val_top_k_categorical_accuracy: 0.2615\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 5.4068 - accuracy: 0.1676 - top3_acc: 0.3505 - top_k_categorical_accuracy: 0.4621 - val_loss: 6.4433 - val_accuracy: 0.1104 - val_top3_acc: 0.2433 - val_top_k_categorical_accuracy: 0.3285\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 5.3425 - accuracy: 0.1800 - top3_acc: 0.3707 - top_k_categorical_accuracy: 0.4820 - val_loss: 6.4393 - val_accuracy: 0.1199 - val_top3_acc: 0.2591 - val_top_k_categorical_accuracy: 0.3514\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 5.2478 - accuracy: 0.1954 - top3_acc: 0.3918 - top_k_categorical_accuracy: 0.5047 - val_loss: 6.8464 - val_accuracy: 0.1020 - val_top3_acc: 0.2274 - val_top_k_categorical_accuracy: 0.3163\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 5.1975 - accuracy: 0.1945 - top3_acc: 0.3916 - top_k_categorical_accuracy: 0.5091 - val_loss: 7.4777 - val_accuracy: 0.0966 - val_top3_acc: 0.2207 - val_top_k_categorical_accuracy: 0.3137\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 5.1393 - accuracy: 0.2082 - top3_acc: 0.4063 - top_k_categorical_accuracy: 0.5204 - val_loss: 6.7839 - val_accuracy: 0.1232 - val_top3_acc: 0.2566 - val_top_k_categorical_accuracy: 0.3449\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 5.0614 - accuracy: 0.2126 - top3_acc: 0.4238 - top_k_categorical_accuracy: 0.5380 - val_loss: 7.2514 - val_accuracy: 0.1115 - val_top3_acc: 0.2363 - val_top_k_categorical_accuracy: 0.3207\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 4.9918 - accuracy: 0.2237 - top3_acc: 0.4353 - top_k_categorical_accuracy: 0.5479 - val_loss: 6.3844 - val_accuracy: 0.1431 - val_top3_acc: 0.2945 - val_top_k_categorical_accuracy: 0.3909\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.9220 - accuracy: 0.2378 - top3_acc: 0.4516 - top_k_categorical_accuracy: 0.5664 - val_loss: 6.5073 - val_accuracy: 0.1395 - val_top3_acc: 0.2866 - val_top_k_categorical_accuracy: 0.3808\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.8972 - accuracy: 0.2380 - top3_acc: 0.4506 - top_k_categorical_accuracy: 0.5696 - val_loss: 6.5430 - val_accuracy: 0.1505 - val_top3_acc: 0.2933 - val_top_k_categorical_accuracy: 0.3938\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.8333 - accuracy: 0.2506 - top3_acc: 0.4675 - top_k_categorical_accuracy: 0.5819 - val_loss: 6.3304 - val_accuracy: 0.1626 - val_top3_acc: 0.3161 - val_top_k_categorical_accuracy: 0.4160\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 4.7735 - accuracy: 0.2577 - top3_acc: 0.4770 - top_k_categorical_accuracy: 0.5901 - val_loss: 6.4573 - val_accuracy: 0.1447 - val_top3_acc: 0.2943 - val_top_k_categorical_accuracy: 0.3844\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.7224 - accuracy: 0.2654 - top3_acc: 0.4922 - top_k_categorical_accuracy: 0.6086 - val_loss: 6.6431 - val_accuracy: 0.1545 - val_top3_acc: 0.3067 - val_top_k_categorical_accuracy: 0.4085\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.6861 - accuracy: 0.2732 - top3_acc: 0.4970 - top_k_categorical_accuracy: 0.6124 - val_loss: 6.9121 - val_accuracy: 0.1466 - val_top3_acc: 0.2965 - val_top_k_categorical_accuracy: 0.3864\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.6470 - accuracy: 0.2806 - top3_acc: 0.5053 - top_k_categorical_accuracy: 0.6184 - val_loss: 7.9355 - val_accuracy: 0.1157 - val_top3_acc: 0.2419 - val_top_k_categorical_accuracy: 0.3271\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 4.5948 - accuracy: 0.2881 - top3_acc: 0.5164 - top_k_categorical_accuracy: 0.6295 - val_loss: 6.3878 - val_accuracy: 0.1749 - val_top3_acc: 0.3320 - val_top_k_categorical_accuracy: 0.4337\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 4.5446 - accuracy: 0.2936 - top3_acc: 0.5218 - top_k_categorical_accuracy: 0.6369 - val_loss: 6.3476 - val_accuracy: 0.1682 - val_top3_acc: 0.3360 - val_top_k_categorical_accuracy: 0.4351\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 4.5102 - accuracy: 0.3050 - top3_acc: 0.5282 - top_k_categorical_accuracy: 0.6439 - val_loss: 6.5798 - val_accuracy: 0.1724 - val_top3_acc: 0.3325 - val_top_k_categorical_accuracy: 0.4294\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 4.4781 - accuracy: 0.3004 - top3_acc: 0.5358 - top_k_categorical_accuracy: 0.6507 - val_loss: 6.3002 - val_accuracy: 0.1819 - val_top3_acc: 0.3472 - val_top_k_categorical_accuracy: 0.4545\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.4386 - accuracy: 0.3090 - top3_acc: 0.5403 - top_k_categorical_accuracy: 0.6565 - val_loss: 6.8175 - val_accuracy: 0.1705 - val_top3_acc: 0.3222 - val_top_k_categorical_accuracy: 0.4230\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 4.3705 - accuracy: 0.3234 - top3_acc: 0.5561 - top_k_categorical_accuracy: 0.6671 - val_loss: 7.2999 - val_accuracy: 0.1521 - val_top3_acc: 0.3086 - val_top_k_categorical_accuracy: 0.4024\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 4.3437 - accuracy: 0.3247 - top3_acc: 0.5619 - top_k_categorical_accuracy: 0.6712 - val_loss: 5.8833 - val_accuracy: 0.2054 - val_top3_acc: 0.3938 - val_top_k_categorical_accuracy: 0.5004\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 4.3103 - accuracy: 0.3294 - top3_acc: 0.5626 - top_k_categorical_accuracy: 0.6772 - val_loss: 6.6312 - val_accuracy: 0.1835 - val_top3_acc: 0.3421 - val_top_k_categorical_accuracy: 0.4435\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.2689 - accuracy: 0.3414 - top3_acc: 0.5702 - top_k_categorical_accuracy: 0.6826 - val_loss: 6.3515 - val_accuracy: 0.1984 - val_top3_acc: 0.3685 - val_top_k_categorical_accuracy: 0.4754\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.2210 - accuracy: 0.3453 - top3_acc: 0.5845 - top_k_categorical_accuracy: 0.6940 - val_loss: 6.0533 - val_accuracy: 0.2046 - val_top3_acc: 0.3819 - val_top_k_categorical_accuracy: 0.4864\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.2009 - accuracy: 0.3518 - top3_acc: 0.5869 - top_k_categorical_accuracy: 0.6978 - val_loss: 6.2221 - val_accuracy: 0.2096 - val_top3_acc: 0.3840 - val_top_k_categorical_accuracy: 0.4918\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.1614 - accuracy: 0.3566 - top3_acc: 0.5925 - top_k_categorical_accuracy: 0.7005 - val_loss: 6.0979 - val_accuracy: 0.2120 - val_top3_acc: 0.3819 - val_top_k_categorical_accuracy: 0.4864\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.1255 - accuracy: 0.3646 - top3_acc: 0.5985 - top_k_categorical_accuracy: 0.7071 - val_loss: 5.7763 - val_accuracy: 0.2320 - val_top3_acc: 0.4211 - val_top_k_categorical_accuracy: 0.5242\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.0983 - accuracy: 0.3629 - top3_acc: 0.6020 - top_k_categorical_accuracy: 0.7065 - val_loss: 5.7217 - val_accuracy: 0.2412 - val_top3_acc: 0.4348 - val_top_k_categorical_accuracy: 0.5396\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 4.0661 - accuracy: 0.3728 - top3_acc: 0.6070 - top_k_categorical_accuracy: 0.7098 - val_loss: 6.0132 - val_accuracy: 0.2209 - val_top3_acc: 0.4064 - val_top_k_categorical_accuracy: 0.5065\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.0301 - accuracy: 0.3773 - top3_acc: 0.6131 - top_k_categorical_accuracy: 0.7163 - val_loss: 5.8795 - val_accuracy: 0.2396 - val_top3_acc: 0.4213 - val_top_k_categorical_accuracy: 0.5295\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 4.0113 - accuracy: 0.3819 - top3_acc: 0.6161 - top_k_categorical_accuracy: 0.7215 - val_loss: 5.7803 - val_accuracy: 0.2412 - val_top3_acc: 0.4334 - val_top_k_categorical_accuracy: 0.5362\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.9764 - accuracy: 0.3892 - top3_acc: 0.6212 - top_k_categorical_accuracy: 0.7258 - val_loss: 5.4075 - val_accuracy: 0.2530 - val_top3_acc: 0.4529 - val_top_k_categorical_accuracy: 0.5615\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.9367 - accuracy: 0.3936 - top3_acc: 0.6286 - top_k_categorical_accuracy: 0.7333 - val_loss: 5.9197 - val_accuracy: 0.2433 - val_top3_acc: 0.4310 - val_top_k_categorical_accuracy: 0.5316\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 3.9065 - accuracy: 0.3969 - top3_acc: 0.6379 - top_k_categorical_accuracy: 0.7413 - val_loss: 5.7707 - val_accuracy: 0.2300 - val_top3_acc: 0.4109 - val_top_k_categorical_accuracy: 0.5179\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.8627 - accuracy: 0.4048 - top3_acc: 0.6423 - top_k_categorical_accuracy: 0.7429 - val_loss: 6.0312 - val_accuracy: 0.2471 - val_top3_acc: 0.4368 - val_top_k_categorical_accuracy: 0.5391\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 3.8649 - accuracy: 0.4021 - top3_acc: 0.6376 - top_k_categorical_accuracy: 0.7433 - val_loss: 5.3133 - val_accuracy: 0.2793 - val_top3_acc: 0.4776 - val_top_k_categorical_accuracy: 0.5779\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('selu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "1bfb1c49-af0b-451f-b68d-fef046f5314f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [7.83663272857666, 7.179443836212158, 6.819190502166748, 6.588608741760254, 6.406019687652588, 6.263506889343262, 6.138219356536865, 6.012587547302246, 5.901250839233398, 5.807515621185303, 5.715878963470459, 5.629108905792236, 5.548047065734863, 5.458676338195801, 5.388364315032959, 5.315263748168945, 5.251594543457031, 5.186031341552734, 5.1200971603393555, 5.052945613861084, 4.992014408111572, 4.933462619781494, 4.88562536239624, 4.826899528503418, 4.773690700531006, 4.728302001953125, 4.669209003448486, 4.635509014129639, 4.588254928588867, 4.550121307373047, 4.5010833740234375, 4.466403007507324, 4.42039155960083, 4.379002094268799, 4.336315631866455, 4.300891399383545, 4.2634358406066895, 4.2279372215271, 4.195367336273193, 4.162644863128662, 4.132744312286377, 4.094911575317383, 4.072724342346191, 4.028414249420166, 4.002265453338623, 3.968947649002075, 3.9384398460388184, 3.912175416946411, 3.8756816387176514, 3.8476145267486572], 'accuracy': [0.020600000396370888, 0.036274999380111694, 0.051750000566244125, 0.06350000202655792, 0.07580000162124634, 0.08067499846220016, 0.09354999661445618, 0.10369999706745148, 0.11437500268220901, 0.12434999644756317, 0.13477499783039093, 0.14252500236034393, 0.1545249968767166, 0.16257500648498535, 0.17080000042915344, 0.18369999527931213, 0.1922750025987625, 0.19852499663829803, 0.20960000157356262, 0.21722500026226044, 0.22642500698566437, 0.23405000567436218, 0.24092499911785126, 0.25152501463890076, 0.25802499055862427, 0.2657249867916107, 0.27572500705718994, 0.2805500030517578, 0.28677499294281006, 0.29272499680519104, 0.303849995136261, 0.30842500925064087, 0.3140749931335449, 0.32260000705718994, 0.328249990940094, 0.3333500027656555, 0.3411250114440918, 0.3461500108242035, 0.35385000705718994, 0.35682499408721924, 0.3599250018596649, 0.3652999997138977, 0.36947500705718994, 0.37732499837875366, 0.3832249939441681, 0.3876250088214874, 0.3944999873638153, 0.3942750096321106, 0.4021250009536743, 0.4043999910354614], 'top3_acc': [0.05640000104904175, 0.09657499939203262, 0.1312749981880188, 0.1561499983072281, 0.17964999377727509, 0.196724995970726, 0.21667499840259552, 0.23932500183582306, 0.260699987411499, 0.2773999869823456, 0.29272499680519104, 0.3092249929904938, 0.3257000148296356, 0.34267500042915344, 0.3565250039100647, 0.3736250102519989, 0.3876250088214874, 0.39547500014305115, 0.4101499915122986, 0.42432498931884766, 0.43689998984336853, 0.4483250081539154, 0.45304998755455017, 0.469525009393692, 0.47769999504089355, 0.4890750050544739, 0.5005249977111816, 0.5077999830245972, 0.5149250030517578, 0.5228000283241272, 0.5303249955177307, 0.538224995136261, 0.5433750152587891, 0.5533750057220459, 0.5632500052452087, 0.5661749839782715, 0.5721499919891357, 0.5824750065803528, 0.5863999724388123, 0.5929999947547913, 0.5986250042915344, 0.6028500199317932, 0.6044999957084656, 0.6140000224113464, 0.6188499927520752, 0.6237750053405762, 0.6280750036239624, 0.6348000168800354, 0.6387249827384949, 0.6419249773025513], 'top_k_categorical_accuracy': [0.08730000257492065, 0.14624999463558197, 0.19402499496936798, 0.2277500033378601, 0.2562749981880188, 0.28060001134872437, 0.3052999973297119, 0.3351750075817108, 0.35967499017715454, 0.37834998965263367, 0.39989998936653137, 0.41830000281333923, 0.4359999895095825, 0.45087501406669617, 0.46742498874664307, 0.4857499897480011, 0.501924991607666, 0.5101749897003174, 0.5252500176429749, 0.5408499836921692, 0.5500249862670898, 0.5644000172615051, 0.5731750130653381, 0.5841749906539917, 0.5931249856948853, 0.6050000190734863, 0.6153749823570251, 0.6212999820709229, 0.629925012588501, 0.6364499926567078, 0.6453250050544739, 0.652275025844574, 0.6578249931335449, 0.6660249829292297, 0.6738749742507935, 0.6785500049591064, 0.6837249994277954, 0.6899499893188477, 0.6964250206947327, 0.7005749940872192, 0.7065500020980835, 0.7076249718666077, 0.7099499702453613, 0.7192249894142151, 0.723800003528595, 0.7279000282287598, 0.7304250001907349, 0.737725019454956, 0.7406749725341797, 0.746999979019165], 'val_loss': [7.074699878692627, 6.898675918579102, 6.71862268447876, 6.711145877838135, 6.469340801239014, 6.560504913330078, 6.431960105895996, 6.638270378112793, 6.362059593200684, 6.787311553955078, 6.678295135498047, 6.260365962982178, 6.9455060958862305, 7.071488857269287, 6.443319797515869, 6.439347267150879, 6.846444606781006, 7.4777069091796875, 6.783918857574463, 7.25138521194458, 6.3844451904296875, 6.5073347091674805, 6.542983055114746, 6.330398082733154, 6.457319259643555, 6.643143653869629, 6.91208028793335, 7.935527324676514, 6.387817859649658, 6.347593307495117, 6.579763412475586, 6.3002424240112305, 6.81748104095459, 7.299877166748047, 5.883283615112305, 6.631249904632568, 6.35153865814209, 6.053283214569092, 6.222099304199219, 6.097912788391113, 5.776317596435547, 5.7216715812683105, 6.013227939605713, 5.8794755935668945, 5.780333518981934, 5.40753173828125, 5.919722080230713, 5.770658493041992, 6.031242370605469, 5.313285827636719], 'val_accuracy': [0.027400000020861626, 0.03739999979734421, 0.041200000792741776, 0.061000000685453415, 0.06989999860525131, 0.07349999994039536, 0.0731000006198883, 0.06340000033378601, 0.0934000015258789, 0.0723000019788742, 0.08240000158548355, 0.09989999979734421, 0.08150000125169754, 0.0820000022649765, 0.1103999987244606, 0.11990000307559967, 0.10199999809265137, 0.0966000035405159, 0.12319999933242798, 0.11150000244379044, 0.14309999346733093, 0.13950000703334808, 0.15049999952316284, 0.16259999573230743, 0.14470000565052032, 0.15449999272823334, 0.14659999310970306, 0.11569999903440475, 0.17489999532699585, 0.16820000112056732, 0.17239999771118164, 0.1818999946117401, 0.1704999953508377, 0.15209999680519104, 0.2054000049829483, 0.1835000067949295, 0.19840000569820404, 0.2046000063419342, 0.20960000157356262, 0.21199999749660492, 0.23199999332427979, 0.24120000004768372, 0.22089999914169312, 0.23960000276565552, 0.24120000004768372, 0.2529999911785126, 0.24330000579357147, 0.23000000417232513, 0.24709999561309814, 0.2793000042438507], 'val_top3_acc': [0.07609999924898148, 0.10080000013113022, 0.09989999979734421, 0.12929999828338623, 0.1671999990940094, 0.16210000216960907, 0.1688999980688095, 0.15449999272823334, 0.20360000431537628, 0.15940000116825104, 0.18289999663829803, 0.21649999916553497, 0.1826999932527542, 0.17990000545978546, 0.24330000579357147, 0.2590999901294708, 0.227400004863739, 0.2206999957561493, 0.2565999925136566, 0.2363000065088272, 0.2944999933242798, 0.2865999937057495, 0.29330000281333923, 0.31610000133514404, 0.29429998993873596, 0.3066999912261963, 0.29649999737739563, 0.2418999969959259, 0.3319999873638153, 0.335999995470047, 0.33250001072883606, 0.3472000062465668, 0.3222000002861023, 0.3086000084877014, 0.3937999904155731, 0.34209999442100525, 0.3684999942779541, 0.38190001249313354, 0.3840000033378601, 0.38190001249313354, 0.421099990606308, 0.43479999899864197, 0.40639999508857727, 0.4212999939918518, 0.4334000051021576, 0.4528999924659729, 0.4309999942779541, 0.4108999967575073, 0.4368000030517578, 0.47760000824928284], 'val_top_k_categorical_accuracy': [0.11729999631643295, 0.14990000426769257, 0.147599995136261, 0.18700000643730164, 0.2425999939441681, 0.2248000055551529, 0.24289999902248383, 0.2207999974489212, 0.2865999937057495, 0.225600004196167, 0.2630000114440918, 0.30570000410079956, 0.25450000166893005, 0.2615000009536743, 0.32850000262260437, 0.3513999879360199, 0.31630000472068787, 0.31369999051094055, 0.3449000120162964, 0.3206999897956848, 0.39089998602867126, 0.3808000087738037, 0.3937999904155731, 0.41600000858306885, 0.38440001010894775, 0.40849998593330383, 0.3864000141620636, 0.32710000872612, 0.43369999527931213, 0.4350999891757965, 0.4293999969959259, 0.4544999897480011, 0.4230000078678131, 0.4023999869823456, 0.5004000067710876, 0.44350001215934753, 0.47540000081062317, 0.4864000082015991, 0.4918000102043152, 0.4864000082015991, 0.5242000222206116, 0.5396000146865845, 0.5065000057220459, 0.5295000076293945, 0.5361999869346619, 0.5615000128746033, 0.5315999984741211, 0.5178999900817871, 0.5390999913215637, 0.5778999924659729]}\n",
      "313/313 [==============================] - 5s 11ms/step - loss: 5.4172 - accuracy: 0.2768 - top3_acc: 0.4669 - top_k_categorical_accuracy: 0.5664\n",
      "[5.4171977043151855, 0.2768000066280365, 0.4668999910354614, 0.5663999915122986]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_vgg16_selu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
