{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WljAm5f0fKkw",
    "outputId": "a34ec441-516e-4342-bab0-238867b6bb3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 4s 0us/step\n",
      "169017344/169001437 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "2fe69a2a-fb40-4ecb-ca65-64edca8a3e6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "24348cba-d956-4ca4-affb-8d1c866f5b5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 82s 99ms/step - loss: 7.9613 - accuracy: 0.0106 - top3_acc: 0.0315 - top_k_categorical_accuracy: 0.0530 - val_loss: 6.8319 - val_accuracy: 0.0081 - val_top3_acc: 0.0302 - val_top_k_categorical_accuracy: 0.0518\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 7.2250 - accuracy: 0.0192 - top3_acc: 0.0542 - top_k_categorical_accuracy: 0.0867 - val_loss: 6.7070 - val_accuracy: 0.0248 - val_top3_acc: 0.0616 - val_top_k_categorical_accuracy: 0.0987\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 6.9475 - accuracy: 0.0279 - top3_acc: 0.0788 - top_k_categorical_accuracy: 0.1197 - val_loss: 6.6834 - val_accuracy: 0.0177 - val_top3_acc: 0.0593 - val_top_k_categorical_accuracy: 0.1012\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 6.7696 - accuracy: 0.0394 - top3_acc: 0.1016 - top_k_categorical_accuracy: 0.1559 - val_loss: 6.5695 - val_accuracy: 0.0263 - val_top3_acc: 0.0844 - val_top_k_categorical_accuracy: 0.1344\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 6.6197 - accuracy: 0.0486 - top3_acc: 0.1252 - top_k_categorical_accuracy: 0.1854 - val_loss: 6.4713 - val_accuracy: 0.0347 - val_top3_acc: 0.1086 - val_top_k_categorical_accuracy: 0.1637\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 6.5296 - accuracy: 0.0539 - top3_acc: 0.1377 - top_k_categorical_accuracy: 0.2049 - val_loss: 6.4637 - val_accuracy: 0.0350 - val_top3_acc: 0.0996 - val_top_k_categorical_accuracy: 0.1541\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 6.4429 - accuracy: 0.0564 - top3_acc: 0.1495 - top_k_categorical_accuracy: 0.2204 - val_loss: 6.3324 - val_accuracy: 0.0405 - val_top3_acc: 0.1301 - val_top_k_categorical_accuracy: 0.2006\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 6.3435 - accuracy: 0.0655 - top3_acc: 0.1650 - top_k_categorical_accuracy: 0.2437 - val_loss: 6.3094 - val_accuracy: 0.0446 - val_top3_acc: 0.1316 - val_top_k_categorical_accuracy: 0.1988\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 6.2774 - accuracy: 0.0712 - top3_acc: 0.1733 - top_k_categorical_accuracy: 0.2524 - val_loss: 6.2780 - val_accuracy: 0.0470 - val_top3_acc: 0.1299 - val_top_k_categorical_accuracy: 0.1967\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 6.2148 - accuracy: 0.0781 - top3_acc: 0.1894 - top_k_categorical_accuracy: 0.2680 - val_loss: 6.1774 - val_accuracy: 0.0609 - val_top3_acc: 0.1587 - val_top_k_categorical_accuracy: 0.2320\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 6.1333 - accuracy: 0.0802 - top3_acc: 0.1979 - top_k_categorical_accuracy: 0.2802 - val_loss: 6.4530 - val_accuracy: 0.0596 - val_top3_acc: 0.1545 - val_top_k_categorical_accuracy: 0.2287\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 6.0898 - accuracy: 0.0881 - top3_acc: 0.2082 - top_k_categorical_accuracy: 0.2900 - val_loss: 6.1674 - val_accuracy: 0.0726 - val_top3_acc: 0.1779 - val_top_k_categorical_accuracy: 0.2607\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 6.0078 - accuracy: 0.0926 - top3_acc: 0.2157 - top_k_categorical_accuracy: 0.3027 - val_loss: 6.3843 - val_accuracy: 0.0539 - val_top3_acc: 0.1415 - val_top_k_categorical_accuracy: 0.2135\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 5.9632 - accuracy: 0.1008 - top3_acc: 0.2280 - top_k_categorical_accuracy: 0.3191 - val_loss: 6.0664 - val_accuracy: 0.0780 - val_top3_acc: 0.1849 - val_top_k_categorical_accuracy: 0.2599\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 5.8862 - accuracy: 0.1029 - top3_acc: 0.2354 - top_k_categorical_accuracy: 0.3277 - val_loss: 6.0566 - val_accuracy: 0.0756 - val_top3_acc: 0.1875 - val_top_k_categorical_accuracy: 0.2712\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 5.8419 - accuracy: 0.1081 - top3_acc: 0.2460 - top_k_categorical_accuracy: 0.3451 - val_loss: 6.1018 - val_accuracy: 0.0840 - val_top3_acc: 0.1957 - val_top_k_categorical_accuracy: 0.2778\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 5.7876 - accuracy: 0.1142 - top3_acc: 0.2562 - top_k_categorical_accuracy: 0.3551 - val_loss: 5.9276 - val_accuracy: 0.1025 - val_top3_acc: 0.2305 - val_top_k_categorical_accuracy: 0.3252\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 5.7023 - accuracy: 0.1208 - top3_acc: 0.2711 - top_k_categorical_accuracy: 0.3739 - val_loss: 5.8022 - val_accuracy: 0.1155 - val_top3_acc: 0.2545 - val_top_k_categorical_accuracy: 0.3464\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 5.6509 - accuracy: 0.1279 - top3_acc: 0.2816 - top_k_categorical_accuracy: 0.3834 - val_loss: 5.6787 - val_accuracy: 0.1317 - val_top3_acc: 0.2768 - val_top_k_categorical_accuracy: 0.3760\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 5.6038 - accuracy: 0.1348 - top3_acc: 0.2915 - top_k_categorical_accuracy: 0.3967 - val_loss: 5.7040 - val_accuracy: 0.1312 - val_top3_acc: 0.2698 - val_top_k_categorical_accuracy: 0.3653\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 5.5318 - accuracy: 0.1366 - top3_acc: 0.3010 - top_k_categorical_accuracy: 0.4076 - val_loss: 5.5200 - val_accuracy: 0.1474 - val_top3_acc: 0.3032 - val_top_k_categorical_accuracy: 0.4072\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 5.4672 - accuracy: 0.1494 - top3_acc: 0.3177 - top_k_categorical_accuracy: 0.4225 - val_loss: 5.6146 - val_accuracy: 0.1388 - val_top3_acc: 0.2895 - val_top_k_categorical_accuracy: 0.3857\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 5.4098 - accuracy: 0.1589 - top3_acc: 0.3310 - top_k_categorical_accuracy: 0.4403 - val_loss: 5.5761 - val_accuracy: 0.1495 - val_top3_acc: 0.3027 - val_top_k_categorical_accuracy: 0.3999\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 5.3429 - accuracy: 0.1680 - top3_acc: 0.3430 - top_k_categorical_accuracy: 0.4519 - val_loss: 5.4676 - val_accuracy: 0.1560 - val_top3_acc: 0.3210 - val_top_k_categorical_accuracy: 0.4213\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 5.2977 - accuracy: 0.1722 - top3_acc: 0.3548 - top_k_categorical_accuracy: 0.4643 - val_loss: 5.4025 - val_accuracy: 0.1816 - val_top3_acc: 0.3539 - val_top_k_categorical_accuracy: 0.4589\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 5.2472 - accuracy: 0.1820 - top3_acc: 0.3608 - top_k_categorical_accuracy: 0.4715 - val_loss: 5.3196 - val_accuracy: 0.1780 - val_top3_acc: 0.3485 - val_top_k_categorical_accuracy: 0.4534\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 5.1732 - accuracy: 0.1911 - top3_acc: 0.3743 - top_k_categorical_accuracy: 0.4863 - val_loss: 5.3667 - val_accuracy: 0.1827 - val_top3_acc: 0.3484 - val_top_k_categorical_accuracy: 0.4421\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 5.1237 - accuracy: 0.1950 - top3_acc: 0.3887 - top_k_categorical_accuracy: 0.5000 - val_loss: 5.2911 - val_accuracy: 0.1905 - val_top3_acc: 0.3683 - val_top_k_categorical_accuracy: 0.4748\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 5.0682 - accuracy: 0.2038 - top3_acc: 0.4024 - top_k_categorical_accuracy: 0.5135 - val_loss: 5.2686 - val_accuracy: 0.1995 - val_top3_acc: 0.3797 - val_top_k_categorical_accuracy: 0.4835\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 5.0284 - accuracy: 0.2106 - top3_acc: 0.4068 - top_k_categorical_accuracy: 0.5207 - val_loss: 5.3076 - val_accuracy: 0.1982 - val_top3_acc: 0.3801 - val_top_k_categorical_accuracy: 0.4855\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.9639 - accuracy: 0.2192 - top3_acc: 0.4257 - top_k_categorical_accuracy: 0.5380 - val_loss: 5.1435 - val_accuracy: 0.2149 - val_top3_acc: 0.3920 - val_top_k_categorical_accuracy: 0.4952\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 4.9198 - accuracy: 0.2293 - top3_acc: 0.4291 - top_k_categorical_accuracy: 0.5428 - val_loss: 5.2390 - val_accuracy: 0.2046 - val_top3_acc: 0.3818 - val_top_k_categorical_accuracy: 0.4864\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.8732 - accuracy: 0.2331 - top3_acc: 0.4402 - top_k_categorical_accuracy: 0.5481 - val_loss: 5.0250 - val_accuracy: 0.2331 - val_top3_acc: 0.4319 - val_top_k_categorical_accuracy: 0.5309\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.8129 - accuracy: 0.2442 - top3_acc: 0.4530 - top_k_categorical_accuracy: 0.5672 - val_loss: 5.0324 - val_accuracy: 0.2346 - val_top3_acc: 0.4321 - val_top_k_categorical_accuracy: 0.5388\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.7553 - accuracy: 0.2526 - top3_acc: 0.4578 - top_k_categorical_accuracy: 0.5728 - val_loss: 5.0709 - val_accuracy: 0.2353 - val_top3_acc: 0.4267 - val_top_k_categorical_accuracy: 0.5248\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 4.7040 - accuracy: 0.2614 - top3_acc: 0.4742 - top_k_categorical_accuracy: 0.5853 - val_loss: 5.1218 - val_accuracy: 0.2284 - val_top3_acc: 0.4146 - val_top_k_categorical_accuracy: 0.5184\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 4.6883 - accuracy: 0.2632 - top3_acc: 0.4757 - top_k_categorical_accuracy: 0.5895 - val_loss: 5.2812 - val_accuracy: 0.2274 - val_top3_acc: 0.4161 - val_top_k_categorical_accuracy: 0.5079\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.6178 - accuracy: 0.2747 - top3_acc: 0.4864 - top_k_categorical_accuracy: 0.6006 - val_loss: 4.9389 - val_accuracy: 0.2566 - val_top3_acc: 0.4539 - val_top_k_categorical_accuracy: 0.5588\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 4.5605 - accuracy: 0.2801 - top3_acc: 0.4957 - top_k_categorical_accuracy: 0.6088 - val_loss: 4.8837 - val_accuracy: 0.2652 - val_top3_acc: 0.4698 - val_top_k_categorical_accuracy: 0.5738\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 4.5406 - accuracy: 0.2842 - top3_acc: 0.5025 - top_k_categorical_accuracy: 0.6170 - val_loss: 5.1239 - val_accuracy: 0.2499 - val_top3_acc: 0.4461 - val_top_k_categorical_accuracy: 0.5505\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.5031 - accuracy: 0.2896 - top3_acc: 0.5083 - top_k_categorical_accuracy: 0.6225 - val_loss: 5.0995 - val_accuracy: 0.2597 - val_top3_acc: 0.4553 - val_top_k_categorical_accuracy: 0.5576\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.4522 - accuracy: 0.2957 - top3_acc: 0.5197 - top_k_categorical_accuracy: 0.6358 - val_loss: 4.9586 - val_accuracy: 0.2593 - val_top3_acc: 0.4597 - val_top_k_categorical_accuracy: 0.5578\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 4.3828 - accuracy: 0.3085 - top3_acc: 0.5315 - top_k_categorical_accuracy: 0.6450 - val_loss: 4.6717 - val_accuracy: 0.2940 - val_top3_acc: 0.5085 - val_top_k_categorical_accuracy: 0.6162\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.3542 - accuracy: 0.3110 - top3_acc: 0.5431 - top_k_categorical_accuracy: 0.6547 - val_loss: 4.8649 - val_accuracy: 0.2762 - val_top3_acc: 0.4808 - val_top_k_categorical_accuracy: 0.5814\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.3128 - accuracy: 0.3188 - top3_acc: 0.5491 - top_k_categorical_accuracy: 0.6580 - val_loss: 4.6162 - val_accuracy: 0.3013 - val_top3_acc: 0.5144 - val_top_k_categorical_accuracy: 0.6150\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 4.2640 - accuracy: 0.3253 - top3_acc: 0.5557 - top_k_categorical_accuracy: 0.6680 - val_loss: 4.9618 - val_accuracy: 0.2798 - val_top3_acc: 0.4839 - val_top_k_categorical_accuracy: 0.5868\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.2217 - accuracy: 0.3360 - top3_acc: 0.5694 - top_k_categorical_accuracy: 0.6806 - val_loss: 4.7805 - val_accuracy: 0.3091 - val_top3_acc: 0.5238 - val_top_k_categorical_accuracy: 0.6283\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 4.1892 - accuracy: 0.3401 - top3_acc: 0.5726 - top_k_categorical_accuracy: 0.6836 - val_loss: 4.8429 - val_accuracy: 0.2844 - val_top3_acc: 0.4921 - val_top_k_categorical_accuracy: 0.5952\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.1480 - accuracy: 0.3491 - top3_acc: 0.5795 - top_k_categorical_accuracy: 0.6911 - val_loss: 4.5664 - val_accuracy: 0.3224 - val_top3_acc: 0.5418 - val_top_k_categorical_accuracy: 0.6483\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 4.1046 - accuracy: 0.3573 - top3_acc: 0.5892 - top_k_categorical_accuracy: 0.6997 - val_loss: 4.5730 - val_accuracy: 0.3327 - val_top3_acc: 0.5497 - val_top_k_categorical_accuracy: 0.6567\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "6975e809-61d5-4627-ce74-125f8a1748f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [7.729734420776367, 7.1569600105285645, 6.906226634979248, 6.735522747039795, 6.600096702575684, 6.511033535003662, 6.407034873962402, 6.332050800323486, 6.257588863372803, 6.1912126541137695, 6.126110553741455, 6.070921897888184, 6.004239559173584, 5.945972442626953, 5.8809614181518555, 5.824333190917969, 5.7656331062316895, 5.69864559173584, 5.644565105438232, 5.584532737731934, 5.520832061767578, 5.453485488891602, 5.402429103851318, 5.337864398956299, 5.291219234466553, 5.223597526550293, 5.16128396987915, 5.1115922927856445, 5.059945583343506, 5.017101287841797, 4.967563629150391, 4.919062614440918, 4.870182514190674, 4.804478645324707, 4.766251087188721, 4.711299896240234, 4.662263870239258, 4.6145758628845215, 4.569904327392578, 4.534721374511719, 4.490486145019531, 4.439613342285156, 4.387755870819092, 4.3472113609313965, 4.316227912902832, 4.264671802520752, 4.219183444976807, 4.188995361328125, 4.146381855010986, 4.108191967010498], 'accuracy': [0.012275000102818012, 0.02160000056028366, 0.03127500042319298, 0.041875001043081284, 0.05047500133514404, 0.05335000157356262, 0.059574998915195465, 0.06764999777078629, 0.07289999723434448, 0.07760000228881836, 0.08115000277757645, 0.08889999985694885, 0.09284999966621399, 0.09915000200271606, 0.10352499783039093, 0.11007499694824219, 0.11585000157356262, 0.12212499976158142, 0.12787500023841858, 0.1351500004529953, 0.14000000059604645, 0.15047499537467957, 0.15809999406337738, 0.1676499992609024, 0.17399999499320984, 0.18244999647140503, 0.19222499430179596, 0.19859999418258667, 0.20542499423027039, 0.21357500553131104, 0.22055000066757202, 0.2298000007867813, 0.23309999704360962, 0.24560000002384186, 0.250775009393692, 0.25885000824928284, 0.2678999900817871, 0.2737250030040741, 0.27847498655319214, 0.2857249975204468, 0.29159998893737793, 0.29877498745918274, 0.3068999946117401, 0.3137499988079071, 0.3192000091075897, 0.32587501406669617, 0.33425000309944153, 0.3381499946117401, 0.34907498955726624, 0.3544749915599823], 'top3_acc': [0.035624999552965164, 0.058274999260902405, 0.08502499759197235, 0.10757499933242798, 0.12725000083446503, 0.13989999890327454, 0.1544249951839447, 0.1678750067949295, 0.1772499978542328, 0.19009999930858612, 0.19932499527931213, 0.21082499623298645, 0.21815000474452972, 0.22865000367164612, 0.2362000048160553, 0.24815000593662262, 0.25984999537467957, 0.27265000343322754, 0.28165000677108765, 0.29372501373291016, 0.30559998750686646, 0.3189750015735626, 0.3314000070095062, 0.34415000677108765, 0.35462498664855957, 0.3679499924182892, 0.37747499346733093, 0.39100000262260437, 0.4009000062942505, 0.4089750051498413, 0.4247249960899353, 0.4287000000476837, 0.43939998745918274, 0.45295000076293945, 0.45957499742507935, 0.47255000472068787, 0.4839250147342682, 0.4893999993801117, 0.4948999881744385, 0.5033749938011169, 0.5127750039100647, 0.5231249928474426, 0.5313249826431274, 0.543524980545044, 0.5475999712944031, 0.5565000176429749, 0.5683749914169312, 0.5742999911308289, 0.5794249773025513, 0.587149977684021], 'top_k_categorical_accuracy': [0.05860000103712082, 0.09205000102519989, 0.1295749992132187, 0.16347500681877136, 0.18982499837875366, 0.20925000309944153, 0.22637499868869781, 0.24494999647140503, 0.25562500953674316, 0.2703250050544739, 0.283174991607666, 0.2957499921321869, 0.3075999915599823, 0.3208250105381012, 0.33044999837875366, 0.34735000133514404, 0.3596999943256378, 0.3753499984741211, 0.38532501459121704, 0.39934998750686646, 0.4117250144481659, 0.42627501487731934, 0.4407249987125397, 0.453000009059906, 0.4646250009536743, 0.4780749976634979, 0.49254998564720154, 0.50347501039505, 0.5132750272750854, 0.5233749747276306, 0.5350750088691711, 0.5429999828338623, 0.5496000051498413, 0.5677750110626221, 0.5744500160217285, 0.5859249830245972, 0.5981249809265137, 0.6045500040054321, 0.609624981880188, 0.6192749738693237, 0.6263250112533569, 0.6388750076293945, 0.6447749733924866, 0.6549749970436096, 0.658050000667572, 0.6678500175476074, 0.6800000071525574, 0.684249997138977, 0.690625011920929, 0.6971499919891357], 'val_loss': [6.8319478034973145, 6.706972599029541, 6.68344783782959, 6.5695061683654785, 6.471251010894775, 6.463687419891357, 6.332427501678467, 6.30941915512085, 6.277999401092529, 6.177430152893066, 6.453022480010986, 6.167380332946777, 6.384338855743408, 6.06637716293335, 6.056617736816406, 6.101816654205322, 5.927643299102783, 5.802160739898682, 5.678718566894531, 5.703978538513184, 5.520028591156006, 5.614613056182861, 5.5760908126831055, 5.467593669891357, 5.402473449707031, 5.31955099105835, 5.366732597351074, 5.291060924530029, 5.268561840057373, 5.307621479034424, 5.143519401550293, 5.23903751373291, 5.025026321411133, 5.032382965087891, 5.070938587188721, 5.121829032897949, 5.281219482421875, 4.938903331756592, 4.883674144744873, 5.123905181884766, 5.099524021148682, 4.958611488342285, 4.671732425689697, 4.864909648895264, 4.616235256195068, 4.961767673492432, 4.780498027801514, 4.8429059982299805, 4.5663557052612305, 4.572977542877197], 'val_accuracy': [0.008100000210106373, 0.024800000712275505, 0.01769999973475933, 0.02630000002682209, 0.034699998795986176, 0.03500000014901161, 0.04050000011920929, 0.044599998742341995, 0.04699999839067459, 0.0608999989926815, 0.05959999933838844, 0.07259999960660934, 0.05389999970793724, 0.07800000160932541, 0.07559999823570251, 0.08399999886751175, 0.10249999910593033, 0.11550000309944153, 0.13169999420642853, 0.13120000064373016, 0.14740000665187836, 0.1387999951839447, 0.14949999749660492, 0.15600000321865082, 0.18160000443458557, 0.17800000309944153, 0.1826999932527542, 0.19050000607967377, 0.19949999451637268, 0.19820000231266022, 0.21490000188350677, 0.2046000063419342, 0.23309999704360962, 0.2345999926328659, 0.2353000044822693, 0.22840000689029694, 0.227400004863739, 0.2565999925136566, 0.2651999890804291, 0.2498999983072281, 0.2597000002861023, 0.25929999351501465, 0.2939999997615814, 0.27619999647140503, 0.3012999892234802, 0.2797999978065491, 0.3091000020503998, 0.28439998626708984, 0.3224000036716461, 0.3327000141143799], 'val_top3_acc': [0.03020000085234642, 0.06159999966621399, 0.059300001710653305, 0.0843999981880188, 0.10859999805688858, 0.09960000216960907, 0.13009999692440033, 0.1316000074148178, 0.1298999935388565, 0.15870000422000885, 0.15449999272823334, 0.17790000140666962, 0.14149999618530273, 0.18490000069141388, 0.1875, 0.195700004696846, 0.2304999977350235, 0.25450000166893005, 0.2768000066280365, 0.26980000734329224, 0.30320000648498535, 0.28949999809265137, 0.302700012922287, 0.32100000977516174, 0.3538999855518341, 0.34850001335144043, 0.3483999967575073, 0.3682999908924103, 0.3797000050544739, 0.3801000118255615, 0.3919999897480011, 0.38179999589920044, 0.4318999946117401, 0.43209999799728394, 0.42669999599456787, 0.4146000146865845, 0.41609999537467957, 0.453900009393692, 0.4697999954223633, 0.44609999656677246, 0.4553000032901764, 0.45969998836517334, 0.5084999799728394, 0.48080000281333923, 0.5144000053405762, 0.4839000105857849, 0.5238000154495239, 0.4921000003814697, 0.5418000221252441, 0.5497000217437744], 'val_top_k_categorical_accuracy': [0.05180000141263008, 0.09870000183582306, 0.10119999945163727, 0.13439999520778656, 0.16369999945163727, 0.15410000085830688, 0.20059999823570251, 0.1987999975681305, 0.19670000672340393, 0.23199999332427979, 0.22869999706745148, 0.260699987411499, 0.2134999930858612, 0.2599000036716461, 0.2712000012397766, 0.2777999937534332, 0.32519999146461487, 0.3463999927043915, 0.37599998712539673, 0.3652999997138977, 0.40720000863075256, 0.385699987411499, 0.39989998936653137, 0.4212999939918518, 0.45890000462532043, 0.45339998602867126, 0.44209998846054077, 0.4747999906539917, 0.48350000381469727, 0.4855000078678131, 0.4952000081539154, 0.4864000082015991, 0.5309000015258789, 0.5388000011444092, 0.5248000025749207, 0.5184000134468079, 0.5078999996185303, 0.5587999820709229, 0.5738000273704529, 0.5504999756813049, 0.5576000213623047, 0.5577999949455261, 0.6161999702453613, 0.5813999772071838, 0.6150000095367432, 0.5867999792098999, 0.6283000111579895, 0.5952000021934509, 0.6482999920845032, 0.6567000150680542]}\n",
      "313/313 [==============================] - 5s 11ms/step - loss: 4.5408 - accuracy: 0.3342 - top3_acc: 0.5548 - top_k_categorical_accuracy: 0.6545\n",
      "[4.540757656097412, 0.334199994802475, 0.5547999739646912, 0.6545000076293945]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_vgg16_relu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
