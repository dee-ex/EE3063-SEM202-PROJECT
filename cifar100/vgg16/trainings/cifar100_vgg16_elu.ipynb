{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WljAm5f0fKkw",
    "outputId": "219b636c-13d7-44e2-9f07-6b37c750457c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 4s 0us/step\n",
      "169017344/169001437 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "a2acb51d-15ba-417b-9dae-020c9858de9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "1670d15b-a0bd-49c0-ca7c-364f82b27c3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 35s 99ms/step - loss: 7.9751 - accuracy: 0.0158 - top3_acc: 0.0450 - top_k_categorical_accuracy: 0.0727 - val_loss: 6.9341 - val_accuracy: 0.0216 - val_top3_acc: 0.0633 - val_top_k_categorical_accuracy: 0.1010\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 7.0690 - accuracy: 0.0369 - top3_acc: 0.0929 - top_k_categorical_accuracy: 0.1433 - val_loss: 7.0137 - val_accuracy: 0.0312 - val_top3_acc: 0.0848 - val_top_k_categorical_accuracy: 0.1324\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 6.7313 - accuracy: 0.0522 - top3_acc: 0.1313 - top_k_categorical_accuracy: 0.1937 - val_loss: 6.8694 - val_accuracy: 0.0424 - val_top3_acc: 0.0972 - val_top_k_categorical_accuracy: 0.1451\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 6.5212 - accuracy: 0.0613 - top3_acc: 0.1546 - top_k_categorical_accuracy: 0.2285 - val_loss: 6.6295 - val_accuracy: 0.0481 - val_top3_acc: 0.1215 - val_top_k_categorical_accuracy: 0.1716\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 6.3670 - accuracy: 0.0716 - top3_acc: 0.1747 - top_k_categorical_accuracy: 0.2525 - val_loss: 6.9180 - val_accuracy: 0.0445 - val_top3_acc: 0.1078 - val_top_k_categorical_accuracy: 0.1586\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 6.2862 - accuracy: 0.0798 - top3_acc: 0.1904 - top_k_categorical_accuracy: 0.2723 - val_loss: 7.0360 - val_accuracy: 0.0307 - val_top3_acc: 0.0909 - val_top_k_categorical_accuracy: 0.1378\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 6.1539 - accuracy: 0.0870 - top3_acc: 0.2123 - top_k_categorical_accuracy: 0.3019 - val_loss: 6.5133 - val_accuracy: 0.0551 - val_top3_acc: 0.1362 - val_top_k_categorical_accuracy: 0.2074\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 6.0504 - accuracy: 0.0978 - top3_acc: 0.2274 - top_k_categorical_accuracy: 0.3204 - val_loss: 6.6024 - val_accuracy: 0.0482 - val_top3_acc: 0.1247 - val_top_k_categorical_accuracy: 0.1886\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 5.9663 - accuracy: 0.1061 - top3_acc: 0.2415 - top_k_categorical_accuracy: 0.3382 - val_loss: 7.2103 - val_accuracy: 0.0469 - val_top3_acc: 0.1190 - val_top_k_categorical_accuracy: 0.1772\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 5.8892 - accuracy: 0.1152 - top3_acc: 0.2582 - top_k_categorical_accuracy: 0.3612 - val_loss: 6.6329 - val_accuracy: 0.0614 - val_top3_acc: 0.1552 - val_top_k_categorical_accuracy: 0.2225\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 5.7868 - accuracy: 0.1260 - top3_acc: 0.2750 - top_k_categorical_accuracy: 0.3800 - val_loss: 6.8169 - val_accuracy: 0.0608 - val_top3_acc: 0.1541 - val_top_k_categorical_accuracy: 0.2257\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 5.7189 - accuracy: 0.1326 - top3_acc: 0.2906 - top_k_categorical_accuracy: 0.3966 - val_loss: 6.6991 - val_accuracy: 0.0645 - val_top3_acc: 0.1620 - val_top_k_categorical_accuracy: 0.2408\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 5.6346 - accuracy: 0.1465 - top3_acc: 0.3118 - top_k_categorical_accuracy: 0.4175 - val_loss: 6.2185 - val_accuracy: 0.1006 - val_top3_acc: 0.2218 - val_top_k_categorical_accuracy: 0.3122\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 31s 97ms/step - loss: 5.5521 - accuracy: 0.1565 - top3_acc: 0.3241 - top_k_categorical_accuracy: 0.4340 - val_loss: 7.0721 - val_accuracy: 0.0740 - val_top3_acc: 0.1706 - val_top_k_categorical_accuracy: 0.2406\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 5.4841 - accuracy: 0.1600 - top3_acc: 0.3331 - top_k_categorical_accuracy: 0.4454 - val_loss: 6.8362 - val_accuracy: 0.0752 - val_top3_acc: 0.1828 - val_top_k_categorical_accuracy: 0.2667\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 5.4305 - accuracy: 0.1684 - top3_acc: 0.3475 - top_k_categorical_accuracy: 0.4567 - val_loss: 7.4192 - val_accuracy: 0.0720 - val_top3_acc: 0.1565 - val_top_k_categorical_accuracy: 0.2229\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 5.3716 - accuracy: 0.1791 - top3_acc: 0.3568 - top_k_categorical_accuracy: 0.4737 - val_loss: 6.6488 - val_accuracy: 0.0994 - val_top3_acc: 0.2131 - val_top_k_categorical_accuracy: 0.2928\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 5.2792 - accuracy: 0.1897 - top3_acc: 0.3806 - top_k_categorical_accuracy: 0.4909 - val_loss: 6.2980 - val_accuracy: 0.1213 - val_top3_acc: 0.2464 - val_top_k_categorical_accuracy: 0.3345\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 5.2071 - accuracy: 0.1965 - top3_acc: 0.3912 - top_k_categorical_accuracy: 0.5073 - val_loss: 7.3007 - val_accuracy: 0.0915 - val_top3_acc: 0.1963 - val_top_k_categorical_accuracy: 0.2687\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 31s 97ms/step - loss: 5.1700 - accuracy: 0.1994 - top3_acc: 0.3969 - top_k_categorical_accuracy: 0.5122 - val_loss: 6.3444 - val_accuracy: 0.1202 - val_top3_acc: 0.2621 - val_top_k_categorical_accuracy: 0.3454\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 5.0960 - accuracy: 0.2122 - top3_acc: 0.4156 - top_k_categorical_accuracy: 0.5313 - val_loss: 6.5907 - val_accuracy: 0.1205 - val_top3_acc: 0.2448 - val_top_k_categorical_accuracy: 0.3262\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 5.0361 - accuracy: 0.2199 - top3_acc: 0.4248 - top_k_categorical_accuracy: 0.5402 - val_loss: 5.9259 - val_accuracy: 0.1607 - val_top3_acc: 0.3180 - val_top_k_categorical_accuracy: 0.4217\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.9961 - accuracy: 0.2296 - top3_acc: 0.4360 - top_k_categorical_accuracy: 0.5535 - val_loss: 6.2545 - val_accuracy: 0.1569 - val_top3_acc: 0.3033 - val_top_k_categorical_accuracy: 0.3943\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 4.9265 - accuracy: 0.2349 - top3_acc: 0.4469 - top_k_categorical_accuracy: 0.5630 - val_loss: 6.5576 - val_accuracy: 0.1423 - val_top3_acc: 0.2787 - val_top_k_categorical_accuracy: 0.3743\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.8738 - accuracy: 0.2413 - top3_acc: 0.4557 - top_k_categorical_accuracy: 0.5748 - val_loss: 6.5057 - val_accuracy: 0.1581 - val_top3_acc: 0.3039 - val_top_k_categorical_accuracy: 0.4057\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.8099 - accuracy: 0.2510 - top3_acc: 0.4648 - top_k_categorical_accuracy: 0.5838 - val_loss: 6.3076 - val_accuracy: 0.1615 - val_top3_acc: 0.3095 - val_top_k_categorical_accuracy: 0.4010\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.7527 - accuracy: 0.2610 - top3_acc: 0.4766 - top_k_categorical_accuracy: 0.5976 - val_loss: 6.8155 - val_accuracy: 0.1406 - val_top3_acc: 0.2840 - val_top_k_categorical_accuracy: 0.3831\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.6892 - accuracy: 0.2679 - top3_acc: 0.4912 - top_k_categorical_accuracy: 0.6106 - val_loss: 6.3044 - val_accuracy: 0.1605 - val_top3_acc: 0.3110 - val_top_k_categorical_accuracy: 0.4157\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.6544 - accuracy: 0.2780 - top3_acc: 0.4973 - top_k_categorical_accuracy: 0.6144 - val_loss: 5.9746 - val_accuracy: 0.1821 - val_top3_acc: 0.3520 - val_top_k_categorical_accuracy: 0.4577\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 4.6154 - accuracy: 0.2809 - top3_acc: 0.5055 - top_k_categorical_accuracy: 0.6246 - val_loss: 6.3717 - val_accuracy: 0.1736 - val_top3_acc: 0.3313 - val_top_k_categorical_accuracy: 0.4306\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.5822 - accuracy: 0.2900 - top3_acc: 0.5145 - top_k_categorical_accuracy: 0.6320 - val_loss: 6.1309 - val_accuracy: 0.1800 - val_top3_acc: 0.3566 - val_top_k_categorical_accuracy: 0.4595\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 4.5244 - accuracy: 0.2955 - top3_acc: 0.5228 - top_k_categorical_accuracy: 0.6404 - val_loss: 6.5047 - val_accuracy: 0.1744 - val_top3_acc: 0.3316 - val_top_k_categorical_accuracy: 0.4323\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 4.4781 - accuracy: 0.3007 - top3_acc: 0.5283 - top_k_categorical_accuracy: 0.6459 - val_loss: 5.6704 - val_accuracy: 0.2150 - val_top3_acc: 0.3995 - val_top_k_categorical_accuracy: 0.5048\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.4311 - accuracy: 0.3129 - top3_acc: 0.5391 - top_k_categorical_accuracy: 0.6523 - val_loss: 5.8299 - val_accuracy: 0.2093 - val_top3_acc: 0.3840 - val_top_k_categorical_accuracy: 0.4912\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 4.3825 - accuracy: 0.3189 - top3_acc: 0.5523 - top_k_categorical_accuracy: 0.6672 - val_loss: 5.7439 - val_accuracy: 0.2172 - val_top3_acc: 0.4082 - val_top_k_categorical_accuracy: 0.5115\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.3714 - accuracy: 0.3207 - top3_acc: 0.5505 - top_k_categorical_accuracy: 0.6620 - val_loss: 6.0950 - val_accuracy: 0.1996 - val_top3_acc: 0.3724 - val_top_k_categorical_accuracy: 0.4750\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 4.2966 - accuracy: 0.3347 - top3_acc: 0.5675 - top_k_categorical_accuracy: 0.6803 - val_loss: 6.0771 - val_accuracy: 0.2021 - val_top3_acc: 0.3701 - val_top_k_categorical_accuracy: 0.4715\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.2577 - accuracy: 0.3360 - top3_acc: 0.5705 - top_k_categorical_accuracy: 0.6819 - val_loss: 5.1572 - val_accuracy: 0.2639 - val_top3_acc: 0.4751 - val_top_k_categorical_accuracy: 0.5875\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.2214 - accuracy: 0.3463 - top3_acc: 0.5801 - top_k_categorical_accuracy: 0.6882 - val_loss: 6.2289 - val_accuracy: 0.2173 - val_top3_acc: 0.3967 - val_top_k_categorical_accuracy: 0.4914\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.1882 - accuracy: 0.3506 - top3_acc: 0.5868 - top_k_categorical_accuracy: 0.6933 - val_loss: 5.5546 - val_accuracy: 0.2399 - val_top3_acc: 0.4432 - val_top_k_categorical_accuracy: 0.5448\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 4.1443 - accuracy: 0.3598 - top3_acc: 0.5938 - top_k_categorical_accuracy: 0.7036 - val_loss: 5.4940 - val_accuracy: 0.2628 - val_top3_acc: 0.4665 - val_top_k_categorical_accuracy: 0.5686\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 4.1112 - accuracy: 0.3677 - top3_acc: 0.5994 - top_k_categorical_accuracy: 0.7100 - val_loss: 5.4802 - val_accuracy: 0.2680 - val_top3_acc: 0.4677 - val_top_k_categorical_accuracy: 0.5744\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.0806 - accuracy: 0.3695 - top3_acc: 0.6058 - top_k_categorical_accuracy: 0.7112 - val_loss: 6.3703 - val_accuracy: 0.2231 - val_top3_acc: 0.3982 - val_top_k_categorical_accuracy: 0.4987\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.0602 - accuracy: 0.3745 - top3_acc: 0.6113 - top_k_categorical_accuracy: 0.7166 - val_loss: 5.4846 - val_accuracy: 0.2603 - val_top3_acc: 0.4627 - val_top_k_categorical_accuracy: 0.5696\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 3.9963 - accuracy: 0.3826 - top3_acc: 0.6198 - top_k_categorical_accuracy: 0.7262 - val_loss: 5.5549 - val_accuracy: 0.2625 - val_top3_acc: 0.4692 - val_top_k_categorical_accuracy: 0.5717\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 3.9714 - accuracy: 0.3903 - top3_acc: 0.6212 - top_k_categorical_accuracy: 0.7280 - val_loss: 5.5143 - val_accuracy: 0.2634 - val_top3_acc: 0.4756 - val_top_k_categorical_accuracy: 0.5840\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.9393 - accuracy: 0.3912 - top3_acc: 0.6289 - top_k_categorical_accuracy: 0.7348 - val_loss: 5.1239 - val_accuracy: 0.3061 - val_top3_acc: 0.5121 - val_top_k_categorical_accuracy: 0.6117\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.9018 - accuracy: 0.3981 - top3_acc: 0.6398 - top_k_categorical_accuracy: 0.7428 - val_loss: 5.1259 - val_accuracy: 0.2976 - val_top3_acc: 0.5111 - val_top_k_categorical_accuracy: 0.6149\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.8647 - accuracy: 0.4099 - top3_acc: 0.6390 - top_k_categorical_accuracy: 0.7417 - val_loss: 5.2726 - val_accuracy: 0.2846 - val_top3_acc: 0.4832 - val_top_k_categorical_accuracy: 0.5850\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 3.8437 - accuracy: 0.4050 - top3_acc: 0.6458 - top_k_categorical_accuracy: 0.7478 - val_loss: 5.6740 - val_accuracy: 0.2687 - val_top3_acc: 0.4761 - val_top_k_categorical_accuracy: 0.5742\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('elu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "dc3b1d1e-e70d-4d62-f1b3-f19ed925af6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [7.673943519592285, 6.968329906463623, 6.67452335357666, 6.4793195724487305, 6.35328483581543, 6.249958515167236, 6.138543128967285, 6.044961929321289, 5.945988655090332, 5.865896701812744, 5.780890464782715, 5.694162845611572, 5.620155334472656, 5.5457329750061035, 5.479309558868408, 5.418554782867432, 5.343653678894043, 5.2700629234313965, 5.204709529876709, 5.149707794189453, 5.085022926330566, 5.029592990875244, 4.9687042236328125, 4.91947603225708, 4.8571085929870605, 4.803508758544922, 4.756048202514648, 4.694848537445068, 4.64919376373291, 4.603182792663574, 4.564877510070801, 4.517166614532471, 4.467426776885986, 4.4146037101745605, 4.385295867919922, 4.353514194488525, 4.301515579223633, 4.264156818389893, 4.223448753356934, 4.191092014312744, 4.155045986175537, 4.114895820617676, 4.081058979034424, 4.046826362609863, 4.00756311416626, 3.969705104827881, 3.94016170501709, 3.902858257293701, 3.8746719360351562, 3.8434200286865234], 'accuracy': [0.020925000309944153, 0.04097500070929527, 0.05465000122785568, 0.06522499769926071, 0.07384999841451645, 0.08129999786615372, 0.08980000019073486, 0.0996749997138977, 0.10814999788999557, 0.11482500284910202, 0.1281999945640564, 0.1354999989271164, 0.14685000479221344, 0.15472500026226044, 0.16142499446868896, 0.1695999950170517, 0.1799750030040741, 0.19075000286102295, 0.19837500154972076, 0.203125, 0.21457499265670776, 0.22335000336170197, 0.2310750037431717, 0.23442499339580536, 0.24529999494552612, 0.2545750141143799, 0.2630000114440918, 0.26877498626708984, 0.279449999332428, 0.28314998745918274, 0.29109999537467957, 0.29714998602867126, 0.30387499928474426, 0.3150250017642975, 0.31872498989105225, 0.32587501406669617, 0.3336000144481659, 0.338824987411499, 0.34549999237060547, 0.34950000047683716, 0.35702499747276306, 0.36467498540878296, 0.3684999942779541, 0.3754749894142151, 0.3834249973297119, 0.390500009059906, 0.3894749879837036, 0.39809998869895935, 0.4058000147342682, 0.4064750075340271], 'top3_acc': [0.05817500129342079, 0.10397499799728394, 0.13910000026226044, 0.16152499616146088, 0.1776999980211258, 0.19474999606609344, 0.2145249992609024, 0.22994999587535858, 0.2463500052690506, 0.26087498664855957, 0.2796500027179718, 0.29622501134872437, 0.3111250102519989, 0.32624998688697815, 0.33649998903274536, 0.35179999470710754, 0.3637000024318695, 0.3815000057220459, 0.39309999346733093, 0.40299999713897705, 0.4167749881744385, 0.4267500042915344, 0.4395500123500824, 0.4460749924182892, 0.4586000144481659, 0.4676249921321869, 0.47874999046325684, 0.491100013256073, 0.5008999705314636, 0.508525013923645, 0.51705002784729, 0.524399995803833, 0.5328999757766724, 0.5452250242233276, 0.5509999990463257, 0.5563750267028809, 0.5661749839782715, 0.5723749995231628, 0.5784000158309937, 0.5848749876022339, 0.5906000137329102, 0.5976250171661377, 0.6050999760627747, 0.6127750277519226, 0.6188250184059143, 0.6240000128746033, 0.6302250027656555, 0.6351500153541565, 0.6370499730110168, 0.6451749801635742], 'top_k_categorical_accuracy': [0.09144999831914902, 0.15652500092983246, 0.20327499508857727, 0.23627500236034393, 0.25600001215934753, 0.2766000032424927, 0.30300000309944153, 0.3227500021457672, 0.34272500872612, 0.36550000309944153, 0.38484999537467957, 0.4016999900341034, 0.41885000467300415, 0.43697500228881836, 0.4491499960422516, 0.4616999924182892, 0.47824999690055847, 0.49287500977516174, 0.5086749792098999, 0.5166249871253967, 0.5343999862670898, 0.5433250069618225, 0.5576000213623047, 0.5631999969482422, 0.5776000022888184, 0.5854499936103821, 0.5976499915122986, 0.6082249879837036, 0.614674985408783, 0.625249981880188, 0.6331499814987183, 0.6406750082969666, 0.6481750011444092, 0.659600019454956, 0.6655750274658203, 0.6671500205993652, 0.6791250109672546, 0.6834250092506409, 0.6875500082969666, 0.6930999755859375, 0.70107501745224, 0.7074249982833862, 0.7123749852180481, 0.7179999947547913, 0.7238249778747559, 0.7281249761581421, 0.7335500121116638, 0.7380250096321106, 0.7398499846458435, 0.7477999925613403], 'val_loss': [6.934146881103516, 7.013650894165039, 6.869446277618408, 6.629463195800781, 6.917984485626221, 7.035974979400635, 6.513293266296387, 6.602414608001709, 7.210329055786133, 6.63290548324585, 6.81692361831665, 6.699117183685303, 6.218533039093018, 7.072110176086426, 6.836241245269775, 7.419222831726074, 6.648777961730957, 6.297970294952393, 7.300740718841553, 6.344407081604004, 6.590707778930664, 5.925872802734375, 6.254544734954834, 6.557573318481445, 6.50572395324707, 6.307588577270508, 6.815535068511963, 6.3044023513793945, 5.974553108215332, 6.371729373931885, 6.130878925323486, 6.504661560058594, 5.670398712158203, 5.829882621765137, 5.743906021118164, 6.095032215118408, 6.077062606811523, 5.157164573669434, 6.228860378265381, 5.554627418518066, 5.494028091430664, 5.480216979980469, 6.370346546173096, 5.484557628631592, 5.554861545562744, 5.51430606842041, 5.123902797698975, 5.125892639160156, 5.272634506225586, 5.673986911773682], 'val_accuracy': [0.02160000056028366, 0.031199999153614044, 0.042399998754262924, 0.04809999838471413, 0.04450000077486038, 0.030700000002980232, 0.05510000139474869, 0.04820000007748604, 0.04690000042319298, 0.061400000005960464, 0.06080000102519989, 0.06449999660253525, 0.1005999967455864, 0.07400000095367432, 0.07519999891519547, 0.07199999690055847, 0.09939999878406525, 0.12129999697208405, 0.09149999916553497, 0.12020000070333481, 0.12049999833106995, 0.1606999933719635, 0.15690000355243683, 0.14229999482631683, 0.15809999406337738, 0.1615000069141388, 0.14059999585151672, 0.16050000488758087, 0.18209999799728394, 0.1736000031232834, 0.18000000715255737, 0.17440000176429749, 0.2150000035762787, 0.2092999964952469, 0.21719999611377716, 0.1995999962091446, 0.2020999938249588, 0.2639000117778778, 0.21729999780654907, 0.23989999294281006, 0.262800008058548, 0.2680000066757202, 0.22310000658035278, 0.26030001044273376, 0.26249998807907104, 0.26339998841285706, 0.3061000108718872, 0.29760000109672546, 0.28459998965263367, 0.2687000036239624], 'val_top3_acc': [0.0632999986410141, 0.08479999750852585, 0.09719999879598618, 0.12150000035762787, 0.10779999941587448, 0.0908999964594841, 0.13619999587535858, 0.12470000237226486, 0.11900000274181366, 0.15520000457763672, 0.15410000085830688, 0.16200000047683716, 0.22179999947547913, 0.17059999704360962, 0.18279999494552612, 0.15649999678134918, 0.21310000121593475, 0.24639999866485596, 0.19629999995231628, 0.2621000111103058, 0.24480000138282776, 0.3179999887943268, 0.30329999327659607, 0.27869999408721924, 0.30390000343322754, 0.3095000088214874, 0.2840000092983246, 0.3109999895095825, 0.35199999809265137, 0.3312999904155731, 0.35659998655319214, 0.33160001039505005, 0.3995000123977661, 0.3840000033378601, 0.4081999957561493, 0.3723999857902527, 0.3700999915599823, 0.47510001063346863, 0.396699994802475, 0.4431999921798706, 0.46650001406669617, 0.4677000045776367, 0.39820000529289246, 0.4627000093460083, 0.4691999852657318, 0.475600004196167, 0.5120999813079834, 0.5110999941825867, 0.4832000136375427, 0.47609999775886536], 'val_top_k_categorical_accuracy': [0.10100000351667404, 0.1324000060558319, 0.14509999752044678, 0.17159999907016754, 0.15860000252723694, 0.13779999315738678, 0.20739999413490295, 0.18860000371932983, 0.17720000445842743, 0.2224999964237213, 0.2257000058889389, 0.24079999327659607, 0.31220000982284546, 0.24060000479221344, 0.26669999957084656, 0.22290000319480896, 0.29280000925064087, 0.3345000147819519, 0.2687000036239624, 0.34540000557899475, 0.326200008392334, 0.42170000076293945, 0.39430001378059387, 0.3743000030517578, 0.4056999981403351, 0.4009999930858612, 0.3831000030040741, 0.4156999886035919, 0.4577000141143799, 0.43059998750686646, 0.4595000147819519, 0.43230000138282776, 0.504800021648407, 0.4912000000476837, 0.5115000009536743, 0.4749999940395355, 0.4715000092983246, 0.5874999761581421, 0.49140000343322754, 0.5447999835014343, 0.5685999989509583, 0.574400007724762, 0.49869999289512634, 0.569599986076355, 0.5716999769210815, 0.5839999914169312, 0.6116999983787537, 0.6148999929428101, 0.5849999785423279, 0.5741999745368958]}\n",
      "313/313 [==============================] - 5s 12ms/step - loss: 5.8539 - accuracy: 0.2625 - top3_acc: 0.4542 - top_k_categorical_accuracy: 0.5553\n",
      "[5.853903293609619, 0.26249998807907104, 0.45419999957084656, 0.5552999973297119]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_vgg16_elu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
