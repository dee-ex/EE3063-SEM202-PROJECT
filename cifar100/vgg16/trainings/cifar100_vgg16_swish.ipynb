{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WljAm5f0fKkw",
    "outputId": "219b636c-13d7-44e2-9f07-6b37c750457c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 4s 0us/step\n",
      "169017344/169001437 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "a2acb51d-15ba-417b-9dae-020c9858de9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "82e74956-2629-4a89-b2e0-f343494e2d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 37s 102ms/step - loss: 7.6788 - accuracy: 0.0131 - top3_acc: 0.0360 - top_k_categorical_accuracy: 0.0589 - val_loss: 6.7706 - val_accuracy: 0.0167 - val_top3_acc: 0.0490 - val_top_k_categorical_accuracy: 0.0728\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 7.1561 - accuracy: 0.0218 - top3_acc: 0.0593 - top_k_categorical_accuracy: 0.0933 - val_loss: 6.6111 - val_accuracy: 0.0275 - val_top3_acc: 0.0829 - val_top_k_categorical_accuracy: 0.1369\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 6.8735 - accuracy: 0.0345 - top3_acc: 0.0892 - top_k_categorical_accuracy: 0.1350 - val_loss: 6.5582 - val_accuracy: 0.0321 - val_top3_acc: 0.0900 - val_top_k_categorical_accuracy: 0.1489\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 6.7116 - accuracy: 0.0439 - top3_acc: 0.1144 - top_k_categorical_accuracy: 0.1680 - val_loss: 6.5059 - val_accuracy: 0.0405 - val_top3_acc: 0.1031 - val_top_k_categorical_accuracy: 0.1598\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 6.5820 - accuracy: 0.0508 - top3_acc: 0.1283 - top_k_categorical_accuracy: 0.1921 - val_loss: 6.4585 - val_accuracy: 0.0547 - val_top3_acc: 0.1253 - val_top_k_categorical_accuracy: 0.1801\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 6.4494 - accuracy: 0.0588 - top3_acc: 0.1482 - top_k_categorical_accuracy: 0.2192 - val_loss: 6.4743 - val_accuracy: 0.0526 - val_top3_acc: 0.1243 - val_top_k_categorical_accuracy: 0.1799\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 6.3596 - accuracy: 0.0634 - top3_acc: 0.1606 - top_k_categorical_accuracy: 0.2375 - val_loss: 6.6560 - val_accuracy: 0.0410 - val_top3_acc: 0.0924 - val_top_k_categorical_accuracy: 0.1373\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 6.2622 - accuracy: 0.0701 - top3_acc: 0.1764 - top_k_categorical_accuracy: 0.2527 - val_loss: 6.5046 - val_accuracy: 0.0716 - val_top3_acc: 0.1574 - val_top_k_categorical_accuracy: 0.2265\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 32s 103ms/step - loss: 6.2076 - accuracy: 0.0772 - top3_acc: 0.1885 - top_k_categorical_accuracy: 0.2719 - val_loss: 6.2178 - val_accuracy: 0.0732 - val_top3_acc: 0.1705 - val_top_k_categorical_accuracy: 0.2398\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 6.1091 - accuracy: 0.0877 - top3_acc: 0.2019 - top_k_categorical_accuracy: 0.2886 - val_loss: 6.2918 - val_accuracy: 0.0675 - val_top3_acc: 0.1632 - val_top_k_categorical_accuracy: 0.2289\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 6.0221 - accuracy: 0.0896 - top3_acc: 0.2162 - top_k_categorical_accuracy: 0.3059 - val_loss: 6.2041 - val_accuracy: 0.0783 - val_top3_acc: 0.1770 - val_top_k_categorical_accuracy: 0.2534\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 5.9740 - accuracy: 0.0955 - top3_acc: 0.2246 - top_k_categorical_accuracy: 0.3201 - val_loss: 6.1509 - val_accuracy: 0.0695 - val_top3_acc: 0.1738 - val_top_k_categorical_accuracy: 0.2513\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 31s 97ms/step - loss: 5.9128 - accuracy: 0.0996 - top3_acc: 0.2417 - top_k_categorical_accuracy: 0.3354 - val_loss: 5.9896 - val_accuracy: 0.0777 - val_top3_acc: 0.1918 - val_top_k_categorical_accuracy: 0.2775\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 5.8529 - accuracy: 0.1072 - top3_acc: 0.2509 - top_k_categorical_accuracy: 0.3476 - val_loss: 6.0379 - val_accuracy: 0.0891 - val_top3_acc: 0.2124 - val_top_k_categorical_accuracy: 0.3002\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 5.7643 - accuracy: 0.1207 - top3_acc: 0.2678 - top_k_categorical_accuracy: 0.3689 - val_loss: 6.0139 - val_accuracy: 0.0765 - val_top3_acc: 0.1857 - val_top_k_categorical_accuracy: 0.2740\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 5.7126 - accuracy: 0.1211 - top3_acc: 0.2756 - top_k_categorical_accuracy: 0.3777 - val_loss: 6.0049 - val_accuracy: 0.1051 - val_top3_acc: 0.2364 - val_top_k_categorical_accuracy: 0.3267\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 5.6643 - accuracy: 0.1265 - top3_acc: 0.2852 - top_k_categorical_accuracy: 0.3861 - val_loss: 5.8457 - val_accuracy: 0.0937 - val_top3_acc: 0.2270 - val_top_k_categorical_accuracy: 0.3081\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 5.6044 - accuracy: 0.1342 - top3_acc: 0.2968 - top_k_categorical_accuracy: 0.4050 - val_loss: 5.8467 - val_accuracy: 0.1115 - val_top3_acc: 0.2450 - val_top_k_categorical_accuracy: 0.3388\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 5.5458 - accuracy: 0.1450 - top3_acc: 0.3085 - top_k_categorical_accuracy: 0.4178 - val_loss: 5.8457 - val_accuracy: 0.1122 - val_top3_acc: 0.2526 - val_top_k_categorical_accuracy: 0.3455\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 5.4851 - accuracy: 0.1467 - top3_acc: 0.3210 - top_k_categorical_accuracy: 0.4281 - val_loss: 5.8392 - val_accuracy: 0.1123 - val_top3_acc: 0.2548 - val_top_k_categorical_accuracy: 0.3477\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 5.4872 - accuracy: 0.1534 - top3_acc: 0.3243 - top_k_categorical_accuracy: 0.4338 - val_loss: 5.7360 - val_accuracy: 0.1066 - val_top3_acc: 0.2377 - val_top_k_categorical_accuracy: 0.3268\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 5.3871 - accuracy: 0.1619 - top3_acc: 0.3369 - top_k_categorical_accuracy: 0.4547 - val_loss: 5.6456 - val_accuracy: 0.1451 - val_top3_acc: 0.3064 - val_top_k_categorical_accuracy: 0.4128\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 31s 97ms/step - loss: 5.3079 - accuracy: 0.1673 - top3_acc: 0.3540 - top_k_categorical_accuracy: 0.4654 - val_loss: 5.4972 - val_accuracy: 0.1530 - val_top3_acc: 0.3209 - val_top_k_categorical_accuracy: 0.4217\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 5.2749 - accuracy: 0.1772 - top3_acc: 0.3616 - top_k_categorical_accuracy: 0.4751 - val_loss: 5.3963 - val_accuracy: 0.1639 - val_top3_acc: 0.3310 - val_top_k_categorical_accuracy: 0.4412\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 31s 97ms/step - loss: 5.2111 - accuracy: 0.1836 - top3_acc: 0.3730 - top_k_categorical_accuracy: 0.4899 - val_loss: 5.5270 - val_accuracy: 0.1390 - val_top3_acc: 0.2884 - val_top_k_categorical_accuracy: 0.3868\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 5.1767 - accuracy: 0.1894 - top3_acc: 0.3798 - top_k_categorical_accuracy: 0.4937 - val_loss: 5.4106 - val_accuracy: 0.1553 - val_top3_acc: 0.3165 - val_top_k_categorical_accuracy: 0.4236\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 5.0961 - accuracy: 0.1981 - top3_acc: 0.3969 - top_k_categorical_accuracy: 0.5089 - val_loss: 5.4740 - val_accuracy: 0.1699 - val_top3_acc: 0.3535 - val_top_k_categorical_accuracy: 0.4605\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 5.0392 - accuracy: 0.2076 - top3_acc: 0.4066 - top_k_categorical_accuracy: 0.5215 - val_loss: 5.3584 - val_accuracy: 0.1926 - val_top3_acc: 0.3779 - val_top_k_categorical_accuracy: 0.4801\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 4.9755 - accuracy: 0.2146 - top3_acc: 0.4194 - top_k_categorical_accuracy: 0.5357 - val_loss: 5.2914 - val_accuracy: 0.1937 - val_top3_acc: 0.3745 - val_top_k_categorical_accuracy: 0.4733\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 4.9455 - accuracy: 0.2247 - top3_acc: 0.4217 - top_k_categorical_accuracy: 0.5417 - val_loss: 5.0569 - val_accuracy: 0.2116 - val_top3_acc: 0.4003 - val_top_k_categorical_accuracy: 0.5059\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 4.9007 - accuracy: 0.2309 - top3_acc: 0.4370 - top_k_categorical_accuracy: 0.5538 - val_loss: 5.2235 - val_accuracy: 0.2094 - val_top3_acc: 0.3859 - val_top_k_categorical_accuracy: 0.4864\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 4.8366 - accuracy: 0.2406 - top3_acc: 0.4466 - top_k_categorical_accuracy: 0.5615 - val_loss: 6.0270 - val_accuracy: 0.1861 - val_top3_acc: 0.3573 - val_top_k_categorical_accuracy: 0.4699\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 4.7934 - accuracy: 0.2457 - top3_acc: 0.4577 - top_k_categorical_accuracy: 0.5730 - val_loss: 5.0288 - val_accuracy: 0.2303 - val_top3_acc: 0.4238 - val_top_k_categorical_accuracy: 0.5329\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.7203 - accuracy: 0.2539 - top3_acc: 0.4713 - top_k_categorical_accuracy: 0.5871 - val_loss: 5.0320 - val_accuracy: 0.2319 - val_top3_acc: 0.4243 - val_top_k_categorical_accuracy: 0.5306\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 4.6946 - accuracy: 0.2582 - top3_acc: 0.4771 - top_k_categorical_accuracy: 0.5923 - val_loss: 4.8530 - val_accuracy: 0.2479 - val_top3_acc: 0.4545 - val_top_k_categorical_accuracy: 0.5570\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 4.6208 - accuracy: 0.2686 - top3_acc: 0.4921 - top_k_categorical_accuracy: 0.6093 - val_loss: 5.0431 - val_accuracy: 0.2417 - val_top3_acc: 0.4353 - val_top_k_categorical_accuracy: 0.5370\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 4.5599 - accuracy: 0.2780 - top3_acc: 0.5013 - top_k_categorical_accuracy: 0.6205 - val_loss: 4.8244 - val_accuracy: 0.2584 - val_top3_acc: 0.4659 - val_top_k_categorical_accuracy: 0.5719\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 4.5349 - accuracy: 0.2867 - top3_acc: 0.5081 - top_k_categorical_accuracy: 0.6249 - val_loss: 4.7179 - val_accuracy: 0.2730 - val_top3_acc: 0.4835 - val_top_k_categorical_accuracy: 0.5909\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.5054 - accuracy: 0.2895 - top3_acc: 0.5134 - top_k_categorical_accuracy: 0.6294 - val_loss: 4.7139 - val_accuracy: 0.2677 - val_top3_acc: 0.4791 - val_top_k_categorical_accuracy: 0.5857\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 4.4427 - accuracy: 0.2997 - top3_acc: 0.5266 - top_k_categorical_accuracy: 0.6411 - val_loss: 4.5837 - val_accuracy: 0.2872 - val_top3_acc: 0.5020 - val_top_k_categorical_accuracy: 0.6095\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.4000 - accuracy: 0.3100 - top3_acc: 0.5371 - top_k_categorical_accuracy: 0.6489 - val_loss: 4.7937 - val_accuracy: 0.2790 - val_top3_acc: 0.4886 - val_top_k_categorical_accuracy: 0.5935\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 32s 103ms/step - loss: 4.3683 - accuracy: 0.3137 - top3_acc: 0.5438 - top_k_categorical_accuracy: 0.6562 - val_loss: 4.6202 - val_accuracy: 0.2981 - val_top3_acc: 0.5117 - val_top_k_categorical_accuracy: 0.6246\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 4.3019 - accuracy: 0.3248 - top3_acc: 0.5534 - top_k_categorical_accuracy: 0.6650 - val_loss: 4.6753 - val_accuracy: 0.3023 - val_top3_acc: 0.5161 - val_top_k_categorical_accuracy: 0.6235\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.2633 - accuracy: 0.3246 - top3_acc: 0.5608 - top_k_categorical_accuracy: 0.6717 - val_loss: 4.5412 - val_accuracy: 0.3154 - val_top3_acc: 0.5303 - val_top_k_categorical_accuracy: 0.6359\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 4.2062 - accuracy: 0.3386 - top3_acc: 0.5676 - top_k_categorical_accuracy: 0.6816 - val_loss: 4.5755 - val_accuracy: 0.3189 - val_top3_acc: 0.5393 - val_top_k_categorical_accuracy: 0.6437\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 4.2120 - accuracy: 0.3365 - top3_acc: 0.5728 - top_k_categorical_accuracy: 0.6835 - val_loss: 4.5081 - val_accuracy: 0.3145 - val_top3_acc: 0.5344 - val_top_k_categorical_accuracy: 0.6362\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 4.1286 - accuracy: 0.3510 - top3_acc: 0.5826 - top_k_categorical_accuracy: 0.6947 - val_loss: 4.3501 - val_accuracy: 0.3391 - val_top3_acc: 0.5630 - val_top_k_categorical_accuracy: 0.6653\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 4.0957 - accuracy: 0.3551 - top3_acc: 0.5883 - top_k_categorical_accuracy: 0.6983 - val_loss: 4.4908 - val_accuracy: 0.3339 - val_top3_acc: 0.5599 - val_top_k_categorical_accuracy: 0.6616\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 31s 101ms/step - loss: 4.0478 - accuracy: 0.3650 - top3_acc: 0.6028 - top_k_categorical_accuracy: 0.7102 - val_loss: 4.5073 - val_accuracy: 0.3316 - val_top3_acc: 0.5481 - val_top_k_categorical_accuracy: 0.6478\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 4.0171 - accuracy: 0.3699 - top3_acc: 0.6071 - top_k_categorical_accuracy: 0.7138 - val_loss: 4.3464 - val_accuracy: 0.3487 - val_top3_acc: 0.5735 - val_top_k_categorical_accuracy: 0.6798\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('swish')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "2b9e9627-8593-43c3-c282-bdb9d7d1a857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [7.472177982330322, 7.077722072601318, 6.831551551818848, 6.67418909072876, 6.550060272216797, 6.424322128295898, 6.3366522789001465, 6.245131015777588, 6.173294544219971, 6.09303617477417, 6.016339302062988, 5.959704875946045, 5.9033284187316895, 5.841166973114014, 5.76823616027832, 5.714346885681152, 5.648235321044922, 5.6060638427734375, 5.536468505859375, 5.472583770751953, 5.48850154876709, 5.370535373687744, 5.313182353973389, 5.267466068267822, 5.19428825378418, 5.147706508636475, 5.081202030181885, 5.03920316696167, 4.978122234344482, 4.932803630828857, 4.891966342926025, 4.832868576049805, 4.772943019866943, 4.720978736877441, 4.67540168762207, 4.626881122589111, 4.574121952056885, 4.531702518463135, 4.495290756225586, 4.436429500579834, 4.3946852684021, 4.368070602416992, 4.297738075256348, 4.269054889678955, 4.217511177062988, 4.2007975578308105, 4.126684188842773, 4.103014945983887, 4.057690620422363, 4.019659519195557], 'accuracy': [0.014024999924004078, 0.024974999949336052, 0.03584999963641167, 0.044224999845027924, 0.053599998354911804, 0.060499999672174454, 0.06520000100135803, 0.07237499952316284, 0.07962500303983688, 0.0879250019788742, 0.09047500044107437, 0.09622500091791153, 0.10254999995231628, 0.10930000245571136, 0.12007500231266022, 0.1215749979019165, 0.12950000166893005, 0.13507500290870667, 0.1451749950647354, 0.1506749987602234, 0.15242500603199005, 0.16290000081062317, 0.1678750067949295, 0.1788250058889389, 0.1868250072002411, 0.1931000053882599, 0.2011999934911728, 0.20822499692440033, 0.21604999899864197, 0.22624999284744263, 0.23080000281333923, 0.24027499556541443, 0.24709999561309814, 0.25519999861717224, 0.2624250054359436, 0.2675749957561493, 0.27927500009536743, 0.2869749963283539, 0.29030001163482666, 0.3008500039577484, 0.306674987077713, 0.3125999867916107, 0.32534998655319214, 0.3285500109195709, 0.33959999680519104, 0.3353250026702881, 0.3510249853134155, 0.35462498664855957, 0.3610000014305115, 0.36809998750686646], 'top3_acc': [0.04112499952316284, 0.06577499955892563, 0.0935249999165535, 0.11502499878406525, 0.13410000503063202, 0.15072500705718994, 0.16407500207424164, 0.17922499775886536, 0.19337500631809235, 0.20547500252723694, 0.21937499940395355, 0.2290000021457672, 0.24379999935626984, 0.2551249861717224, 0.2677749991416931, 0.27390000224113464, 0.28815001249313354, 0.29772499203681946, 0.31189998984336853, 0.32292500138282776, 0.32257500290870667, 0.33799999952316284, 0.35202500224113464, 0.36605000495910645, 0.3752000033855438, 0.3820750117301941, 0.39765000343322754, 0.4054250121116638, 0.41815000772476196, 0.4273749887943268, 0.4366999864578247, 0.44792500138282776, 0.4593000113964081, 0.4719249904155731, 0.4832000136375427, 0.4907500147819519, 0.4987500011920929, 0.5087000131607056, 0.5141500234603882, 0.527525007724762, 0.5354750156402588, 0.5425750017166138, 0.5537750124931335, 0.5613750219345093, 0.5663250088691711, 0.5704500079154968, 0.583299994468689, 0.586775004863739, 0.6015250086784363, 0.6029750108718872], 'top_k_categorical_accuracy': [0.06687500327825546, 0.10312499850988388, 0.14307500422000885, 0.17180000245571136, 0.19859999418258667, 0.2243250012397766, 0.24072499573230743, 0.25859999656677246, 0.2783749997615814, 0.29304999113082886, 0.31037500500679016, 0.3234249949455261, 0.33947500586509705, 0.351375013589859, 0.3675749897956848, 0.37744998931884766, 0.39077499508857727, 0.4044249951839447, 0.420974999666214, 0.4312250018119812, 0.43140000104904175, 0.4532249867916107, 0.4643999934196472, 0.47839999198913574, 0.4916999936103821, 0.4981499910354614, 0.5124499797821045, 0.5211499929428101, 0.5350250005722046, 0.5457249879837036, 0.5517749786376953, 0.5642499923706055, 0.5767499804496765, 0.5892500281333923, 0.5987750291824341, 0.60794997215271, 0.6169499754905701, 0.6251749992370605, 0.6285750269889832, 0.6413750052452087, 0.6480749845504761, 0.6547250151634216, 0.6680750250816345, 0.6723499894142151, 0.6786749958992004, 0.6844000220298767, 0.6945250034332275, 0.6981750130653381, 0.7093750238418579, 0.7120749950408936], 'val_loss': [6.770622730255127, 6.611097812652588, 6.558161735534668, 6.5059099197387695, 6.4585161209106445, 6.474308013916016, 6.655985355377197, 6.504648685455322, 6.217785358428955, 6.2917985916137695, 6.204076766967773, 6.150949954986572, 5.989607810974121, 6.037912368774414, 6.0138654708862305, 6.00492525100708, 5.845672130584717, 5.8466691970825195, 5.84574556350708, 5.839230060577393, 5.7360358238220215, 5.645595550537109, 5.497224807739258, 5.396329879760742, 5.527049541473389, 5.410561561584473, 5.474010467529297, 5.358434677124023, 5.291440010070801, 5.056882381439209, 5.223503589630127, 6.026960372924805, 5.028796195983887, 5.032042026519775, 4.853000164031982, 5.043094158172607, 4.824388027191162, 4.71793794631958, 4.713916301727295, 4.583716869354248, 4.793663501739502, 4.620197772979736, 4.675297737121582, 4.541159629821777, 4.57545280456543, 4.508076190948486, 4.350080966949463, 4.4908318519592285, 4.507299423217773, 4.3463568687438965], 'val_accuracy': [0.016699999570846558, 0.027499999850988388, 0.032099999487400055, 0.04050000011920929, 0.05469999834895134, 0.05260000005364418, 0.04100000113248825, 0.07159999758005142, 0.07320000231266022, 0.06750000268220901, 0.07829999923706055, 0.06949999928474426, 0.07769999653100967, 0.08910000324249268, 0.07649999856948853, 0.10509999841451645, 0.09369999915361404, 0.11150000244379044, 0.11219999939203262, 0.11230000108480453, 0.10660000145435333, 0.14509999752044678, 0.15299999713897705, 0.1639000028371811, 0.13899999856948853, 0.15530000627040863, 0.16990000009536743, 0.19259999692440033, 0.19370000064373016, 0.21160000562667847, 0.2093999981880188, 0.18610000610351562, 0.23029999434947968, 0.23190000653266907, 0.24789999425411224, 0.24169999361038208, 0.25839999318122864, 0.27300000190734863, 0.2676999866962433, 0.287200003862381, 0.27900001406669617, 0.29809999465942383, 0.30230000615119934, 0.31540000438690186, 0.3188999891281128, 0.31450000405311584, 0.3391000032424927, 0.33390000462532043, 0.33160001039505005, 0.34869998693466187], 'val_top3_acc': [0.04899999871850014, 0.08290000259876251, 0.09000000357627869, 0.1031000018119812, 0.12530000507831573, 0.12430000305175781, 0.09239999949932098, 0.1573999971151352, 0.1704999953508377, 0.1632000058889389, 0.1770000010728836, 0.1738000065088272, 0.19179999828338623, 0.21240000426769257, 0.18569999933242798, 0.23639999330043793, 0.22699999809265137, 0.24500000476837158, 0.2526000142097473, 0.2547999918460846, 0.23770000040531158, 0.30640000104904175, 0.32089999318122864, 0.3310000002384186, 0.28839999437332153, 0.3165000081062317, 0.35350000858306885, 0.37790000438690186, 0.37450000643730164, 0.400299996137619, 0.38589999079704285, 0.3573000133037567, 0.423799991607666, 0.4242999851703644, 0.4544999897480011, 0.43529999256134033, 0.4659000039100647, 0.48350000381469727, 0.47909998893737793, 0.5019999742507935, 0.4885999858379364, 0.5116999745368958, 0.5160999894142151, 0.5303000211715698, 0.5393000245094299, 0.5343999862670898, 0.5630000233650208, 0.5598999857902527, 0.5480999946594238, 0.5734999775886536], 'val_top_k_categorical_accuracy': [0.07280000299215317, 0.13689999282360077, 0.14890000224113464, 0.1597999930381775, 0.1800999939441681, 0.17990000545978546, 0.13729999959468842, 0.226500004529953, 0.23980000615119934, 0.2289000004529953, 0.2533999979496002, 0.25130000710487366, 0.2775000035762787, 0.3001999855041504, 0.27399998903274536, 0.32670000195503235, 0.30809998512268066, 0.33880001306533813, 0.34549999237060547, 0.34769999980926514, 0.32679998874664307, 0.41280001401901245, 0.42170000076293945, 0.44119998812675476, 0.38679999113082886, 0.4235999882221222, 0.46050000190734863, 0.48010000586509705, 0.4733000099658966, 0.5059000253677368, 0.4864000082015991, 0.4699000120162964, 0.5328999757766724, 0.5306000113487244, 0.5569999814033508, 0.5370000004768372, 0.5719000101089478, 0.5909000039100647, 0.5856999754905701, 0.609499990940094, 0.593500018119812, 0.6245999932289124, 0.6234999895095825, 0.6359000205993652, 0.6437000036239624, 0.6362000107765198, 0.6653000116348267, 0.6615999937057495, 0.6478000283241272, 0.6797999739646912]}\n",
      "313/313 [==============================] - 5s 12ms/step - loss: 4.3560 - accuracy: 0.3496 - top3_acc: 0.5710 - top_k_categorical_accuracy: 0.6770\n",
      "[4.356009483337402, 0.3495999872684479, 0.5709999799728394, 0.6769999861717224]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_vgg16_swish.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
