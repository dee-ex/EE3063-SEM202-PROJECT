{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WljAm5f0fKkw",
    "outputId": "a34ec441-516e-4342-bab0-238867b6bb3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 4s 0us/step\n",
      "169017344/169001437 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "2fe69a2a-fb40-4ecb-ca65-64edca8a3e6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "fcadb673-21ce-4676-c6fc-58e851166cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 35s 94ms/step - loss: 7.7323 - accuracy: 0.0134 - top3_acc: 0.0369 - top_k_categorical_accuracy: 0.0617 - val_loss: 6.7393 - val_accuracy: 0.0204 - val_top3_acc: 0.0578 - val_top_k_categorical_accuracy: 0.0918\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 7.0394 - accuracy: 0.0258 - top3_acc: 0.0671 - top_k_categorical_accuracy: 0.1051 - val_loss: 6.7146 - val_accuracy: 0.0194 - val_top3_acc: 0.0599 - val_top_k_categorical_accuracy: 0.1020\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 6.8620 - accuracy: 0.0358 - top3_acc: 0.0937 - top_k_categorical_accuracy: 0.1447 - val_loss: 6.6488 - val_accuracy: 0.0329 - val_top3_acc: 0.0924 - val_top_k_categorical_accuracy: 0.1374\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 6.6716 - accuracy: 0.0471 - top3_acc: 0.1204 - top_k_categorical_accuracy: 0.1787 - val_loss: 6.6455 - val_accuracy: 0.0334 - val_top3_acc: 0.0920 - val_top_k_categorical_accuracy: 0.1333\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 6.5375 - accuracy: 0.0529 - top3_acc: 0.1344 - top_k_categorical_accuracy: 0.1998 - val_loss: 6.8015 - val_accuracy: 0.0371 - val_top3_acc: 0.0928 - val_top_k_categorical_accuracy: 0.1436\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 6.4380 - accuracy: 0.0577 - top3_acc: 0.1484 - top_k_categorical_accuracy: 0.2193 - val_loss: 6.5803 - val_accuracy: 0.0427 - val_top3_acc: 0.1149 - val_top_k_categorical_accuracy: 0.1679\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 6.3136 - accuracy: 0.0701 - top3_acc: 0.1707 - top_k_categorical_accuracy: 0.2509 - val_loss: 7.0044 - val_accuracy: 0.0426 - val_top3_acc: 0.1000 - val_top_k_categorical_accuracy: 0.1475\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 6.2295 - accuracy: 0.0747 - top3_acc: 0.1817 - top_k_categorical_accuracy: 0.2606 - val_loss: 6.5274 - val_accuracy: 0.0476 - val_top3_acc: 0.1252 - val_top_k_categorical_accuracy: 0.1924\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 6.1500 - accuracy: 0.0812 - top3_acc: 0.1960 - top_k_categorical_accuracy: 0.2821 - val_loss: 6.8098 - val_accuracy: 0.0568 - val_top3_acc: 0.1341 - val_top_k_categorical_accuracy: 0.2060\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 6.1029 - accuracy: 0.0853 - top3_acc: 0.2029 - top_k_categorical_accuracy: 0.2907 - val_loss: 7.0164 - val_accuracy: 0.0518 - val_top3_acc: 0.1333 - val_top_k_categorical_accuracy: 0.1957\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 6.0244 - accuracy: 0.0943 - top3_acc: 0.2230 - top_k_categorical_accuracy: 0.3153 - val_loss: 6.3578 - val_accuracy: 0.0783 - val_top3_acc: 0.1820 - val_top_k_categorical_accuracy: 0.2598\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 5.9511 - accuracy: 0.0957 - top3_acc: 0.2287 - top_k_categorical_accuracy: 0.3214 - val_loss: 6.0848 - val_accuracy: 0.0893 - val_top3_acc: 0.2062 - val_top_k_categorical_accuracy: 0.2913\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 5.8814 - accuracy: 0.1066 - top3_acc: 0.2434 - top_k_categorical_accuracy: 0.3398 - val_loss: 5.9848 - val_accuracy: 0.0985 - val_top3_acc: 0.2174 - val_top_k_categorical_accuracy: 0.3088\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 5.8074 - accuracy: 0.1119 - top3_acc: 0.2593 - top_k_categorical_accuracy: 0.3601 - val_loss: 6.4432 - val_accuracy: 0.0674 - val_top3_acc: 0.1639 - val_top_k_categorical_accuracy: 0.2445\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 5.7199 - accuracy: 0.1243 - top3_acc: 0.2754 - top_k_categorical_accuracy: 0.3786 - val_loss: 6.1504 - val_accuracy: 0.1047 - val_top3_acc: 0.2346 - val_top_k_categorical_accuracy: 0.3224\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 5.6368 - accuracy: 0.1366 - top3_acc: 0.2961 - top_k_categorical_accuracy: 0.3972 - val_loss: 6.4279 - val_accuracy: 0.0946 - val_top3_acc: 0.2170 - val_top_k_categorical_accuracy: 0.3027\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 5.5851 - accuracy: 0.1381 - top3_acc: 0.3043 - top_k_categorical_accuracy: 0.4111 - val_loss: 6.1955 - val_accuracy: 0.1052 - val_top3_acc: 0.2291 - val_top_k_categorical_accuracy: 0.3139\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 5.5079 - accuracy: 0.1516 - top3_acc: 0.3197 - top_k_categorical_accuracy: 0.4310 - val_loss: 6.0860 - val_accuracy: 0.1193 - val_top3_acc: 0.2513 - val_top_k_categorical_accuracy: 0.3442\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 5.4547 - accuracy: 0.1577 - top3_acc: 0.3328 - top_k_categorical_accuracy: 0.4385 - val_loss: 5.7777 - val_accuracy: 0.1356 - val_top3_acc: 0.3009 - val_top_k_categorical_accuracy: 0.3922\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 5.3976 - accuracy: 0.1636 - top3_acc: 0.3443 - top_k_categorical_accuracy: 0.4563 - val_loss: 5.8454 - val_accuracy: 0.1415 - val_top3_acc: 0.2937 - val_top_k_categorical_accuracy: 0.3948\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 5.3237 - accuracy: 0.1735 - top3_acc: 0.3537 - top_k_categorical_accuracy: 0.4669 - val_loss: 5.8461 - val_accuracy: 0.1567 - val_top3_acc: 0.3252 - val_top_k_categorical_accuracy: 0.4261\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 5.2736 - accuracy: 0.1809 - top3_acc: 0.3685 - top_k_categorical_accuracy: 0.4805 - val_loss: 5.7141 - val_accuracy: 0.1724 - val_top3_acc: 0.3392 - val_top_k_categorical_accuracy: 0.4451\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 5.2033 - accuracy: 0.1948 - top3_acc: 0.3852 - top_k_categorical_accuracy: 0.4958 - val_loss: 5.7781 - val_accuracy: 0.1429 - val_top3_acc: 0.3051 - val_top_k_categorical_accuracy: 0.4046\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 5.1505 - accuracy: 0.1982 - top3_acc: 0.3897 - top_k_categorical_accuracy: 0.4983 - val_loss: 5.7385 - val_accuracy: 0.1764 - val_top3_acc: 0.3444 - val_top_k_categorical_accuracy: 0.4466\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 5.0814 - accuracy: 0.2056 - top3_acc: 0.4020 - top_k_categorical_accuracy: 0.5186 - val_loss: 5.6803 - val_accuracy: 0.1919 - val_top3_acc: 0.3629 - val_top_k_categorical_accuracy: 0.4666\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 5.0225 - accuracy: 0.2191 - top3_acc: 0.4198 - top_k_categorical_accuracy: 0.5345 - val_loss: 6.1281 - val_accuracy: 0.1521 - val_top3_acc: 0.3079 - val_top_k_categorical_accuracy: 0.4084\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.9780 - accuracy: 0.2222 - top3_acc: 0.4319 - top_k_categorical_accuracy: 0.5480 - val_loss: 5.4788 - val_accuracy: 0.1868 - val_top3_acc: 0.3638 - val_top_k_categorical_accuracy: 0.4774\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.9341 - accuracy: 0.2302 - top3_acc: 0.4372 - top_k_categorical_accuracy: 0.5550 - val_loss: 6.1605 - val_accuracy: 0.1971 - val_top3_acc: 0.3777 - val_top_k_categorical_accuracy: 0.4879\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.8704 - accuracy: 0.2396 - top3_acc: 0.4420 - top_k_categorical_accuracy: 0.5615 - val_loss: 5.1259 - val_accuracy: 0.2391 - val_top3_acc: 0.4422 - val_top_k_categorical_accuracy: 0.5479\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 4.8343 - accuracy: 0.2464 - top3_acc: 0.4590 - top_k_categorical_accuracy: 0.5748 - val_loss: 5.3829 - val_accuracy: 0.2272 - val_top3_acc: 0.4220 - val_top_k_categorical_accuracy: 0.5364\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 4.7686 - accuracy: 0.2520 - top3_acc: 0.4692 - top_k_categorical_accuracy: 0.5835 - val_loss: 5.6088 - val_accuracy: 0.2224 - val_top3_acc: 0.4216 - val_top_k_categorical_accuracy: 0.5320\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 4.7214 - accuracy: 0.2589 - top3_acc: 0.4779 - top_k_categorical_accuracy: 0.5938 - val_loss: 5.8388 - val_accuracy: 0.2164 - val_top3_acc: 0.4085 - val_top_k_categorical_accuracy: 0.5198\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 4.6802 - accuracy: 0.2650 - top3_acc: 0.4878 - top_k_categorical_accuracy: 0.6067 - val_loss: 5.0256 - val_accuracy: 0.2614 - val_top3_acc: 0.4712 - val_top_k_categorical_accuracy: 0.5852\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.6276 - accuracy: 0.2810 - top3_acc: 0.5009 - top_k_categorical_accuracy: 0.6147 - val_loss: 5.3131 - val_accuracy: 0.2552 - val_top3_acc: 0.4572 - val_top_k_categorical_accuracy: 0.5637\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.5693 - accuracy: 0.2868 - top3_acc: 0.5116 - top_k_categorical_accuracy: 0.6231 - val_loss: 4.9580 - val_accuracy: 0.2759 - val_top3_acc: 0.4781 - val_top_k_categorical_accuracy: 0.5874\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 4.5339 - accuracy: 0.2900 - top3_acc: 0.5174 - top_k_categorical_accuracy: 0.6276 - val_loss: 5.0063 - val_accuracy: 0.2642 - val_top3_acc: 0.4698 - val_top_k_categorical_accuracy: 0.5810\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 4.4808 - accuracy: 0.2948 - top3_acc: 0.5270 - top_k_categorical_accuracy: 0.6401 - val_loss: 5.1703 - val_accuracy: 0.2948 - val_top3_acc: 0.5133 - val_top_k_categorical_accuracy: 0.6264\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 4.4400 - accuracy: 0.3024 - top3_acc: 0.5291 - top_k_categorical_accuracy: 0.6468 - val_loss: 4.8758 - val_accuracy: 0.2876 - val_top3_acc: 0.4954 - val_top_k_categorical_accuracy: 0.6037\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 4.4040 - accuracy: 0.3099 - top3_acc: 0.5412 - top_k_categorical_accuracy: 0.6559 - val_loss: 5.0767 - val_accuracy: 0.2749 - val_top3_acc: 0.4744 - val_top_k_categorical_accuracy: 0.5782\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 4.3784 - accuracy: 0.3154 - top3_acc: 0.5452 - top_k_categorical_accuracy: 0.6599 - val_loss: 4.8396 - val_accuracy: 0.3066 - val_top3_acc: 0.5241 - val_top_k_categorical_accuracy: 0.6340\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 4.3078 - accuracy: 0.3207 - top3_acc: 0.5559 - top_k_categorical_accuracy: 0.6735 - val_loss: 4.7388 - val_accuracy: 0.3152 - val_top3_acc: 0.5385 - val_top_k_categorical_accuracy: 0.6405\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 4.2747 - accuracy: 0.3315 - top3_acc: 0.5659 - top_k_categorical_accuracy: 0.6786 - val_loss: 4.6741 - val_accuracy: 0.3279 - val_top3_acc: 0.5516 - val_top_k_categorical_accuracy: 0.6552\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 4.2504 - accuracy: 0.3320 - top3_acc: 0.5681 - top_k_categorical_accuracy: 0.6793 - val_loss: 4.9069 - val_accuracy: 0.3122 - val_top3_acc: 0.5334 - val_top_k_categorical_accuracy: 0.6349\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 4.2013 - accuracy: 0.3398 - top3_acc: 0.5765 - top_k_categorical_accuracy: 0.6875 - val_loss: 4.5235 - val_accuracy: 0.3460 - val_top3_acc: 0.5716 - val_top_k_categorical_accuracy: 0.6727\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.1576 - accuracy: 0.3472 - top3_acc: 0.5878 - top_k_categorical_accuracy: 0.6949 - val_loss: 4.5036 - val_accuracy: 0.3407 - val_top3_acc: 0.5676 - val_top_k_categorical_accuracy: 0.6714\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 4.1215 - accuracy: 0.3538 - top3_acc: 0.5971 - top_k_categorical_accuracy: 0.7044 - val_loss: 4.5526 - val_accuracy: 0.3383 - val_top3_acc: 0.5498 - val_top_k_categorical_accuracy: 0.6519\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.0779 - accuracy: 0.3602 - top3_acc: 0.6005 - top_k_categorical_accuracy: 0.7076 - val_loss: 4.5484 - val_accuracy: 0.3478 - val_top3_acc: 0.5642 - val_top_k_categorical_accuracy: 0.6637\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 4.0465 - accuracy: 0.3667 - top3_acc: 0.6106 - top_k_categorical_accuracy: 0.7162 - val_loss: 4.6053 - val_accuracy: 0.3477 - val_top3_acc: 0.5586 - val_top_k_categorical_accuracy: 0.6676\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 3.9964 - accuracy: 0.3796 - top3_acc: 0.6176 - top_k_categorical_accuracy: 0.7206 - val_loss: 4.4006 - val_accuracy: 0.3839 - val_top3_acc: 0.6057 - val_top_k_categorical_accuracy: 0.7092\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 3.9589 - accuracy: 0.3824 - top3_acc: 0.6177 - top_k_categorical_accuracy: 0.7249 - val_loss: 4.2654 - val_accuracy: 0.3702 - val_top3_acc: 0.5979 - val_top_k_categorical_accuracy: 0.7009\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('leaky-relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "4c5be44c-050c-45ef-a276-bee207c3e3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [7.425841331481934, 6.993841171264648, 6.79506254196167, 6.646729469299316, 6.512420654296875, 6.397972106933594, 6.309744834899902, 6.2209086418151855, 6.133425712585449, 6.080513954162598, 6.013786315917969, 5.94043493270874, 5.86517858505249, 5.782331466674805, 5.716068267822266, 5.635840892791748, 5.568363189697266, 5.4982500076293945, 5.4359025955200195, 5.377991199493408, 5.313051700592041, 5.263700008392334, 5.19821834564209, 5.129355430603027, 5.078160285949707, 5.017527103424072, 4.9729743003845215, 4.920618534088135, 4.863058090209961, 4.817158222198486, 4.7688069343566895, 4.714781761169434, 4.667296409606934, 4.618702411651611, 4.576879024505615, 4.529605388641357, 4.475616455078125, 4.437078952789307, 4.392620086669922, 4.356578350067139, 4.307193756103516, 4.263282299041748, 4.232749938964844, 4.194904804229736, 4.148136138916016, 4.116144180297852, 4.076384544372559, 4.03790283203125, 4.0059733390808105, 3.9676907062530518], 'accuracy': [0.01730000041425228, 0.028175000101327896, 0.03657500073313713, 0.04670000076293945, 0.05544999986886978, 0.06037500128149986, 0.06952500343322754, 0.07514999806880951, 0.08177500218153, 0.08569999784231186, 0.09212499856948853, 0.09882500022649765, 0.10864999890327454, 0.11562500149011612, 0.12335000187158585, 0.1358499974012375, 0.13907499611377716, 0.14955000579357147, 0.1593250036239624, 0.1662999987602234, 0.17432500422000885, 0.18162499368190765, 0.19449999928474426, 0.20239999890327454, 0.20874999463558197, 0.2193250060081482, 0.22165000438690186, 0.23395000398159027, 0.2410999983549118, 0.24892500042915344, 0.2528750002384186, 0.2612999975681305, 0.26772499084472656, 0.27992498874664307, 0.2847749888896942, 0.2894749939441681, 0.2983500063419342, 0.3034999966621399, 0.3106499910354614, 0.31804999709129333, 0.32295000553131104, 0.33355000615119934, 0.33730000257492065, 0.342849999666214, 0.34755000472068787, 0.3558749854564667, 0.36227500438690186, 0.36812499165534973, 0.3767249882221222, 0.38042500615119934], 'top3_acc': [0.04520000144839287, 0.07374999672174454, 0.10019999742507935, 0.12165000289678574, 0.1373250037431717, 0.15307499468326569, 0.17045000195503235, 0.18379999697208405, 0.1976500004529953, 0.20630000531673431, 0.22005000710487366, 0.23407499492168427, 0.24687500298023224, 0.2632249891757965, 0.2758750021457672, 0.2948499917984009, 0.30570000410079956, 0.31894999742507935, 0.33367499709129333, 0.3467000126838684, 0.3564249873161316, 0.3699750006198883, 0.3851499855518341, 0.39582499861717224, 0.40459999442100525, 0.4204249978065491, 0.43037500977516174, 0.4389500021934509, 0.44757500290870667, 0.4584999978542328, 0.46912500262260437, 0.47929999232292175, 0.48832499980926514, 0.5008999705314636, 0.5076749920845032, 0.5168499946594238, 0.527525007724762, 0.532800018787384, 0.5420500040054321, 0.54830002784729, 0.5550500154495239, 0.5654000043869019, 0.5716750025749207, 0.5791000127792358, 0.5878499746322632, 0.5927000045776367, 0.6006500124931335, 0.6085749864578247, 0.6129999756813049, 0.6166999936103821], 'top_k_categorical_accuracy': [0.07320000231266022, 0.11574999988079071, 0.15289999544620514, 0.18277500569820404, 0.20577499270439148, 0.22517499327659607, 0.2506749927997589, 0.2630000114440918, 0.2849999964237213, 0.29534998536109924, 0.3138749897480011, 0.32682499289512634, 0.34505000710487366, 0.36422500014305115, 0.38065001368522644, 0.3982999920845032, 0.41290000081062317, 0.43160000443458557, 0.4421499967575073, 0.4584999978542328, 0.46892499923706055, 0.48295000195503235, 0.49492499232292175, 0.5058000087738037, 0.5199750065803528, 0.5346500277519226, 0.5470499992370605, 0.5547999739646912, 0.5646250247955322, 0.5741000175476074, 0.5831999778747559, 0.5947750210762024, 0.6050000190734863, 0.614300012588501, 0.6202750205993652, 0.6296749711036682, 0.63919997215271, 0.6484500169754028, 0.6563000082969666, 0.6610249876976013, 0.6705250144004822, 0.677299976348877, 0.6838250160217285, 0.6876500248908997, 0.6966000199317932, 0.7010999917984009, 0.7078499794006348, 0.7129499912261963, 0.7165250182151794, 0.7218000292778015], 'val_loss': [6.739261150360107, 6.7146148681640625, 6.64883279800415, 6.645495891571045, 6.801520347595215, 6.580336093902588, 7.004390716552734, 6.527369499206543, 6.809755325317383, 7.016382694244385, 6.357783794403076, 6.084821701049805, 5.984760761260986, 6.443206310272217, 6.150374412536621, 6.4278974533081055, 6.19552755355835, 6.0860185623168945, 5.777688503265381, 5.845398426055908, 5.8460869789123535, 5.714074611663818, 5.7780632972717285, 5.738483428955078, 5.680316925048828, 6.1281304359436035, 5.478771209716797, 6.160464763641357, 5.125947952270508, 5.38287878036499, 5.608787536621094, 5.838778018951416, 5.025598049163818, 5.3130974769592285, 4.958049774169922, 5.006317138671875, 5.170300483703613, 4.875829219818115, 5.076699733734131, 4.839632034301758, 4.738767147064209, 4.674055099487305, 4.906914234161377, 4.523499965667725, 4.503594398498535, 4.5526123046875, 4.548366069793701, 4.605315685272217, 4.400570392608643, 4.265390396118164], 'val_accuracy': [0.020400000736117363, 0.01940000057220459, 0.03290000185370445, 0.033399999141693115, 0.03709999844431877, 0.04270000010728836, 0.04259999841451645, 0.047600001096725464, 0.0568000003695488, 0.05180000141263008, 0.07829999923706055, 0.0892999991774559, 0.09849999845027924, 0.0674000009894371, 0.1046999990940094, 0.09459999948740005, 0.10520000010728836, 0.1193000003695488, 0.1356000006198883, 0.14149999618530273, 0.156700000166893, 0.17239999771118164, 0.1429000049829483, 0.17640000581741333, 0.19189999997615814, 0.15209999680519104, 0.1868000030517578, 0.19709999859333038, 0.23909999430179596, 0.2272000014781952, 0.2223999947309494, 0.21639999747276306, 0.2614000141620636, 0.25519999861717224, 0.2759000062942505, 0.26420000195503235, 0.2948000133037567, 0.28760001063346863, 0.27489998936653137, 0.30660000443458557, 0.31520000100135803, 0.3278999924659729, 0.31220000982284546, 0.34599998593330383, 0.3407000005245209, 0.3382999897003174, 0.34779998660087585, 0.34769999980926514, 0.383899986743927, 0.3702000081539154], 'val_top3_acc': [0.05779999867081642, 0.05990000069141388, 0.09239999949932098, 0.09200000017881393, 0.09279999881982803, 0.11490000039339066, 0.10000000149011612, 0.12520000338554382, 0.13410000503063202, 0.13330000638961792, 0.18199999630451202, 0.2062000036239624, 0.21739999949932098, 0.1639000028371811, 0.2345999926328659, 0.21699999272823334, 0.22910000383853912, 0.25130000710487366, 0.30090001225471497, 0.2937000095844269, 0.32519999146461487, 0.3391999900341034, 0.3050999939441681, 0.34439998865127563, 0.3628999888896942, 0.30790001153945923, 0.3637999892234802, 0.37770000100135803, 0.4422000050544739, 0.421999990940094, 0.42160001397132874, 0.40849998593330383, 0.47119998931884766, 0.45719999074935913, 0.4781000018119812, 0.4697999954223633, 0.5133000016212463, 0.49540001153945923, 0.47440001368522644, 0.5241000056266785, 0.5385000109672546, 0.5515999794006348, 0.5333999991416931, 0.5716000199317932, 0.5676000118255615, 0.5497999787330627, 0.5641999840736389, 0.5586000084877014, 0.6057000160217285, 0.5978999733924866], 'val_top_k_categorical_accuracy': [0.09179999679327011, 0.10199999809265137, 0.13740000128746033, 0.13330000638961792, 0.1436000019311905, 0.1678999960422516, 0.14749999344348907, 0.1923999935388565, 0.20600000023841858, 0.195700004696846, 0.259799987077713, 0.2912999987602234, 0.30880001187324524, 0.24449999630451202, 0.3224000036716461, 0.302700012922287, 0.3138999938964844, 0.3441999852657318, 0.3921999931335449, 0.39480000734329224, 0.4260999858379364, 0.44510000944137573, 0.40459999442100525, 0.4465999901294708, 0.4666000008583069, 0.4083999991416931, 0.477400004863739, 0.4878999888896942, 0.5479000210762024, 0.5364000201225281, 0.5320000052452087, 0.5198000073432922, 0.5852000117301941, 0.5637000203132629, 0.5874000191688538, 0.5809999704360962, 0.6263999938964844, 0.6036999821662903, 0.5781999826431274, 0.6340000033378601, 0.640500009059906, 0.6552000045776367, 0.6348999738693237, 0.6726999878883362, 0.6714000105857849, 0.6518999934196472, 0.6636999845504761, 0.6675999760627747, 0.7092000246047974, 0.7009000182151794]}\n",
      "313/313 [==============================] - 6s 11ms/step - loss: 4.2291 - accuracy: 0.3751 - top3_acc: 0.6004 - top_k_categorical_accuracy: 0.7058\n",
      "[4.229095935821533, 0.3750999867916107, 0.6003999710083008, 0.7057999968528748]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_vgg16_leaky.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
