{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WljAm5f0fKkw"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "3af2becf-e784-4952-a89f-405ba5e56174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "ff237339-0cb1-4a90-b8d9-df35c25e9f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 47s 137ms/step - loss: 4.5607 - accuracy: 0.0208 - top3_acc: 0.0561 - top_k_categorical_accuracy: 0.0884 - val_loss: 4.6224 - val_accuracy: 0.0123 - val_top3_acc: 0.0345 - val_top_k_categorical_accuracy: 0.0540\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 4.2094 - accuracy: 0.0584 - top3_acc: 0.1401 - top_k_categorical_accuracy: 0.2052 - val_loss: 4.6542 - val_accuracy: 0.0230 - val_top3_acc: 0.0652 - val_top_k_categorical_accuracy: 0.0941\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.9317 - accuracy: 0.0916 - top3_acc: 0.2067 - top_k_categorical_accuracy: 0.2864 - val_loss: 4.5788 - val_accuracy: 0.0247 - val_top3_acc: 0.0683 - val_top_k_categorical_accuracy: 0.1023\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.7339 - accuracy: 0.1131 - top3_acc: 0.2517 - top_k_categorical_accuracy: 0.3452 - val_loss: 4.2543 - val_accuracy: 0.0627 - val_top3_acc: 0.1403 - val_top_k_categorical_accuracy: 0.1960\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.5796 - accuracy: 0.1389 - top3_acc: 0.2948 - top_k_categorical_accuracy: 0.3921 - val_loss: 4.5693 - val_accuracy: 0.0398 - val_top3_acc: 0.0994 - val_top_k_categorical_accuracy: 0.1532\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.4669 - accuracy: 0.1583 - top3_acc: 0.3211 - top_k_categorical_accuracy: 0.4269 - val_loss: 4.1351 - val_accuracy: 0.0841 - val_top3_acc: 0.1778 - val_top_k_categorical_accuracy: 0.2454\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.3062 - accuracy: 0.1910 - top3_acc: 0.3710 - top_k_categorical_accuracy: 0.4758 - val_loss: 4.8337 - val_accuracy: 0.0412 - val_top3_acc: 0.0975 - val_top_k_categorical_accuracy: 0.1429\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.1829 - accuracy: 0.2146 - top3_acc: 0.4022 - top_k_categorical_accuracy: 0.5054 - val_loss: 4.0604 - val_accuracy: 0.0990 - val_top3_acc: 0.2162 - val_top_k_categorical_accuracy: 0.2924\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.0510 - accuracy: 0.2355 - top3_acc: 0.4335 - top_k_categorical_accuracy: 0.5375 - val_loss: 3.7191 - val_accuracy: 0.1360 - val_top3_acc: 0.2802 - val_top_k_categorical_accuracy: 0.3641\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.9018 - accuracy: 0.2651 - top3_acc: 0.4674 - top_k_categorical_accuracy: 0.5763 - val_loss: 3.9912 - val_accuracy: 0.1090 - val_top3_acc: 0.2377 - val_top_k_categorical_accuracy: 0.3216\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.8087 - accuracy: 0.2870 - top3_acc: 0.4928 - top_k_categorical_accuracy: 0.5980 - val_loss: 3.6132 - val_accuracy: 0.1657 - val_top3_acc: 0.3162 - val_top_k_categorical_accuracy: 0.3993\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.7038 - accuracy: 0.3009 - top3_acc: 0.5165 - top_k_categorical_accuracy: 0.6249 - val_loss: 3.4299 - val_accuracy: 0.1958 - val_top3_acc: 0.3558 - val_top_k_categorical_accuracy: 0.4526\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 2.6085 - accuracy: 0.3222 - top3_acc: 0.5376 - top_k_categorical_accuracy: 0.6442 - val_loss: 3.4278 - val_accuracy: 0.1890 - val_top3_acc: 0.3680 - val_top_k_categorical_accuracy: 0.4646\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.5372 - accuracy: 0.3382 - top3_acc: 0.5602 - top_k_categorical_accuracy: 0.6673 - val_loss: 3.2475 - val_accuracy: 0.2123 - val_top3_acc: 0.3924 - val_top_k_categorical_accuracy: 0.4962\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.4500 - accuracy: 0.3562 - top3_acc: 0.5769 - top_k_categorical_accuracy: 0.6799 - val_loss: 3.6935 - val_accuracy: 0.1670 - val_top3_acc: 0.3342 - val_top_k_categorical_accuracy: 0.4301\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.3904 - accuracy: 0.3685 - top3_acc: 0.5942 - top_k_categorical_accuracy: 0.6960 - val_loss: 3.3593 - val_accuracy: 0.2097 - val_top3_acc: 0.3884 - val_top_k_categorical_accuracy: 0.4810\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.3021 - accuracy: 0.3920 - top3_acc: 0.6097 - top_k_categorical_accuracy: 0.7125 - val_loss: 3.1853 - val_accuracy: 0.2348 - val_top3_acc: 0.4143 - val_top_k_categorical_accuracy: 0.5131\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.2523 - accuracy: 0.4003 - top3_acc: 0.6249 - top_k_categorical_accuracy: 0.7226 - val_loss: 2.8724 - val_accuracy: 0.2832 - val_top3_acc: 0.4894 - val_top_k_categorical_accuracy: 0.5872\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.2165 - accuracy: 0.4081 - top3_acc: 0.6315 - top_k_categorical_accuracy: 0.7319 - val_loss: 2.6640 - val_accuracy: 0.3266 - val_top3_acc: 0.5367 - val_top_k_categorical_accuracy: 0.6343\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.1566 - accuracy: 0.4175 - top3_acc: 0.6482 - top_k_categorical_accuracy: 0.7468 - val_loss: 2.8121 - val_accuracy: 0.2965 - val_top3_acc: 0.5032 - val_top_k_categorical_accuracy: 0.6024\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.0897 - accuracy: 0.4407 - top3_acc: 0.6611 - top_k_categorical_accuracy: 0.7585 - val_loss: 2.8763 - val_accuracy: 0.2830 - val_top3_acc: 0.4880 - val_top_k_categorical_accuracy: 0.5897\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.0451 - accuracy: 0.4454 - top3_acc: 0.6732 - top_k_categorical_accuracy: 0.7648 - val_loss: 2.6865 - val_accuracy: 0.3221 - val_top3_acc: 0.5361 - val_top_k_categorical_accuracy: 0.6317\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.0134 - accuracy: 0.4494 - top3_acc: 0.6823 - top_k_categorical_accuracy: 0.7757 - val_loss: 2.7718 - val_accuracy: 0.3120 - val_top3_acc: 0.5273 - val_top_k_categorical_accuracy: 0.6236\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.9693 - accuracy: 0.4662 - top3_acc: 0.6896 - top_k_categorical_accuracy: 0.7818 - val_loss: 2.7647 - val_accuracy: 0.3051 - val_top3_acc: 0.5178 - val_top_k_categorical_accuracy: 0.6187\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.9207 - accuracy: 0.4745 - top3_acc: 0.7009 - top_k_categorical_accuracy: 0.7895 - val_loss: 2.4144 - val_accuracy: 0.3734 - val_top3_acc: 0.5938 - val_top_k_categorical_accuracy: 0.6896\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.8796 - accuracy: 0.4843 - top3_acc: 0.7098 - top_k_categorical_accuracy: 0.8006 - val_loss: 2.3131 - val_accuracy: 0.3918 - val_top3_acc: 0.6118 - val_top_k_categorical_accuracy: 0.7090\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.8305 - accuracy: 0.4937 - top3_acc: 0.7206 - top_k_categorical_accuracy: 0.8074 - val_loss: 2.4155 - val_accuracy: 0.3757 - val_top3_acc: 0.5938 - val_top_k_categorical_accuracy: 0.6916\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.8106 - accuracy: 0.4977 - top3_acc: 0.7256 - top_k_categorical_accuracy: 0.8101 - val_loss: 2.4094 - val_accuracy: 0.3827 - val_top3_acc: 0.5930 - val_top_k_categorical_accuracy: 0.6876\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.7769 - accuracy: 0.5088 - top3_acc: 0.7297 - top_k_categorical_accuracy: 0.8160 - val_loss: 2.1752 - val_accuracy: 0.4273 - val_top3_acc: 0.6468 - val_top_k_categorical_accuracy: 0.7401\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.7376 - accuracy: 0.5169 - top3_acc: 0.7389 - top_k_categorical_accuracy: 0.8208 - val_loss: 2.2227 - val_accuracy: 0.4106 - val_top3_acc: 0.6401 - val_top_k_categorical_accuracy: 0.7327\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.7317 - accuracy: 0.5161 - top3_acc: 0.7426 - top_k_categorical_accuracy: 0.8254 - val_loss: 2.1127 - val_accuracy: 0.4380 - val_top3_acc: 0.6641 - val_top_k_categorical_accuracy: 0.7531\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.6821 - accuracy: 0.5315 - top3_acc: 0.7520 - top_k_categorical_accuracy: 0.8332 - val_loss: 2.2137 - val_accuracy: 0.4114 - val_top3_acc: 0.6390 - val_top_k_categorical_accuracy: 0.7333\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.6627 - accuracy: 0.5311 - top3_acc: 0.7591 - top_k_categorical_accuracy: 0.8388 - val_loss: 2.1157 - val_accuracy: 0.4390 - val_top3_acc: 0.6658 - val_top_k_categorical_accuracy: 0.7500\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.6403 - accuracy: 0.5362 - top3_acc: 0.7599 - top_k_categorical_accuracy: 0.8408 - val_loss: 2.1060 - val_accuracy: 0.4439 - val_top3_acc: 0.6664 - val_top_k_categorical_accuracy: 0.7560\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.6129 - accuracy: 0.5467 - top3_acc: 0.7644 - top_k_categorical_accuracy: 0.8417 - val_loss: 2.1224 - val_accuracy: 0.4306 - val_top3_acc: 0.6666 - val_top_k_categorical_accuracy: 0.7552\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.5840 - accuracy: 0.5537 - top3_acc: 0.7735 - top_k_categorical_accuracy: 0.8482 - val_loss: 1.9901 - val_accuracy: 0.4664 - val_top3_acc: 0.6880 - val_top_k_categorical_accuracy: 0.7711\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.5607 - accuracy: 0.5594 - top3_acc: 0.7808 - top_k_categorical_accuracy: 0.8543 - val_loss: 2.0399 - val_accuracy: 0.4547 - val_top3_acc: 0.6832 - val_top_k_categorical_accuracy: 0.7747\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.5419 - accuracy: 0.5641 - top3_acc: 0.7798 - top_k_categorical_accuracy: 0.8549 - val_loss: 1.9388 - val_accuracy: 0.4748 - val_top3_acc: 0.6981 - val_top_k_categorical_accuracy: 0.7827\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.5323 - accuracy: 0.5644 - top3_acc: 0.7820 - top_k_categorical_accuracy: 0.8573 - val_loss: 2.0141 - val_accuracy: 0.4579 - val_top3_acc: 0.6865 - val_top_k_categorical_accuracy: 0.7700\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.5187 - accuracy: 0.5678 - top3_acc: 0.7841 - top_k_categorical_accuracy: 0.8571 - val_loss: 1.8982 - val_accuracy: 0.4887 - val_top3_acc: 0.7068 - val_top_k_categorical_accuracy: 0.7910\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.4713 - accuracy: 0.5784 - top3_acc: 0.7951 - top_k_categorical_accuracy: 0.8676 - val_loss: 1.9236 - val_accuracy: 0.4832 - val_top3_acc: 0.7056 - val_top_k_categorical_accuracy: 0.7897\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.4693 - accuracy: 0.5823 - top3_acc: 0.7958 - top_k_categorical_accuracy: 0.8673 - val_loss: 1.9153 - val_accuracy: 0.4820 - val_top3_acc: 0.7064 - val_top_k_categorical_accuracy: 0.7898\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.4391 - accuracy: 0.5874 - top3_acc: 0.8027 - top_k_categorical_accuracy: 0.8718 - val_loss: 1.8753 - val_accuracy: 0.4903 - val_top3_acc: 0.7125 - val_top_k_categorical_accuracy: 0.7946\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.4014 - accuracy: 0.5980 - top3_acc: 0.8104 - top_k_categorical_accuracy: 0.8777 - val_loss: 1.8735 - val_accuracy: 0.4903 - val_top3_acc: 0.7110 - val_top_k_categorical_accuracy: 0.7915\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.3999 - accuracy: 0.5993 - top3_acc: 0.8102 - top_k_categorical_accuracy: 0.8796 - val_loss: 1.8228 - val_accuracy: 0.5001 - val_top3_acc: 0.7267 - val_top_k_categorical_accuracy: 0.8053\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.3994 - accuracy: 0.6013 - top3_acc: 0.8085 - top_k_categorical_accuracy: 0.8752 - val_loss: 1.9217 - val_accuracy: 0.4832 - val_top3_acc: 0.7097 - val_top_k_categorical_accuracy: 0.7877\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.3479 - accuracy: 0.6112 - top3_acc: 0.8205 - top_k_categorical_accuracy: 0.8876 - val_loss: 1.8570 - val_accuracy: 0.4950 - val_top3_acc: 0.7185 - val_top_k_categorical_accuracy: 0.7986\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.3440 - accuracy: 0.6137 - top3_acc: 0.8212 - top_k_categorical_accuracy: 0.8862 - val_loss: 1.8238 - val_accuracy: 0.5080 - val_top3_acc: 0.7239 - val_top_k_categorical_accuracy: 0.8063\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.3218 - accuracy: 0.6190 - top3_acc: 0.8266 - top_k_categorical_accuracy: 0.8895 - val_loss: 1.7810 - val_accuracy: 0.5084 - val_top3_acc: 0.7371 - val_top_k_categorical_accuracy: 0.8169\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.2973 - accuracy: 0.6222 - top3_acc: 0.8304 - top_k_categorical_accuracy: 0.8933 - val_loss: 1.7616 - val_accuracy: 0.5192 - val_top3_acc: 0.7407 - val_top_k_categorical_accuracy: 0.8155\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('leaky-relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "1b7bbc76-dcdb-4414-f52b-3ec32ab4037e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [4.457212924957275, 4.132564067840576, 3.884798049926758, 3.700155019760132, 3.5534207820892334, 3.4209065437316895, 3.282975673675537, 3.1517951488494873, 3.0220556259155273, 2.8948898315429688, 2.7873523235321045, 2.6939022541046143, 2.6071994304656982, 2.5271289348602295, 2.446538209915161, 2.387545585632324, 2.3186557292938232, 2.256547689437866, 2.2017316818237305, 2.1583778858184814, 2.1012346744537354, 2.057471752166748, 2.0113720893859863, 1.9710583686828613, 1.934136152267456, 1.887224555015564, 1.8536685705184937, 1.8256924152374268, 1.7858855724334717, 1.7533656358718872, 1.7329833507537842, 1.6964929103851318, 1.6777068376541138, 1.639694333076477, 1.620201587677002, 1.6000138521194458, 1.5763187408447266, 1.5455126762390137, 1.5225324630737305, 1.5069799423217773, 1.4861533641815186, 1.4694308042526245, 1.4427757263183594, 1.4228944778442383, 1.400535225868225, 1.3882019519805908, 1.3677833080291748, 1.3560196161270142, 1.3395464420318604, 1.3214960098266602], 'accuracy': [0.030124999582767487, 0.06605000048875809, 0.09727499634027481, 0.12080000340938568, 0.14502499997615814, 0.16779999434947968, 0.19552500545978546, 0.2193250060081482, 0.241349995136261, 0.26727500557899475, 0.2874250113964081, 0.30402499437332153, 0.3223249912261963, 0.33869999647140503, 0.3569999933242798, 0.3686000108718872, 0.3852500021457672, 0.3989250063896179, 0.41077500581741333, 0.4193750023841858, 0.4358749985694885, 0.44179999828338623, 0.4502750039100647, 0.46070000529289246, 0.47084999084472656, 0.4821000099182129, 0.48832499980926514, 0.4963749945163727, 0.5055000185966492, 0.515250027179718, 0.5160499811172485, 0.527275025844574, 0.5306749939918518, 0.5400500297546387, 0.5440999865531921, 0.5490750074386597, 0.5544999837875366, 0.5618500113487244, 0.5688999891281128, 0.5739750266075134, 0.5749499797821045, 0.5822250247001648, 0.5882499814033508, 0.5921499729156494, 0.5999500155448914, 0.6013000011444092, 0.6055750250816345, 0.6112750172615051, 0.6148999929428101, 0.618274986743927], 'top3_acc': [0.08217500150203705, 0.15729999542236328, 0.2171500027179718, 0.2625249922275543, 0.3014500141143799, 0.3364250063896179, 0.37572500109672546, 0.4086749851703644, 0.442425012588501, 0.47099998593330383, 0.4973999857902527, 0.5186750292778015, 0.5396749973297119, 0.5616250038146973, 0.5776000022888184, 0.5950499773025513, 0.6083750128746033, 0.6237249970436096, 0.6371750235557556, 0.6467750072479248, 0.6582000255584717, 0.6694499850273132, 0.6807000041007996, 0.6895999908447266, 0.6961749792098999, 0.7076500058174133, 0.7152000069618225, 0.7217249870300293, 0.7293999791145325, 0.7352499961853027, 0.7408249974250793, 0.7490249872207642, 0.7530999779701233, 0.7597500085830688, 0.7630000114440918, 0.7684999704360962, 0.7749249935150146, 0.7811499834060669, 0.7848250269889832, 0.7867249846458435, 0.7911499738693237, 0.7963749766349792, 0.802049994468689, 0.8052999973297119, 0.8090000152587891, 0.8103500008583069, 0.8157250285148621, 0.8178499937057495, 0.8217250108718872, 0.824999988079071], 'top_k_categorical_accuracy': [0.1264999955892563, 0.2267249971628189, 0.30012500286102295, 0.35530000925064087, 0.3987500071525574, 0.4410249888896942, 0.4817500114440918, 0.5134000182151794, 0.5473250150680542, 0.5791500210762024, 0.6035500168800354, 0.6258749961853027, 0.6460000276565552, 0.6660500168800354, 0.6830000281333923, 0.6969249844551086, 0.7117000222206116, 0.7217249870300293, 0.7353500127792358, 0.7435500025749207, 0.755299985408783, 0.7630749940872192, 0.7746250033378601, 0.7818750143051147, 0.7875249981880188, 0.7973750233650208, 0.8039500117301941, 0.806725025177002, 0.8142750263214111, 0.8187249898910522, 0.8235750198364258, 0.8311499953269958, 0.831849992275238, 0.8393750190734863, 0.8416500091552734, 0.8449000120162964, 0.8506249785423279, 0.8553500175476074, 0.8593000173568726, 0.8603500127792358, 0.8654000163078308, 0.8684750199317932, 0.87152498960495, 0.8750749826431274, 0.878724992275238, 0.8793249726295471, 0.8838750123977661, 0.8840000033378601, 0.8867499828338623, 0.889074981212616], 'val_loss': [4.622402191162109, 4.654223442077637, 4.578815460205078, 4.254306793212891, 4.569284439086914, 4.135084629058838, 4.833706855773926, 4.060356616973877, 3.719144821166992, 3.9911932945251465, 3.61321759223938, 3.429943084716797, 3.427844524383545, 3.247490644454956, 3.693535566329956, 3.359269857406616, 3.1853132247924805, 2.8724076747894287, 2.663994073867798, 2.8121438026428223, 2.8762800693511963, 2.6865477561950684, 2.771845817565918, 2.7647149562835693, 2.4143900871276855, 2.313077688217163, 2.415470600128174, 2.4094350337982178, 2.17521071434021, 2.222719669342041, 2.112661600112915, 2.2136611938476562, 2.1157329082489014, 2.1060078144073486, 2.1223714351654053, 1.9901211261749268, 2.039853811264038, 1.9387978315353394, 2.0140786170959473, 1.8981925249099731, 1.923606038093567, 1.915337085723877, 1.875269889831543, 1.8735278844833374, 1.8228245973587036, 1.9216678142547607, 1.8570009469985962, 1.8237916231155396, 1.7809937000274658, 1.7616374492645264], 'val_accuracy': [0.012299999594688416, 0.023000000044703484, 0.024700000882148743, 0.06270000338554382, 0.039799999445676804, 0.08410000056028366, 0.041200000792741776, 0.0989999994635582, 0.13600000739097595, 0.10899999737739563, 0.1657000035047531, 0.19580000638961792, 0.1889999955892563, 0.21230000257492065, 0.16699999570846558, 0.20970000326633453, 0.23479999601840973, 0.2831999957561493, 0.32659998536109924, 0.29649999737739563, 0.28299999237060547, 0.3221000134944916, 0.31200000643730164, 0.3050999939441681, 0.3734000027179718, 0.3917999863624573, 0.3756999969482422, 0.38269999623298645, 0.42730000615119934, 0.4106000065803528, 0.43799999356269836, 0.4113999903202057, 0.4390000104904175, 0.4438999891281128, 0.43059998750686646, 0.46639999747276306, 0.4546999931335449, 0.4747999906539917, 0.4578999876976013, 0.4887000024318695, 0.4832000136375427, 0.4819999933242798, 0.4902999997138977, 0.4902999997138977, 0.5001000165939331, 0.4832000136375427, 0.4950000047683716, 0.5080000162124634, 0.508400022983551, 0.5192000269889832], 'val_top3_acc': [0.03449999913573265, 0.06520000100135803, 0.06830000132322311, 0.14030000567436218, 0.09939999878406525, 0.1777999997138977, 0.09749999642372131, 0.21619999408721924, 0.2802000045776367, 0.23770000040531158, 0.31619998812675476, 0.35580000281333923, 0.36800000071525574, 0.39239999651908875, 0.334199994802475, 0.38839998841285706, 0.41429999470710754, 0.4893999993801117, 0.5367000102996826, 0.5031999945640564, 0.4880000054836273, 0.5360999703407288, 0.5273000001907349, 0.517799973487854, 0.5938000082969666, 0.6118000149726868, 0.5938000082969666, 0.5929999947547913, 0.6467999815940857, 0.6401000022888184, 0.6640999913215637, 0.6389999985694885, 0.6657999753952026, 0.6664000153541565, 0.6665999889373779, 0.6880000233650208, 0.6832000017166138, 0.6980999708175659, 0.6865000128746033, 0.7067999839782715, 0.7056000232696533, 0.7063999772071838, 0.7124999761581421, 0.7110000252723694, 0.7267000079154968, 0.7096999883651733, 0.718500018119812, 0.7239000201225281, 0.7371000051498413, 0.7407000064849854], 'val_top_k_categorical_accuracy': [0.05400000140070915, 0.0940999984741211, 0.1023000031709671, 0.19599999487400055, 0.15320000052452087, 0.24539999663829803, 0.1429000049829483, 0.2924000024795532, 0.36410000920295715, 0.3215999901294708, 0.3993000090122223, 0.45260000228881836, 0.46459999680519104, 0.49619999527931213, 0.4300999939441681, 0.48100000619888306, 0.5131000280380249, 0.5871999859809875, 0.6342999935150146, 0.602400004863739, 0.5896999835968018, 0.6316999793052673, 0.6236000061035156, 0.6187000274658203, 0.6895999908447266, 0.7089999914169312, 0.6916000247001648, 0.6876000165939331, 0.7401000261306763, 0.732699990272522, 0.7530999779701233, 0.733299970626831, 0.75, 0.7559999823570251, 0.7552000284194946, 0.7710999846458435, 0.7746999859809875, 0.7827000021934509, 0.7699999809265137, 0.7910000085830688, 0.7896999716758728, 0.7897999882698059, 0.7946000099182129, 0.7914999723434448, 0.8052999973297119, 0.7876999974250793, 0.7986000180244446, 0.8062999844551086, 0.8169000148773193, 0.815500020980835]}\n",
      "313/313 [==============================] - 5s 12ms/step - loss: 1.7741 - accuracy: 0.5192 - top3_acc: 0.7257 - top_k_categorical_accuracy: 0.8090\n",
      "[1.7740756273269653, 0.5192000269889832, 0.7257000207901001, 0.8090000152587891]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_simplenet_leaky.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
