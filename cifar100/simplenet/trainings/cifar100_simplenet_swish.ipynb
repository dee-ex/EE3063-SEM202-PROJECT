{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WljAm5f0fKkw"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "3af2becf-e784-4952-a89f-405ba5e56174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "b3c4e8dd-540f-4afb-f1c6-36ca6d3c3992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 52s 154ms/step - loss: 4.5683 - accuracy: 0.0142 - top3_acc: 0.0411 - top_k_categorical_accuracy: 0.0682 - val_loss: 4.6046 - val_accuracy: 0.0113 - val_top3_acc: 0.0337 - val_top_k_categorical_accuracy: 0.0534\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 46s 146ms/step - loss: 4.4713 - accuracy: 0.0269 - top3_acc: 0.0694 - top_k_categorical_accuracy: 0.1050 - val_loss: 4.5968 - val_accuracy: 0.0175 - val_top3_acc: 0.0424 - val_top_k_categorical_accuracy: 0.0638\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 4.4037 - accuracy: 0.0391 - top3_acc: 0.0946 - top_k_categorical_accuracy: 0.1362 - val_loss: 4.5816 - val_accuracy: 0.0231 - val_top3_acc: 0.0521 - val_top_k_categorical_accuracy: 0.0737\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 4.3419 - accuracy: 0.0487 - top3_acc: 0.1148 - top_k_categorical_accuracy: 0.1652 - val_loss: 4.5825 - val_accuracy: 0.0187 - val_top3_acc: 0.0434 - val_top_k_categorical_accuracy: 0.0687\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 4.2470 - accuracy: 0.0626 - top3_acc: 0.1399 - top_k_categorical_accuracy: 0.1942 - val_loss: 4.6392 - val_accuracy: 0.0103 - val_top3_acc: 0.0352 - val_top_k_categorical_accuracy: 0.0592\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 4.1005 - accuracy: 0.0768 - top3_acc: 0.1703 - top_k_categorical_accuracy: 0.2390 - val_loss: 5.1433 - val_accuracy: 0.0091 - val_top3_acc: 0.0292 - val_top_k_categorical_accuracy: 0.0556\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 3.9207 - accuracy: 0.0958 - top3_acc: 0.2085 - top_k_categorical_accuracy: 0.2883 - val_loss: 5.6388 - val_accuracy: 0.0129 - val_top3_acc: 0.0330 - val_top_k_categorical_accuracy: 0.0538\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 3.7180 - accuracy: 0.1285 - top3_acc: 0.2635 - top_k_categorical_accuracy: 0.3508 - val_loss: 5.5086 - val_accuracy: 0.0186 - val_top3_acc: 0.0490 - val_top_k_categorical_accuracy: 0.0705\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 3.5488 - accuracy: 0.1460 - top3_acc: 0.2977 - top_k_categorical_accuracy: 0.3970 - val_loss: 5.7852 - val_accuracy: 0.0226 - val_top3_acc: 0.0549 - val_top_k_categorical_accuracy: 0.0773\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 3.3970 - accuracy: 0.1733 - top3_acc: 0.3445 - top_k_categorical_accuracy: 0.4469 - val_loss: 5.4857 - val_accuracy: 0.0203 - val_top3_acc: 0.0670 - val_top_k_categorical_accuracy: 0.0921\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 3.2614 - accuracy: 0.1970 - top3_acc: 0.3794 - top_k_categorical_accuracy: 0.4843 - val_loss: 5.2312 - val_accuracy: 0.0333 - val_top3_acc: 0.0829 - val_top_k_categorical_accuracy: 0.1166\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 3.1129 - accuracy: 0.2228 - top3_acc: 0.4194 - top_k_categorical_accuracy: 0.5256 - val_loss: 5.5886 - val_accuracy: 0.0288 - val_top3_acc: 0.0749 - val_top_k_categorical_accuracy: 0.1125\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 2.9716 - accuracy: 0.2519 - top3_acc: 0.4544 - top_k_categorical_accuracy: 0.5610 - val_loss: 5.1444 - val_accuracy: 0.0433 - val_top3_acc: 0.1059 - val_top_k_categorical_accuracy: 0.1478\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 2.8352 - accuracy: 0.2740 - top3_acc: 0.4789 - top_k_categorical_accuracy: 0.5908 - val_loss: 5.2823 - val_accuracy: 0.0459 - val_top3_acc: 0.1171 - val_top_k_categorical_accuracy: 0.1664\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 2.7168 - accuracy: 0.3008 - top3_acc: 0.5150 - top_k_categorical_accuracy: 0.6213 - val_loss: 4.6657 - val_accuracy: 0.0618 - val_top3_acc: 0.1448 - val_top_k_categorical_accuracy: 0.1998\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 2.5998 - accuracy: 0.3226 - top3_acc: 0.5408 - top_k_categorical_accuracy: 0.6481 - val_loss: 4.1721 - val_accuracy: 0.0979 - val_top3_acc: 0.2344 - val_top_k_categorical_accuracy: 0.3138\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 2.4890 - accuracy: 0.3428 - top3_acc: 0.5673 - top_k_categorical_accuracy: 0.6741 - val_loss: 4.3783 - val_accuracy: 0.0854 - val_top3_acc: 0.2060 - val_top_k_categorical_accuracy: 0.2803\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 2.4192 - accuracy: 0.3599 - top3_acc: 0.5862 - top_k_categorical_accuracy: 0.6869 - val_loss: 4.0257 - val_accuracy: 0.1130 - val_top3_acc: 0.2494 - val_top_k_categorical_accuracy: 0.3295\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 2.3366 - accuracy: 0.3773 - top3_acc: 0.6038 - top_k_categorical_accuracy: 0.7056 - val_loss: 4.4544 - val_accuracy: 0.0921 - val_top3_acc: 0.2059 - val_top_k_categorical_accuracy: 0.2851\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 2.2650 - accuracy: 0.3896 - top3_acc: 0.6220 - top_k_categorical_accuracy: 0.7218 - val_loss: 4.3037 - val_accuracy: 0.1029 - val_top3_acc: 0.2366 - val_top_k_categorical_accuracy: 0.3147\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 2.1856 - accuracy: 0.4130 - top3_acc: 0.6371 - top_k_categorical_accuracy: 0.7387 - val_loss: 3.3724 - val_accuracy: 0.2084 - val_top3_acc: 0.3786 - val_top_k_categorical_accuracy: 0.4674\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 2.1096 - accuracy: 0.4233 - top3_acc: 0.6544 - top_k_categorical_accuracy: 0.7529 - val_loss: 3.4619 - val_accuracy: 0.1918 - val_top3_acc: 0.3680 - val_top_k_categorical_accuracy: 0.4593\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 2.0469 - accuracy: 0.4389 - top3_acc: 0.6713 - top_k_categorical_accuracy: 0.7661 - val_loss: 3.5680 - val_accuracy: 0.1799 - val_top3_acc: 0.3543 - val_top_k_categorical_accuracy: 0.4508\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 2.0166 - accuracy: 0.4508 - top3_acc: 0.6792 - top_k_categorical_accuracy: 0.7718 - val_loss: 3.1337 - val_accuracy: 0.2417 - val_top3_acc: 0.4375 - val_top_k_categorical_accuracy: 0.5378\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.9645 - accuracy: 0.4601 - top3_acc: 0.6887 - top_k_categorical_accuracy: 0.7827 - val_loss: 3.3215 - val_accuracy: 0.2138 - val_top3_acc: 0.4009 - val_top_k_categorical_accuracy: 0.4955\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.9051 - accuracy: 0.4739 - top3_acc: 0.7016 - top_k_categorical_accuracy: 0.7918 - val_loss: 2.7844 - val_accuracy: 0.3000 - val_top3_acc: 0.4986 - val_top_k_categorical_accuracy: 0.5968\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.8788 - accuracy: 0.4816 - top3_acc: 0.7086 - top_k_categorical_accuracy: 0.7957 - val_loss: 2.9459 - val_accuracy: 0.2745 - val_top3_acc: 0.4720 - val_top_k_categorical_accuracy: 0.5752\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.8551 - accuracy: 0.4876 - top3_acc: 0.7133 - top_k_categorical_accuracy: 0.8027 - val_loss: 3.2301 - val_accuracy: 0.2374 - val_top3_acc: 0.4294 - val_top_k_categorical_accuracy: 0.5265\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.7848 - accuracy: 0.5014 - top3_acc: 0.7300 - top_k_categorical_accuracy: 0.8148 - val_loss: 2.7197 - val_accuracy: 0.3244 - val_top3_acc: 0.5211 - val_top_k_categorical_accuracy: 0.6125\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.7565 - accuracy: 0.5086 - top3_acc: 0.7329 - top_k_categorical_accuracy: 0.8188 - val_loss: 2.8873 - val_accuracy: 0.2889 - val_top3_acc: 0.4919 - val_top_k_categorical_accuracy: 0.5900\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.7148 - accuracy: 0.5214 - top3_acc: 0.7422 - top_k_categorical_accuracy: 0.8250 - val_loss: 2.8916 - val_accuracy: 0.2929 - val_top3_acc: 0.5057 - val_top_k_categorical_accuracy: 0.6065\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.6740 - accuracy: 0.5289 - top3_acc: 0.7553 - top_k_categorical_accuracy: 0.8332 - val_loss: 2.7557 - val_accuracy: 0.3261 - val_top3_acc: 0.5201 - val_top_k_categorical_accuracy: 0.6163\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.6401 - accuracy: 0.5392 - top3_acc: 0.7613 - top_k_categorical_accuracy: 0.8381 - val_loss: 2.6512 - val_accuracy: 0.3402 - val_top3_acc: 0.5469 - val_top_k_categorical_accuracy: 0.6382\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.6091 - accuracy: 0.5427 - top3_acc: 0.7650 - top_k_categorical_accuracy: 0.8461 - val_loss: 2.3585 - val_accuracy: 0.3935 - val_top3_acc: 0.6010 - val_top_k_categorical_accuracy: 0.6893\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.5888 - accuracy: 0.5473 - top3_acc: 0.7690 - top_k_categorical_accuracy: 0.8497 - val_loss: 2.4605 - val_accuracy: 0.3795 - val_top3_acc: 0.5795 - val_top_k_categorical_accuracy: 0.6724\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.5594 - accuracy: 0.5560 - top3_acc: 0.7782 - top_k_categorical_accuracy: 0.8529 - val_loss: 2.4328 - val_accuracy: 0.3831 - val_top3_acc: 0.5875 - val_top_k_categorical_accuracy: 0.6776\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.5370 - accuracy: 0.5646 - top3_acc: 0.7791 - top_k_categorical_accuracy: 0.8559 - val_loss: 2.4185 - val_accuracy: 0.3876 - val_top3_acc: 0.5864 - val_top_k_categorical_accuracy: 0.6747\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.5064 - accuracy: 0.5683 - top3_acc: 0.7838 - top_k_categorical_accuracy: 0.8588 - val_loss: 2.3113 - val_accuracy: 0.4053 - val_top3_acc: 0.6114 - val_top_k_categorical_accuracy: 0.7027\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.4817 - accuracy: 0.5730 - top3_acc: 0.7919 - top_k_categorical_accuracy: 0.8672 - val_loss: 2.1004 - val_accuracy: 0.4453 - val_top3_acc: 0.6573 - val_top_k_categorical_accuracy: 0.7480\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.4757 - accuracy: 0.5800 - top3_acc: 0.7936 - top_k_categorical_accuracy: 0.8658 - val_loss: 2.3453 - val_accuracy: 0.4001 - val_top3_acc: 0.6087 - val_top_k_categorical_accuracy: 0.7018\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.4374 - accuracy: 0.5876 - top3_acc: 0.7994 - top_k_categorical_accuracy: 0.8682 - val_loss: 2.3255 - val_accuracy: 0.4069 - val_top3_acc: 0.6129 - val_top_k_categorical_accuracy: 0.7010\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.4136 - accuracy: 0.5936 - top3_acc: 0.8052 - top_k_categorical_accuracy: 0.8769 - val_loss: 2.2361 - val_accuracy: 0.4179 - val_top3_acc: 0.6256 - val_top_k_categorical_accuracy: 0.7168\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.3918 - accuracy: 0.5980 - top3_acc: 0.8070 - top_k_categorical_accuracy: 0.8787 - val_loss: 2.0883 - val_accuracy: 0.4524 - val_top3_acc: 0.6638 - val_top_k_categorical_accuracy: 0.7441\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.3720 - accuracy: 0.6052 - top3_acc: 0.8131 - top_k_categorical_accuracy: 0.8813 - val_loss: 2.1801 - val_accuracy: 0.4299 - val_top3_acc: 0.6414 - val_top_k_categorical_accuracy: 0.7314\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.3561 - accuracy: 0.6119 - top3_acc: 0.8170 - top_k_categorical_accuracy: 0.8824 - val_loss: 2.3399 - val_accuracy: 0.4135 - val_top3_acc: 0.6111 - val_top_k_categorical_accuracy: 0.6953\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.3214 - accuracy: 0.6135 - top3_acc: 0.8230 - top_k_categorical_accuracy: 0.8871 - val_loss: 2.1018 - val_accuracy: 0.4440 - val_top3_acc: 0.6565 - val_top_k_categorical_accuracy: 0.7360\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.3140 - accuracy: 0.6170 - top3_acc: 0.8250 - top_k_categorical_accuracy: 0.8896 - val_loss: 2.2819 - val_accuracy: 0.4162 - val_top3_acc: 0.6248 - val_top_k_categorical_accuracy: 0.7131\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.2832 - accuracy: 0.6271 - top3_acc: 0.8309 - top_k_categorical_accuracy: 0.8919 - val_loss: 2.0239 - val_accuracy: 0.4654 - val_top3_acc: 0.6744 - val_top_k_categorical_accuracy: 0.7568\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.2721 - accuracy: 0.6266 - top3_acc: 0.8325 - top_k_categorical_accuracy: 0.8954 - val_loss: 2.0794 - val_accuracy: 0.4617 - val_top3_acc: 0.6618 - val_top_k_categorical_accuracy: 0.7429\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.2459 - accuracy: 0.6357 - top3_acc: 0.8380 - top_k_categorical_accuracy: 0.8994 - val_loss: 2.1370 - val_accuracy: 0.4454 - val_top3_acc: 0.6503 - val_top_k_categorical_accuracy: 0.7385\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('swish')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "a8d89b3d-5750-4aec-ddf8-666f8e1ef444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [4.532835006713867, 4.458946228027344, 4.3915228843688965, 4.315042018890381, 4.219127655029297, 4.054031848907471, 3.861006736755371, 3.671999216079712, 3.512974500656128, 3.366607427597046, 3.2253758907318115, 3.08965802192688, 2.9496653079986572, 2.8157145977020264, 2.6885876655578613, 2.585306406021118, 2.4799907207489014, 2.404360055923462, 2.32139253616333, 2.2495954036712646, 2.1831934452056885, 2.120950937271118, 2.058474540710449, 2.012575149536133, 1.9602528810501099, 1.9125357866287231, 1.8696393966674805, 1.8389382362365723, 1.791387677192688, 1.756760597229004, 1.7137351036071777, 1.6813251972198486, 1.6512950658798218, 1.6239362955093384, 1.5925995111465454, 1.5673080682754517, 1.5403305292129517, 1.5145268440246582, 1.4858486652374268, 1.463504672050476, 1.4435319900512695, 1.4235827922821045, 1.3978415727615356, 1.375935673713684, 1.3650635480880737, 1.3284506797790527, 1.3238279819488525, 1.2936878204345703, 1.2796080112457275, 1.2530425786972046], 'accuracy': [0.017924999818205833, 0.028824999928474426, 0.04064999893307686, 0.05274999886751175, 0.06522499769926071, 0.08002500236034393, 0.10459999740123749, 0.1325249969959259, 0.15312500298023224, 0.1799750030040741, 0.2042749971151352, 0.22814999520778656, 0.25542500615119934, 0.27912500500679016, 0.3050000071525574, 0.322299987077713, 0.3467000126838684, 0.3626500070095062, 0.3813750147819519, 0.396450012922287, 0.4128499925136566, 0.4267750084400177, 0.4395749866962433, 0.4519749879837036, 0.4631749987602234, 0.4731999933719635, 0.4823000133037567, 0.4930500090122223, 0.49912500381469727, 0.5083000063896179, 0.5249500274658203, 0.525825023651123, 0.5353749990463257, 0.5410500168800354, 0.5488250255584717, 0.556850016117096, 0.5634750127792358, 0.5672000050544739, 0.5732750296592712, 0.5807750225067139, 0.5860499739646912, 0.590399980545044, 0.5969499945640564, 0.6048499941825867, 0.607450008392334, 0.6139000058174133, 0.6149749755859375, 0.6226750016212463, 0.627174973487854, 0.6346499919891357], 'top3_acc': [0.0505249984562397, 0.07392500340938568, 0.0984250009059906, 0.12174999713897705, 0.14755000174045563, 0.17832499742507935, 0.22417500615119934, 0.27342501282691956, 0.3100750148296356, 0.35042500495910645, 0.38907501101493835, 0.4250999987125397, 0.45817500352859497, 0.4870249927043915, 0.5233749747276306, 0.5437250137329102, 0.5697500109672546, 0.588949978351593, 0.6069999933242798, 0.6262249946594238, 0.6381250023841858, 0.654325008392334, 0.6690499782562256, 0.6816750168800354, 0.6897249817848206, 0.6991999745368958, 0.7106249928474426, 0.7152000069618225, 0.7287499904632568, 0.7329750061035156, 0.7437250018119812, 0.7520250082015991, 0.7576000094413757, 0.7626000046730042, 0.7681499719619751, 0.7755249738693237, 0.779449999332428, 0.7839249968528748, 0.790274977684021, 0.7964749932289124, 0.799875020980835, 0.8027999997138977, 0.8082500100135803, 0.8122249841690063, 0.814674973487854, 0.8216249942779541, 0.822825014591217, 0.828249990940094, 0.8292750120162964, 0.8363249897956848], 'top_k_categorical_accuracy': [0.08169999718666077, 0.11042500287294388, 0.14145000278949738, 0.17477500438690186, 0.2062000036239624, 0.24995000660419464, 0.3072499930858612, 0.36627501249313354, 0.4110499918460846, 0.45692500472068787, 0.4944249987602234, 0.5337749719619751, 0.5644999742507935, 0.597000002861023, 0.6286749839782715, 0.6503999829292297, 0.6766250133514404, 0.6908000111579895, 0.7104750275611877, 0.7260249853134155, 0.739549994468689, 0.7507749795913696, 0.7640500068664551, 0.7740749716758728, 0.7821499705314636, 0.7900500297546387, 0.7995749711990356, 0.8041499853134155, 0.8141499757766724, 0.8182500004768372, 0.8261749744415283, 0.8329749703407288, 0.8369250297546387, 0.8442000150680542, 0.8478749990463257, 0.8514000177383423, 0.8563500046730042, 0.8585500121116638, 0.8647249937057495, 0.8680750131607056, 0.8703749775886536, 0.8740249872207642, 0.8784000277519226, 0.8807250261306763, 0.881725013256073, 0.8864499926567078, 0.8881250023841858, 0.8924999833106995, 0.8939999938011169, 0.8984749913215637], 'val_loss': [4.604587078094482, 4.59676456451416, 4.581559658050537, 4.582474231719971, 4.639221668243408, 5.143272399902344, 5.6388020515441895, 5.508578300476074, 5.785200119018555, 5.48574686050415, 5.231233596801758, 5.588568210601807, 5.144432544708252, 5.282255172729492, 4.665703296661377, 4.172060012817383, 4.3783392906188965, 4.025731086730957, 4.454428672790527, 4.303670883178711, 3.372422695159912, 3.461926221847534, 3.567970037460327, 3.133668899536133, 3.321538209915161, 2.784353733062744, 2.9458508491516113, 3.230062961578369, 2.7197461128234863, 2.8873279094696045, 2.8916430473327637, 2.755730390548706, 2.651155710220337, 2.3584530353546143, 2.460538387298584, 2.432756185531616, 2.4185101985931396, 2.3112568855285645, 2.100374698638916, 2.3452866077423096, 2.32546067237854, 2.2361485958099365, 2.0883049964904785, 2.180067300796509, 2.3398683071136475, 2.101778507232666, 2.2819271087646484, 2.023874044418335, 2.0794425010681152, 2.1370480060577393], 'val_accuracy': [0.011300000362098217, 0.017500000074505806, 0.023099999874830246, 0.018699999898672104, 0.010300000198185444, 0.009100000374019146, 0.012900000438094139, 0.01860000006854534, 0.022600000724196434, 0.0203000009059906, 0.0333000011742115, 0.02879999950528145, 0.043299999088048935, 0.045899998396635056, 0.061799999326467514, 0.09790000319480896, 0.08540000021457672, 0.11299999803304672, 0.09210000187158585, 0.10289999842643738, 0.20839999616146088, 0.19179999828338623, 0.17990000545978546, 0.24169999361038208, 0.21379999816417694, 0.30000001192092896, 0.2745000123977661, 0.23739999532699585, 0.32440000772476196, 0.2888999879360199, 0.2928999960422516, 0.3260999917984009, 0.3402000069618225, 0.3935000002384186, 0.37950000166893005, 0.3831000030040741, 0.38760000467300415, 0.40529999136924744, 0.44530001282691956, 0.4000999927520752, 0.40689998865127563, 0.4178999960422516, 0.45239999890327454, 0.42989999055862427, 0.41350001096725464, 0.4440000057220459, 0.41620001196861267, 0.46540001034736633, 0.4616999924182892, 0.4453999996185303], 'val_top3_acc': [0.03370000049471855, 0.042399998754262924, 0.05209999904036522, 0.04340000078082085, 0.03519999980926514, 0.029200000688433647, 0.032999999821186066, 0.04899999871850014, 0.05490000173449516, 0.06700000166893005, 0.08290000259876251, 0.07490000128746033, 0.10589999705553055, 0.11710000038146973, 0.14480000734329224, 0.23440000414848328, 0.20600000023841858, 0.24940000474452972, 0.20589999854564667, 0.23659999668598175, 0.37860000133514404, 0.36800000071525574, 0.35429999232292175, 0.4375, 0.4009000062942505, 0.4986000061035156, 0.47200000286102295, 0.4293999969959259, 0.5210999846458435, 0.4918999969959259, 0.5056999921798706, 0.5200999975204468, 0.5468999743461609, 0.6010000109672546, 0.5795000195503235, 0.5874999761581421, 0.5863999724388123, 0.6114000082015991, 0.6572999954223633, 0.6086999773979187, 0.6129000186920166, 0.6255999803543091, 0.6638000011444092, 0.6413999795913696, 0.6111000180244446, 0.656499981880188, 0.6248000264167786, 0.6743999719619751, 0.6618000268936157, 0.6503000259399414], 'val_top_k_categorical_accuracy': [0.05339999869465828, 0.06379999965429306, 0.07370000332593918, 0.06870000064373016, 0.05920000001788139, 0.05559999868273735, 0.05380000174045563, 0.07050000131130219, 0.07729999721050262, 0.09210000187158585, 0.11659999936819077, 0.11249999701976776, 0.1477999985218048, 0.1664000004529953, 0.19979999959468842, 0.31380000710487366, 0.28029999136924744, 0.3294999897480011, 0.2851000130176544, 0.31470000743865967, 0.4674000144004822, 0.4593000113964081, 0.45080000162124634, 0.5378000140190125, 0.49549999833106995, 0.5968000292778015, 0.5752000212669373, 0.5264999866485596, 0.612500011920929, 0.5899999737739563, 0.6065000295639038, 0.6162999868392944, 0.6381999850273132, 0.689300000667572, 0.6723999977111816, 0.6776000261306763, 0.6747000217437744, 0.7027000188827515, 0.7480000257492065, 0.7017999887466431, 0.7009999752044678, 0.7167999744415283, 0.7440999746322632, 0.7314000129699707, 0.6952999830245972, 0.7360000014305115, 0.713100016117096, 0.7567999958992004, 0.742900013923645, 0.7384999990463257]}\n",
      "313/313 [==============================] - 6s 13ms/step - loss: 2.1527 - accuracy: 0.4443 - top3_acc: 0.6455 - top_k_categorical_accuracy: 0.7315\n",
      "[2.1526787281036377, 0.44429999589920044, 0.6455000042915344, 0.7315000295639038]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_simplenet_swish.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
