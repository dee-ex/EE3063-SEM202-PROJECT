{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WljAm5f0fKkw"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "3af2becf-e784-4952-a89f-405ba5e56174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "52b3839d-c7ca-4e4e-ec85-f9a0debb9a65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 65s 137ms/step - loss: 4.5780 - accuracy: 0.0199 - top3_acc: 0.0538 - top_k_categorical_accuracy: 0.0854 - val_loss: 4.3214 - val_accuracy: 0.0440 - val_top3_acc: 0.1199 - val_top_k_categorical_accuracy: 0.1797\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 4.2865 - accuracy: 0.0502 - top3_acc: 0.1289 - top_k_categorical_accuracy: 0.1900 - val_loss: 4.1441 - val_accuracy: 0.0687 - val_top3_acc: 0.1625 - val_top_k_categorical_accuracy: 0.2272\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 4.1231 - accuracy: 0.0782 - top3_acc: 0.1741 - top_k_categorical_accuracy: 0.2434 - val_loss: 4.1683 - val_accuracy: 0.0668 - val_top3_acc: 0.1540 - val_top_k_categorical_accuracy: 0.2191\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.9820 - accuracy: 0.0937 - top3_acc: 0.2063 - top_k_categorical_accuracy: 0.2864 - val_loss: 4.3463 - val_accuracy: 0.0489 - val_top3_acc: 0.1238 - val_top_k_categorical_accuracy: 0.1923\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 3.8617 - accuracy: 0.1129 - top3_acc: 0.2368 - top_k_categorical_accuracy: 0.3192 - val_loss: 4.1576 - val_accuracy: 0.0689 - val_top3_acc: 0.1625 - val_top_k_categorical_accuracy: 0.2445\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.7386 - accuracy: 0.1321 - top3_acc: 0.2728 - top_k_categorical_accuracy: 0.3644 - val_loss: 4.0869 - val_accuracy: 0.0741 - val_top3_acc: 0.1766 - val_top_k_categorical_accuracy: 0.2634\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.6347 - accuracy: 0.1460 - top3_acc: 0.2954 - top_k_categorical_accuracy: 0.3886 - val_loss: 4.6798 - val_accuracy: 0.0546 - val_top3_acc: 0.1262 - val_top_k_categorical_accuracy: 0.1900\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.5229 - accuracy: 0.1625 - top3_acc: 0.3255 - top_k_categorical_accuracy: 0.4235 - val_loss: 4.3563 - val_accuracy: 0.0632 - val_top3_acc: 0.1502 - val_top_k_categorical_accuracy: 0.2222\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 3.4199 - accuracy: 0.1819 - top3_acc: 0.3493 - top_k_categorical_accuracy: 0.4532 - val_loss: 4.3081 - val_accuracy: 0.0644 - val_top3_acc: 0.1567 - val_top_k_categorical_accuracy: 0.2235\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.3373 - accuracy: 0.1934 - top3_acc: 0.3688 - top_k_categorical_accuracy: 0.4721 - val_loss: 4.5219 - val_accuracy: 0.0709 - val_top3_acc: 0.1712 - val_top_k_categorical_accuracy: 0.2380\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 3.2473 - accuracy: 0.2075 - top3_acc: 0.3965 - top_k_categorical_accuracy: 0.5011 - val_loss: 4.1082 - val_accuracy: 0.0976 - val_top3_acc: 0.2183 - val_top_k_categorical_accuracy: 0.2935\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.1744 - accuracy: 0.2236 - top3_acc: 0.4112 - top_k_categorical_accuracy: 0.5169 - val_loss: 3.7430 - val_accuracy: 0.1253 - val_top3_acc: 0.2689 - val_top_k_categorical_accuracy: 0.3565\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.1025 - accuracy: 0.2337 - top3_acc: 0.4241 - top_k_categorical_accuracy: 0.5386 - val_loss: 3.9663 - val_accuracy: 0.1081 - val_top3_acc: 0.2376 - val_top_k_categorical_accuracy: 0.3232\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.0565 - accuracy: 0.2414 - top3_acc: 0.4362 - top_k_categorical_accuracy: 0.5442 - val_loss: 3.9762 - val_accuracy: 0.1171 - val_top3_acc: 0.2454 - val_top_k_categorical_accuracy: 0.3258\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.0019 - accuracy: 0.2481 - top3_acc: 0.4504 - top_k_categorical_accuracy: 0.5551 - val_loss: 4.7359 - val_accuracy: 0.0761 - val_top3_acc: 0.1685 - val_top_k_categorical_accuracy: 0.2361\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.9486 - accuracy: 0.2619 - top3_acc: 0.4650 - top_k_categorical_accuracy: 0.5705 - val_loss: 4.1944 - val_accuracy: 0.1025 - val_top3_acc: 0.2068 - val_top_k_categorical_accuracy: 0.2880\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.8953 - accuracy: 0.2694 - top3_acc: 0.4776 - top_k_categorical_accuracy: 0.5856 - val_loss: 4.2854 - val_accuracy: 0.0869 - val_top3_acc: 0.1933 - val_top_k_categorical_accuracy: 0.2670\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.8420 - accuracy: 0.2781 - top3_acc: 0.4911 - top_k_categorical_accuracy: 0.5998 - val_loss: 4.1472 - val_accuracy: 0.0990 - val_top3_acc: 0.2154 - val_top_k_categorical_accuracy: 0.2930\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.7844 - accuracy: 0.2909 - top3_acc: 0.5066 - top_k_categorical_accuracy: 0.6166 - val_loss: 4.0974 - val_accuracy: 0.1098 - val_top3_acc: 0.2373 - val_top_k_categorical_accuracy: 0.3207\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.7570 - accuracy: 0.2971 - top3_acc: 0.5099 - top_k_categorical_accuracy: 0.6152 - val_loss: 3.9273 - val_accuracy: 0.1323 - val_top3_acc: 0.2666 - val_top_k_categorical_accuracy: 0.3603\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.7108 - accuracy: 0.3053 - top3_acc: 0.5206 - top_k_categorical_accuracy: 0.6269 - val_loss: 4.1032 - val_accuracy: 0.1109 - val_top3_acc: 0.2448 - val_top_k_categorical_accuracy: 0.3348\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.6777 - accuracy: 0.3150 - top3_acc: 0.5299 - top_k_categorical_accuracy: 0.6347 - val_loss: 3.8267 - val_accuracy: 0.1298 - val_top3_acc: 0.2778 - val_top_k_categorical_accuracy: 0.3786\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.6220 - accuracy: 0.3278 - top3_acc: 0.5419 - top_k_categorical_accuracy: 0.6480 - val_loss: 4.0255 - val_accuracy: 0.1226 - val_top3_acc: 0.2497 - val_top_k_categorical_accuracy: 0.3470\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.5873 - accuracy: 0.3298 - top3_acc: 0.5506 - top_k_categorical_accuracy: 0.6584 - val_loss: 3.6386 - val_accuracy: 0.1500 - val_top3_acc: 0.3034 - val_top_k_categorical_accuracy: 0.4065\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.5565 - accuracy: 0.3351 - top3_acc: 0.5567 - top_k_categorical_accuracy: 0.6652 - val_loss: 4.2530 - val_accuracy: 0.1097 - val_top3_acc: 0.2245 - val_top_k_categorical_accuracy: 0.3122\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.5111 - accuracy: 0.3466 - top3_acc: 0.5709 - top_k_categorical_accuracy: 0.6766 - val_loss: 4.1338 - val_accuracy: 0.1173 - val_top3_acc: 0.2394 - val_top_k_categorical_accuracy: 0.3368\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.4908 - accuracy: 0.3516 - top3_acc: 0.5717 - top_k_categorical_accuracy: 0.6795 - val_loss: 4.4015 - val_accuracy: 0.0996 - val_top3_acc: 0.2078 - val_top_k_categorical_accuracy: 0.2969\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.4617 - accuracy: 0.3589 - top3_acc: 0.5822 - top_k_categorical_accuracy: 0.6860 - val_loss: 4.0308 - val_accuracy: 0.1334 - val_top3_acc: 0.2652 - val_top_k_categorical_accuracy: 0.3633\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.4305 - accuracy: 0.3637 - top3_acc: 0.5893 - top_k_categorical_accuracy: 0.6933 - val_loss: 4.0492 - val_accuracy: 0.1320 - val_top3_acc: 0.2602 - val_top_k_categorical_accuracy: 0.3498\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.4047 - accuracy: 0.3687 - top3_acc: 0.5927 - top_k_categorical_accuracy: 0.6974 - val_loss: 4.0241 - val_accuracy: 0.1260 - val_top3_acc: 0.2602 - val_top_k_categorical_accuracy: 0.3538\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.3784 - accuracy: 0.3759 - top3_acc: 0.6015 - top_k_categorical_accuracy: 0.7059 - val_loss: 4.3603 - val_accuracy: 0.1073 - val_top3_acc: 0.2140 - val_top_k_categorical_accuracy: 0.3063\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.3542 - accuracy: 0.3802 - top3_acc: 0.6033 - top_k_categorical_accuracy: 0.7085 - val_loss: 4.3242 - val_accuracy: 0.1130 - val_top3_acc: 0.2320 - val_top_k_categorical_accuracy: 0.3213\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.3174 - accuracy: 0.3889 - top3_acc: 0.6137 - top_k_categorical_accuracy: 0.7179 - val_loss: 4.2843 - val_accuracy: 0.1143 - val_top3_acc: 0.2319 - val_top_k_categorical_accuracy: 0.3233\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.2934 - accuracy: 0.3958 - top3_acc: 0.6195 - top_k_categorical_accuracy: 0.7216 - val_loss: 4.1613 - val_accuracy: 0.1285 - val_top3_acc: 0.2573 - val_top_k_categorical_accuracy: 0.3461\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.2506 - accuracy: 0.4033 - top3_acc: 0.6319 - top_k_categorical_accuracy: 0.7324 - val_loss: 3.9192 - val_accuracy: 0.1424 - val_top3_acc: 0.2774 - val_top_k_categorical_accuracy: 0.3739\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.2412 - accuracy: 0.4086 - top3_acc: 0.6324 - top_k_categorical_accuracy: 0.7327 - val_loss: 4.1085 - val_accuracy: 0.1345 - val_top3_acc: 0.2638 - val_top_k_categorical_accuracy: 0.3613\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.2043 - accuracy: 0.4121 - top3_acc: 0.6415 - top_k_categorical_accuracy: 0.7391 - val_loss: 3.9713 - val_accuracy: 0.1528 - val_top3_acc: 0.2902 - val_top_k_categorical_accuracy: 0.3895\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.1996 - accuracy: 0.4148 - top3_acc: 0.6438 - top_k_categorical_accuracy: 0.7413 - val_loss: 4.1260 - val_accuracy: 0.1406 - val_top3_acc: 0.2696 - val_top_k_categorical_accuracy: 0.3559\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.1777 - accuracy: 0.4234 - top3_acc: 0.6503 - top_k_categorical_accuracy: 0.7473 - val_loss: 4.0323 - val_accuracy: 0.1439 - val_top3_acc: 0.2809 - val_top_k_categorical_accuracy: 0.3749\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.1649 - accuracy: 0.4255 - top3_acc: 0.6508 - top_k_categorical_accuracy: 0.7454 - val_loss: 3.7754 - val_accuracy: 0.1643 - val_top3_acc: 0.3159 - val_top_k_categorical_accuracy: 0.4242\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.1241 - accuracy: 0.4335 - top3_acc: 0.6582 - top_k_categorical_accuracy: 0.7543 - val_loss: 3.8380 - val_accuracy: 0.1547 - val_top3_acc: 0.3018 - val_top_k_categorical_accuracy: 0.3998\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.1304 - accuracy: 0.4297 - top3_acc: 0.6572 - top_k_categorical_accuracy: 0.7530 - val_loss: 3.7723 - val_accuracy: 0.1651 - val_top3_acc: 0.3166 - val_top_k_categorical_accuracy: 0.4165\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 2.0899 - accuracy: 0.4404 - top3_acc: 0.6691 - top_k_categorical_accuracy: 0.7611 - val_loss: 3.8560 - val_accuracy: 0.1680 - val_top3_acc: 0.3198 - val_top_k_categorical_accuracy: 0.4209\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.0724 - accuracy: 0.4468 - top3_acc: 0.6727 - top_k_categorical_accuracy: 0.7646 - val_loss: 4.5679 - val_accuracy: 0.1200 - val_top3_acc: 0.2237 - val_top_k_categorical_accuracy: 0.3018\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 2.0309 - accuracy: 0.4543 - top3_acc: 0.6843 - top_k_categorical_accuracy: 0.7743 - val_loss: 3.9974 - val_accuracy: 0.1558 - val_top3_acc: 0.2965 - val_top_k_categorical_accuracy: 0.3890\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.0360 - accuracy: 0.4572 - top3_acc: 0.6767 - top_k_categorical_accuracy: 0.7724 - val_loss: 3.7981 - val_accuracy: 0.1598 - val_top3_acc: 0.3227 - val_top_k_categorical_accuracy: 0.4256\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.0238 - accuracy: 0.4551 - top3_acc: 0.6809 - top_k_categorical_accuracy: 0.7725 - val_loss: 4.1778 - val_accuracy: 0.1403 - val_top3_acc: 0.2694 - val_top_k_categorical_accuracy: 0.3644\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.0105 - accuracy: 0.4553 - top3_acc: 0.6839 - top_k_categorical_accuracy: 0.7758 - val_loss: 3.8447 - val_accuracy: 0.1655 - val_top3_acc: 0.3183 - val_top_k_categorical_accuracy: 0.4203\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.9933 - accuracy: 0.4602 - top3_acc: 0.6847 - top_k_categorical_accuracy: 0.7794 - val_loss: 3.6502 - val_accuracy: 0.1866 - val_top3_acc: 0.3483 - val_top_k_categorical_accuracy: 0.4534\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.9767 - accuracy: 0.4661 - top3_acc: 0.6908 - top_k_categorical_accuracy: 0.7834 - val_loss: 4.3251 - val_accuracy: 0.1292 - val_top3_acc: 0.2540 - val_top_k_categorical_accuracy: 0.3446\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('tanh')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "e8850f09-9884-4f95-ff55-f38dfcaaf9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [4.491558074951172, 4.243117332458496, 4.092601776123047, 3.9506828784942627, 3.8287320137023926, 3.713796854019165, 3.608391523361206, 3.5014488697052, 3.4043991565704346, 3.310196876525879, 3.2305805683135986, 3.1626412868499756, 3.1017324924468994, 3.0438120365142822, 2.9864721298217773, 2.9283101558685303, 2.8828063011169434, 2.8329010009765625, 2.785733699798584, 2.744074583053589, 2.7047178745269775, 2.6613121032714844, 2.6240346431732178, 2.589068651199341, 2.5548152923583984, 2.522932529449463, 2.4917924404144287, 2.4613680839538574, 2.4301869869232178, 2.3999016284942627, 2.3716461658477783, 2.346834182739258, 2.315127372741699, 2.289548873901367, 2.268415927886963, 2.244999885559082, 2.2179250717163086, 2.1997029781341553, 2.181605577468872, 2.1567978858947754, 2.1383979320526123, 2.118461847305298, 2.090174674987793, 2.080312967300415, 2.052410840988159, 2.0444486141204834, 2.025426149368286, 2.010711431503296, 1.9910187721252441, 1.9741652011871338], 'accuracy': [0.030400000512599945, 0.058150000870227814, 0.08092500269412994, 0.09724999964237213, 0.11722499877214432, 0.13439999520778656, 0.1504250019788742, 0.1658249944448471, 0.1837249994277954, 0.19767500460147858, 0.20845000445842743, 0.22372500598430634, 0.23307499289512634, 0.24355000257492065, 0.2531999945640564, 0.2633500099182129, 0.2722499966621399, 0.2836250066757202, 0.29202499985694885, 0.30254998803138733, 0.30717501044273376, 0.3154749870300293, 0.3252499997615814, 0.3322499990463257, 0.335099995136261, 0.34402498602867126, 0.352275013923645, 0.3605000078678131, 0.3640750050544739, 0.3719500005245209, 0.3776499927043915, 0.3806000053882599, 0.3885749876499176, 0.39820000529289246, 0.4003250002861023, 0.4055500030517578, 0.4118250012397766, 0.41682499647140503, 0.4177500009536743, 0.42762500047683716, 0.430525004863739, 0.4331499934196472, 0.440324991941452, 0.4442000091075897, 0.44882500171661377, 0.4542500078678131, 0.45707499980926514, 0.4575999975204468, 0.4623749852180481, 0.4667249917984009], 'top3_acc': [0.07702499628067017, 0.14194999635219574, 0.1812250018119812, 0.21287499368190765, 0.24535000324249268, 0.27744999527931213, 0.30149999260902405, 0.328000009059906, 0.35234999656677246, 0.37459999322891235, 0.3968999981880188, 0.41257500648498535, 0.42465001344680786, 0.4418250024318695, 0.4553999900817871, 0.46867498755455017, 0.48147499561309814, 0.49445000290870667, 0.5045499801635742, 0.5131499767303467, 0.5202000141143799, 0.535224974155426, 0.5421000123023987, 0.5504500269889832, 0.5580499768257141, 0.5681999921798706, 0.5721499919891357, 0.5805249810218811, 0.5884000062942505, 0.5956500172615051, 0.603950023651123, 0.6064249873161316, 0.616225004196167, 0.6210749745368958, 0.6258999705314636, 0.6320750117301941, 0.6380000114440918, 0.6431499719619751, 0.6469249725341797, 0.6532999873161316, 0.6557750105857849, 0.6620749831199646, 0.6680499911308289, 0.6690250039100647, 0.6778249740600586, 0.6754249930381775, 0.681850016117096, 0.6848999857902527, 0.6888250112533569, 0.6916499733924866], 'top_k_categorical_accuracy': [0.11789999902248383, 0.2040500044822693, 0.2517000138759613, 0.2932249903678894, 0.32977500557899475, 0.3694249987602234, 0.39739999175071716, 0.4277999997138977, 0.45669999718666077, 0.4798249900341034, 0.5022249817848206, 0.518750011920929, 0.5359500050544739, 0.5475500226020813, 0.5595999956130981, 0.5750499963760376, 0.5863500237464905, 0.6000750064849854, 0.6125500202178955, 0.6182000041007996, 0.6285499930381775, 0.6399499773979187, 0.6486250162124634, 0.6584749817848206, 0.6660500168800354, 0.6730750203132629, 0.6777999997138977, 0.6850249767303467, 0.6927000284194946, 0.6979749798774719, 0.7062249779701233, 0.7085999846458435, 0.7185999751091003, 0.7225000262260437, 0.7274500131607056, 0.7304250001907349, 0.73642498254776, 0.7422999739646912, 0.7456750273704529, 0.7480999827384949, 0.7509250044822693, 0.7558500170707703, 0.7613499760627747, 0.762274980545044, 0.7692750096321106, 0.7713249921798706, 0.7734249830245972, 0.7769250273704529, 0.7801499962806702, 0.7835749983787537], 'val_loss': [4.321383953094482, 4.144135475158691, 4.168266773223877, 4.346345901489258, 4.157562732696533, 4.08690881729126, 4.679841995239258, 4.35627555847168, 4.308107852935791, 4.521934986114502, 4.108179569244385, 3.743039846420288, 3.966298818588257, 3.9762442111968994, 4.735945224761963, 4.194418907165527, 4.285366058349609, 4.147192478179932, 4.097401142120361, 3.927267551422119, 4.103153705596924, 3.826742172241211, 4.025493144989014, 3.6385676860809326, 4.252984523773193, 4.133781433105469, 4.401467323303223, 4.030806541442871, 4.049246788024902, 4.0240607261657715, 4.360265731811523, 4.32417106628418, 4.284312725067139, 4.161320686340332, 3.919203996658325, 4.108482360839844, 3.9712789058685303, 4.125965595245361, 4.032326698303223, 3.7754156589508057, 3.8380448818206787, 3.7722952365875244, 3.855952739715576, 4.567941188812256, 3.997357130050659, 3.7981116771698, 4.1778130531311035, 3.8447346687316895, 3.6501874923706055, 4.325106620788574], 'val_accuracy': [0.04399999976158142, 0.06870000064373016, 0.06679999828338623, 0.048900000751018524, 0.06889999657869339, 0.07410000264644623, 0.05460000038146973, 0.06319999694824219, 0.06440000236034393, 0.07090000063180923, 0.09759999811649323, 0.12530000507831573, 0.10809999704360962, 0.11710000038146973, 0.07609999924898148, 0.10249999910593033, 0.0869000032544136, 0.0989999994635582, 0.10980000346899033, 0.13230000436306, 0.11089999973773956, 0.1298000067472458, 0.1225999966263771, 0.15000000596046448, 0.10970000177621841, 0.11729999631643295, 0.09960000216960907, 0.13339999318122864, 0.13199999928474426, 0.12600000202655792, 0.10729999840259552, 0.11299999803304672, 0.11429999768733978, 0.12849999964237213, 0.14239999651908875, 0.13449999690055847, 0.15279999375343323, 0.14059999585151672, 0.14390000700950623, 0.16429999470710754, 0.15469999611377716, 0.16509999334812164, 0.1679999977350235, 0.11999999731779099, 0.155799999833107, 0.1597999930381775, 0.14030000567436218, 0.1655000001192093, 0.186599999666214, 0.12919999659061432], 'val_top3_acc': [0.11990000307559967, 0.16249999403953552, 0.15399999916553497, 0.12380000203847885, 0.16249999403953552, 0.17659999430179596, 0.12620000541210175, 0.1501999944448471, 0.156700000166893, 0.1712000072002411, 0.218299999833107, 0.2689000070095062, 0.23759999871253967, 0.24539999663829803, 0.16850000619888306, 0.20679999887943268, 0.19329999387264252, 0.21539999544620514, 0.23729999363422394, 0.26660001277923584, 0.24480000138282776, 0.2777999937534332, 0.24969999492168427, 0.3034000098705292, 0.22450000047683716, 0.2393999993801117, 0.2078000009059906, 0.2651999890804291, 0.26019999384880066, 0.26019999384880066, 0.21400000154972076, 0.23199999332427979, 0.23190000653266907, 0.2572999894618988, 0.2773999869823456, 0.2637999951839447, 0.29019999504089355, 0.2696000039577484, 0.2809000015258789, 0.3158999979496002, 0.301800012588501, 0.3165999948978424, 0.3197999894618988, 0.22370000183582306, 0.29649999737739563, 0.32269999384880066, 0.2694000005722046, 0.3183000087738037, 0.3483000099658966, 0.2540000081062317], 'val_top_k_categorical_accuracy': [0.17970000207424164, 0.2272000014781952, 0.2190999984741211, 0.1923000067472458, 0.24449999630451202, 0.26339998841285706, 0.1899999976158142, 0.22220000624656677, 0.22349999845027924, 0.23800000548362732, 0.29350000619888306, 0.3564999997615814, 0.323199987411499, 0.32580000162124634, 0.2361000031232834, 0.2879999876022339, 0.2669999897480011, 0.2930000126361847, 0.3206999897956848, 0.3603000044822693, 0.33480000495910645, 0.37860000133514404, 0.34700000286102295, 0.4065000116825104, 0.31220000982284546, 0.3368000090122223, 0.2969000041484833, 0.36329999566078186, 0.3497999906539917, 0.3537999987602234, 0.30630001425743103, 0.3212999999523163, 0.32330000400543213, 0.34610000252723694, 0.37389999628067017, 0.361299991607666, 0.3894999921321869, 0.35589998960494995, 0.3749000132083893, 0.42419999837875366, 0.39980000257492065, 0.4165000021457672, 0.42089998722076416, 0.301800012588501, 0.3889999985694885, 0.42559999227523804, 0.3643999993801117, 0.4203000068664551, 0.45339998602867126, 0.34459999203681946]}\n",
      "313/313 [==============================] - 5s 11ms/step - loss: 4.3326 - accuracy: 0.1280 - top3_acc: 0.2516 - top_k_categorical_accuracy: 0.3410\n",
      "[4.332625865936279, 0.12800000607967377, 0.2515999972820282, 0.3409999907016754]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_simplenet_tanh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
