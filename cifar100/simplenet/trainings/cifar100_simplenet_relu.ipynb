{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WljAm5f0fKkw"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "3af2becf-e784-4952-a89f-405ba5e56174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "65630be5-12e9-48cb-8e54-e17e95f0da61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 45s 131ms/step - loss: 4.5898 - accuracy: 0.0151 - top3_acc: 0.0429 - top_k_categorical_accuracy: 0.0681 - val_loss: 4.6125 - val_accuracy: 0.0120 - val_top3_acc: 0.0322 - val_top_k_categorical_accuracy: 0.0528\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 4.4319 - accuracy: 0.0275 - top3_acc: 0.0751 - top_k_categorical_accuracy: 0.1178 - val_loss: 4.6967 - val_accuracy: 0.0096 - val_top3_acc: 0.0295 - val_top_k_categorical_accuracy: 0.0505\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 4.2857 - accuracy: 0.0462 - top3_acc: 0.1123 - top_k_categorical_accuracy: 0.1647 - val_loss: 5.2599 - val_accuracy: 0.0091 - val_top3_acc: 0.0284 - val_top_k_categorical_accuracy: 0.0507\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 4.1041 - accuracy: 0.0649 - top3_acc: 0.1570 - top_k_categorical_accuracy: 0.2271 - val_loss: 5.9970 - val_accuracy: 0.0095 - val_top3_acc: 0.0313 - val_top_k_categorical_accuracy: 0.0501\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 3.9093 - accuracy: 0.0922 - top3_acc: 0.2054 - top_k_categorical_accuracy: 0.2862 - val_loss: 6.1136 - val_accuracy: 0.0137 - val_top3_acc: 0.0367 - val_top_k_categorical_accuracy: 0.0575\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 3.7638 - accuracy: 0.1153 - top3_acc: 0.2428 - top_k_categorical_accuracy: 0.3335 - val_loss: 5.1016 - val_accuracy: 0.0187 - val_top3_acc: 0.0606 - val_top_k_categorical_accuracy: 0.0976\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 3.6241 - accuracy: 0.1318 - top3_acc: 0.2834 - top_k_categorical_accuracy: 0.3803 - val_loss: 5.3321 - val_accuracy: 0.0174 - val_top3_acc: 0.0497 - val_top_k_categorical_accuracy: 0.0881\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.4919 - accuracy: 0.1546 - top3_acc: 0.3164 - top_k_categorical_accuracy: 0.4181 - val_loss: 5.4805 - val_accuracy: 0.0290 - val_top3_acc: 0.0739 - val_top_k_categorical_accuracy: 0.1212\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 3.3713 - accuracy: 0.1784 - top3_acc: 0.3453 - top_k_categorical_accuracy: 0.4485 - val_loss: 5.3863 - val_accuracy: 0.0312 - val_top3_acc: 0.0736 - val_top_k_categorical_accuracy: 0.1156\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 3.2654 - accuracy: 0.1987 - top3_acc: 0.3799 - top_k_categorical_accuracy: 0.4812 - val_loss: 4.3852 - val_accuracy: 0.0686 - val_top3_acc: 0.1635 - val_top_k_categorical_accuracy: 0.2301\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 3.1359 - accuracy: 0.2170 - top3_acc: 0.4110 - top_k_categorical_accuracy: 0.5190 - val_loss: 5.2388 - val_accuracy: 0.0405 - val_top3_acc: 0.1330 - val_top_k_categorical_accuracy: 0.1908\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.0417 - accuracy: 0.2348 - top3_acc: 0.4271 - top_k_categorical_accuracy: 0.5391 - val_loss: 5.2019 - val_accuracy: 0.0372 - val_top3_acc: 0.1093 - val_top_k_categorical_accuracy: 0.1667\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 2.9190 - accuracy: 0.2563 - top3_acc: 0.4616 - top_k_categorical_accuracy: 0.5721 - val_loss: 5.2881 - val_accuracy: 0.0379 - val_top3_acc: 0.0918 - val_top_k_categorical_accuracy: 0.1424\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 2.8210 - accuracy: 0.2797 - top3_acc: 0.4825 - top_k_categorical_accuracy: 0.5944 - val_loss: 4.5179 - val_accuracy: 0.0601 - val_top3_acc: 0.1396 - val_top_k_categorical_accuracy: 0.1980\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.7219 - accuracy: 0.2997 - top3_acc: 0.5112 - top_k_categorical_accuracy: 0.6204 - val_loss: 3.9627 - val_accuracy: 0.1180 - val_top3_acc: 0.2463 - val_top_k_categorical_accuracy: 0.3312\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.6635 - accuracy: 0.3066 - top3_acc: 0.5267 - top_k_categorical_accuracy: 0.6328 - val_loss: 4.2096 - val_accuracy: 0.1042 - val_top3_acc: 0.2250 - val_top_k_categorical_accuracy: 0.3030\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 2.5764 - accuracy: 0.3244 - top3_acc: 0.5432 - top_k_categorical_accuracy: 0.6539 - val_loss: 4.2008 - val_accuracy: 0.0991 - val_top3_acc: 0.2177 - val_top_k_categorical_accuracy: 0.2851\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.5212 - accuracy: 0.3356 - top3_acc: 0.5556 - top_k_categorical_accuracy: 0.6670 - val_loss: 3.6911 - val_accuracy: 0.1626 - val_top3_acc: 0.3058 - val_top_k_categorical_accuracy: 0.3916\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.4508 - accuracy: 0.3495 - top3_acc: 0.5748 - top_k_categorical_accuracy: 0.6821 - val_loss: 3.6047 - val_accuracy: 0.1670 - val_top3_acc: 0.3096 - val_top_k_categorical_accuracy: 0.3986\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 2.3770 - accuracy: 0.3616 - top3_acc: 0.5939 - top_k_categorical_accuracy: 0.6992 - val_loss: 4.4020 - val_accuracy: 0.0979 - val_top3_acc: 0.2143 - val_top_k_categorical_accuracy: 0.2827\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.3371 - accuracy: 0.3817 - top3_acc: 0.6042 - top_k_categorical_accuracy: 0.7052 - val_loss: 3.0442 - val_accuracy: 0.2497 - val_top3_acc: 0.4470 - val_top_k_categorical_accuracy: 0.5434\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 2.2792 - accuracy: 0.3922 - top3_acc: 0.6154 - top_k_categorical_accuracy: 0.7205 - val_loss: 3.2653 - val_accuracy: 0.2142 - val_top3_acc: 0.4021 - val_top_k_categorical_accuracy: 0.4973\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 2.2138 - accuracy: 0.4031 - top3_acc: 0.6339 - top_k_categorical_accuracy: 0.7336 - val_loss: 3.7763 - val_accuracy: 0.1557 - val_top3_acc: 0.3022 - val_top_k_categorical_accuracy: 0.3898\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.1749 - accuracy: 0.4112 - top3_acc: 0.6422 - top_k_categorical_accuracy: 0.7401 - val_loss: 3.0379 - val_accuracy: 0.2494 - val_top3_acc: 0.4523 - val_top_k_categorical_accuracy: 0.5494\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.1244 - accuracy: 0.4245 - top3_acc: 0.6556 - top_k_categorical_accuracy: 0.7517 - val_loss: 3.2088 - val_accuracy: 0.2322 - val_top3_acc: 0.4118 - val_top_k_categorical_accuracy: 0.5068\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 2.0957 - accuracy: 0.4308 - top3_acc: 0.6624 - top_k_categorical_accuracy: 0.7601 - val_loss: 3.3594 - val_accuracy: 0.2032 - val_top3_acc: 0.3877 - val_top_k_categorical_accuracy: 0.4809\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.0468 - accuracy: 0.4393 - top3_acc: 0.6704 - top_k_categorical_accuracy: 0.7617 - val_loss: 3.4546 - val_accuracy: 0.1971 - val_top3_acc: 0.3727 - val_top_k_categorical_accuracy: 0.4662\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.0136 - accuracy: 0.4468 - top3_acc: 0.6808 - top_k_categorical_accuracy: 0.7757 - val_loss: 2.7844 - val_accuracy: 0.3032 - val_top3_acc: 0.4975 - val_top_k_categorical_accuracy: 0.5991\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.9568 - accuracy: 0.4659 - top3_acc: 0.6914 - top_k_categorical_accuracy: 0.7847 - val_loss: 2.7560 - val_accuracy: 0.3035 - val_top3_acc: 0.5070 - val_top_k_categorical_accuracy: 0.6114\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.9258 - accuracy: 0.4695 - top3_acc: 0.6975 - top_k_categorical_accuracy: 0.7903 - val_loss: 3.5265 - val_accuracy: 0.1870 - val_top3_acc: 0.3557 - val_top_k_categorical_accuracy: 0.4447\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.9078 - accuracy: 0.4751 - top3_acc: 0.6985 - top_k_categorical_accuracy: 0.7910 - val_loss: 3.0369 - val_accuracy: 0.2582 - val_top3_acc: 0.4583 - val_top_k_categorical_accuracy: 0.5536\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.8658 - accuracy: 0.4817 - top3_acc: 0.7142 - top_k_categorical_accuracy: 0.8013 - val_loss: 2.6369 - val_accuracy: 0.3260 - val_top3_acc: 0.5371 - val_top_k_categorical_accuracy: 0.6319\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.8344 - accuracy: 0.4867 - top3_acc: 0.7193 - top_k_categorical_accuracy: 0.8048 - val_loss: 2.2952 - val_accuracy: 0.3979 - val_top3_acc: 0.6184 - val_top_k_categorical_accuracy: 0.7147\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.8129 - accuracy: 0.4982 - top3_acc: 0.7212 - top_k_categorical_accuracy: 0.8079 - val_loss: 2.3542 - val_accuracy: 0.3850 - val_top3_acc: 0.6021 - val_top_k_categorical_accuracy: 0.6980\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.7750 - accuracy: 0.5056 - top3_acc: 0.7325 - top_k_categorical_accuracy: 0.8184 - val_loss: 2.3737 - val_accuracy: 0.3840 - val_top3_acc: 0.5988 - val_top_k_categorical_accuracy: 0.6934\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.7544 - accuracy: 0.5109 - top3_acc: 0.7358 - top_k_categorical_accuracy: 0.8197 - val_loss: 2.8637 - val_accuracy: 0.2945 - val_top3_acc: 0.4946 - val_top_k_categorical_accuracy: 0.5892\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.7253 - accuracy: 0.5150 - top3_acc: 0.7442 - top_k_categorical_accuracy: 0.8233 - val_loss: 2.1934 - val_accuracy: 0.4167 - val_top3_acc: 0.6391 - val_top_k_categorical_accuracy: 0.7376\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.6885 - accuracy: 0.5250 - top3_acc: 0.7482 - top_k_categorical_accuracy: 0.8302 - val_loss: 2.5010 - val_accuracy: 0.3540 - val_top3_acc: 0.5714 - val_top_k_categorical_accuracy: 0.6675\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.6645 - accuracy: 0.5294 - top3_acc: 0.7546 - top_k_categorical_accuracy: 0.8367 - val_loss: 2.2067 - val_accuracy: 0.4210 - val_top3_acc: 0.6360 - val_top_k_categorical_accuracy: 0.7274\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.6400 - accuracy: 0.5345 - top3_acc: 0.7591 - top_k_categorical_accuracy: 0.8398 - val_loss: 2.3535 - val_accuracy: 0.3890 - val_top3_acc: 0.6025 - val_top_k_categorical_accuracy: 0.6977\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.6192 - accuracy: 0.5437 - top3_acc: 0.7654 - top_k_categorical_accuracy: 0.8442 - val_loss: 2.3565 - val_accuracy: 0.3849 - val_top3_acc: 0.6022 - val_top_k_categorical_accuracy: 0.6956\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.6080 - accuracy: 0.5486 - top3_acc: 0.7691 - top_k_categorical_accuracy: 0.8453 - val_loss: 2.2163 - val_accuracy: 0.4169 - val_top3_acc: 0.6322 - val_top_k_categorical_accuracy: 0.7255\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.5666 - accuracy: 0.5593 - top3_acc: 0.7738 - top_k_categorical_accuracy: 0.8542 - val_loss: 2.4087 - val_accuracy: 0.3811 - val_top3_acc: 0.5907 - val_top_k_categorical_accuracy: 0.6824\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.5410 - accuracy: 0.5618 - top3_acc: 0.7788 - top_k_categorical_accuracy: 0.8546 - val_loss: 2.1256 - val_accuracy: 0.4434 - val_top3_acc: 0.6588 - val_top_k_categorical_accuracy: 0.7446\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.5158 - accuracy: 0.5686 - top3_acc: 0.7863 - top_k_categorical_accuracy: 0.8585 - val_loss: 1.9730 - val_accuracy: 0.4626 - val_top3_acc: 0.6880 - val_top_k_categorical_accuracy: 0.7770\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.5230 - accuracy: 0.5635 - top3_acc: 0.7855 - top_k_categorical_accuracy: 0.8593 - val_loss: 2.3196 - val_accuracy: 0.4006 - val_top3_acc: 0.6139 - val_top_k_categorical_accuracy: 0.7033\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.4872 - accuracy: 0.5771 - top3_acc: 0.7904 - top_k_categorical_accuracy: 0.8659 - val_loss: 1.9268 - val_accuracy: 0.4843 - val_top3_acc: 0.6993 - val_top_k_categorical_accuracy: 0.7831\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.4700 - accuracy: 0.5751 - top3_acc: 0.7971 - top_k_categorical_accuracy: 0.8683 - val_loss: 2.1870 - val_accuracy: 0.4271 - val_top3_acc: 0.6422 - val_top_k_categorical_accuracy: 0.7358\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.4518 - accuracy: 0.5830 - top3_acc: 0.7976 - top_k_categorical_accuracy: 0.8673 - val_loss: 2.1025 - val_accuracy: 0.4487 - val_top3_acc: 0.6573 - val_top_k_categorical_accuracy: 0.7438\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.4229 - accuracy: 0.5904 - top3_acc: 0.8037 - top_k_categorical_accuracy: 0.8721 - val_loss: 2.2949 - val_accuracy: 0.4017 - val_top3_acc: 0.6153 - val_top_k_categorical_accuracy: 0.7097\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "0075b473-a91b-4b04-a817-58773945bb62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [4.531716823577881, 4.401214122772217, 4.246602535247803, 4.055988311767578, 3.879645347595215, 3.7295753955841064, 3.5972793102264404, 3.471210479736328, 3.350360870361328, 3.226804256439209, 3.116773843765259, 3.0133934020996094, 2.9047181606292725, 2.8115971088409424, 2.7179524898529053, 2.6535143852233887, 2.5763585567474365, 2.512035846710205, 2.448869228363037, 2.377668857574463, 2.324556350708008, 2.275979518890381, 2.222717761993408, 2.172999382019043, 2.1344196796417236, 2.0940561294555664, 2.0501205921173096, 2.0017576217651367, 1.9736148118972778, 1.9381152391433716, 1.904128909111023, 1.8738411664962769, 1.8395894765853882, 1.804709792137146, 1.77095365524292, 1.7463737726211548, 1.7247978448867798, 1.700275182723999, 1.668502688407898, 1.644116759300232, 1.6212711334228516, 1.6045671701431274, 1.5778793096542358, 1.5551838874816895, 1.5282397270202637, 1.5158483982086182, 1.4930490255355835, 1.47233247756958, 1.4620229005813599, 1.437757134437561], 'accuracy': [0.01810000091791153, 0.03137499839067459, 0.04919999837875366, 0.07114999741315842, 0.09537500143051147, 0.11812499910593033, 0.13615000247955322, 0.15547500550746918, 0.1808999925851822, 0.2041500061750412, 0.22267499566078186, 0.24267500638961792, 0.2593249976634979, 0.2808000147342682, 0.29649999737739563, 0.3087500035762787, 0.3255999982357025, 0.3393250107765198, 0.35167500376701355, 0.366225004196167, 0.3821749985218048, 0.3920750021934509, 0.40220001339912415, 0.41222500801086426, 0.42294999957084656, 0.42992499470710754, 0.44064998626708984, 0.45080000162124634, 0.4600749909877777, 0.465925008058548, 0.4745999872684479, 0.4823000133037567, 0.48967498540878296, 0.4986250102519989, 0.5067999958992004, 0.5119500160217285, 0.5155749917030334, 0.524399995803833, 0.5317000150680542, 0.5348250269889832, 0.5419999957084656, 0.546999990940094, 0.5546749830245972, 0.5552999973297119, 0.5670999884605408, 0.5662000179290771, 0.5736500024795532, 0.5751500129699707, 0.5808749794960022, 0.5869250297546387], 'top3_acc': [0.0515500009059906, 0.08357500284910202, 0.12177500128746033, 0.1673000007867813, 0.21195000410079956, 0.2513499855995178, 0.287975013256073, 0.31882500648498535, 0.3518500030040741, 0.388949990272522, 0.41727501153945923, 0.43947499990463257, 0.4652250111103058, 0.48672500252723694, 0.512274980545044, 0.5279499888420105, 0.5439000129699707, 0.5587999820709229, 0.5754500031471252, 0.5929999947547913, 0.6079249978065491, 0.6164000034332275, 0.6306750178337097, 0.6413499712944031, 0.6523000001907349, 0.663100004196167, 0.670799970626831, 0.6842749714851379, 0.6875500082969666, 0.6953999996185303, 0.7016000151634216, 0.7112249732017517, 0.7177500128746033, 0.7254499793052673, 0.7310500144958496, 0.7366499900817871, 0.7425500154495239, 0.7457000017166138, 0.7545750141143799, 0.7590500116348267, 0.7646999955177307, 0.7677000164985657, 0.7725250124931335, 0.7769500017166138, 0.7837250232696533, 0.7859500050544739, 0.7892749905586243, 0.7971749901771545, 0.7962750196456909, 0.8016250133514404], 'top_k_categorical_accuracy': [0.08252499997615814, 0.12804999947547913, 0.17982499301433563, 0.24047499895095825, 0.294050008058548, 0.3422999978065491, 0.38522499799728394, 0.4210500121116638, 0.4561749994754791, 0.49184998869895935, 0.5241249799728394, 0.5481250286102295, 0.5752750039100647, 0.599524974822998, 0.6214500069618225, 0.6364750266075134, 0.6525999903678894, 0.6683750152587891, 0.6813250184059143, 0.6974999904632568, 0.708774983882904, 0.7196000218391418, 0.7310749888420105, 0.7394750118255615, 0.7485499978065491, 0.760450005531311, 0.7654749751091003, 0.7767999768257141, 0.7815750241279602, 0.788349986076355, 0.7934250235557556, 0.7991499900817871, 0.8040750026702881, 0.8125, 0.8169000148773193, 0.8220999836921692, 0.8251749873161316, 0.8290249705314636, 0.8350499868392944, 0.8400499820709229, 0.8441500067710876, 0.8458999991416931, 0.8503999710083008, 0.8533999919891357, 0.8575999736785889, 0.8601250052452087, 0.865024983882904, 0.8668249845504761, 0.8679749965667725, 0.8713499903678894], 'val_loss': [4.612544059753418, 4.6966729164123535, 5.259937286376953, 5.996967315673828, 6.113597869873047, 5.101638317108154, 5.332122802734375, 5.48048734664917, 5.386277675628662, 4.385211944580078, 5.238753318786621, 5.201877593994141, 5.2880659103393555, 4.517872333526611, 3.9626567363739014, 4.209555625915527, 4.200754642486572, 3.6910691261291504, 3.6046793460845947, 4.401984691619873, 3.044212579727173, 3.2653415203094482, 3.776275873184204, 3.0379016399383545, 3.2087700366973877, 3.359387159347534, 3.454615592956543, 2.784372091293335, 2.7559597492218018, 3.526536703109741, 3.0369231700897217, 2.6369316577911377, 2.2951672077178955, 2.3542258739471436, 2.37372088432312, 2.8637375831604004, 2.193443775177002, 2.5009922981262207, 2.206677198410034, 2.353532552719116, 2.356482744216919, 2.2162952423095703, 2.4087417125701904, 2.1256110668182373, 1.9730197191238403, 2.3196096420288086, 1.9267911911010742, 2.187034845352173, 2.1024653911590576, 2.2948555946350098], 'val_accuracy': [0.012000000104308128, 0.009600000455975533, 0.009100000374019146, 0.009499999694526196, 0.013700000010430813, 0.018699999898672104, 0.017400000244379044, 0.028999999165534973, 0.031199999153614044, 0.06859999895095825, 0.04050000011920929, 0.03720000013709068, 0.03790000081062317, 0.060100000351667404, 0.11800000071525574, 0.10419999808073044, 0.09910000115633011, 0.16259999573230743, 0.16699999570846558, 0.09790000319480896, 0.24969999492168427, 0.2142000049352646, 0.15569999814033508, 0.24940000474452972, 0.2321999967098236, 0.20319999754428864, 0.19709999859333038, 0.30320000648498535, 0.3034999966621399, 0.18700000643730164, 0.2581999897956848, 0.32600000500679016, 0.3978999853134155, 0.38499999046325684, 0.3840000033378601, 0.2944999933242798, 0.41670000553131104, 0.3540000021457672, 0.42100000381469727, 0.3889999985694885, 0.3849000036716461, 0.41690000891685486, 0.38109999895095825, 0.44339999556541443, 0.4625999927520752, 0.40059998631477356, 0.48429998755455017, 0.4271000027656555, 0.4487000107765198, 0.4016999900341034], 'val_top3_acc': [0.03220000118017197, 0.029500000178813934, 0.0284000001847744, 0.031300000846385956, 0.03669999912381172, 0.060600001364946365, 0.04969999939203262, 0.0738999992609024, 0.07360000163316727, 0.16349999606609344, 0.13300000131130219, 0.10930000245571136, 0.09179999679327011, 0.1395999938249588, 0.24629999697208405, 0.22499999403953552, 0.21770000457763672, 0.3057999908924103, 0.30959999561309814, 0.2143000066280365, 0.44699999690055847, 0.40209999680519104, 0.30219998955726624, 0.4523000121116638, 0.41179999709129333, 0.38769999146461487, 0.3727000057697296, 0.4975000023841858, 0.5070000290870667, 0.35569998621940613, 0.45829999446868896, 0.5371000170707703, 0.618399977684021, 0.6021000146865845, 0.598800003528595, 0.49459999799728394, 0.6391000151634216, 0.571399986743927, 0.6359999775886536, 0.6025000214576721, 0.6021999716758728, 0.6322000026702881, 0.5906999707221985, 0.6588000059127808, 0.6880000233650208, 0.6139000058174133, 0.6992999911308289, 0.6421999931335449, 0.6572999954223633, 0.6152999997138977], 'val_top_k_categorical_accuracy': [0.052799999713897705, 0.05050000175833702, 0.050700001418590546, 0.05009999871253967, 0.057500001043081284, 0.09759999811649323, 0.08810000121593475, 0.12120000272989273, 0.11559999734163284, 0.23010000586509705, 0.1907999962568283, 0.16670000553131104, 0.14239999651908875, 0.1979999989271164, 0.3312000036239624, 0.30300000309944153, 0.2851000130176544, 0.39160001277923584, 0.3986000120639801, 0.2827000021934509, 0.54339998960495, 0.49729999899864197, 0.3898000121116638, 0.5493999719619751, 0.5067999958992004, 0.48089998960494995, 0.46619999408721924, 0.5990999937057495, 0.6114000082015991, 0.4447000026702881, 0.553600013256073, 0.6319000124931335, 0.7146999835968018, 0.6980000138282776, 0.6934000253677368, 0.5892000198364258, 0.7376000285148621, 0.6675000190734863, 0.727400004863739, 0.697700023651123, 0.6955999732017517, 0.7254999876022339, 0.6823999881744385, 0.7445999979972839, 0.7770000100135803, 0.7032999992370605, 0.7831000089645386, 0.73580002784729, 0.7437999844551086, 0.7096999883651733]}\n",
      "313/313 [==============================] - 5s 11ms/step - loss: 2.1945 - accuracy: 0.4225 - top3_acc: 0.6409 - top_k_categorical_accuracy: 0.7300\n",
      "[2.19446063041687, 0.42250001430511475, 0.6409000158309937, 0.7300000190734863]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_simplenet_relu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
