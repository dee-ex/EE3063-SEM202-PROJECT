{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WljAm5f0fKkw"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "3af2becf-e784-4952-a89f-405ba5e56174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "9ebd30c2-e788-4abf-b452-b0f0d40fc824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 47s 139ms/step - loss: 4.5614 - accuracy: 0.0374 - top3_acc: 0.0936 - top_k_categorical_accuracy: 0.1402 - val_loss: 4.6486 - val_accuracy: 0.0478 - val_top3_acc: 0.1151 - val_top_k_categorical_accuracy: 0.1716\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.8753 - accuracy: 0.1060 - top3_acc: 0.2366 - top_k_categorical_accuracy: 0.3234 - val_loss: 4.3667 - val_accuracy: 0.0764 - val_top3_acc: 0.1738 - val_top_k_categorical_accuracy: 0.2437\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.6298 - accuracy: 0.1493 - top3_acc: 0.3014 - top_k_categorical_accuracy: 0.3941 - val_loss: 3.8871 - val_accuracy: 0.1304 - val_top3_acc: 0.2729 - val_top_k_categorical_accuracy: 0.3565\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.4106 - accuracy: 0.1815 - top3_acc: 0.3498 - top_k_categorical_accuracy: 0.4498 - val_loss: 3.7765 - val_accuracy: 0.1399 - val_top3_acc: 0.2915 - val_top_k_categorical_accuracy: 0.3791\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 3.2334 - accuracy: 0.2138 - top3_acc: 0.3922 - top_k_categorical_accuracy: 0.4935 - val_loss: 3.5490 - val_accuracy: 0.1868 - val_top3_acc: 0.3596 - val_top_k_categorical_accuracy: 0.4532\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 3.0274 - accuracy: 0.2470 - top3_acc: 0.4413 - top_k_categorical_accuracy: 0.5468 - val_loss: 3.6227 - val_accuracy: 0.1932 - val_top3_acc: 0.3487 - val_top_k_categorical_accuracy: 0.4395\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.8912 - accuracy: 0.2719 - top3_acc: 0.4802 - top_k_categorical_accuracy: 0.5849 - val_loss: 3.2160 - val_accuracy: 0.2434 - val_top3_acc: 0.4194 - val_top_k_categorical_accuracy: 0.5194\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.7698 - accuracy: 0.2959 - top3_acc: 0.5017 - top_k_categorical_accuracy: 0.6094 - val_loss: 3.1577 - val_accuracy: 0.2441 - val_top3_acc: 0.4311 - val_top_k_categorical_accuracy: 0.5361\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.6577 - accuracy: 0.3249 - top3_acc: 0.5329 - top_k_categorical_accuracy: 0.6352 - val_loss: 3.1863 - val_accuracy: 0.2445 - val_top3_acc: 0.4387 - val_top_k_categorical_accuracy: 0.5386\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.5849 - accuracy: 0.3353 - top3_acc: 0.5527 - top_k_categorical_accuracy: 0.6543 - val_loss: 2.9269 - val_accuracy: 0.2876 - val_top3_acc: 0.4896 - val_top_k_categorical_accuracy: 0.5895\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.4909 - accuracy: 0.3535 - top3_acc: 0.5721 - top_k_categorical_accuracy: 0.6741 - val_loss: 2.8340 - val_accuracy: 0.3049 - val_top3_acc: 0.5148 - val_top_k_categorical_accuracy: 0.6173\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.4130 - accuracy: 0.3676 - top3_acc: 0.5909 - top_k_categorical_accuracy: 0.6910 - val_loss: 2.8335 - val_accuracy: 0.3174 - val_top3_acc: 0.5129 - val_top_k_categorical_accuracy: 0.6151\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.3509 - accuracy: 0.3859 - top3_acc: 0.6066 - top_k_categorical_accuracy: 0.7058 - val_loss: 2.6868 - val_accuracy: 0.3368 - val_top3_acc: 0.5476 - val_top_k_categorical_accuracy: 0.6479\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.2762 - accuracy: 0.3981 - top3_acc: 0.6214 - top_k_categorical_accuracy: 0.7194 - val_loss: 2.7466 - val_accuracy: 0.3393 - val_top3_acc: 0.5412 - val_top_k_categorical_accuracy: 0.6407\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.2132 - accuracy: 0.4148 - top3_acc: 0.6358 - top_k_categorical_accuracy: 0.7315 - val_loss: 2.6865 - val_accuracy: 0.3391 - val_top3_acc: 0.5551 - val_top_k_categorical_accuracy: 0.6540\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.1571 - accuracy: 0.4249 - top3_acc: 0.6498 - top_k_categorical_accuracy: 0.7424 - val_loss: 2.5185 - val_accuracy: 0.3692 - val_top3_acc: 0.5844 - val_top_k_categorical_accuracy: 0.6871\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.0931 - accuracy: 0.4395 - top3_acc: 0.6664 - top_k_categorical_accuracy: 0.7573 - val_loss: 2.5690 - val_accuracy: 0.3737 - val_top3_acc: 0.5751 - val_top_k_categorical_accuracy: 0.6737\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.0670 - accuracy: 0.4471 - top3_acc: 0.6692 - top_k_categorical_accuracy: 0.7625 - val_loss: 2.4194 - val_accuracy: 0.3930 - val_top3_acc: 0.6127 - val_top_k_categorical_accuracy: 0.7084\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.0253 - accuracy: 0.4522 - top3_acc: 0.6787 - top_k_categorical_accuracy: 0.7676 - val_loss: 2.4631 - val_accuracy: 0.3926 - val_top3_acc: 0.5979 - val_top_k_categorical_accuracy: 0.6954\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.9713 - accuracy: 0.4669 - top3_acc: 0.6923 - top_k_categorical_accuracy: 0.7792 - val_loss: 2.4246 - val_accuracy: 0.3971 - val_top3_acc: 0.6102 - val_top_k_categorical_accuracy: 0.7036\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.9323 - accuracy: 0.4743 - top3_acc: 0.6991 - top_k_categorical_accuracy: 0.7854 - val_loss: 2.3122 - val_accuracy: 0.4153 - val_top3_acc: 0.6277 - val_top_k_categorical_accuracy: 0.7243\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.8910 - accuracy: 0.4893 - top3_acc: 0.7095 - top_k_categorical_accuracy: 0.7940 - val_loss: 2.3550 - val_accuracy: 0.4071 - val_top3_acc: 0.6278 - val_top_k_categorical_accuracy: 0.7206\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.8654 - accuracy: 0.4948 - top3_acc: 0.7141 - top_k_categorical_accuracy: 0.7979 - val_loss: 2.3168 - val_accuracy: 0.4197 - val_top3_acc: 0.6344 - val_top_k_categorical_accuracy: 0.7308\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.8319 - accuracy: 0.5023 - top3_acc: 0.7172 - top_k_categorical_accuracy: 0.8035 - val_loss: 2.3314 - val_accuracy: 0.4202 - val_top3_acc: 0.6331 - val_top_k_categorical_accuracy: 0.7296\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.7875 - accuracy: 0.5092 - top3_acc: 0.7317 - top_k_categorical_accuracy: 0.8131 - val_loss: 2.3229 - val_accuracy: 0.4148 - val_top3_acc: 0.6362 - val_top_k_categorical_accuracy: 0.7319\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.7553 - accuracy: 0.5216 - top3_acc: 0.7378 - top_k_categorical_accuracy: 0.8174 - val_loss: 2.2786 - val_accuracy: 0.4290 - val_top3_acc: 0.6469 - val_top_k_categorical_accuracy: 0.7381\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.7223 - accuracy: 0.5293 - top3_acc: 0.7428 - top_k_categorical_accuracy: 0.8226 - val_loss: 2.3390 - val_accuracy: 0.4152 - val_top3_acc: 0.6387 - val_top_k_categorical_accuracy: 0.7335\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.7008 - accuracy: 0.5329 - top3_acc: 0.7474 - top_k_categorical_accuracy: 0.8275 - val_loss: 2.2041 - val_accuracy: 0.4443 - val_top3_acc: 0.6624 - val_top_k_categorical_accuracy: 0.7489\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.6508 - accuracy: 0.5468 - top3_acc: 0.7548 - top_k_categorical_accuracy: 0.8343 - val_loss: 2.2005 - val_accuracy: 0.4499 - val_top3_acc: 0.6628 - val_top_k_categorical_accuracy: 0.7507\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.6295 - accuracy: 0.5448 - top3_acc: 0.7653 - top_k_categorical_accuracy: 0.8406 - val_loss: 2.1817 - val_accuracy: 0.4495 - val_top3_acc: 0.6705 - val_top_k_categorical_accuracy: 0.7565\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.5936 - accuracy: 0.5579 - top3_acc: 0.7723 - top_k_categorical_accuracy: 0.8450 - val_loss: 2.1642 - val_accuracy: 0.4546 - val_top3_acc: 0.6708 - val_top_k_categorical_accuracy: 0.7626\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.5753 - accuracy: 0.5633 - top3_acc: 0.7774 - top_k_categorical_accuracy: 0.8482 - val_loss: 2.1930 - val_accuracy: 0.4480 - val_top3_acc: 0.6666 - val_top_k_categorical_accuracy: 0.7598\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.5613 - accuracy: 0.5632 - top3_acc: 0.7758 - top_k_categorical_accuracy: 0.8482 - val_loss: 2.0542 - val_accuracy: 0.4758 - val_top3_acc: 0.6926 - val_top_k_categorical_accuracy: 0.7741\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 1.5260 - accuracy: 0.5706 - top3_acc: 0.7870 - top_k_categorical_accuracy: 0.8579 - val_loss: 2.1306 - val_accuracy: 0.4592 - val_top3_acc: 0.6776 - val_top_k_categorical_accuracy: 0.7706\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.5119 - accuracy: 0.5781 - top3_acc: 0.7854 - top_k_categorical_accuracy: 0.8583 - val_loss: 2.1530 - val_accuracy: 0.4577 - val_top3_acc: 0.6805 - val_top_k_categorical_accuracy: 0.7660\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.4737 - accuracy: 0.5879 - top3_acc: 0.7948 - top_k_categorical_accuracy: 0.8657 - val_loss: 2.0774 - val_accuracy: 0.4689 - val_top3_acc: 0.6929 - val_top_k_categorical_accuracy: 0.7811\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.4524 - accuracy: 0.5907 - top3_acc: 0.8002 - top_k_categorical_accuracy: 0.8661 - val_loss: 2.0259 - val_accuracy: 0.4844 - val_top3_acc: 0.7018 - val_top_k_categorical_accuracy: 0.7850\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.4291 - accuracy: 0.5948 - top3_acc: 0.8010 - top_k_categorical_accuracy: 0.8703 - val_loss: 1.9836 - val_accuracy: 0.4884 - val_top3_acc: 0.7057 - val_top_k_categorical_accuracy: 0.7951\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.4017 - accuracy: 0.6053 - top3_acc: 0.8073 - top_k_categorical_accuracy: 0.8765 - val_loss: 2.0424 - val_accuracy: 0.4789 - val_top3_acc: 0.6995 - val_top_k_categorical_accuracy: 0.7861\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.3950 - accuracy: 0.6036 - top3_acc: 0.8112 - top_k_categorical_accuracy: 0.8775 - val_loss: 2.0294 - val_accuracy: 0.4856 - val_top3_acc: 0.7067 - val_top_k_categorical_accuracy: 0.7855\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 1.3752 - accuracy: 0.6077 - top3_acc: 0.8114 - top_k_categorical_accuracy: 0.8783 - val_loss: 1.9554 - val_accuracy: 0.4956 - val_top3_acc: 0.7186 - val_top_k_categorical_accuracy: 0.8015\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 42s 136ms/step - loss: 1.3406 - accuracy: 0.6157 - top3_acc: 0.8216 - top_k_categorical_accuracy: 0.8855 - val_loss: 1.9627 - val_accuracy: 0.5034 - val_top3_acc: 0.7197 - val_top_k_categorical_accuracy: 0.7972\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.3391 - accuracy: 0.6195 - top3_acc: 0.8191 - top_k_categorical_accuracy: 0.8863 - val_loss: 1.9535 - val_accuracy: 0.4988 - val_top3_acc: 0.7172 - val_top_k_categorical_accuracy: 0.8007\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 42s 136ms/step - loss: 1.3127 - accuracy: 0.6238 - top3_acc: 0.8258 - top_k_categorical_accuracy: 0.8865 - val_loss: 1.9945 - val_accuracy: 0.4996 - val_top3_acc: 0.7146 - val_top_k_categorical_accuracy: 0.7962\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.2824 - accuracy: 0.6320 - top3_acc: 0.8306 - top_k_categorical_accuracy: 0.8921 - val_loss: 1.9454 - val_accuracy: 0.5101 - val_top3_acc: 0.7205 - val_top_k_categorical_accuracy: 0.7990\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 42s 136ms/step - loss: 1.2731 - accuracy: 0.6374 - top3_acc: 0.8315 - top_k_categorical_accuracy: 0.8953 - val_loss: 1.9402 - val_accuracy: 0.5038 - val_top3_acc: 0.7205 - val_top_k_categorical_accuracy: 0.8015\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 1.2397 - accuracy: 0.6419 - top3_acc: 0.8383 - top_k_categorical_accuracy: 0.8992 - val_loss: 1.9446 - val_accuracy: 0.5013 - val_top3_acc: 0.7225 - val_top_k_categorical_accuracy: 0.8014\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.2452 - accuracy: 0.6420 - top3_acc: 0.8394 - top_k_categorical_accuracy: 0.8973 - val_loss: 1.9509 - val_accuracy: 0.5108 - val_top3_acc: 0.7249 - val_top_k_categorical_accuracy: 0.8060\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 1.2081 - accuracy: 0.6522 - top3_acc: 0.8464 - top_k_categorical_accuracy: 0.9059 - val_loss: 1.8761 - val_accuracy: 0.5274 - val_top3_acc: 0.7330 - val_top_k_categorical_accuracy: 0.8133\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.1803 - accuracy: 0.6611 - top3_acc: 0.8489 - top_k_categorical_accuracy: 0.9079 - val_loss: 1.8885 - val_accuracy: 0.5186 - val_top3_acc: 0.7317 - val_top_k_categorical_accuracy: 0.8117\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('selu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "0ec965df-cd1c-4735-d870-686f05296391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [4.3050665855407715, 3.8150765895843506, 3.5795936584472656, 3.381761312484741, 3.1762590408325195, 3.001593589782715, 2.8736462593078613, 2.755958318710327, 2.6491897106170654, 2.566411256790161, 2.4776484966278076, 2.4125149250030518, 2.342266321182251, 2.275954008102417, 2.2200191020965576, 2.1688947677612305, 2.1163697242736816, 2.0683488845825195, 2.0268545150756836, 1.9853689670562744, 1.9469974040985107, 1.9030333757400513, 1.8698785305023193, 1.8336890935897827, 1.8010094165802002, 1.7631160020828247, 1.731229543685913, 1.704890251159668, 1.671431303024292, 1.640040397644043, 1.614471435546875, 1.5911457538604736, 1.560863733291626, 1.5323569774627686, 1.5073715448379517, 1.4897630214691162, 1.4637115001678467, 1.4383500814437866, 1.4198790788650513, 1.4005659818649292, 1.3799453973770142, 1.3475979566574097, 1.3463716506958008, 1.318154215812683, 1.298464298248291, 1.2767282724380493, 1.2538751363754272, 1.2441409826278687, 1.2193074226379395, 1.2078039646148682], 'accuracy': [0.057500001043081284, 0.11704999953508377, 0.15502500534057617, 0.18542499840259552, 0.22335000336170197, 0.25222501158714294, 0.2771250009536743, 0.299699991941452, 0.32337498664855957, 0.33934998512268066, 0.35762500762939453, 0.3707750141620636, 0.38714998960494995, 0.40095001459121704, 0.4141499996185303, 0.42362499237060547, 0.4337249994277954, 0.44780001044273376, 0.4554249942302704, 0.4643250107765198, 0.47417500615119934, 0.4875749945640564, 0.4926750063896179, 0.5023499727249146, 0.5092750191688538, 0.5163750052452087, 0.5267000198364258, 0.5324500203132629, 0.5408750176429749, 0.5427250266075134, 0.5515750050544739, 0.5599750280380249, 0.5637500286102295, 0.5699999928474426, 0.5796499848365784, 0.5822499990463257, 0.5896750092506409, 0.5934749841690063, 0.5990250110626221, 0.600974977016449, 0.6065999865531921, 0.616225004196167, 0.6177250146865845, 0.6223750114440918, 0.6275249719619751, 0.6344000101089478, 0.6398000121116638, 0.6426500082015991, 0.6474000215530396, 0.650825023651123], 'top3_acc': [0.13695000112056732, 0.25095000863075256, 0.3111500144004822, 0.3564000129699707, 0.4070500135421753, 0.44859999418258667, 0.4825249910354614, 0.5055750012397766, 0.5341500043869019, 0.5557500123977661, 0.5741750001907349, 0.5910500288009644, 0.6078749895095825, 0.622825026512146, 0.637274980545044, 0.645924985408783, 0.6580749750137329, 0.6689249873161316, 0.6804500222206116, 0.6877250075340271, 0.6963750123977661, 0.7069249749183655, 0.7112500071525574, 0.7181500196456909, 0.7279750108718872, 0.734375, 0.7398499846458435, 0.7470999956130981, 0.7530999779701233, 0.7627999782562256, 0.7659500241279602, 0.7725499868392944, 0.7763000130653381, 0.7836750149726868, 0.7871749997138977, 0.7906249761581421, 0.7960500121116638, 0.7996000051498413, 0.8043249845504761, 0.8086749911308289, 0.8118749856948853, 0.8191499710083008, 0.8168249726295471, 0.8244249820709229, 0.8277999758720398, 0.8317750096321106, 0.8360000252723694, 0.8392500281333923, 0.8438249826431274, 0.8434500098228455], 'top_k_categorical_accuracy': [0.19920000433921814, 0.3391749858856201, 0.40607500076293945, 0.4566250145435333, 0.5102499723434448, 0.5541499853134155, 0.5865499973297119, 0.6129500269889832, 0.6375250220298767, 0.6575000286102295, 0.6762499809265137, 0.690750002861023, 0.706974983215332, 0.7197750210762024, 0.7306749820709229, 0.7402499914169312, 0.7495750188827515, 0.7609500288963318, 0.7699999809265137, 0.7756249904632568, 0.7827249765396118, 0.7919750213623047, 0.7969250082969666, 0.8047999739646912, 0.8076750040054321, 0.8169249892234802, 0.8217499852180481, 0.8267750144004822, 0.8321499824523926, 0.8388000130653381, 0.8421750068664551, 0.8450000286102295, 0.8496999740600586, 0.8557999730110168, 0.8594750165939331, 0.8612250089645386, 0.8639249801635742, 0.8694999814033508, 0.8726999759674072, 0.8744000196456909, 0.8777750134468079, 0.8826749920845032, 0.883650004863739, 0.8867999911308289, 0.890874981880188, 0.893625020980835, 0.8968999981880188, 0.8982750177383423, 0.9029750227928162, 0.9046499729156494], 'val_loss': [4.6485700607299805, 4.366734981536865, 3.8870627880096436, 3.7764832973480225, 3.5489981174468994, 3.6227102279663086, 3.216020107269287, 3.157728672027588, 3.1862878799438477, 2.9268546104431152, 2.834049940109253, 2.8335368633270264, 2.6867949962615967, 2.7466375827789307, 2.6864893436431885, 2.518482208251953, 2.5690228939056396, 2.419398784637451, 2.4631311893463135, 2.4246044158935547, 2.3122355937957764, 2.354961633682251, 2.31681227684021, 2.3314430713653564, 2.3228769302368164, 2.2786388397216797, 2.3390352725982666, 2.2041096687316895, 2.200482130050659, 2.1816704273223877, 2.1641952991485596, 2.192958354949951, 2.0541622638702393, 2.1305630207061768, 2.152984142303467, 2.0774013996124268, 2.025906562805176, 1.9835871458053589, 2.0423574447631836, 2.0293896198272705, 1.9554363489151, 1.9626611471176147, 1.9535208940505981, 1.9944779872894287, 1.9454196691513062, 1.9402062892913818, 1.9445853233337402, 1.9509146213531494, 1.8761154413223267, 1.8885185718536377], 'val_accuracy': [0.04780000075697899, 0.07639999687671661, 0.13040000200271606, 0.13989999890327454, 0.1868000030517578, 0.1932000070810318, 0.2433999925851822, 0.24410000443458557, 0.24449999630451202, 0.28760001063346863, 0.30489999055862427, 0.3174000084400177, 0.3368000090122223, 0.3393000066280365, 0.3391000032424927, 0.3691999912261963, 0.37369999289512634, 0.3930000066757202, 0.39259999990463257, 0.3971000015735626, 0.41530001163482666, 0.40709999203681946, 0.4196999967098236, 0.420199990272522, 0.4147999882698059, 0.42899999022483826, 0.41519999504089355, 0.44429999589920044, 0.4499000012874603, 0.4494999945163727, 0.4546000063419342, 0.4480000138282776, 0.4758000075817108, 0.459199994802475, 0.4577000141143799, 0.46889999508857727, 0.4844000041484833, 0.48840001225471497, 0.4788999855518341, 0.48559999465942383, 0.49559998512268066, 0.5034000277519226, 0.49880000948905945, 0.49959999322891235, 0.5101000070571899, 0.5037999749183655, 0.5012999773025513, 0.5108000040054321, 0.527400016784668, 0.5185999870300293], 'val_top3_acc': [0.11509999632835388, 0.1738000065088272, 0.2728999853134155, 0.2915000021457672, 0.3596000075340271, 0.34869998693466187, 0.41940000653266907, 0.4311000108718872, 0.43869999051094055, 0.4896000027656555, 0.5148000121116638, 0.5128999948501587, 0.5475999712944031, 0.5411999821662903, 0.5551000237464905, 0.5843999981880188, 0.5751000046730042, 0.6126999855041504, 0.5978999733924866, 0.6101999878883362, 0.6276999711990356, 0.6277999877929688, 0.6344000101089478, 0.6330999732017517, 0.6362000107765198, 0.6468999981880188, 0.638700008392334, 0.6624000072479248, 0.6628000140190125, 0.6704999804496765, 0.670799970626831, 0.6665999889373779, 0.6926000118255615, 0.6776000261306763, 0.6804999709129333, 0.6929000020027161, 0.7017999887466431, 0.7056999802589417, 0.6995000243186951, 0.7067000269889832, 0.7185999751091003, 0.7196999788284302, 0.717199981212616, 0.7146000266075134, 0.7204999923706055, 0.7204999923706055, 0.7225000262260437, 0.7249000072479248, 0.7329999804496765, 0.7317000031471252], 'val_top_k_categorical_accuracy': [0.17159999907016754, 0.24369999766349792, 0.3564999997615814, 0.3790999948978424, 0.45320001244544983, 0.43950000405311584, 0.5194000005722046, 0.5360999703407288, 0.5386000275611877, 0.5895000100135803, 0.6172999739646912, 0.6151000261306763, 0.6478999853134155, 0.6406999826431274, 0.6539999842643738, 0.6870999932289124, 0.6736999750137329, 0.7084000110626221, 0.6953999996185303, 0.7035999894142151, 0.7243000268936157, 0.7206000089645386, 0.7307999730110168, 0.7296000123023987, 0.7318999767303467, 0.738099992275238, 0.7335000038146973, 0.7488999962806702, 0.7506999969482422, 0.7565000057220459, 0.7626000046730042, 0.7598000168800354, 0.7741000056266785, 0.7706000208854675, 0.765999972820282, 0.7810999751091003, 0.7850000262260437, 0.7950999736785889, 0.7860999703407288, 0.7854999899864197, 0.8015000224113464, 0.7972000241279602, 0.8007000088691711, 0.7961999773979187, 0.7990000247955322, 0.8015000224113464, 0.8014000058174133, 0.8059999942779541, 0.8133000135421753, 0.8116999864578247]}\n",
      "313/313 [==============================] - 5s 12ms/step - loss: 1.9013 - accuracy: 0.5177 - top3_acc: 0.7211 - top_k_categorical_accuracy: 0.8044\n",
      "[1.9012800455093384, 0.5177000164985657, 0.7210999727249146, 0.8044000267982483]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_simplenet_selu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
