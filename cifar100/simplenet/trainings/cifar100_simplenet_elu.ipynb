{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WljAm5f0fKkw"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "3af2becf-e784-4952-a89f-405ba5e56174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "c9f1eb97-1024-42a2-fee1-cf66f5d226c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 45s 131ms/step - loss: 4.4530 - accuracy: 0.0354 - top3_acc: 0.0899 - top_k_categorical_accuracy: 0.1345 - val_loss: 4.4981 - val_accuracy: 0.0292 - val_top3_acc: 0.0814 - val_top_k_categorical_accuracy: 0.1296\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 3.8916 - accuracy: 0.0977 - top3_acc: 0.2173 - top_k_categorical_accuracy: 0.3020 - val_loss: 4.2395 - val_accuracy: 0.0733 - val_top3_acc: 0.1638 - val_top_k_categorical_accuracy: 0.2287\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 3.6448 - accuracy: 0.1369 - top3_acc: 0.2819 - top_k_categorical_accuracy: 0.3771 - val_loss: 4.1845 - val_accuracy: 0.0841 - val_top3_acc: 0.1823 - val_top_k_categorical_accuracy: 0.2507\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 3.4481 - accuracy: 0.1732 - top3_acc: 0.3384 - top_k_categorical_accuracy: 0.4390 - val_loss: 4.0443 - val_accuracy: 0.0988 - val_top3_acc: 0.2056 - val_top_k_categorical_accuracy: 0.2850\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.2497 - accuracy: 0.2020 - top3_acc: 0.3844 - top_k_categorical_accuracy: 0.4894 - val_loss: 3.8604 - val_accuracy: 0.1194 - val_top3_acc: 0.2566 - val_top_k_categorical_accuracy: 0.3409\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 3.0511 - accuracy: 0.2389 - top3_acc: 0.4340 - top_k_categorical_accuracy: 0.5412 - val_loss: 3.5876 - val_accuracy: 0.1613 - val_top3_acc: 0.3156 - val_top_k_categorical_accuracy: 0.4108\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.8825 - accuracy: 0.2707 - top3_acc: 0.4788 - top_k_categorical_accuracy: 0.5805 - val_loss: 3.6832 - val_accuracy: 0.1579 - val_top3_acc: 0.3166 - val_top_k_categorical_accuracy: 0.4110\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.7579 - accuracy: 0.2952 - top3_acc: 0.5061 - top_k_categorical_accuracy: 0.6167 - val_loss: 3.3224 - val_accuracy: 0.2141 - val_top3_acc: 0.3888 - val_top_k_categorical_accuracy: 0.4868\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.6423 - accuracy: 0.3193 - top3_acc: 0.5362 - top_k_categorical_accuracy: 0.6411 - val_loss: 3.2231 - val_accuracy: 0.2277 - val_top3_acc: 0.4133 - val_top_k_categorical_accuracy: 0.5161\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.5449 - accuracy: 0.3425 - top3_acc: 0.5574 - top_k_categorical_accuracy: 0.6614 - val_loss: 2.9529 - val_accuracy: 0.2672 - val_top3_acc: 0.4692 - val_top_k_categorical_accuracy: 0.5712\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.4377 - accuracy: 0.3637 - top3_acc: 0.5831 - top_k_categorical_accuracy: 0.6857 - val_loss: 2.9324 - val_accuracy: 0.2782 - val_top3_acc: 0.4701 - val_top_k_categorical_accuracy: 0.5739\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.3724 - accuracy: 0.3821 - top3_acc: 0.5972 - top_k_categorical_accuracy: 0.6988 - val_loss: 2.8696 - val_accuracy: 0.2867 - val_top3_acc: 0.4919 - val_top_k_categorical_accuracy: 0.5969\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.2982 - accuracy: 0.3922 - top3_acc: 0.6184 - top_k_categorical_accuracy: 0.7151 - val_loss: 2.7356 - val_accuracy: 0.3021 - val_top3_acc: 0.5162 - val_top_k_categorical_accuracy: 0.6239\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.2164 - accuracy: 0.4097 - top3_acc: 0.6329 - top_k_categorical_accuracy: 0.7290 - val_loss: 2.8387 - val_accuracy: 0.2927 - val_top3_acc: 0.4981 - val_top_k_categorical_accuracy: 0.6000\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 2.1585 - accuracy: 0.4254 - top3_acc: 0.6479 - top_k_categorical_accuracy: 0.7422 - val_loss: 2.6637 - val_accuracy: 0.3242 - val_top3_acc: 0.5386 - val_top_k_categorical_accuracy: 0.6433\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 2.0913 - accuracy: 0.4392 - top3_acc: 0.6656 - top_k_categorical_accuracy: 0.7556 - val_loss: 2.6104 - val_accuracy: 0.3311 - val_top3_acc: 0.5457 - val_top_k_categorical_accuracy: 0.6552\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 2.0514 - accuracy: 0.4518 - top3_acc: 0.6723 - top_k_categorical_accuracy: 0.7643 - val_loss: 2.7238 - val_accuracy: 0.3172 - val_top3_acc: 0.5271 - val_top_k_categorical_accuracy: 0.6369\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.9838 - accuracy: 0.4644 - top3_acc: 0.6852 - top_k_categorical_accuracy: 0.7763 - val_loss: 2.4641 - val_accuracy: 0.3643 - val_top3_acc: 0.5829 - val_top_k_categorical_accuracy: 0.6857\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.9706 - accuracy: 0.4675 - top3_acc: 0.6906 - top_k_categorical_accuracy: 0.7804 - val_loss: 2.5793 - val_accuracy: 0.3388 - val_top3_acc: 0.5617 - val_top_k_categorical_accuracy: 0.6678\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.9252 - accuracy: 0.4799 - top3_acc: 0.7019 - top_k_categorical_accuracy: 0.7869 - val_loss: 2.4754 - val_accuracy: 0.3597 - val_top3_acc: 0.5788 - val_top_k_categorical_accuracy: 0.6867\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.8748 - accuracy: 0.4889 - top3_acc: 0.7091 - top_k_categorical_accuracy: 0.7982 - val_loss: 2.5033 - val_accuracy: 0.3577 - val_top3_acc: 0.5787 - val_top_k_categorical_accuracy: 0.6831\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.8349 - accuracy: 0.4972 - top3_acc: 0.7214 - top_k_categorical_accuracy: 0.8052 - val_loss: 2.4411 - val_accuracy: 0.3730 - val_top3_acc: 0.5894 - val_top_k_categorical_accuracy: 0.6972\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 42s 136ms/step - loss: 1.7934 - accuracy: 0.5096 - top3_acc: 0.7308 - top_k_categorical_accuracy: 0.8122 - val_loss: 2.3569 - val_accuracy: 0.3828 - val_top3_acc: 0.6135 - val_top_k_categorical_accuracy: 0.7181\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.7547 - accuracy: 0.5156 - top3_acc: 0.7345 - top_k_categorical_accuracy: 0.8207 - val_loss: 2.3925 - val_accuracy: 0.3706 - val_top3_acc: 0.6006 - val_top_k_categorical_accuracy: 0.7067\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.7253 - accuracy: 0.5236 - top3_acc: 0.7420 - top_k_categorical_accuracy: 0.8229 - val_loss: 2.2522 - val_accuracy: 0.4067 - val_top3_acc: 0.6360 - val_top_k_categorical_accuracy: 0.7383\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.7056 - accuracy: 0.5310 - top3_acc: 0.7485 - top_k_categorical_accuracy: 0.8256 - val_loss: 2.3582 - val_accuracy: 0.3844 - val_top3_acc: 0.6163 - val_top_k_categorical_accuracy: 0.7234\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.6594 - accuracy: 0.5391 - top3_acc: 0.7558 - top_k_categorical_accuracy: 0.8362 - val_loss: 2.2717 - val_accuracy: 0.4056 - val_top3_acc: 0.6326 - val_top_k_categorical_accuracy: 0.7329\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.6264 - accuracy: 0.5464 - top3_acc: 0.7637 - top_k_categorical_accuracy: 0.8408 - val_loss: 2.3422 - val_accuracy: 0.3904 - val_top3_acc: 0.6193 - val_top_k_categorical_accuracy: 0.7194\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.5964 - accuracy: 0.5581 - top3_acc: 0.7664 - top_k_categorical_accuracy: 0.8441 - val_loss: 2.1878 - val_accuracy: 0.4251 - val_top3_acc: 0.6494 - val_top_k_categorical_accuracy: 0.7459\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.5797 - accuracy: 0.5564 - top3_acc: 0.7709 - top_k_categorical_accuracy: 0.8485 - val_loss: 2.1262 - val_accuracy: 0.4324 - val_top3_acc: 0.6622 - val_top_k_categorical_accuracy: 0.7600\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.5428 - accuracy: 0.5711 - top3_acc: 0.7808 - top_k_categorical_accuracy: 0.8538 - val_loss: 2.2777 - val_accuracy: 0.4027 - val_top3_acc: 0.6306 - val_top_k_categorical_accuracy: 0.7334\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.5280 - accuracy: 0.5713 - top3_acc: 0.7879 - top_k_categorical_accuracy: 0.8591 - val_loss: 2.2427 - val_accuracy: 0.4048 - val_top3_acc: 0.6442 - val_top_k_categorical_accuracy: 0.7411\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.5086 - accuracy: 0.5771 - top3_acc: 0.7863 - top_k_categorical_accuracy: 0.8594 - val_loss: 2.2659 - val_accuracy: 0.4090 - val_top3_acc: 0.6321 - val_top_k_categorical_accuracy: 0.7379\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.4728 - accuracy: 0.5907 - top3_acc: 0.7959 - top_k_categorical_accuracy: 0.8644 - val_loss: 2.1735 - val_accuracy: 0.4249 - val_top3_acc: 0.6539 - val_top_k_categorical_accuracy: 0.7544\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.4630 - accuracy: 0.5878 - top3_acc: 0.7958 - top_k_categorical_accuracy: 0.8657 - val_loss: 2.2320 - val_accuracy: 0.4184 - val_top3_acc: 0.6418 - val_top_k_categorical_accuracy: 0.7403\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.4388 - accuracy: 0.5923 - top3_acc: 0.8013 - top_k_categorical_accuracy: 0.8721 - val_loss: 2.0915 - val_accuracy: 0.4514 - val_top3_acc: 0.6768 - val_top_k_categorical_accuracy: 0.7696\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.4121 - accuracy: 0.5999 - top3_acc: 0.8058 - top_k_categorical_accuracy: 0.8765 - val_loss: 2.2515 - val_accuracy: 0.4150 - val_top3_acc: 0.6487 - val_top_k_categorical_accuracy: 0.7441\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.3801 - accuracy: 0.6113 - top3_acc: 0.8157 - top_k_categorical_accuracy: 0.8809 - val_loss: 2.0824 - val_accuracy: 0.4517 - val_top3_acc: 0.6727 - val_top_k_categorical_accuracy: 0.7646\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.3641 - accuracy: 0.6115 - top3_acc: 0.8145 - top_k_categorical_accuracy: 0.8799 - val_loss: 2.0309 - val_accuracy: 0.4596 - val_top3_acc: 0.6846 - val_top_k_categorical_accuracy: 0.7792\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.3477 - accuracy: 0.6160 - top3_acc: 0.8184 - top_k_categorical_accuracy: 0.8865 - val_loss: 1.9817 - val_accuracy: 0.4712 - val_top3_acc: 0.6951 - val_top_k_categorical_accuracy: 0.7885\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.3213 - accuracy: 0.6246 - top3_acc: 0.8247 - top_k_categorical_accuracy: 0.8887 - val_loss: 2.0088 - val_accuracy: 0.4697 - val_top3_acc: 0.6927 - val_top_k_categorical_accuracy: 0.7807\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.3194 - accuracy: 0.6215 - top3_acc: 0.8227 - top_k_categorical_accuracy: 0.8885 - val_loss: 2.0951 - val_accuracy: 0.4468 - val_top3_acc: 0.6760 - val_top_k_categorical_accuracy: 0.7697\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.2874 - accuracy: 0.6314 - top3_acc: 0.8301 - top_k_categorical_accuracy: 0.8934 - val_loss: 1.9025 - val_accuracy: 0.4923 - val_top3_acc: 0.7167 - val_top_k_categorical_accuracy: 0.8017\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.2670 - accuracy: 0.6343 - top3_acc: 0.8377 - top_k_categorical_accuracy: 0.8971 - val_loss: 1.9573 - val_accuracy: 0.4813 - val_top3_acc: 0.6992 - val_top_k_categorical_accuracy: 0.7808\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.2342 - accuracy: 0.6469 - top3_acc: 0.8429 - top_k_categorical_accuracy: 0.9023 - val_loss: 1.8919 - val_accuracy: 0.4940 - val_top3_acc: 0.7174 - val_top_k_categorical_accuracy: 0.8040\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.2395 - accuracy: 0.6470 - top3_acc: 0.8392 - top_k_categorical_accuracy: 0.9006 - val_loss: 1.9784 - val_accuracy: 0.4747 - val_top3_acc: 0.7044 - val_top_k_categorical_accuracy: 0.7920\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.2239 - accuracy: 0.6457 - top3_acc: 0.8440 - top_k_categorical_accuracy: 0.9029 - val_loss: 1.9403 - val_accuracy: 0.4867 - val_top3_acc: 0.7120 - val_top_k_categorical_accuracy: 0.7973\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.2061 - accuracy: 0.6508 - top3_acc: 0.8444 - top_k_categorical_accuracy: 0.9047 - val_loss: 1.9694 - val_accuracy: 0.4798 - val_top3_acc: 0.7060 - val_top_k_categorical_accuracy: 0.7911\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.1711 - accuracy: 0.6597 - top3_acc: 0.8529 - top_k_categorical_accuracy: 0.9090 - val_loss: 1.9493 - val_accuracy: 0.4839 - val_top3_acc: 0.7099 - val_top_k_categorical_accuracy: 0.7952\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 1.1689 - accuracy: 0.6597 - top3_acc: 0.8524 - top_k_categorical_accuracy: 0.9106 - val_loss: 1.8436 - val_accuracy: 0.5091 - val_top3_acc: 0.7252 - val_top_k_categorical_accuracy: 0.8070\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('elu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "12e95ac8-7497-44e5-ea95-a05e6f9a1e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [4.247246742248535, 3.8307204246520996, 3.595013380050659, 3.401118040084839, 3.203895330429077, 3.009812593460083, 2.8619418144226074, 2.7377352714538574, 2.6253154277801514, 2.5291764736175537, 2.430870294570923, 2.3583436012268066, 2.29134464263916, 2.2240896224975586, 2.148958921432495, 2.096599817276001, 2.0519626140594482, 1.9994817972183228, 1.955482840538025, 1.9119937419891357, 1.8710294961929321, 1.8359804153442383, 1.797605037689209, 1.7571462392807007, 1.7267310619354248, 1.699851393699646, 1.6608041524887085, 1.637890100479126, 1.609549880027771, 1.5824394226074219, 1.5583282709121704, 1.5328036546707153, 1.505378246307373, 1.4794232845306396, 1.4675159454345703, 1.4412378072738647, 1.4161376953125, 1.38896644115448, 1.3714888095855713, 1.353454828262329, 1.333494782447815, 1.3121432065963745, 1.2950327396392822, 1.2783281803131104, 1.2616990804672241, 1.2418034076690674, 1.2236361503601074, 1.2125892639160156, 1.1857874393463135, 1.175622820854187], 'accuracy': [0.05442500114440918, 0.10427500307559967, 0.1441749930381775, 0.17932499945163727, 0.21287499368190765, 0.24944999814033508, 0.27790001034736633, 0.3005000054836273, 0.3250750005245209, 0.34747499227523804, 0.3649500012397766, 0.383774995803833, 0.3950499892234802, 0.40927499532699585, 0.42829999327659607, 0.44062501192092896, 0.4499500095844269, 0.46050000190734863, 0.4712750017642975, 0.4801749885082245, 0.48969998955726624, 0.49904999136924744, 0.5069500207901001, 0.5156499743461609, 0.5223749876022339, 0.5298500061035156, 0.5376499891281128, 0.54544997215271, 0.5540000200271606, 0.5572999715805054, 0.5647000074386597, 0.5703750252723694, 0.5768499970436096, 0.5856000185012817, 0.5856999754905701, 0.5914999842643738, 0.6000249981880188, 0.6058250069618225, 0.6083250045776367, 0.6163250207901001, 0.618149995803833, 0.6248000264167786, 0.6307250261306763, 0.6315500140190125, 0.6370499730110168, 0.6435499787330627, 0.6450250148773193, 0.6488749980926514, 0.6556749939918518, 0.6589999794960022], 'top3_acc': [0.1366250067949295, 0.23225000500679016, 0.29512500762939453, 0.35190001130104065, 0.3977000117301941, 0.4450249969959259, 0.48377498984336853, 0.5118749737739563, 0.5409250259399414, 0.5611749887466431, 0.5844749808311462, 0.6007500290870667, 0.6182000041007996, 0.6323500275611877, 0.6507499814033508, 0.6645500063896179, 0.6711999773979187, 0.683899998664856, 0.6930249929428101, 0.7050750255584717, 0.7092000246047974, 0.7184749841690063, 0.7291499972343445, 0.7331500053405762, 0.7407749891281128, 0.7495499849319458, 0.7558249831199646, 0.7606499791145325, 0.7653250098228455, 0.7704499959945679, 0.7752000093460083, 0.7842749953269958, 0.7870000004768372, 0.7951750159263611, 0.7956249713897705, 0.8009499907493591, 0.8042250275611877, 0.8131250143051147, 0.8138750195503235, 0.8165500164031982, 0.8220250010490417, 0.8246750235557556, 0.8289250135421753, 0.8333749771118164, 0.8358250260353088, 0.8392000198364258, 0.8434000015258789, 0.8435999751091003, 0.8511750102043152, 0.8512499928474426], 'top_k_categorical_accuracy': [0.19737499952316284, 0.31847500801086426, 0.3920249938964844, 0.4539499878883362, 0.5029000043869019, 0.550000011920929, 0.5874750018119812, 0.6187750101089478, 0.6450999975204468, 0.6645500063896179, 0.6879749894142151, 0.7016749978065491, 0.7157999873161316, 0.7279750108718872, 0.7441499829292297, 0.7546250224113464, 0.7633500099182129, 0.775600016117096, 0.7826250195503235, 0.7894250154495239, 0.7965250015258789, 0.8036749958992004, 0.8119999766349792, 0.8193249702453613, 0.822950005531311, 0.8276000022888184, 0.8342999815940857, 0.8399500250816345, 0.8424999713897705, 0.8465250134468079, 0.8519250154495239, 0.8571000099182129, 0.8605499863624573, 0.8634750247001648, 0.8668749928474426, 0.8709750175476074, 0.8745250105857849, 0.8798750042915344, 0.8797749876976013, 0.8839750289916992, 0.8877999782562256, 0.8894000053405762, 0.8916500210762024, 0.8944000005722046, 0.8976749777793884, 0.8995000123977661, 0.9028499722480774, 0.902999997138977, 0.9081500172615051, 0.9093999862670898], 'val_loss': [4.4980998039245605, 4.239526748657227, 4.184535980224609, 4.044283390045166, 3.8604469299316406, 3.587573528289795, 3.683157444000244, 3.3223862648010254, 3.2230517864227295, 2.9528684616088867, 2.9324491024017334, 2.86956524848938, 2.735564708709717, 2.838716983795166, 2.663694381713867, 2.6104278564453125, 2.7238411903381348, 2.4641082286834717, 2.5792603492736816, 2.4754061698913574, 2.503310203552246, 2.441091299057007, 2.3568735122680664, 2.3925468921661377, 2.252211809158325, 2.3582305908203125, 2.271717071533203, 2.3422465324401855, 2.187826633453369, 2.126218557357788, 2.2777280807495117, 2.2427427768707275, 2.265923261642456, 2.173520565032959, 2.231959104537964, 2.0914690494537354, 2.251511335372925, 2.082412004470825, 2.030925989151001, 1.9816615581512451, 2.0087995529174805, 2.0951082706451416, 1.9024927616119385, 1.9573203325271606, 1.8918968439102173, 1.9784064292907715, 1.9403128623962402, 1.9693719148635864, 1.9493249654769897, 1.8436092138290405], 'val_accuracy': [0.029200000688433647, 0.07329999655485153, 0.08410000056028366, 0.09880000352859497, 0.11940000206232071, 0.16130000352859497, 0.15790000557899475, 0.21410000324249268, 0.22769999504089355, 0.2671999931335449, 0.2782000005245209, 0.2867000102996826, 0.3021000027656555, 0.29269999265670776, 0.32420000433921814, 0.3310999870300293, 0.3172000050544739, 0.364300012588501, 0.33880001306533813, 0.3596999943256378, 0.357699990272522, 0.37299999594688416, 0.38280001282691956, 0.37059998512268066, 0.4066999852657318, 0.38440001010894775, 0.40560001134872437, 0.3903999924659729, 0.4250999987125397, 0.4323999881744385, 0.4027000069618225, 0.4047999978065491, 0.4090000092983246, 0.42489999532699585, 0.41839998960494995, 0.4514000117778778, 0.41499999165534973, 0.45170000195503235, 0.4596000015735626, 0.47119998931884766, 0.46970000863075256, 0.44679999351501465, 0.49230000376701355, 0.4812999963760376, 0.49399998784065247, 0.474700003862381, 0.48669999837875366, 0.4797999858856201, 0.4839000105857849, 0.5091000199317932], 'val_top3_acc': [0.08139999955892563, 0.16380000114440918, 0.18230000138282776, 0.20559999346733093, 0.2565999925136566, 0.3156000077724457, 0.3165999948978424, 0.3887999951839447, 0.4133000075817108, 0.4691999852657318, 0.4700999855995178, 0.4918999969959259, 0.5162000060081482, 0.49810001254081726, 0.5386000275611877, 0.5457000136375427, 0.5271000266075134, 0.5828999876976013, 0.5616999864578247, 0.5788000226020813, 0.5787000060081482, 0.5893999934196472, 0.6134999990463257, 0.600600004196167, 0.6359999775886536, 0.6162999868392944, 0.6326000094413757, 0.6193000078201294, 0.649399995803833, 0.6621999740600586, 0.6305999755859375, 0.6442000269889832, 0.632099986076355, 0.6539000272750854, 0.6417999863624573, 0.676800012588501, 0.6486999988555908, 0.6726999878883362, 0.6845999956130981, 0.6951000094413757, 0.6927000284194946, 0.6759999990463257, 0.71670001745224, 0.6991999745368958, 0.7174000144004822, 0.7044000029563904, 0.7120000123977661, 0.7059999704360962, 0.7099000215530396, 0.7251999974250793], 'val_top_k_categorical_accuracy': [0.12960000336170197, 0.22869999706745148, 0.2506999969482422, 0.2849999964237213, 0.3409000039100647, 0.4108000099658966, 0.41100001335144043, 0.4867999851703644, 0.5160999894142151, 0.5712000131607056, 0.5738999843597412, 0.5968999862670898, 0.6238999962806702, 0.6000000238418579, 0.6432999968528748, 0.6552000045776367, 0.636900007724762, 0.685699999332428, 0.6678000092506409, 0.6866999864578247, 0.6830999851226807, 0.6972000002861023, 0.7181000113487244, 0.7067000269889832, 0.7383000254631042, 0.7233999967575073, 0.7329000234603882, 0.7193999886512756, 0.7458999752998352, 0.7599999904632568, 0.7333999872207642, 0.741100013256073, 0.7379000186920166, 0.7544000148773193, 0.7402999997138977, 0.769599974155426, 0.7440999746322632, 0.7645999789237976, 0.77920001745224, 0.7885000109672546, 0.7807000279426575, 0.7696999907493591, 0.8016999959945679, 0.7807999849319458, 0.8040000200271606, 0.7919999957084656, 0.7972999811172485, 0.791100025177002, 0.795199990272522, 0.8069999814033508]}\n",
      "313/313 [==============================] - 5s 12ms/step - loss: 1.8354 - accuracy: 0.5125 - top3_acc: 0.7281 - top_k_categorical_accuracy: 0.8055\n",
      "[1.8353785276412964, 0.512499988079071, 0.7281000018119812, 0.8054999709129333]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_simplenet_elu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
