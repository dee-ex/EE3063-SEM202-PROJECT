{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.initializers import RandomNormal, GlorotNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WljAm5f0fKkw"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "3af2becf-e784-4952-a89f-405ba5e56174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "5f96fe2c-72e9-4ac2-f798-ddddd3659337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 71s 211ms/step - loss: 4.5573 - accuracy: 0.0164 - top3_acc: 0.0486 - top_k_categorical_accuracy: 0.0763 - val_loss: 4.6048 - val_accuracy: 0.0097 - val_top3_acc: 0.0272 - val_top_k_categorical_accuracy: 0.0495\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 4.4661 - accuracy: 0.0281 - top3_acc: 0.0743 - top_k_categorical_accuracy: 0.1104 - val_loss: 4.5917 - val_accuracy: 0.0177 - val_top3_acc: 0.0455 - val_top_k_categorical_accuracy: 0.0680\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 4.4051 - accuracy: 0.0391 - top3_acc: 0.0906 - top_k_categorical_accuracy: 0.1287 - val_loss: 4.6053 - val_accuracy: 0.0114 - val_top3_acc: 0.0339 - val_top_k_categorical_accuracy: 0.0528\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 4.3150 - accuracy: 0.0481 - top3_acc: 0.1104 - top_k_categorical_accuracy: 0.1586 - val_loss: 4.8186 - val_accuracy: 0.0091 - val_top3_acc: 0.0309 - val_top_k_categorical_accuracy: 0.0512\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 4.1542 - accuracy: 0.0611 - top3_acc: 0.1432 - top_k_categorical_accuracy: 0.2091 - val_loss: 5.7623 - val_accuracy: 0.0125 - val_top3_acc: 0.0294 - val_top_k_categorical_accuracy: 0.0524\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 3.9473 - accuracy: 0.0844 - top3_acc: 0.1934 - top_k_categorical_accuracy: 0.2769 - val_loss: 6.6116 - val_accuracy: 0.0149 - val_top3_acc: 0.0330 - val_top_k_categorical_accuracy: 0.0545\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 3.7527 - accuracy: 0.1147 - top3_acc: 0.2457 - top_k_categorical_accuracy: 0.3360 - val_loss: 6.1199 - val_accuracy: 0.0208 - val_top3_acc: 0.0388 - val_top_k_categorical_accuracy: 0.0647\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 3.5742 - accuracy: 0.1416 - top3_acc: 0.2936 - top_k_categorical_accuracy: 0.3887 - val_loss: 5.6660 - val_accuracy: 0.0212 - val_top3_acc: 0.0551 - val_top_k_categorical_accuracy: 0.0903\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 3.4290 - accuracy: 0.1676 - top3_acc: 0.3294 - top_k_categorical_accuracy: 0.4342 - val_loss: 6.0796 - val_accuracy: 0.0167 - val_top3_acc: 0.0543 - val_top_k_categorical_accuracy: 0.0869\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 69s 220ms/step - loss: 3.2896 - accuracy: 0.1935 - top3_acc: 0.3698 - top_k_categorical_accuracy: 0.4752 - val_loss: 5.2388 - val_accuracy: 0.0362 - val_top3_acc: 0.0941 - val_top_k_categorical_accuracy: 0.1416\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 3.1541 - accuracy: 0.2172 - top3_acc: 0.4049 - top_k_categorical_accuracy: 0.5094 - val_loss: 6.1843 - val_accuracy: 0.0273 - val_top3_acc: 0.0741 - val_top_k_categorical_accuracy: 0.1196\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 3.0186 - accuracy: 0.2419 - top3_acc: 0.4392 - top_k_categorical_accuracy: 0.5488 - val_loss: 5.6942 - val_accuracy: 0.0275 - val_top3_acc: 0.0798 - val_top_k_categorical_accuracy: 0.1235\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 2.8916 - accuracy: 0.2646 - top3_acc: 0.4690 - top_k_categorical_accuracy: 0.5763 - val_loss: 4.6987 - val_accuracy: 0.0608 - val_top3_acc: 0.1487 - val_top_k_categorical_accuracy: 0.2159\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 2.7462 - accuracy: 0.2874 - top3_acc: 0.5042 - top_k_categorical_accuracy: 0.6127 - val_loss: 5.4274 - val_accuracy: 0.0449 - val_top3_acc: 0.1283 - val_top_k_categorical_accuracy: 0.1835\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 2.6347 - accuracy: 0.3119 - top3_acc: 0.5278 - top_k_categorical_accuracy: 0.6372 - val_loss: 4.6840 - val_accuracy: 0.0743 - val_top3_acc: 0.1755 - val_top_k_categorical_accuracy: 0.2449\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 2.5282 - accuracy: 0.3337 - top3_acc: 0.5594 - top_k_categorical_accuracy: 0.6668 - val_loss: 3.8321 - val_accuracy: 0.1320 - val_top3_acc: 0.2745 - val_top_k_categorical_accuracy: 0.3605\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 2.4495 - accuracy: 0.3543 - top3_acc: 0.5780 - top_k_categorical_accuracy: 0.6830 - val_loss: 4.3315 - val_accuracy: 0.0981 - val_top3_acc: 0.2264 - val_top_k_categorical_accuracy: 0.3049\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 2.3634 - accuracy: 0.3649 - top3_acc: 0.5928 - top_k_categorical_accuracy: 0.7013 - val_loss: 3.7781 - val_accuracy: 0.1519 - val_top3_acc: 0.3219 - val_top_k_categorical_accuracy: 0.4068\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 2.2903 - accuracy: 0.3839 - top3_acc: 0.6146 - top_k_categorical_accuracy: 0.7165 - val_loss: 4.0183 - val_accuracy: 0.1251 - val_top3_acc: 0.2781 - val_top_k_categorical_accuracy: 0.3659\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 2.2352 - accuracy: 0.3977 - top3_acc: 0.6259 - top_k_categorical_accuracy: 0.7273 - val_loss: 3.5144 - val_accuracy: 0.1823 - val_top3_acc: 0.3554 - val_top_k_categorical_accuracy: 0.4486\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 65s 206ms/step - loss: 2.1520 - accuracy: 0.4198 - top3_acc: 0.6451 - top_k_categorical_accuracy: 0.7452 - val_loss: 3.1285 - val_accuracy: 0.2471 - val_top3_acc: 0.4316 - val_top_k_categorical_accuracy: 0.5254\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 2.0916 - accuracy: 0.4309 - top3_acc: 0.6617 - top_k_categorical_accuracy: 0.7584 - val_loss: 3.1561 - val_accuracy: 0.2460 - val_top3_acc: 0.4369 - val_top_k_categorical_accuracy: 0.5353\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 2.0602 - accuracy: 0.4403 - top3_acc: 0.6721 - top_k_categorical_accuracy: 0.7644 - val_loss: 4.0199 - val_accuracy: 0.1525 - val_top3_acc: 0.3109 - val_top_k_categorical_accuracy: 0.4062\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.9860 - accuracy: 0.4535 - top3_acc: 0.6820 - top_k_categorical_accuracy: 0.7761 - val_loss: 3.0631 - val_accuracy: 0.2607 - val_top3_acc: 0.4538 - val_top_k_categorical_accuracy: 0.5489\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 64s 206ms/step - loss: 1.9445 - accuracy: 0.4656 - top3_acc: 0.6925 - top_k_categorical_accuracy: 0.7844 - val_loss: 3.0959 - val_accuracy: 0.2510 - val_top3_acc: 0.4431 - val_top_k_categorical_accuracy: 0.5405\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.8983 - accuracy: 0.4766 - top3_acc: 0.7054 - top_k_categorical_accuracy: 0.7937 - val_loss: 2.8790 - val_accuracy: 0.2910 - val_top3_acc: 0.4891 - val_top_k_categorical_accuracy: 0.5924\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.8446 - accuracy: 0.4890 - top3_acc: 0.7128 - top_k_categorical_accuracy: 0.8028 - val_loss: 3.1275 - val_accuracy: 0.2559 - val_top3_acc: 0.4445 - val_top_k_categorical_accuracy: 0.5410\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.8142 - accuracy: 0.4941 - top3_acc: 0.7214 - top_k_categorical_accuracy: 0.8091 - val_loss: 2.8994 - val_accuracy: 0.2977 - val_top3_acc: 0.4841 - val_top_k_categorical_accuracy: 0.5772\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.7715 - accuracy: 0.5040 - top3_acc: 0.7293 - top_k_categorical_accuracy: 0.8174 - val_loss: 2.6363 - val_accuracy: 0.3382 - val_top3_acc: 0.5418 - val_top_k_categorical_accuracy: 0.6372\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.7430 - accuracy: 0.5143 - top3_acc: 0.7385 - top_k_categorical_accuracy: 0.8236 - val_loss: 3.2083 - val_accuracy: 0.2547 - val_top3_acc: 0.4366 - val_top_k_categorical_accuracy: 0.5230\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.6909 - accuracy: 0.5225 - top3_acc: 0.7488 - top_k_categorical_accuracy: 0.8302 - val_loss: 2.5432 - val_accuracy: 0.3613 - val_top3_acc: 0.5620 - val_top_k_categorical_accuracy: 0.6569\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 64s 203ms/step - loss: 1.6652 - accuracy: 0.5315 - top3_acc: 0.7550 - top_k_categorical_accuracy: 0.8357 - val_loss: 2.6680 - val_accuracy: 0.3272 - val_top3_acc: 0.5402 - val_top_k_categorical_accuracy: 0.6378\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.6434 - accuracy: 0.5367 - top3_acc: 0.7600 - top_k_categorical_accuracy: 0.8400 - val_loss: 2.5442 - val_accuracy: 0.3537 - val_top3_acc: 0.5634 - val_top_k_categorical_accuracy: 0.6599\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.6229 - accuracy: 0.5456 - top3_acc: 0.7618 - top_k_categorical_accuracy: 0.8395 - val_loss: 2.6656 - val_accuracy: 0.3411 - val_top3_acc: 0.5415 - val_top_k_categorical_accuracy: 0.6345\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.5646 - accuracy: 0.5525 - top3_acc: 0.7757 - top_k_categorical_accuracy: 0.8522 - val_loss: 2.9681 - val_accuracy: 0.2971 - val_top3_acc: 0.4936 - val_top_k_categorical_accuracy: 0.5898\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.5466 - accuracy: 0.5601 - top3_acc: 0.7775 - top_k_categorical_accuracy: 0.8541 - val_loss: 2.3301 - val_accuracy: 0.4001 - val_top3_acc: 0.6043 - val_top_k_categorical_accuracy: 0.6978\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.5314 - accuracy: 0.5631 - top3_acc: 0.7821 - top_k_categorical_accuracy: 0.8579 - val_loss: 2.4854 - val_accuracy: 0.3700 - val_top3_acc: 0.5768 - val_top_k_categorical_accuracy: 0.6720\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.4945 - accuracy: 0.5726 - top3_acc: 0.7872 - top_k_categorical_accuracy: 0.8626 - val_loss: 2.3301 - val_accuracy: 0.4043 - val_top3_acc: 0.6111 - val_top_k_categorical_accuracy: 0.6982\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.4546 - accuracy: 0.5858 - top3_acc: 0.7982 - top_k_categorical_accuracy: 0.8690 - val_loss: 2.7560 - val_accuracy: 0.3310 - val_top3_acc: 0.5223 - val_top_k_categorical_accuracy: 0.6208\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.4578 - accuracy: 0.5820 - top3_acc: 0.7943 - top_k_categorical_accuracy: 0.8689 - val_loss: 2.3378 - val_accuracy: 0.3993 - val_top3_acc: 0.6109 - val_top_k_categorical_accuracy: 0.6986\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.4420 - accuracy: 0.5861 - top3_acc: 0.7997 - top_k_categorical_accuracy: 0.8729 - val_loss: 2.4420 - val_accuracy: 0.3820 - val_top3_acc: 0.5931 - val_top_k_categorical_accuracy: 0.6776\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.3961 - accuracy: 0.5977 - top3_acc: 0.8108 - top_k_categorical_accuracy: 0.8794 - val_loss: 2.4707 - val_accuracy: 0.3786 - val_top3_acc: 0.5827 - val_top_k_categorical_accuracy: 0.6730\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.3800 - accuracy: 0.6010 - top3_acc: 0.8113 - top_k_categorical_accuracy: 0.8817 - val_loss: 2.0921 - val_accuracy: 0.4499 - val_top3_acc: 0.6620 - val_top_k_categorical_accuracy: 0.7436\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 1.3621 - accuracy: 0.6046 - top3_acc: 0.8132 - top_k_categorical_accuracy: 0.8825 - val_loss: 2.0449 - val_accuracy: 0.4585 - val_top3_acc: 0.6755 - val_top_k_categorical_accuracy: 0.7595\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.3527 - accuracy: 0.6049 - top3_acc: 0.8188 - top_k_categorical_accuracy: 0.8868 - val_loss: 2.1375 - val_accuracy: 0.4473 - val_top3_acc: 0.6534 - val_top_k_categorical_accuracy: 0.7373\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.3105 - accuracy: 0.6211 - top3_acc: 0.8241 - top_k_categorical_accuracy: 0.8888 - val_loss: 2.0760 - val_accuracy: 0.4533 - val_top3_acc: 0.6671 - val_top_k_categorical_accuracy: 0.7503\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.3058 - accuracy: 0.6207 - top3_acc: 0.8274 - top_k_categorical_accuracy: 0.8921 - val_loss: 2.2945 - val_accuracy: 0.4136 - val_top3_acc: 0.6297 - val_top_k_categorical_accuracy: 0.7194\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.2710 - accuracy: 0.6305 - top3_acc: 0.8357 - top_k_categorical_accuracy: 0.8977 - val_loss: 2.1145 - val_accuracy: 0.4547 - val_top3_acc: 0.6638 - val_top_k_categorical_accuracy: 0.7442\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.2608 - accuracy: 0.6278 - top3_acc: 0.8380 - top_k_categorical_accuracy: 0.8995 - val_loss: 1.9168 - val_accuracy: 0.4903 - val_top3_acc: 0.6972 - val_top_k_categorical_accuracy: 0.7779\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 1.2334 - accuracy: 0.6383 - top3_acc: 0.8409 - top_k_categorical_accuracy: 0.9023 - val_loss: 1.9163 - val_accuracy: 0.4858 - val_top3_acc: 0.7034 - val_top_k_categorical_accuracy: 0.7861\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('gelu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "top3_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy', top3_acc, 'top_k_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "c4da0a1e-6be7-4cfa-d1e7-df75055bdc40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [4.5176167488098145, 4.4523138999938965, 4.384772777557373, 4.282270908355713, 4.106595993041992, 3.907115936279297, 3.7103679180145264, 3.5374269485473633, 3.396066427230835, 3.2643394470214844, 3.125515937805176, 2.989588975906372, 2.8592803478240967, 2.7316596508026123, 2.622786521911621, 2.5238564014434814, 2.43013596534729, 2.3555188179016113, 2.284473419189453, 2.2196860313415527, 2.1545188426971436, 2.0905258655548096, 2.0418894290924072, 1.987250566482544, 1.9444130659103394, 1.8999273777008057, 1.8546172380447388, 1.8175801038742065, 1.7801966667175293, 1.7383917570114136, 1.706026554107666, 1.6701107025146484, 1.643744945526123, 1.6183359622955322, 1.5842729806900024, 1.5571643114089966, 1.5379711389541626, 1.502303957939148, 1.4737699031829834, 1.4607199430465698, 1.441097617149353, 1.4091143608093262, 1.3885279893875122, 1.369489312171936, 1.3549790382385254, 1.3259921073913574, 1.3116732835769653, 1.2854958772659302, 1.2659224271774292, 1.2555170059204102], 'accuracy': [0.020400000736117363, 0.02979999966919422, 0.040800001472234726, 0.051350001245737076, 0.06707499921321869, 0.0906749963760376, 0.12129999697208405, 0.14740000665187836, 0.1729000061750412, 0.194474995136261, 0.22267499566078186, 0.24747499823570251, 0.27067500352859497, 0.2920750081539154, 0.31642499566078186, 0.33627501130104065, 0.35690000653266907, 0.36967501044273376, 0.3894749879837036, 0.4021250009536743, 0.4185749888420105, 0.4329499900341034, 0.4446749985218048, 0.45317500829696655, 0.4657000005245209, 0.47655001282691956, 0.4864000082015991, 0.49334999918937683, 0.503125011920929, 0.5131000280380249, 0.5214999914169312, 0.5311999917030334, 0.5365750193595886, 0.5437750220298767, 0.5487750172615051, 0.5557249784469604, 0.5602999925613403, 0.5698750019073486, 0.5805749893188477, 0.5805500149726868, 0.5857999920845032, 0.5925999879837036, 0.5985000133514404, 0.6033750176429749, 0.6063249707221985, 0.6178249716758728, 0.6187499761581421, 0.6268500089645386, 0.6285499930381775, 0.6334999799728394], 'top3_acc': [0.05745000019669533, 0.07537499815225601, 0.09647499769926071, 0.11682499945163727, 0.15584999322891235, 0.2050500065088272, 0.25745001435279846, 0.3029249906539917, 0.33972498774528503, 0.37527498602867126, 0.4125249981880188, 0.44850000739097595, 0.4777500033378601, 0.5082749724388123, 0.5335749983787537, 0.5619999766349792, 0.5825250148773193, 0.5976750254631042, 0.6167749762535095, 0.6310999989509583, 0.6444249749183655, 0.661674976348877, 0.6746000051498413, 0.6818749904632568, 0.6937500238418579, 0.7044000029563904, 0.712149977684021, 0.7194749712944031, 0.7301750183105469, 0.737975001335144, 0.7446749806404114, 0.7552499771118164, 0.7597249746322632, 0.7633000016212463, 0.7702249884605408, 0.7769500017166138, 0.7815999984741211, 0.7869250178337097, 0.7943000197410583, 0.7947750091552734, 0.7996249794960022, 0.8081250190734863, 0.8106750249862671, 0.8131750226020813, 0.8169999718666077, 0.8209999799728394, 0.8256000280380249, 0.831974983215332, 0.8375750184059143, 0.8381249904632568], 'top_k_categorical_accuracy': [0.0885000005364418, 0.11259999871253967, 0.1370999962091446, 0.16932499408721924, 0.22407500445842743, 0.2878749966621399, 0.3493500053882599, 0.4022499918937683, 0.44359999895095825, 0.4829750061035156, 0.5206249952316284, 0.55902498960495, 0.5854250192642212, 0.6171249747276306, 0.6424999833106995, 0.6690000295639038, 0.6880000233650208, 0.7024499773979187, 0.7178249955177307, 0.7310000061988831, 0.7436249852180481, 0.7578250169754028, 0.7668499946594238, 0.7766000032424927, 0.785224974155426, 0.7933750152587891, 0.8014000058174133, 0.8090999722480774, 0.8154500126838684, 0.8238250017166138, 0.8270750045776367, 0.8349000215530396, 0.8387249708175659, 0.8412250280380249, 0.8471500277519226, 0.8543000221252441, 0.8557500243186951, 0.8611249923706055, 0.8655250072479248, 0.8675749897956848, 0.8722000122070312, 0.8773499727249146, 0.8804000020027161, 0.882224977016449, 0.8856499791145325, 0.8875499963760376, 0.8903250098228455, 0.8966000080108643, 0.8989250063896179, 0.8999000191688538], 'val_loss': [4.6047773361206055, 4.591737747192383, 4.605344772338867, 4.818621635437012, 5.76225471496582, 6.61157751083374, 6.119871139526367, 5.665971279144287, 6.0796003341674805, 5.238792896270752, 6.184345245361328, 5.694199562072754, 4.698673248291016, 5.427422523498535, 4.684035778045654, 3.832113265991211, 4.331503868103027, 3.778128147125244, 4.018305778503418, 3.514353036880493, 3.1285059452056885, 3.1561079025268555, 4.019919395446777, 3.0630507469177246, 3.095944404602051, 2.8790104389190674, 3.127462387084961, 2.899435520172119, 2.6363234519958496, 3.2083499431610107, 2.543154001235962, 2.668020486831665, 2.5442397594451904, 2.6655960083007812, 2.96807599067688, 2.3301360607147217, 2.4853875637054443, 2.330096960067749, 2.7560293674468994, 2.337757110595703, 2.4420065879821777, 2.4707343578338623, 2.0921080112457275, 2.044867992401123, 2.13748836517334, 2.0760464668273926, 2.294538974761963, 2.1145284175872803, 1.916778326034546, 1.9163448810577393], 'val_accuracy': [0.009700000286102295, 0.01769999973475933, 0.01140000019222498, 0.009100000374019146, 0.012500000186264515, 0.01489999983459711, 0.020800000056624413, 0.021199999377131462, 0.016699999570846558, 0.03620000183582306, 0.027300000190734863, 0.027499999850988388, 0.06080000102519989, 0.04490000009536743, 0.07429999858140945, 0.13199999928474426, 0.09809999912977219, 0.15189999341964722, 0.1251000016927719, 0.18230000138282776, 0.24709999561309814, 0.2460000067949295, 0.1525000035762787, 0.260699987411499, 0.25099998712539673, 0.29100000858306885, 0.25589999556541443, 0.2976999878883362, 0.33820000290870667, 0.2547000050544739, 0.361299991607666, 0.3271999955177307, 0.35370001196861267, 0.3411000072956085, 0.2971000075340271, 0.4000999927520752, 0.3700000047683716, 0.4043000042438507, 0.3310000002384186, 0.3993000090122223, 0.38199999928474426, 0.37860000133514404, 0.4499000012874603, 0.4584999978542328, 0.447299987077713, 0.45329999923706055, 0.41359999775886536, 0.4546999931335449, 0.4902999997138977, 0.48579999804496765], 'val_top3_acc': [0.0272000003606081, 0.045499999076128006, 0.033900000154972076, 0.030899999663233757, 0.029400000348687172, 0.032999999821186066, 0.03880000114440918, 0.05510000139474869, 0.05429999902844429, 0.0940999984741211, 0.07410000264644623, 0.07980000227689743, 0.14869999885559082, 0.1282999962568283, 0.17550000548362732, 0.2745000123977661, 0.2264000028371811, 0.32190001010894775, 0.27810001373291016, 0.3553999960422516, 0.43160000443458557, 0.43689998984336853, 0.3109000027179718, 0.4537999927997589, 0.4431000053882599, 0.48910000920295715, 0.44449999928474426, 0.48410001397132874, 0.5418000221252441, 0.436599999666214, 0.5619999766349792, 0.5401999950408936, 0.5633999705314636, 0.5414999723434448, 0.4936000108718872, 0.6043000221252441, 0.5767999887466431, 0.6111000180244446, 0.5223000049591064, 0.6108999848365784, 0.5931000113487244, 0.5827000141143799, 0.6620000004768372, 0.6754999756813049, 0.6534000039100647, 0.6671000123023987, 0.6297000050544739, 0.6638000011444092, 0.6972000002861023, 0.7034000158309937], 'val_top_k_categorical_accuracy': [0.0494999997317791, 0.06800000369548798, 0.052799999713897705, 0.05119999870657921, 0.052400000393390656, 0.054499998688697815, 0.06469999998807907, 0.09030000120401382, 0.0869000032544136, 0.14159999787807465, 0.11959999799728394, 0.12349999696016312, 0.2159000039100647, 0.1835000067949295, 0.24490000307559967, 0.3605000078678131, 0.30489999055862427, 0.4068000018596649, 0.3659000098705292, 0.44859999418258667, 0.5253999829292297, 0.5353000164031982, 0.40619999170303345, 0.5489000082015991, 0.5404999852180481, 0.5924000144004822, 0.5410000085830688, 0.5771999955177307, 0.6371999979019165, 0.5230000019073486, 0.6568999886512756, 0.6377999782562256, 0.6599000096321106, 0.6345000267028809, 0.5898000001907349, 0.6977999806404114, 0.671999990940094, 0.698199987411499, 0.6208000183105469, 0.6985999941825867, 0.6776000261306763, 0.6729999780654907, 0.7436000108718872, 0.7595000267028809, 0.7372999787330627, 0.7502999901771545, 0.7193999886512756, 0.7441999912261963, 0.777899980545044, 0.7860999703407288]}\n",
      "313/313 [==============================] - 7s 17ms/step - loss: 1.9134 - accuracy: 0.4888 - top3_acc: 0.7009 - top_k_categorical_accuracy: 0.7845\n",
      "[1.9134255647659302, 0.4887999892234802, 0.7009000182151794, 0.784500002861023]\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "# y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_pred.shape)\n",
    "# print(y_true.shape)\n",
    "\n",
    "# print(np.sum(y_pred == y_true) / y_pred.shape[0])\n",
    "\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar100_simplenet_gelu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
