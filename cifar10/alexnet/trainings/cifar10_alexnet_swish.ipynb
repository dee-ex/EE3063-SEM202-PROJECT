{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WljAm5f0fKkw",
    "outputId": "86ae0f9f-eacb-49c0-c279-487439ccff00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "170508288/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "104327a9-9165-4f57-aed5-fc6180741516"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 10),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 10),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def alexnet(activation):\n",
    "    AlexNet = Sequential()\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=96, input_shape=(32, 32, 3), kernel_size=(11, 11), strides=(4, 4), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    AlexNet.add(Flatten())\n",
    "    AlexNet.add(Dense(4096, input_shape=(32, 32, 3)))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(Dropout(0.5))\n",
    "\n",
    "    AlexNet.add(Dense(4096))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(Dropout(0.5))\n",
    "\n",
    "    AlexNet.add(Dense(1000))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(Dropout(0.5))\n",
    "\n",
    "    AlexNet.add(Dense(10))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('softmax'))\n",
    "\n",
    "    return AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "a5402967-fec1-450b-eed6-8e10817fdfa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 28s 81ms/step - loss: 2.0768 - accuracy: 0.2622 - val_loss: 1.7958 - val_accuracy: 0.4338\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 1.5497 - accuracy: 0.4598 - val_loss: 1.4903 - val_accuracy: 0.4773\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 26s 81ms/step - loss: 1.3953 - accuracy: 0.5240 - val_loss: 1.4678 - val_accuracy: 0.4892\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 24s 75ms/step - loss: 1.2903 - accuracy: 0.5635 - val_loss: 1.4988 - val_accuracy: 0.4639\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 1.1960 - accuracy: 0.5975 - val_loss: 1.2983 - val_accuracy: 0.5472\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 1.1279 - accuracy: 0.6207 - val_loss: 1.3482 - val_accuracy: 0.5326\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 1.0623 - accuracy: 0.6429 - val_loss: 1.1387 - val_accuracy: 0.6122\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 1.0217 - accuracy: 0.6563 - val_loss: 1.5600 - val_accuracy: 0.4636\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.9794 - accuracy: 0.6747 - val_loss: 1.2230 - val_accuracy: 0.5831\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.9157 - accuracy: 0.6958 - val_loss: 1.1439 - val_accuracy: 0.6080\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.8774 - accuracy: 0.7080 - val_loss: 1.1088 - val_accuracy: 0.6222\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.8320 - accuracy: 0.7231 - val_loss: 1.2047 - val_accuracy: 0.5946\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.8002 - accuracy: 0.7366 - val_loss: 1.2544 - val_accuracy: 0.5792\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.7657 - accuracy: 0.7469 - val_loss: 1.1108 - val_accuracy: 0.6165\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.7245 - accuracy: 0.7626 - val_loss: 1.3134 - val_accuracy: 0.5788\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.6929 - accuracy: 0.7754 - val_loss: 1.1954 - val_accuracy: 0.6143\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.6551 - accuracy: 0.7897 - val_loss: 1.2196 - val_accuracy: 0.6107\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.6111 - accuracy: 0.8011 - val_loss: 1.2374 - val_accuracy: 0.6194\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.5840 - accuracy: 0.8114 - val_loss: 1.3303 - val_accuracy: 0.5781\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 0.5488 - accuracy: 0.8257 - val_loss: 1.3073 - val_accuracy: 0.6048\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 25s 81ms/step - loss: 0.5181 - accuracy: 0.8332 - val_loss: 1.1811 - val_accuracy: 0.6194\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.4854 - accuracy: 0.8455 - val_loss: 1.0963 - val_accuracy: 0.6515\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.4550 - accuracy: 0.8569 - val_loss: 1.3209 - val_accuracy: 0.6179\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 0.4339 - accuracy: 0.8670 - val_loss: 1.1165 - val_accuracy: 0.6542\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 0.3962 - accuracy: 0.8798 - val_loss: 1.1159 - val_accuracy: 0.6524\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 23s 72ms/step - loss: 0.3726 - accuracy: 0.8836 - val_loss: 1.1179 - val_accuracy: 0.6566\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 0.3542 - accuracy: 0.8939 - val_loss: 1.2590 - val_accuracy: 0.6276\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.3327 - accuracy: 0.8994 - val_loss: 1.2028 - val_accuracy: 0.6575\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.2998 - accuracy: 0.9120 - val_loss: 1.1644 - val_accuracy: 0.6597\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 25s 81ms/step - loss: 0.2777 - accuracy: 0.9181 - val_loss: 1.3380 - val_accuracy: 0.6164\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 23s 72ms/step - loss: 0.2564 - accuracy: 0.9260 - val_loss: 1.1794 - val_accuracy: 0.6586\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.2376 - accuracy: 0.9331 - val_loss: 1.4282 - val_accuracy: 0.6189\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 25s 81ms/step - loss: 0.2224 - accuracy: 0.9362 - val_loss: 1.3271 - val_accuracy: 0.6357\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.2085 - accuracy: 0.9430 - val_loss: 1.2654 - val_accuracy: 0.6557\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.1999 - accuracy: 0.9448 - val_loss: 1.2981 - val_accuracy: 0.6532\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.1728 - accuracy: 0.9551 - val_loss: 1.2162 - val_accuracy: 0.6649\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.1658 - accuracy: 0.9563 - val_loss: 1.2488 - val_accuracy: 0.6612\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.1524 - accuracy: 0.9607 - val_loss: 1.2472 - val_accuracy: 0.6660\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 0.1441 - accuracy: 0.9633 - val_loss: 1.3165 - val_accuracy: 0.6584\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.1334 - accuracy: 0.9658 - val_loss: 1.1754 - val_accuracy: 0.6818\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.1209 - accuracy: 0.9704 - val_loss: 1.2953 - val_accuracy: 0.6700\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 25s 81ms/step - loss: 0.1167 - accuracy: 0.9721 - val_loss: 1.2790 - val_accuracy: 0.6660\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 25s 81ms/step - loss: 0.0995 - accuracy: 0.9778 - val_loss: 1.2933 - val_accuracy: 0.6675\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.0941 - accuracy: 0.9788 - val_loss: 1.3875 - val_accuracy: 0.6509\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.0963 - accuracy: 0.9766 - val_loss: 1.2987 - val_accuracy: 0.6770\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.0805 - accuracy: 0.9840 - val_loss: 1.2708 - val_accuracy: 0.6771\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 24s 75ms/step - loss: 0.0808 - accuracy: 0.9815 - val_loss: 1.3004 - val_accuracy: 0.6744\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.0756 - accuracy: 0.9837 - val_loss: 1.3667 - val_accuracy: 0.6588\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.0709 - accuracy: 0.9850 - val_loss: 1.2744 - val_accuracy: 0.6808\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.0616 - accuracy: 0.9885 - val_loss: 1.3174 - val_accuracy: 0.6801\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = alexnet('swish')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "54d12dfe-378b-47db-f6d7-e18bffe833b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.8494691848754883, 1.511410117149353, 1.3718115091323853, 1.2757576704025269, 1.1969853639602661, 1.127747893333435, 1.065446138381958, 1.0123978853225708, 0.9685873985290527, 0.9223372340202332, 0.8858275413513184, 0.8398584723472595, 0.8034319281578064, 0.7674315571784973, 0.7310449481010437, 0.6923319101333618, 0.6601558923721313, 0.6258076429367065, 0.5918991565704346, 0.5576987862586975, 0.530364990234375, 0.4975295066833496, 0.46858182549476624, 0.44097432494163513, 0.41258084774017334, 0.38244596123695374, 0.36341267824172974, 0.34004470705986023, 0.3108637034893036, 0.28961530327796936, 0.26374199986457825, 0.2454206496477127, 0.23235930502414703, 0.21943755447864532, 0.2007129043340683, 0.18528299033641815, 0.17471717298030853, 0.16075444221496582, 0.1509486585855484, 0.1398552805185318, 0.12568044662475586, 0.11941149830818176, 0.10592155903577805, 0.09993626922369003, 0.09875503927469254, 0.08746957778930664, 0.08378904312849045, 0.07695432007312775, 0.0736108049750328, 0.06687254458665848], 'accuracy': [0.34040001034736633, 0.4751499891281128, 0.5314750075340271, 0.5670999884605408, 0.5938000082969666, 0.6201500296592712, 0.64205002784729, 0.6585249900817871, 0.6777250170707703, 0.6920250058174133, 0.7039499878883362, 0.7206500172615051, 0.7348250150680542, 0.7475000023841858, 0.7595250010490417, 0.7737249732017517, 0.786050021648407, 0.7947250008583069, 0.8069499731063843, 0.8206499814987183, 0.8289499878883362, 0.8404750227928162, 0.8514500260353088, 0.8616999983787537, 0.8722249865531921, 0.8797000050544739, 0.8895249962806702, 0.896049976348877, 0.906624972820282, 0.9138249754905701, 0.923425018787384, 0.9291250109672546, 0.9326500296592712, 0.9373250007629395, 0.944599986076355, 0.9502999782562256, 0.9530749917030334, 0.95660001039505, 0.9606000185012817, 0.9639999866485596, 0.9685750007629395, 0.970550000667572, 0.9755499958992004, 0.9765250086784363, 0.9760749936103821, 0.9810500144958496, 0.9812250137329102, 0.9829750061035156, 0.9841750264167786, 0.9864500164985657], 'val_loss': [1.795840859413147, 1.4902528524398804, 1.4677574634552002, 1.4988059997558594, 1.298314094543457, 1.3482213020324707, 1.138711929321289, 1.559969186782837, 1.2230206727981567, 1.1438632011413574, 1.1088275909423828, 1.2046687602996826, 1.2543781995773315, 1.1108477115631104, 1.3134174346923828, 1.1954345703125, 1.2196269035339355, 1.2373656034469604, 1.3302775621414185, 1.3073315620422363, 1.1811034679412842, 1.096327781677246, 1.3209182024002075, 1.1164822578430176, 1.1158846616744995, 1.117877721786499, 1.2590047121047974, 1.2027835845947266, 1.1644095182418823, 1.3380475044250488, 1.1793878078460693, 1.4282423257827759, 1.3270559310913086, 1.2654131650924683, 1.2980663776397705, 1.216154932975769, 1.2487939596176147, 1.2471731901168823, 1.3164899349212646, 1.1754190921783447, 1.2952791452407837, 1.2789912223815918, 1.2932695150375366, 1.3874726295471191, 1.2986679077148438, 1.2708121538162231, 1.3003714084625244, 1.3667104244232178, 1.2744035720825195, 1.3174296617507935], 'val_accuracy': [0.43380001187324524, 0.4772999882698059, 0.48919999599456787, 0.46389999985694885, 0.5472000241279602, 0.5325999855995178, 0.6122000217437744, 0.4636000096797943, 0.5831000208854675, 0.6079999804496765, 0.6222000122070312, 0.5946000218391418, 0.579200029373169, 0.6165000200271606, 0.5788000226020813, 0.614300012588501, 0.6107000112533569, 0.6194000244140625, 0.5781000256538391, 0.6047999858856201, 0.6194000244140625, 0.6514999866485596, 0.617900013923645, 0.65420001745224, 0.652400016784668, 0.6565999984741211, 0.6276000142097473, 0.6575000286102295, 0.6596999764442444, 0.6164000034332275, 0.6585999727249146, 0.6189000010490417, 0.635699987411499, 0.6557000279426575, 0.6531999707221985, 0.664900004863739, 0.6611999869346619, 0.6660000085830688, 0.6583999991416931, 0.6818000078201294, 0.6700000166893005, 0.6660000085830688, 0.6675000190734863, 0.6509000062942505, 0.6769999861717224, 0.6771000027656555, 0.6743999719619751, 0.6588000059127808, 0.6808000206947327, 0.6801000237464905]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.6769\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10_alexnet_swish.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
