{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8e0tAC7e0CI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WljAm5f0fKkw",
    "outputId": "86ae0f9f-eacb-49c0-c279-487439ccff00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "170508288/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7u2htPZHfLP2"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxXF-OFASsu",
    "outputId": "104327a9-9165-4f57-aed5-fc6180741516"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3),\n",
       " (40000, 10),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 10),\n",
       " (10000, 32, 32, 3),\n",
       " (10000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QR8VwuXy-SCk"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UgqsFQ16Gmz4"
   },
   "outputs": [],
   "source": [
    "def alexnet(activation):\n",
    "    AlexNet = Sequential()\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=96, input_shape=(32, 32, 3), kernel_size=(11, 11), strides=(4, 4), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    AlexNet.add(Flatten())\n",
    "    AlexNet.add(Dense(4096, input_shape=(32, 32, 3)))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(Dropout(0.5))\n",
    "\n",
    "    AlexNet.add(Dense(4096))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(Dropout(0.5))\n",
    "\n",
    "    AlexNet.add(Dense(1000))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation(activation))\n",
    "    AlexNet.add(Dropout(0.5))\n",
    "\n",
    "    AlexNet.add(Dense(10))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('softmax'))\n",
    "\n",
    "    return AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvLaricEJB7Y",
    "outputId": "01a568ae-170c-4c72-907d-67ab0682a0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 72s 80ms/step - loss: 2.1473 - accuracy: 0.2353 - val_loss: 1.8497 - val_accuracy: 0.3462\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.6361 - accuracy: 0.4194 - val_loss: 1.5370 - val_accuracy: 0.4640\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 1.4846 - accuracy: 0.4855 - val_loss: 1.3768 - val_accuracy: 0.5276\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.3740 - accuracy: 0.5290 - val_loss: 1.5469 - val_accuracy: 0.4505\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 1.2930 - accuracy: 0.5609 - val_loss: 1.4445 - val_accuracy: 0.4909\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 1.2188 - accuracy: 0.5825 - val_loss: 1.4059 - val_accuracy: 0.5095\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 22s 72ms/step - loss: 1.1698 - accuracy: 0.6012 - val_loss: 1.8661 - val_accuracy: 0.3997\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 1.1120 - accuracy: 0.6257 - val_loss: 1.4700 - val_accuracy: 0.5104\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 1.0596 - accuracy: 0.6411 - val_loss: 1.2758 - val_accuracy: 0.5499\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 22s 72ms/step - loss: 1.0161 - accuracy: 0.6586 - val_loss: 1.1578 - val_accuracy: 0.6018\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.9736 - accuracy: 0.6703 - val_loss: 1.2897 - val_accuracy: 0.5608\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 0.9364 - accuracy: 0.6896 - val_loss: 1.0513 - val_accuracy: 0.6412\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.8957 - accuracy: 0.6987 - val_loss: 1.0954 - val_accuracy: 0.6269\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.8624 - accuracy: 0.7149 - val_loss: 1.0799 - val_accuracy: 0.6328\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.8407 - accuracy: 0.7192 - val_loss: 1.3104 - val_accuracy: 0.5652\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.8016 - accuracy: 0.7354 - val_loss: 1.4090 - val_accuracy: 0.5560\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.7777 - accuracy: 0.7430 - val_loss: 1.2916 - val_accuracy: 0.5775\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 21s 69ms/step - loss: 0.7416 - accuracy: 0.7556 - val_loss: 1.1829 - val_accuracy: 0.6193\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.7043 - accuracy: 0.7676 - val_loss: 1.1459 - val_accuracy: 0.6327\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.6882 - accuracy: 0.7776 - val_loss: 1.2917 - val_accuracy: 0.5867\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6641 - accuracy: 0.7845 - val_loss: 1.1388 - val_accuracy: 0.6405\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.6208 - accuracy: 0.7989 - val_loss: 1.3089 - val_accuracy: 0.6019\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 22s 72ms/step - loss: 0.6016 - accuracy: 0.8042 - val_loss: 1.0982 - val_accuracy: 0.6445\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.5820 - accuracy: 0.8130 - val_loss: 1.0600 - val_accuracy: 0.6624\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.5673 - accuracy: 0.8167 - val_loss: 1.1629 - val_accuracy: 0.6388\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 22s 72ms/step - loss: 0.5282 - accuracy: 0.8325 - val_loss: 1.3995 - val_accuracy: 0.5775\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.5052 - accuracy: 0.8386 - val_loss: 1.1041 - val_accuracy: 0.6582\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.4741 - accuracy: 0.8513 - val_loss: 1.5895 - val_accuracy: 0.5815\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.4536 - accuracy: 0.8559 - val_loss: 1.1838 - val_accuracy: 0.6485\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.4350 - accuracy: 0.8624 - val_loss: 1.1937 - val_accuracy: 0.6448\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.4163 - accuracy: 0.8671 - val_loss: 1.2765 - val_accuracy: 0.6253\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.3945 - accuracy: 0.8746 - val_loss: 1.2998 - val_accuracy: 0.6424\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.3770 - accuracy: 0.8802 - val_loss: 1.3984 - val_accuracy: 0.6250\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.3673 - accuracy: 0.8843 - val_loss: 1.2306 - val_accuracy: 0.6476\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.3393 - accuracy: 0.8926 - val_loss: 1.2766 - val_accuracy: 0.6448\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.3293 - accuracy: 0.8976 - val_loss: 1.2797 - val_accuracy: 0.6420\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.3083 - accuracy: 0.9058 - val_loss: 1.3820 - val_accuracy: 0.6314\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.2991 - accuracy: 0.9073 - val_loss: 1.4923 - val_accuracy: 0.6133\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.2730 - accuracy: 0.9162 - val_loss: 1.3388 - val_accuracy: 0.6529\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.2657 - accuracy: 0.9181 - val_loss: 1.3328 - val_accuracy: 0.6578\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.2549 - accuracy: 0.9214 - val_loss: 1.4485 - val_accuracy: 0.6342\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.2398 - accuracy: 0.9253 - val_loss: 1.5602 - val_accuracy: 0.6143\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 24s 75ms/step - loss: 0.2222 - accuracy: 0.9336 - val_loss: 1.5872 - val_accuracy: 0.6187\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.2109 - accuracy: 0.9362 - val_loss: 1.5100 - val_accuracy: 0.6468\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.2029 - accuracy: 0.9377 - val_loss: 1.4383 - val_accuracy: 0.6505\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.1996 - accuracy: 0.9387 - val_loss: 1.4373 - val_accuracy: 0.6458\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.1850 - accuracy: 0.9437 - val_loss: 1.6624 - val_accuracy: 0.6221\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.1838 - accuracy: 0.9444 - val_loss: 1.5219 - val_accuracy: 0.6450\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 0.1573 - accuracy: 0.9546 - val_loss: 1.5511 - val_accuracy: 0.6444\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.1553 - accuracy: 0.9553 - val_loss: 1.5346 - val_accuracy: 0.6498\n"
     ]
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = alexnet('relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_eJn83kKCwL",
    "outputId": "b5b85dbb-ed26-4087-a9b2-d189c54ec525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.9315803050994873, 1.5992205142974854, 1.4562040567398071, 1.3618193864822388, 1.2806966304779053, 1.2123916149139404, 1.1589703559875488, 1.1078267097473145, 1.0610688924789429, 1.0178948640823364, 0.9778406023979187, 0.9409791231155396, 0.9056694507598877, 0.8719632029533386, 0.8419684767723083, 0.8109716176986694, 0.7838069200515747, 0.7466331720352173, 0.7198708057403564, 0.6957352161407471, 0.6707767844200134, 0.6373634338378906, 0.6145175099372864, 0.5908297896385193, 0.5643681883811951, 0.5395238995552063, 0.5174742937088013, 0.49186405539512634, 0.47206082940101624, 0.45157426595687866, 0.4297679662704468, 0.4099060595035553, 0.39276614785194397, 0.378933310508728, 0.35171109437942505, 0.33860132098197937, 0.31415855884552, 0.30760657787323, 0.28890904784202576, 0.2784215211868286, 0.2650837004184723, 0.2464938908815384, 0.23266291618347168, 0.21967224776744843, 0.21205168962478638, 0.19953615963459015, 0.19468005001544952, 0.18626831471920013, 0.16691702604293823, 0.1653590351343155], 'accuracy': [0.30137500166893005, 0.4359250068664551, 0.49537500739097595, 0.5333750247955322, 0.5637750029563904, 0.585224986076355, 0.6065250039100647, 0.6258249878883362, 0.642175018787384, 0.6571499705314636, 0.6706749796867371, 0.687375009059906, 0.698074996471405, 0.7084500193595886, 0.7196499705314636, 0.7304750084877014, 0.7388499975204468, 0.7522000074386597, 0.7615500092506409, 0.7716749906539917, 0.7821000218391418, 0.7931749820709229, 0.7989749908447266, 0.8076500296592712, 0.8169999718666077, 0.8259750008583069, 0.8338750004768372, 0.8432499766349792, 0.8487250208854675, 0.8547999858856201, 0.8619999885559082, 0.8686000108718872, 0.8749250173568726, 0.8796499967575073, 0.8881499767303467, 0.8938500285148621, 0.9010999798774719, 0.9039250016212463, 0.9098250269889832, 0.9139500260353088, 0.9172250032424927, 0.9224500060081482, 0.9290750026702881, 0.9327999949455261, 0.9345250129699707, 0.93954998254776, 0.9402750134468079, 0.9429500102996826, 0.9505249857902527, 0.9502999782562256], 'val_loss': [1.8497189283370972, 1.5369822978973389, 1.3767931461334229, 1.5469138622283936, 1.4445289373397827, 1.4058581590652466, 1.8660717010498047, 1.4700350761413574, 1.2758232355117798, 1.157759189605713, 1.2896610498428345, 1.0512840747833252, 1.095445990562439, 1.0798919200897217, 1.3104362487792969, 1.4089988470077515, 1.291616439819336, 1.1829274892807007, 1.1459197998046875, 1.2916923761367798, 1.1388084888458252, 1.30891752243042, 1.0982296466827393, 1.0600210428237915, 1.1629419326782227, 1.3994730710983276, 1.104123830795288, 1.589477777481079, 1.1838188171386719, 1.193737268447876, 1.2765458822250366, 1.2998181581497192, 1.3984375, 1.2305980920791626, 1.276579737663269, 1.2797349691390991, 1.3820369243621826, 1.4922605752944946, 1.3387935161590576, 1.3328038454055786, 1.4485042095184326, 1.5602349042892456, 1.5871977806091309, 1.5100017786026, 1.4382855892181396, 1.4372552633285522, 1.6623731851577759, 1.5219193696975708, 1.5511137247085571, 1.5346187353134155], 'val_accuracy': [0.34619998931884766, 0.46399998664855957, 0.5275999903678894, 0.4505000114440918, 0.4909000098705292, 0.5095000267028809, 0.39969998598098755, 0.5103999972343445, 0.5498999953269958, 0.6018000245094299, 0.5608000159263611, 0.6412000060081482, 0.6269000172615051, 0.6327999830245972, 0.5651999711990356, 0.5559999942779541, 0.5774999856948853, 0.6193000078201294, 0.6327000260353088, 0.5867000222206116, 0.640500009059906, 0.6018999814987183, 0.6445000171661377, 0.6624000072479248, 0.6388000249862671, 0.5774999856948853, 0.6582000255584717, 0.5814999938011169, 0.6485000252723694, 0.6448000073432922, 0.6252999901771545, 0.6424000263214111, 0.625, 0.647599995136261, 0.6448000073432922, 0.6420000195503235, 0.6313999891281128, 0.6133000254631042, 0.652899980545044, 0.657800018787384, 0.6341999769210815, 0.614300012588501, 0.6187000274658203, 0.6467999815940857, 0.6504999995231628, 0.645799994468689, 0.6220999956130981, 0.6449999809265137, 0.6444000005722046, 0.6498000025749207]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.6501\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10_alexnet_relu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
