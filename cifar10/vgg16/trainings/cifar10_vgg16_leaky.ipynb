{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "4cac6ec4-196e-46e4-ea19-2dfaedc4b50d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 56s 107ms/step - loss: 5.1008 - accuracy: 0.1595 - val_loss: 4.1761 - val_accuracy: 0.2379\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 4.3168 - accuracy: 0.2622 - val_loss: 4.0001 - val_accuracy: 0.2903\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 4.0504 - accuracy: 0.3261 - val_loss: 4.1415 - val_accuracy: 0.2948\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.8706 - accuracy: 0.3705 - val_loss: 4.0259 - val_accuracy: 0.3529\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 3.7586 - accuracy: 0.4033 - val_loss: 4.1412 - val_accuracy: 0.3656\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.6384 - accuracy: 0.4445 - val_loss: 3.6273 - val_accuracy: 0.4852\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 3.5375 - accuracy: 0.4771 - val_loss: 4.0912 - val_accuracy: 0.4110\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 3.4497 - accuracy: 0.5081 - val_loss: 3.5063 - val_accuracy: 0.5297\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.3718 - accuracy: 0.5326 - val_loss: 3.4585 - val_accuracy: 0.5449\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.3107 - accuracy: 0.5541 - val_loss: 3.4350 - val_accuracy: 0.5590\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.2593 - accuracy: 0.5723 - val_loss: 3.6242 - val_accuracy: 0.5325\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 3.1834 - accuracy: 0.5949 - val_loss: 3.3486 - val_accuracy: 0.5901\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 3.1451 - accuracy: 0.5996 - val_loss: 3.7420 - val_accuracy: 0.5302\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.0890 - accuracy: 0.6166 - val_loss: 3.3592 - val_accuracy: 0.5890\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.0521 - accuracy: 0.6295 - val_loss: 3.1563 - val_accuracy: 0.6360\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 3.0009 - accuracy: 0.6475 - val_loss: 3.1894 - val_accuracy: 0.6276\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.9678 - accuracy: 0.6506 - val_loss: 3.1572 - val_accuracy: 0.6398\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.9411 - accuracy: 0.6579 - val_loss: 3.0641 - val_accuracy: 0.6556\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.8915 - accuracy: 0.6741 - val_loss: 3.1827 - val_accuracy: 0.6315\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.8420 - accuracy: 0.6885 - val_loss: 3.2019 - val_accuracy: 0.6294\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.8169 - accuracy: 0.6932 - val_loss: 2.8962 - val_accuracy: 0.6995\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.7846 - accuracy: 0.6966 - val_loss: 2.8634 - val_accuracy: 0.7000\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.7516 - accuracy: 0.7063 - val_loss: 2.8289 - val_accuracy: 0.7126\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.7285 - accuracy: 0.7151 - val_loss: 2.8237 - val_accuracy: 0.7191\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.6953 - accuracy: 0.7214 - val_loss: 2.7362 - val_accuracy: 0.7337\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.6663 - accuracy: 0.7290 - val_loss: 2.7173 - val_accuracy: 0.7374\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.6389 - accuracy: 0.7340 - val_loss: 2.7175 - val_accuracy: 0.7396\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.6024 - accuracy: 0.7448 - val_loss: 2.6693 - val_accuracy: 0.7420\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5918 - accuracy: 0.7462 - val_loss: 2.6677 - val_accuracy: 0.7474\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5654 - accuracy: 0.7511 - val_loss: 2.5995 - val_accuracy: 0.7621\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 2.5437 - accuracy: 0.7548 - val_loss: 2.6509 - val_accuracy: 0.7469\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.5132 - accuracy: 0.7612 - val_loss: 2.5489 - val_accuracy: 0.7694\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.5121 - accuracy: 0.7576 - val_loss: 2.6348 - val_accuracy: 0.7465\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4732 - accuracy: 0.7686 - val_loss: 2.5858 - val_accuracy: 0.7558\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.4570 - accuracy: 0.7722 - val_loss: 2.5675 - val_accuracy: 0.7602\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.4306 - accuracy: 0.7774 - val_loss: 2.5529 - val_accuracy: 0.7632\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.4176 - accuracy: 0.7769 - val_loss: 2.5077 - val_accuracy: 0.7737\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.3958 - accuracy: 0.7810 - val_loss: 2.4701 - val_accuracy: 0.7791\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.3667 - accuracy: 0.7898 - val_loss: 2.5015 - val_accuracy: 0.7703\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.3625 - accuracy: 0.7854 - val_loss: 2.4381 - val_accuracy: 0.7832\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.3341 - accuracy: 0.7932 - val_loss: 2.3945 - val_accuracy: 0.7990\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.3118 - accuracy: 0.7981 - val_loss: 2.3614 - val_accuracy: 0.8003\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3029 - accuracy: 0.7931 - val_loss: 2.3572 - val_accuracy: 0.7983\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.2844 - accuracy: 0.7982 - val_loss: 2.3388 - val_accuracy: 0.8034\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.2630 - accuracy: 0.8014 - val_loss: 2.3124 - val_accuracy: 0.8085\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.2499 - accuracy: 0.8037 - val_loss: 2.3570 - val_accuracy: 0.7930\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.2252 - accuracy: 0.8091 - val_loss: 2.3075 - val_accuracy: 0.8006\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.2166 - accuracy: 0.8108 - val_loss: 2.2866 - val_accuracy: 0.8031\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.2007 - accuracy: 0.8124 - val_loss: 2.2851 - val_accuracy: 0.8048\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.1801 - accuracy: 0.8165 - val_loss: 2.2218 - val_accuracy: 0.8167\n",
      "{'loss': [4.765742301940918, 4.232779502868652, 4.004805088043213, 3.841256618499756, 3.728098154067993, 3.6130530834198, 3.520113229751587, 3.4343347549438477, 3.3587918281555176, 3.294649124145508, 3.237969398498535, 3.172633171081543, 3.130988121032715, 3.0828545093536377, 3.039799451828003, 2.9952094554901123, 2.9554929733276367, 2.9226560592651367, 2.8867623805999756, 2.847411632537842, 2.812258005142212, 2.780456066131592, 2.744716167449951, 2.7206454277038574, 2.693803071975708, 2.6653037071228027, 2.6345627307891846, 2.6062891483306885, 2.584834337234497, 2.5649335384368896, 2.544154167175293, 2.517965316772461, 2.4938154220581055, 2.471169948577881, 2.453913450241089, 2.432199478149414, 2.410780906677246, 2.390946865081787, 2.373668909072876, 2.359234094619751, 2.3280038833618164, 2.311997175216675, 2.300664186477661, 2.276710271835327, 2.2622780799865723, 2.246095657348633, 2.2238779067993164, 2.2096505165100098, 2.193282127380371, 2.1721527576446533], 'accuracy': [0.19582499563694, 0.2794249951839447, 0.33842501044273376, 0.3795750141143799, 0.41370001435279846, 0.45262500643730164, 0.4824250042438507, 0.51214998960495, 0.5385000109672546, 0.5588499903678894, 0.5784000158309937, 0.5992000102996826, 0.606124997138977, 0.6207249760627747, 0.6353750228881836, 0.6471250057220459, 0.6549749970436096, 0.6636750102043152, 0.6746749877929688, 0.6853500008583069, 0.6952499747276306, 0.6996250152587891, 0.7098749876022339, 0.7168750166893005, 0.7213749885559082, 0.7275750041007996, 0.7368749976158142, 0.7416250109672546, 0.7469000220298767, 0.7511749863624573, 0.7531999945640564, 0.7589499950408936, 0.7636749744415283, 0.7679250240325928, 0.7725499868392944, 0.7771250009536743, 0.7783499956130981, 0.7821499705314636, 0.7858499884605408, 0.7868750095367432, 0.7943500280380249, 0.7962999939918518, 0.7942249774932861, 0.8005499839782715, 0.8014249801635742, 0.8040500283241272, 0.8089500069618225, 0.8119000196456909, 0.8141000270843506, 0.8183500170707703], 'val_loss': [4.176063060760498, 4.000134468078613, 4.1415486335754395, 4.025918960571289, 4.1411967277526855, 3.627251148223877, 4.091211795806885, 3.506319999694824, 3.4585375785827637, 3.434998035430908, 3.624173164367676, 3.3485758304595947, 3.741955518722534, 3.3591785430908203, 3.1563332080841064, 3.189359188079834, 3.1572494506835938, 3.0641438961029053, 3.1827049255371094, 3.2019362449645996, 2.8962364196777344, 2.863417863845825, 2.8288731575012207, 2.823655366897583, 2.7362139225006104, 2.717283248901367, 2.7174558639526367, 2.6693148612976074, 2.6677348613739014, 2.59946346282959, 2.6509265899658203, 2.548902750015259, 2.6347553730010986, 2.585846185684204, 2.5674989223480225, 2.55289626121521, 2.507667064666748, 2.470057725906372, 2.501523971557617, 2.4380905628204346, 2.3944690227508545, 2.3613762855529785, 2.3572025299072266, 2.3388407230377197, 2.312394380569458, 2.3569841384887695, 2.3075108528137207, 2.28658127784729, 2.2851216793060303, 2.22182559967041], 'val_accuracy': [0.2379000037908554, 0.29030001163482666, 0.2948000133037567, 0.3528999984264374, 0.36559998989105225, 0.4851999878883362, 0.41100001335144043, 0.529699981212616, 0.5449000000953674, 0.5590000152587891, 0.5325000286102295, 0.5900999903678894, 0.5302000045776367, 0.5889999866485596, 0.6359999775886536, 0.6276000142097473, 0.6398000121116638, 0.6556000113487244, 0.6315000057220459, 0.6294000148773193, 0.6995000243186951, 0.699999988079071, 0.7125999927520752, 0.7190999984741211, 0.7336999773979187, 0.7373999953269958, 0.7396000027656555, 0.7419999837875366, 0.7473999857902527, 0.7620999813079834, 0.7469000220298767, 0.7694000005722046, 0.7465000152587891, 0.7558000087738037, 0.760200023651123, 0.7631999850273132, 0.7736999988555908, 0.7791000008583069, 0.7702999711036682, 0.7832000255584717, 0.7990000247955322, 0.8003000020980835, 0.79830002784729, 0.8033999800682068, 0.8084999918937683, 0.7929999828338623, 0.800599992275238, 0.8030999898910522, 0.8047999739646912, 0.8166999816894531]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.8192\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import regularizers\n",
    "\n",
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('leaky-relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_vgg16_leaky.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
