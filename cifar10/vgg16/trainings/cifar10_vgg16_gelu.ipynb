{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "5fe2fbf4-06db-47dd-ce73-6802275ca76d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 7s 0us/step\n",
      "170508288/170498071 [==============================] - 7s 0us/step\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 129s 236ms/step - loss: 5.2805 - accuracy: 0.1284 - val_loss: 4.2420 - val_accuracy: 0.2190\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 4.3890 - accuracy: 0.2336 - val_loss: 4.3449 - val_accuracy: 0.2602\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 4.0777 - accuracy: 0.3063 - val_loss: 4.3696 - val_accuracy: 0.3007\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 3.9130 - accuracy: 0.3511 - val_loss: 4.3009 - val_accuracy: 0.2929\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 70s 224ms/step - loss: 3.7934 - accuracy: 0.3870 - val_loss: 3.9752 - val_accuracy: 0.3699\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 70s 224ms/step - loss: 3.6642 - accuracy: 0.4237 - val_loss: 4.2138 - val_accuracy: 0.3528\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 70s 224ms/step - loss: 3.5759 - accuracy: 0.4570 - val_loss: 4.1966 - val_accuracy: 0.3944\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 3.4795 - accuracy: 0.4919 - val_loss: 4.3090 - val_accuracy: 0.3758\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 3.3997 - accuracy: 0.5205 - val_loss: 4.0192 - val_accuracy: 0.4205\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 3.3467 - accuracy: 0.5444 - val_loss: 4.4877 - val_accuracy: 0.4461\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 3.2819 - accuracy: 0.5587 - val_loss: 4.2508 - val_accuracy: 0.4599\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 3.2133 - accuracy: 0.5844 - val_loss: 4.1364 - val_accuracy: 0.4845\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 3.1654 - accuracy: 0.6018 - val_loss: 3.6431 - val_accuracy: 0.5201\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 3.1022 - accuracy: 0.6219 - val_loss: 4.4549 - val_accuracy: 0.5027\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 3.0658 - accuracy: 0.6294 - val_loss: 3.9556 - val_accuracy: 0.5549\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 3.0267 - accuracy: 0.6434 - val_loss: 4.4963 - val_accuracy: 0.4720\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 2.9748 - accuracy: 0.6577 - val_loss: 3.6275 - val_accuracy: 0.5629\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.9224 - accuracy: 0.6695 - val_loss: 3.3793 - val_accuracy: 0.6154\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.8909 - accuracy: 0.6822 - val_loss: 3.2295 - val_accuracy: 0.6157\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.8548 - accuracy: 0.6837 - val_loss: 3.3679 - val_accuracy: 0.6147\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.8135 - accuracy: 0.6997 - val_loss: 3.1494 - val_accuracy: 0.6358\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.7763 - accuracy: 0.7118 - val_loss: 3.1850 - val_accuracy: 0.6333\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.7473 - accuracy: 0.7167 - val_loss: 2.9936 - val_accuracy: 0.6593\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 70s 224ms/step - loss: 2.7260 - accuracy: 0.7212 - val_loss: 2.9998 - val_accuracy: 0.6624\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.6754 - accuracy: 0.7371 - val_loss: 3.0974 - val_accuracy: 0.6515\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.6552 - accuracy: 0.7377 - val_loss: 2.8130 - val_accuracy: 0.7065\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.6300 - accuracy: 0.7446 - val_loss: 3.3837 - val_accuracy: 0.6079\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.5970 - accuracy: 0.7505 - val_loss: 2.8863 - val_accuracy: 0.6889\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 69s 221ms/step - loss: 2.5734 - accuracy: 0.7568 - val_loss: 2.7868 - val_accuracy: 0.7187\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.5395 - accuracy: 0.7620 - val_loss: 2.6855 - val_accuracy: 0.7376\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 2.5125 - accuracy: 0.7728 - val_loss: 2.9345 - val_accuracy: 0.6841\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.4995 - accuracy: 0.7719 - val_loss: 2.8115 - val_accuracy: 0.7158\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.4700 - accuracy: 0.7770 - val_loss: 2.6834 - val_accuracy: 0.7359\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.4584 - accuracy: 0.7800 - val_loss: 2.6931 - val_accuracy: 0.7304\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.4342 - accuracy: 0.7853 - val_loss: 2.5676 - val_accuracy: 0.7537\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.4133 - accuracy: 0.7882 - val_loss: 2.5755 - val_accuracy: 0.7586\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.3847 - accuracy: 0.7925 - val_loss: 2.5495 - val_accuracy: 0.7513\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.3653 - accuracy: 0.7966 - val_loss: 2.5056 - val_accuracy: 0.7733\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.3474 - accuracy: 0.8007 - val_loss: 2.6328 - val_accuracy: 0.7420\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 2.3224 - accuracy: 0.8034 - val_loss: 2.5461 - val_accuracy: 0.7609\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.3128 - accuracy: 0.8044 - val_loss: 2.5860 - val_accuracy: 0.7572\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 70s 222ms/step - loss: 2.2871 - accuracy: 0.8085 - val_loss: 2.7320 - val_accuracy: 0.7297\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 69s 221ms/step - loss: 2.2640 - accuracy: 0.8149 - val_loss: 2.4312 - val_accuracy: 0.7795\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 69s 221ms/step - loss: 2.2450 - accuracy: 0.8170 - val_loss: 2.5066 - val_accuracy: 0.7599\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.2292 - accuracy: 0.8206 - val_loss: 2.3595 - val_accuracy: 0.7915\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 69s 222ms/step - loss: 2.2099 - accuracy: 0.8262 - val_loss: 2.3593 - val_accuracy: 0.7923\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 69s 221ms/step - loss: 2.1953 - accuracy: 0.8211 - val_loss: 2.3179 - val_accuracy: 0.8046\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 69s 221ms/step - loss: 2.1731 - accuracy: 0.8308 - val_loss: 2.3288 - val_accuracy: 0.7987\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 69s 221ms/step - loss: 2.1503 - accuracy: 0.8345 - val_loss: 2.3492 - val_accuracy: 0.7927\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 69s 221ms/step - loss: 2.1329 - accuracy: 0.8383 - val_loss: 2.3071 - val_accuracy: 0.7997\n",
      "{'loss': [4.932751655578613, 4.290877819061279, 4.037783145904541, 3.8779594898223877, 3.7498726844787598, 3.6449077129364014, 3.5459258556365967, 3.4643938541412354, 3.400662899017334, 3.3287172317504883, 3.2713582515716553, 3.204420804977417, 3.1514580249786377, 3.095993757247925, 3.0465683937072754, 3.0045576095581055, 2.9610183238983154, 2.919525384902954, 2.879122734069824, 2.8446531295776367, 2.804354190826416, 2.7777099609375, 2.7371089458465576, 2.7138545513153076, 2.680189847946167, 2.6541309356689453, 2.631728410720825, 2.6030080318450928, 2.5691945552825928, 2.547992706298828, 2.5198681354522705, 2.498199939727783, 2.4702696800231934, 2.4503586292266846, 2.426403045654297, 2.4102671146392822, 2.388679027557373, 2.365692377090454, 2.3460350036621094, 2.3195347785949707, 2.3053791522979736, 2.2827465534210205, 2.2670516967773438, 2.2458057403564453, 2.2317099571228027, 2.2091989517211914, 2.192262649536133, 2.17360520362854, 2.153093099594116, 2.1424708366394043], 'accuracy': [0.16587500274181366, 0.25119999051094055, 0.3156749904155731, 0.35624998807907104, 0.39864999055862427, 0.4321500062942505, 0.46677500009536743, 0.49775001406669617, 0.5199000239372253, 0.5471000075340271, 0.5646250247955322, 0.5893750190734863, 0.6053500175476074, 0.6221500039100647, 0.6363250017166138, 0.647350013256073, 0.6602500081062317, 0.6719499826431274, 0.6841999888420105, 0.6899999976158142, 0.7026500105857849, 0.7083250284194946, 0.7195000052452087, 0.7247999906539917, 0.7323499917984009, 0.7373999953269958, 0.742900013923645, 0.7485499978065491, 0.7562249898910522, 0.7605500221252441, 0.7678750157356262, 0.7721750140190125, 0.7774500250816345, 0.7805749773979187, 0.7864999771118164, 0.7897250056266785, 0.7915250062942505, 0.7971000075340271, 0.7988499999046326, 0.8042749762535095, 0.8070499897003174, 0.8097249865531921, 0.8132500052452087, 0.8155249953269958, 0.8184750080108643, 0.8241999745368958, 0.8219000101089478, 0.8290500044822693, 0.8334749937057495, 0.8320500254631042], 'val_loss': [4.241976737976074, 4.344943046569824, 4.369596004486084, 4.300938606262207, 3.97522234916687, 4.213797092437744, 4.196626663208008, 4.308956623077393, 4.019196033477783, 4.487658500671387, 4.250816822052002, 4.136422634124756, 3.6431074142456055, 4.454946517944336, 3.955609083175659, 4.496336460113525, 3.627478837966919, 3.379303216934204, 3.2294974327087402, 3.3679442405700684, 3.1493678092956543, 3.1849873065948486, 2.9936420917510986, 2.9998013973236084, 3.097355365753174, 2.813040018081665, 3.3837053775787354, 2.8863377571105957, 2.786846399307251, 2.685507297515869, 2.9344944953918457, 2.811542272567749, 2.683387517929077, 2.6931114196777344, 2.567593812942505, 2.575472354888916, 2.549456834793091, 2.5056276321411133, 2.632810115814209, 2.5460751056671143, 2.5859503746032715, 2.7320001125335693, 2.4311509132385254, 2.5066070556640625, 2.359494209289551, 2.359282970428467, 2.3179097175598145, 2.328819513320923, 2.3492252826690674, 2.307053327560425], 'val_accuracy': [0.21899999678134918, 0.26019999384880066, 0.30070000886917114, 0.2928999960422516, 0.3698999881744385, 0.35280001163482666, 0.3944000005722046, 0.3758000135421753, 0.4205000102519989, 0.44609999656677246, 0.45989999175071716, 0.484499990940094, 0.5200999975204468, 0.5026999711990356, 0.5548999905586243, 0.47200000286102295, 0.5629000067710876, 0.6154000163078308, 0.6157000064849854, 0.6147000193595886, 0.6358000040054321, 0.6333000063896179, 0.6593000292778015, 0.6624000072479248, 0.6514999866485596, 0.7064999938011169, 0.6079000234603882, 0.6888999938964844, 0.7186999917030334, 0.7376000285148621, 0.6840999722480774, 0.7157999873161316, 0.7358999848365784, 0.730400025844574, 0.7537000179290771, 0.7585999965667725, 0.7512999773025513, 0.7732999920845032, 0.7419999837875366, 0.7609000205993652, 0.7572000026702881, 0.7297000288963318, 0.7795000076293945, 0.7598999738693237, 0.7914999723434448, 0.7922999858856201, 0.8046000003814697, 0.7986999750137329, 0.7926999926567078, 0.7997000217437744]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.7923\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import regularizers\n",
    "\n",
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('gelu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_vgg16_gelu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
