{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "900dd9e7-7360-457c-ac82-ea5487b94981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 54s 106ms/step - loss: 5.2043 - accuracy: 0.1751 - val_loss: 5.4358 - val_accuracy: 0.2079\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 4.2198 - accuracy: 0.3059 - val_loss: 4.8347 - val_accuracy: 0.2470\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 3.9108 - accuracy: 0.3679 - val_loss: 4.2013 - val_accuracy: 0.3385\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 3.7280 - accuracy: 0.4236 - val_loss: 4.1343 - val_accuracy: 0.3680\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.6049 - accuracy: 0.4654 - val_loss: 4.1423 - val_accuracy: 0.3979\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.4920 - accuracy: 0.5019 - val_loss: 4.5669 - val_accuracy: 0.3358\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 3.3983 - accuracy: 0.5318 - val_loss: 3.8820 - val_accuracy: 0.4427\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 3.3320 - accuracy: 0.5533 - val_loss: 3.7014 - val_accuracy: 0.4889\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 3.2650 - accuracy: 0.5730 - val_loss: 3.5528 - val_accuracy: 0.5107\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.2147 - accuracy: 0.5896 - val_loss: 3.7287 - val_accuracy: 0.4987\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.1714 - accuracy: 0.6028 - val_loss: 3.8576 - val_accuracy: 0.4882\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.1287 - accuracy: 0.6140 - val_loss: 3.5259 - val_accuracy: 0.5428\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 3.0732 - accuracy: 0.6283 - val_loss: 3.5863 - val_accuracy: 0.5399\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 3.0316 - accuracy: 0.6445 - val_loss: 3.6207 - val_accuracy: 0.5422\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 3.0021 - accuracy: 0.6485 - val_loss: 3.4395 - val_accuracy: 0.5703\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.9494 - accuracy: 0.6624 - val_loss: 3.4550 - val_accuracy: 0.5778\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.9175 - accuracy: 0.6745 - val_loss: 3.5084 - val_accuracy: 0.5740\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.8848 - accuracy: 0.6815 - val_loss: 3.2842 - val_accuracy: 0.6226\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.8404 - accuracy: 0.6916 - val_loss: 3.2547 - val_accuracy: 0.6187\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.8207 - accuracy: 0.6965 - val_loss: 3.3972 - val_accuracy: 0.5955\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.7737 - accuracy: 0.7083 - val_loss: 3.6170 - val_accuracy: 0.5717\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.7496 - accuracy: 0.7135 - val_loss: 3.0990 - val_accuracy: 0.6580\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.7158 - accuracy: 0.7240 - val_loss: 3.0244 - val_accuracy: 0.6769\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.6988 - accuracy: 0.7243 - val_loss: 2.8831 - val_accuracy: 0.7093\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.6770 - accuracy: 0.7266 - val_loss: 3.0652 - val_accuracy: 0.6689\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.6579 - accuracy: 0.7325 - val_loss: 2.9232 - val_accuracy: 0.7040\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.6097 - accuracy: 0.7483 - val_loss: 2.9417 - val_accuracy: 0.6909\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.6000 - accuracy: 0.7442 - val_loss: 2.8589 - val_accuracy: 0.7089\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5663 - accuracy: 0.7539 - val_loss: 2.9246 - val_accuracy: 0.6992\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.5369 - accuracy: 0.7562 - val_loss: 2.8309 - val_accuracy: 0.7145\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5277 - accuracy: 0.7598 - val_loss: 2.9040 - val_accuracy: 0.7079\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 2.5096 - accuracy: 0.7613 - val_loss: 2.8045 - val_accuracy: 0.7210\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 2.4815 - accuracy: 0.7685 - val_loss: 2.9590 - val_accuracy: 0.7018\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4559 - accuracy: 0.7712 - val_loss: 2.9595 - val_accuracy: 0.6998\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.4365 - accuracy: 0.7788 - val_loss: 2.7251 - val_accuracy: 0.7406\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4093 - accuracy: 0.7849 - val_loss: 2.7076 - val_accuracy: 0.7400\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.4077 - accuracy: 0.7815 - val_loss: 2.6433 - val_accuracy: 0.7582\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.3817 - accuracy: 0.7808 - val_loss: 3.0580 - val_accuracy: 0.6894\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3518 - accuracy: 0.7932 - val_loss: 2.8800 - val_accuracy: 0.7110\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.3256 - accuracy: 0.7981 - val_loss: 2.8381 - val_accuracy: 0.7142\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.3257 - accuracy: 0.7937 - val_loss: 2.6833 - val_accuracy: 0.7406\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.2983 - accuracy: 0.7984 - val_loss: 2.6329 - val_accuracy: 0.7501\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.2830 - accuracy: 0.8026 - val_loss: 2.6552 - val_accuracy: 0.7478\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.2831 - accuracy: 0.7996 - val_loss: 2.5825 - val_accuracy: 0.7637\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.2406 - accuracy: 0.8137 - val_loss: 2.6011 - val_accuracy: 0.7618\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.2340 - accuracy: 0.8111 - val_loss: 2.5781 - val_accuracy: 0.7644\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.2177 - accuracy: 0.8144 - val_loss: 2.6128 - val_accuracy: 0.7537\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.1901 - accuracy: 0.8180 - val_loss: 2.6243 - val_accuracy: 0.7515\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.1763 - accuracy: 0.8165 - val_loss: 2.5691 - val_accuracy: 0.7623\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.1676 - accuracy: 0.8190 - val_loss: 2.6183 - val_accuracy: 0.7464\n",
      "{'loss': [4.8130879402160645, 4.1248979568481445, 3.8634989261627197, 3.700413227081299, 3.5785269737243652, 3.4703328609466553, 3.3853042125701904, 3.3205173015594482, 3.2536983489990234, 3.2090401649475098, 3.1549458503723145, 3.1171493530273438, 3.068002700805664, 3.026235818862915, 2.991133451461792, 2.948105573654175, 2.9082136154174805, 2.8746488094329834, 2.8412787914276123, 2.806375503540039, 2.773085832595825, 2.7471923828125, 2.7169039249420166, 2.6910319328308105, 2.66978120803833, 2.6417198181152344, 2.61767315864563, 2.595928430557251, 2.5639688968658447, 2.5403823852539062, 2.5217647552490234, 2.5035839080810547, 2.4803051948547363, 2.452503204345703, 2.440513849258423, 2.413818597793579, 2.4024877548217773, 2.377504348754883, 2.3568012714385986, 2.338454008102417, 2.3242013454437256, 2.2986433506011963, 2.2783377170562744, 2.2713823318481445, 2.246885299682617, 2.232166051864624, 2.2151243686676025, 2.1971943378448486, 2.1827075481414795, 2.163123846054077], 'accuracy': [0.219650000333786, 0.3230000138282776, 0.3835499882698059, 0.43470001220703125, 0.4720250070095062, 0.508400022983551, 0.5357000231742859, 0.5583000183105469, 0.5772500038146973, 0.5916000008583069, 0.6077499985694885, 0.6181250214576721, 0.630649983882904, 0.644349992275238, 0.6522250175476074, 0.6622499823570251, 0.6742749810218811, 0.6831499934196472, 0.6907749772071838, 0.7002500295639038, 0.7066249847412109, 0.7123000025749207, 0.7217000126838684, 0.7250499725341797, 0.7293000221252441, 0.7362250089645386, 0.7432000041007996, 0.7457000017166138, 0.7538750171661377, 0.7566750049591064, 0.7610250115394592, 0.7624750137329102, 0.7673749923706055, 0.7734500169754028, 0.7756999731063843, 0.7825999855995178, 0.78329998254776, 0.7828750014305115, 0.7908750176429749, 0.7939500212669373, 0.7950999736785889, 0.8001000285148621, 0.8015750050544739, 0.8023750185966492, 0.8090000152587891, 0.8100249767303467, 0.8129249811172485, 0.8153499960899353, 0.8155500292778015, 0.8203750252723694], 'val_loss': [5.4358015060424805, 4.834722995758057, 4.201344966888428, 4.134303092956543, 4.142300128936768, 4.566929340362549, 3.8819589614868164, 3.701406717300415, 3.5527710914611816, 3.7286975383758545, 3.857616424560547, 3.5259430408477783, 3.5863499641418457, 3.620738983154297, 3.439472198486328, 3.454958915710449, 3.5084340572357178, 3.2841734886169434, 3.254669189453125, 3.397207498550415, 3.6170222759246826, 3.0989861488342285, 3.0243778228759766, 2.88309907913208, 3.06516432762146, 2.923220157623291, 2.941701889038086, 2.8588807582855225, 2.9246034622192383, 2.8308839797973633, 2.9039666652679443, 2.804471969604492, 2.9590206146240234, 2.9594905376434326, 2.725062847137451, 2.707620143890381, 2.643254518508911, 3.057985782623291, 2.880028486251831, 2.838073968887329, 2.68330717086792, 2.6329426765441895, 2.655231237411499, 2.5824508666992188, 2.601133346557617, 2.5780680179595947, 2.612776756286621, 2.6243417263031006, 2.5690619945526123, 2.6182618141174316], 'val_accuracy': [0.2079000025987625, 0.24699999392032623, 0.3384999930858612, 0.36800000071525574, 0.3978999853134155, 0.3357999920845032, 0.44269999861717224, 0.48890000581741333, 0.510699987411499, 0.49869999289512634, 0.48820000886917114, 0.5428000092506409, 0.539900004863739, 0.5422000288963318, 0.5702999830245972, 0.5777999758720398, 0.5740000009536743, 0.6226000189781189, 0.6187000274658203, 0.5954999923706055, 0.5716999769210815, 0.6579999923706055, 0.6769000291824341, 0.7092999815940857, 0.6689000129699707, 0.7039999961853027, 0.6909000277519226, 0.708899974822998, 0.6991999745368958, 0.7145000100135803, 0.7078999876976013, 0.7210000157356262, 0.7017999887466431, 0.6998000144958496, 0.7405999898910522, 0.7400000095367432, 0.7581999897956848, 0.6894000172615051, 0.7110000252723694, 0.7142000198364258, 0.7405999898910522, 0.7501000165939331, 0.7477999925613403, 0.763700008392334, 0.7617999911308289, 0.7644000053405762, 0.7537000179290771, 0.7515000104904175, 0.7623000144958496, 0.746399998664856]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.7302\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import regularizers\n",
    "\n",
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('elu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_vgg16_elu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
