{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "85925ec8-8578-4d90-843e-177b01d02966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "170508288/170498071 [==============================] - 4s 0us/step\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 83s 101ms/step - loss: 5.1429 - accuracy: 0.1354 - val_loss: 4.5798 - val_accuracy: 0.1373\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.3748 - accuracy: 0.2520 - val_loss: 4.5144 - val_accuracy: 0.1600\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 4.1374 - accuracy: 0.3087 - val_loss: 4.3708 - val_accuracy: 0.1990\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 3.9490 - accuracy: 0.3679 - val_loss: 4.1135 - val_accuracy: 0.2753\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.8207 - accuracy: 0.4098 - val_loss: 3.9104 - val_accuracy: 0.3511\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 3.7089 - accuracy: 0.4329 - val_loss: 3.7535 - val_accuracy: 0.4052\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.5933 - accuracy: 0.4739 - val_loss: 3.7231 - val_accuracy: 0.4185\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 3.5124 - accuracy: 0.5049 - val_loss: 3.6065 - val_accuracy: 0.4702\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.4253 - accuracy: 0.5325 - val_loss: 3.6786 - val_accuracy: 0.4711\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 3.3368 - accuracy: 0.5620 - val_loss: 3.6795 - val_accuracy: 0.4701\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 3.2310 - accuracy: 0.5832 - val_loss: 4.2745 - val_accuracy: 0.4367\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.1586 - accuracy: 0.6074 - val_loss: 3.9561 - val_accuracy: 0.4573\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 3.1132 - accuracy: 0.6180 - val_loss: 3.7405 - val_accuracy: 0.5138\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 3.0589 - accuracy: 0.6393 - val_loss: 3.5027 - val_accuracy: 0.5335\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.0078 - accuracy: 0.6491 - val_loss: 3.4575 - val_accuracy: 0.5761\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 2.9599 - accuracy: 0.6632 - val_loss: 3.4003 - val_accuracy: 0.5605\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.9304 - accuracy: 0.6708 - val_loss: 3.2422 - val_accuracy: 0.6045\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.8822 - accuracy: 0.6834 - val_loss: 3.1029 - val_accuracy: 0.6331\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 2.8480 - accuracy: 0.6929 - val_loss: 3.0325 - val_accuracy: 0.6610\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.8020 - accuracy: 0.7067 - val_loss: 2.9056 - val_accuracy: 0.6805\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.7771 - accuracy: 0.7095 - val_loss: 3.0580 - val_accuracy: 0.6486\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.7401 - accuracy: 0.7199 - val_loss: 2.9064 - val_accuracy: 0.6834\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.7159 - accuracy: 0.7262 - val_loss: 2.9802 - val_accuracy: 0.6649\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6791 - accuracy: 0.7324 - val_loss: 2.8450 - val_accuracy: 0.7025\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6440 - accuracy: 0.7455 - val_loss: 2.7698 - val_accuracy: 0.7184\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6257 - accuracy: 0.7480 - val_loss: 2.8778 - val_accuracy: 0.6988\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.5966 - accuracy: 0.7546 - val_loss: 2.9208 - val_accuracy: 0.6924\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5679 - accuracy: 0.7604 - val_loss: 2.9571 - val_accuracy: 0.6801\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.5349 - accuracy: 0.7654 - val_loss: 2.8122 - val_accuracy: 0.7134\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5276 - accuracy: 0.7664 - val_loss: 2.7578 - val_accuracy: 0.7256\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.4919 - accuracy: 0.7729 - val_loss: 2.8291 - val_accuracy: 0.7182\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4730 - accuracy: 0.7798 - val_loss: 2.7139 - val_accuracy: 0.7285\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.4387 - accuracy: 0.7873 - val_loss: 2.6520 - val_accuracy: 0.7468\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.4248 - accuracy: 0.7914 - val_loss: 2.5851 - val_accuracy: 0.7625\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4019 - accuracy: 0.7906 - val_loss: 2.7343 - val_accuracy: 0.7252\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.3779 - accuracy: 0.7951 - val_loss: 2.5464 - val_accuracy: 0.7663\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3556 - accuracy: 0.8010 - val_loss: 2.7027 - val_accuracy: 0.7341\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3384 - accuracy: 0.8039 - val_loss: 2.5186 - val_accuracy: 0.7737\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.3161 - accuracy: 0.8093 - val_loss: 2.5190 - val_accuracy: 0.7712\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.2973 - accuracy: 0.8096 - val_loss: 2.5071 - val_accuracy: 0.7767\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.2770 - accuracy: 0.8157 - val_loss: 2.5985 - val_accuracy: 0.7539\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.2436 - accuracy: 0.8217 - val_loss: 2.3995 - val_accuracy: 0.7969\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.2497 - accuracy: 0.8172 - val_loss: 2.4836 - val_accuracy: 0.7767\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.2287 - accuracy: 0.8230 - val_loss: 2.4241 - val_accuracy: 0.7852\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.1998 - accuracy: 0.8261 - val_loss: 2.4580 - val_accuracy: 0.7847\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.1816 - accuracy: 0.8325 - val_loss: 2.4157 - val_accuracy: 0.7888\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.1667 - accuracy: 0.8319 - val_loss: 2.3995 - val_accuracy: 0.7909\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.1413 - accuracy: 0.8369 - val_loss: 2.3804 - val_accuracy: 0.7894\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.1259 - accuracy: 0.8417 - val_loss: 2.4455 - val_accuracy: 0.7796\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.1239 - accuracy: 0.8373 - val_loss: 2.3259 - val_accuracy: 0.8011\n",
      "{'loss': [4.858515739440918, 4.309426784515381, 4.084926128387451, 3.9105429649353027, 3.7874855995178223, 3.681170701980591, 3.574509382247925, 3.489161252975464, 3.4011731147766113, 3.3165104389190674, 3.218088150024414, 3.1565115451812744, 3.0969762802124023, 3.04496431350708, 3.0009403228759766, 2.954955816268921, 2.9115700721740723, 2.8705859184265137, 2.841315746307373, 2.8046770095825195, 2.771456480026245, 2.7367100715637207, 2.710015296936035, 2.67695689201355, 2.6439900398254395, 2.6216506958007812, 2.5949153900146484, 2.566289186477661, 2.5401108264923096, 2.5163094997406006, 2.4884090423583984, 2.4692845344543457, 2.443854808807373, 2.425919771194458, 2.3978374004364014, 2.3750243186950684, 2.355583906173706, 2.3350143432617188, 2.3156235218048096, 2.294957160949707, 2.276221513748169, 2.252293825149536, 2.241802453994751, 2.222374439239502, 2.1934869289398193, 2.182278633117676, 2.166165828704834, 2.143019199371338, 2.1221442222595215, 2.118645429611206], 'accuracy': [0.17442500591278076, 0.2664250135421753, 0.3226499855518341, 0.3806000053882599, 0.4201500117778778, 0.44632500410079956, 0.48192501068115234, 0.5123999714851379, 0.5388749837875366, 0.5651999711990356, 0.5872750282287598, 0.6075000166893005, 0.6223250031471252, 0.6431750059127808, 0.6512249708175659, 0.6649749875068665, 0.6764749884605408, 0.6866000294685364, 0.6951249837875366, 0.7044000029563904, 0.7117249965667725, 0.7198500037193298, 0.7279999852180481, 0.7326499819755554, 0.7432500123977661, 0.74795001745224, 0.7549499869346619, 0.7597249746322632, 0.7656000256538391, 0.7703499794006348, 0.7740499973297119, 0.7794250249862671, 0.7837250232696533, 0.7900999784469604, 0.7917500138282776, 0.795074999332428, 0.8011500239372253, 0.8057249784469604, 0.8092749714851379, 0.8112499713897705, 0.8146250247955322, 0.8209750056266785, 0.8191999793052673, 0.8233500123023987, 0.828125, 0.8305000066757202, 0.8316249847412109, 0.8354250192642212, 0.8406999707221985, 0.8381500244140625], 'val_loss': [4.579785346984863, 4.514434337615967, 4.370772838592529, 4.113525390625, 3.9104180335998535, 3.7534992694854736, 3.7230894565582275, 3.606475353240967, 3.6786422729492188, 3.6795108318328857, 4.274463176727295, 3.956090211868286, 3.740549325942993, 3.502664089202881, 3.457542896270752, 3.400345802307129, 3.242171287536621, 3.102900266647339, 3.032463788986206, 2.905599355697632, 3.0580248832702637, 2.906446695327759, 2.9802472591400146, 2.8449532985687256, 2.7697949409484863, 2.877823829650879, 2.9208085536956787, 2.9571304321289062, 2.812208652496338, 2.7578275203704834, 2.8291118144989014, 2.713850259780884, 2.6520462036132812, 2.585069179534912, 2.734276294708252, 2.5464208126068115, 2.702693462371826, 2.5185794830322266, 2.5190412998199463, 2.507071018218994, 2.5985333919525146, 2.399526834487915, 2.4835946559906006, 2.424077272415161, 2.457974910736084, 2.415709972381592, 2.3994507789611816, 2.380406379699707, 2.4455037117004395, 2.3259167671203613], 'val_accuracy': [0.13729999959468842, 0.1599999964237213, 0.19900000095367432, 0.275299996137619, 0.35109999775886536, 0.4052000045776367, 0.41850000619888306, 0.4702000021934509, 0.47110000252723694, 0.4700999855995178, 0.4366999864578247, 0.45730000734329224, 0.5138000249862671, 0.5335000157356262, 0.5760999917984009, 0.5605000257492065, 0.6044999957084656, 0.6330999732017517, 0.6610000133514404, 0.6804999709129333, 0.6485999822616577, 0.6833999752998352, 0.664900004863739, 0.7024999856948853, 0.7184000015258789, 0.6988000273704529, 0.6923999786376953, 0.6801000237464905, 0.7134000062942505, 0.725600004196167, 0.7182000279426575, 0.7285000085830688, 0.7468000054359436, 0.762499988079071, 0.7251999974250793, 0.7663000226020813, 0.7340999841690063, 0.7736999988555908, 0.7712000012397766, 0.7767000198364258, 0.7538999915122986, 0.7968999743461609, 0.7767000198364258, 0.7851999998092651, 0.7846999764442444, 0.7888000011444092, 0.7908999919891357, 0.7893999814987183, 0.7796000242233276, 0.8011000156402588]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.8031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import regularizers\n",
    "\n",
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('swish')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_vgg16_swish.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
