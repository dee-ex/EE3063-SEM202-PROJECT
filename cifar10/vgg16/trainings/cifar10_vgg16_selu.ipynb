{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "113a77ea-aad7-410b-f328-f0dc4a74646a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 55s 101ms/step - loss: 5.2318 - accuracy: 0.1688 - val_loss: 5.4412 - val_accuracy: 0.2041\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.2544 - accuracy: 0.2928 - val_loss: 4.1589 - val_accuracy: 0.3504\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.9279 - accuracy: 0.3594 - val_loss: 3.9274 - val_accuracy: 0.4112\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.7606 - accuracy: 0.4081 - val_loss: 4.1201 - val_accuracy: 0.3962\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.6300 - accuracy: 0.4506 - val_loss: 4.2230 - val_accuracy: 0.3803\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.5149 - accuracy: 0.4918 - val_loss: 3.7285 - val_accuracy: 0.4722\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 3.4393 - accuracy: 0.5135 - val_loss: 4.0737 - val_accuracy: 0.4122\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 3.3726 - accuracy: 0.5372 - val_loss: 4.0101 - val_accuracy: 0.4259\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.2829 - accuracy: 0.5693 - val_loss: 3.5322 - val_accuracy: 0.5319\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 3.2490 - accuracy: 0.5739 - val_loss: 3.8233 - val_accuracy: 0.4874\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 3.1831 - accuracy: 0.6011 - val_loss: 3.5841 - val_accuracy: 0.5237\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.1387 - accuracy: 0.6070 - val_loss: 3.6696 - val_accuracy: 0.5252\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.0951 - accuracy: 0.6225 - val_loss: 3.4793 - val_accuracy: 0.5597\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 3.0607 - accuracy: 0.6306 - val_loss: 3.7915 - val_accuracy: 0.5084\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.0145 - accuracy: 0.6432 - val_loss: 3.7444 - val_accuracy: 0.5350\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.9677 - accuracy: 0.6584 - val_loss: 3.5378 - val_accuracy: 0.5607\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.9440 - accuracy: 0.6589 - val_loss: 3.2711 - val_accuracy: 0.6152\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 2.8945 - accuracy: 0.6767 - val_loss: 3.2290 - val_accuracy: 0.6262\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.8639 - accuracy: 0.6815 - val_loss: 3.4637 - val_accuracy: 0.5731\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.8340 - accuracy: 0.6894 - val_loss: 3.2433 - val_accuracy: 0.6296\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.8116 - accuracy: 0.6967 - val_loss: 3.1417 - val_accuracy: 0.6431\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.7849 - accuracy: 0.7009 - val_loss: 3.3096 - val_accuracy: 0.6068\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 2.7609 - accuracy: 0.7051 - val_loss: 3.4692 - val_accuracy: 0.5927\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.7171 - accuracy: 0.7195 - val_loss: 3.2798 - val_accuracy: 0.6251\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.7044 - accuracy: 0.7166 - val_loss: 2.9506 - val_accuracy: 0.6882\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.6668 - accuracy: 0.7245 - val_loss: 2.9858 - val_accuracy: 0.6827\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.6466 - accuracy: 0.7302 - val_loss: 3.0167 - val_accuracy: 0.6715\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.6349 - accuracy: 0.7300 - val_loss: 2.9683 - val_accuracy: 0.6890\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.5959 - accuracy: 0.7448 - val_loss: 2.7752 - val_accuracy: 0.7263\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.5708 - accuracy: 0.7448 - val_loss: 2.9888 - val_accuracy: 0.6761\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.5613 - accuracy: 0.7451 - val_loss: 2.9801 - val_accuracy: 0.6804\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.5322 - accuracy: 0.7561 - val_loss: 2.8773 - val_accuracy: 0.7029\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.5113 - accuracy: 0.7602 - val_loss: 2.8230 - val_accuracy: 0.7187\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.4950 - accuracy: 0.7584 - val_loss: 2.7639 - val_accuracy: 0.7258\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.4766 - accuracy: 0.7657 - val_loss: 2.7683 - val_accuracy: 0.7254\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4458 - accuracy: 0.7698 - val_loss: 2.8311 - val_accuracy: 0.7154\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4378 - accuracy: 0.7699 - val_loss: 2.7101 - val_accuracy: 0.7336\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.4207 - accuracy: 0.7742 - val_loss: 2.6853 - val_accuracy: 0.7346\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.3898 - accuracy: 0.7796 - val_loss: 2.6367 - val_accuracy: 0.7431\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.3768 - accuracy: 0.7814 - val_loss: 2.6667 - val_accuracy: 0.7414\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.3578 - accuracy: 0.7838 - val_loss: 2.7596 - val_accuracy: 0.7126\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.3500 - accuracy: 0.7819 - val_loss: 2.6426 - val_accuracy: 0.7422\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3200 - accuracy: 0.7909 - val_loss: 2.5452 - val_accuracy: 0.7611\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.3041 - accuracy: 0.7906 - val_loss: 2.5111 - val_accuracy: 0.7648\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.2923 - accuracy: 0.7930 - val_loss: 2.6077 - val_accuracy: 0.7451\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.2616 - accuracy: 0.7983 - val_loss: 2.5505 - val_accuracy: 0.7532\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.2466 - accuracy: 0.8029 - val_loss: 2.5215 - val_accuracy: 0.7625\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.2318 - accuracy: 0.8038 - val_loss: 2.5426 - val_accuracy: 0.7538\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.2195 - accuracy: 0.8077 - val_loss: 2.4700 - val_accuracy: 0.7711\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.1989 - accuracy: 0.8090 - val_loss: 2.4265 - val_accuracy: 0.7721\n",
      "{'loss': [4.85217809677124, 4.165505886077881, 3.893920660018921, 3.730252742767334, 3.6036887168884277, 3.4989914894104004, 3.410968780517578, 3.3425071239471436, 3.27984619140625, 3.2290186882019043, 3.1753482818603516, 3.1305530071258545, 3.086697578430176, 3.045562505722046, 3.007963180541992, 2.9680709838867188, 2.931943655014038, 2.8956594467163086, 2.868454694747925, 2.827636241912842, 2.8008370399475098, 2.777763605117798, 2.7468559741973877, 2.721327543258667, 2.696742296218872, 2.6678175926208496, 2.6479685306549072, 2.622131109237671, 2.597923517227173, 2.5768306255340576, 2.561485767364502, 2.5338022708892822, 2.5122618675231934, 2.492612600326538, 2.470489025115967, 2.4504971504211426, 2.432054281234741, 2.4161643981933594, 2.3970141410827637, 2.375950336456299, 2.3562772274017334, 2.344116449356079, 2.321913242340088, 2.305999517440796, 2.284832239151001, 2.264735221862793, 2.252086639404297, 2.2327404022216797, 2.2143115997314453, 2.204315662384033], 'accuracy': [0.21035000681877136, 0.3076249957084656, 0.369049996137619, 0.4175249934196472, 0.4610750079154968, 0.4985249936580658, 0.5240499973297119, 0.5469750165939331, 0.5685250163078308, 0.581250011920929, 0.6018499732017517, 0.611299991607666, 0.6240749955177307, 0.6363000273704529, 0.645924985408783, 0.6550250053405762, 0.662850022315979, 0.6754500269889832, 0.6793500185012817, 0.692674994468689, 0.7001000046730042, 0.7017499804496765, 0.7094749808311462, 0.7157250046730042, 0.7185500264167786, 0.7244750261306763, 0.7301999926567078, 0.7339000105857849, 0.7404249906539917, 0.7439749836921692, 0.748199999332428, 0.7538250088691711, 0.7588750123977661, 0.7600749731063843, 0.7660499811172485, 0.7682750225067139, 0.7711250185966492, 0.7741749882698059, 0.777999997138977, 0.7794749736785889, 0.781000018119812, 0.7827500104904175, 0.7889750003814697, 0.7905499935150146, 0.7953749895095825, 0.7990000247955322, 0.7988499999046326, 0.8016999959945679, 0.8064749836921692, 0.8060749769210815], 'val_loss': [5.441214084625244, 4.158914566040039, 3.9274027347564697, 4.120121955871582, 4.223038196563721, 3.728469133377075, 4.073709487915039, 4.0101189613342285, 3.532161235809326, 3.8232526779174805, 3.5841243267059326, 3.6695713996887207, 3.4792914390563965, 3.7915198802948, 3.7443511486053467, 3.537814140319824, 3.2711198329925537, 3.229022264480591, 3.4637258052825928, 3.2432525157928467, 3.1417489051818848, 3.3096234798431396, 3.469175338745117, 3.279789447784424, 2.95064640045166, 2.9857680797576904, 3.0167033672332764, 2.968302011489868, 2.775151252746582, 2.988844633102417, 2.9800894260406494, 2.8772897720336914, 2.823023796081543, 2.763882637023926, 2.7682526111602783, 2.83105206489563, 2.7100603580474854, 2.685271978378296, 2.636687755584717, 2.6667284965515137, 2.7596237659454346, 2.642592191696167, 2.545241594314575, 2.511107921600342, 2.6076769828796387, 2.55049991607666, 2.5215046405792236, 2.5425989627838135, 2.4700417518615723, 2.4265170097351074], 'val_accuracy': [0.20409999787807465, 0.35040000081062317, 0.41119998693466187, 0.3962000012397766, 0.38029998540878296, 0.4722000062465668, 0.412200003862381, 0.42590001225471497, 0.5318999886512756, 0.48739999532699585, 0.5236999988555908, 0.5252000093460083, 0.5597000122070312, 0.508400022983551, 0.5350000262260437, 0.560699999332428, 0.6151999831199646, 0.6262000203132629, 0.5730999708175659, 0.6295999884605408, 0.6431000232696533, 0.6068000197410583, 0.5927000045776367, 0.6251000165939331, 0.6881999969482422, 0.682699978351593, 0.671500027179718, 0.6890000104904175, 0.7263000011444092, 0.6761000156402588, 0.680400013923645, 0.7028999924659729, 0.7186999917030334, 0.7257999777793884, 0.7253999710083008, 0.715399980545044, 0.7336000204086304, 0.7346000075340271, 0.7430999875068665, 0.7414000034332275, 0.7125999927520752, 0.7422000169754028, 0.7610999941825867, 0.7648000121116638, 0.7451000213623047, 0.7531999945640564, 0.762499988079071, 0.7537999749183655, 0.7710999846458435, 0.7720999717712402]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.7649\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import regularizers\n",
    "\n",
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('selu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_vgg16_selu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
