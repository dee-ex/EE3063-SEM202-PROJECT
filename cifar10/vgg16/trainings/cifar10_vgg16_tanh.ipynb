{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "c234a106-2d77-4ba5-cce5-051d08abc96d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 12s 0us/step\n",
      "170508288/170498071 [==============================] - 12s 0us/step\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 108s 177ms/step - loss: 5.6250 - accuracy: 0.0992 - val_loss: 4.5504 - val_accuracy: 0.0976\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.9220 - accuracy: 0.0996 - val_loss: 4.4967 - val_accuracy: 0.0973\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.6730 - accuracy: 0.0980 - val_loss: 4.4735 - val_accuracy: 0.1019\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.5631 - accuracy: 0.0998 - val_loss: 4.4573 - val_accuracy: 0.0974\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.5031 - accuracy: 0.1012 - val_loss: 4.4438 - val_accuracy: 0.1013\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.4720 - accuracy: 0.0960 - val_loss: 4.4278 - val_accuracy: 0.1003\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.4474 - accuracy: 0.0984 - val_loss: 4.4155 - val_accuracy: 0.0974\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.4306 - accuracy: 0.0990 - val_loss: 4.4028 - val_accuracy: 0.0973\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.4168 - accuracy: 0.0996 - val_loss: 4.3906 - val_accuracy: 0.0973\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.4030 - accuracy: 0.1014 - val_loss: 4.3792 - val_accuracy: 0.1000\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.3871 - accuracy: 0.1003 - val_loss: 4.3632 - val_accuracy: 0.1058\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.3764 - accuracy: 0.1007 - val_loss: 4.3499 - val_accuracy: 0.1044\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.3629 - accuracy: 0.1020 - val_loss: 4.3374 - val_accuracy: 0.0967\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.3498 - accuracy: 0.0981 - val_loss: 4.3251 - val_accuracy: 0.0999\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.3385 - accuracy: 0.0974 - val_loss: 4.3130 - val_accuracy: 0.1006\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.3243 - accuracy: 0.0997 - val_loss: 4.3000 - val_accuracy: 0.0999\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.3122 - accuracy: 0.1038 - val_loss: 4.2875 - val_accuracy: 0.0995\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.3004 - accuracy: 0.0987 - val_loss: 4.2743 - val_accuracy: 0.1018\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.2878 - accuracy: 0.0996 - val_loss: 4.2621 - val_accuracy: 0.1008\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.2755 - accuracy: 0.1024 - val_loss: 4.2497 - val_accuracy: 0.1000\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.2635 - accuracy: 0.0995 - val_loss: 4.2391 - val_accuracy: 0.0974\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.2488 - accuracy: 0.1016 - val_loss: 4.2260 - val_accuracy: 0.0977\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.2391 - accuracy: 0.0973 - val_loss: 4.2146 - val_accuracy: 0.1019\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.2264 - accuracy: 0.0987 - val_loss: 4.2021 - val_accuracy: 0.1018\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.2173 - accuracy: 0.0974 - val_loss: 4.1913 - val_accuracy: 0.0973\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.2030 - accuracy: 0.1008 - val_loss: 4.1791 - val_accuracy: 0.0971\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.1911 - accuracy: 0.1003 - val_loss: 4.1665 - val_accuracy: 0.1057\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.1796 - accuracy: 0.0998 - val_loss: 4.1550 - val_accuracy: 0.1034\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 4.1670 - accuracy: 0.0998 - val_loss: 4.1442 - val_accuracy: 0.1027\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.1595 - accuracy: 0.0969 - val_loss: 4.1333 - val_accuracy: 0.1046\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.1465 - accuracy: 0.0948 - val_loss: 4.1219 - val_accuracy: 0.1000\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 4.1340 - accuracy: 0.1009 - val_loss: 4.1102 - val_accuracy: 0.0998\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.1230 - accuracy: 0.1009 - val_loss: 4.0982 - val_accuracy: 0.1007\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.1117 - accuracy: 0.1003 - val_loss: 4.0880 - val_accuracy: 0.1000\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.1006 - accuracy: 0.1016 - val_loss: 4.0762 - val_accuracy: 0.0988\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.0897 - accuracy: 0.0985 - val_loss: 4.0655 - val_accuracy: 0.1000\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 4.0806 - accuracy: 0.0984 - val_loss: 4.0536 - val_accuracy: 0.1014\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.0680 - accuracy: 0.1002 - val_loss: 4.0441 - val_accuracy: 0.0973\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 4.0574 - accuracy: 0.0981 - val_loss: 4.0336 - val_accuracy: 0.0973\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 4.0457 - accuracy: 0.1026 - val_loss: 4.0220 - val_accuracy: 0.0998\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 4.0346 - accuracy: 0.0994 - val_loss: 4.0113 - val_accuracy: 0.1001\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 4.0249 - accuracy: 0.0995 - val_loss: 4.0012 - val_accuracy: 0.1021\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 51s 161ms/step - loss: 4.0143 - accuracy: 0.1010 - val_loss: 3.9897 - val_accuracy: 0.1000\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 4.0013 - accuracy: 0.1025 - val_loss: 3.9799 - val_accuracy: 0.1052\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 3.9929 - accuracy: 0.1007 - val_loss: 3.9694 - val_accuracy: 0.0981\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 3.9814 - accuracy: 0.1017 - val_loss: 3.9584 - val_accuracy: 0.1005\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 3.9702 - accuracy: 0.1030 - val_loss: 3.9478 - val_accuracy: 0.0986\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 3.9601 - accuracy: 0.1000 - val_loss: 3.9372 - val_accuracy: 0.1008\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 3.9522 - accuracy: 0.1007 - val_loss: 3.9271 - val_accuracy: 0.1026\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 3.9407 - accuracy: 0.0992 - val_loss: 3.9169 - val_accuracy: 0.1019\n",
      "{'loss': [5.401231288909912, 4.840610504150391, 4.639318466186523, 4.5466084480285645, 4.494863510131836, 4.467088222503662, 4.444155693054199, 4.426782608032227, 4.4128737449646, 4.399763107299805, 4.384521007537842, 4.371964931488037, 4.360018253326416, 4.34696102142334, 4.334628582000732, 4.321104049682617, 4.309389114379883, 4.297101974487305, 4.284152507781982, 4.272254467010498, 4.259995460510254, 4.246618270874023, 4.236789226531982, 4.222909927368164, 4.2135162353515625, 4.200171947479248, 4.188224792480469, 4.177184581756592, 4.164426326751709, 4.155115604400635, 4.143315315246582, 4.130984783172607, 4.121153831481934, 4.106906414031982, 4.096757411956787, 4.08696985244751, 4.07668924331665, 4.063845634460449, 4.0532026290893555, 4.042479515075684, 4.032768249511719, 4.021754741668701, 4.011349678039551, 3.999376058578491, 3.9895808696746826, 3.978996992111206, 3.969529390335083, 3.957552433013916, 3.9491629600524902, 3.9392645359039307], 'accuracy': [0.09849999845027924, 0.09972500056028366, 0.09825000166893005, 0.09907499700784683, 0.10077500343322754, 0.09594999998807907, 0.09767500311136246, 0.09934999793767929, 0.1006999984383583, 0.09947499632835388, 0.10067500174045563, 0.10234999656677246, 0.10217499732971191, 0.09917499870061874, 0.09884999692440033, 0.10085000097751617, 0.10225000232458115, 0.09915000200271606, 0.09932500123977661, 0.10140000283718109, 0.10037499666213989, 0.10114999860525131, 0.09969999641180038, 0.09952499717473984, 0.09769999980926514, 0.10032500326633453, 0.10257499665021896, 0.09907499700784683, 0.10147500038146973, 0.09942500293254852, 0.09674999862909317, 0.10109999775886536, 0.09934999793767929, 0.10227499902248383, 0.10217499732971191, 0.0996749997138977, 0.09844999760389328, 0.10135000199079514, 0.09907499700784683, 0.10225000232458115, 0.0986500009894371, 0.09952499717473984, 0.0994499996304512, 0.10244999825954437, 0.10180000215768814, 0.10112500190734863, 0.10005000233650208, 0.10027500241994858, 0.09984999895095825, 0.09777499735355377], 'val_loss': [4.550434589385986, 4.496650218963623, 4.473461627960205, 4.457309246063232, 4.443759918212891, 4.427834987640381, 4.415487289428711, 4.402794361114502, 4.3905744552612305, 4.379192352294922, 4.363208293914795, 4.349930286407471, 4.337365627288818, 4.325066566467285, 4.312976360321045, 4.300018787384033, 4.2874755859375, 4.274328231811523, 4.262085437774658, 4.249663829803467, 4.2391486167907715, 4.225983619689941, 4.214592456817627, 4.202080249786377, 4.191286087036133, 4.1790618896484375, 4.166495323181152, 4.155049800872803, 4.144233226776123, 4.1332502365112305, 4.121863842010498, 4.110179424285889, 4.098196983337402, 4.08798360824585, 4.076216220855713, 4.0655412673950195, 4.053584575653076, 4.04409646987915, 4.033593654632568, 4.021975994110107, 4.011290550231934, 4.00121545791626, 3.98974347114563, 3.9799065589904785, 3.969435930252075, 3.9583799839019775, 3.9477999210357666, 3.9372031688690186, 3.927064895629883, 3.916917085647583], 'val_accuracy': [0.09759999811649323, 0.09730000048875809, 0.10189999639987946, 0.09740000218153, 0.10130000114440918, 0.10029999911785126, 0.09740000218153, 0.09730000048875809, 0.09730000048875809, 0.10000000149011612, 0.10580000281333923, 0.10440000146627426, 0.09669999778270721, 0.09989999979734421, 0.1005999967455864, 0.09989999979734421, 0.09950000047683716, 0.10180000215768814, 0.10080000013113022, 0.10000000149011612, 0.09740000218153, 0.09769999980926514, 0.10189999639987946, 0.10180000215768814, 0.09730000048875809, 0.09709999710321426, 0.10570000112056732, 0.10339999943971634, 0.10270000249147415, 0.10459999740123749, 0.10000000149011612, 0.0997999981045723, 0.1006999984383583, 0.10000000149011612, 0.09880000352859497, 0.10000000149011612, 0.10140000283718109, 0.09730000048875809, 0.09730000048875809, 0.0997999981045723, 0.10010000318288803, 0.10209999978542328, 0.10000000149011612, 0.10520000010728836, 0.09809999912977219, 0.10050000250339508, 0.09860000014305115, 0.10080000013113022, 0.10260000079870224, 0.10189999639987946]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.1002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import regularizers\n",
    "\n",
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('tanh')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_vgg16_selu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
