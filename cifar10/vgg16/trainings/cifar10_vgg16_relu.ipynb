{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "5bce9dc4-ca4c-424a-d70d-4f51fb7a0399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "170508288/170498071 [==============================] - 4s 0us/step\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 84s 105ms/step - loss: 5.2076 - accuracy: 0.1509 - val_loss: 4.2199 - val_accuracy: 0.2311\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 4.3530 - accuracy: 0.2519 - val_loss: 3.9949 - val_accuracy: 0.3133\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 4.0694 - accuracy: 0.3145 - val_loss: 3.8648 - val_accuracy: 0.3711\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 3.8759 - accuracy: 0.3647 - val_loss: 4.3718 - val_accuracy: 0.3269\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.7719 - accuracy: 0.4003 - val_loss: 3.8793 - val_accuracy: 0.4099\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 3.6679 - accuracy: 0.4297 - val_loss: 4.6196 - val_accuracy: 0.3453\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.5818 - accuracy: 0.4627 - val_loss: 4.3209 - val_accuracy: 0.3709\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.5049 - accuracy: 0.4895 - val_loss: 5.1132 - val_accuracy: 0.3844\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 3.4380 - accuracy: 0.5157 - val_loss: 4.2074 - val_accuracy: 0.4540\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 3.3680 - accuracy: 0.5318 - val_loss: 4.4041 - val_accuracy: 0.4718\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 3.3118 - accuracy: 0.5596 - val_loss: 4.1176 - val_accuracy: 0.4886\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.2495 - accuracy: 0.5710 - val_loss: 4.3600 - val_accuracy: 0.4734\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.1904 - accuracy: 0.5946 - val_loss: 4.3694 - val_accuracy: 0.4303\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 3.1539 - accuracy: 0.6007 - val_loss: 4.3724 - val_accuracy: 0.5078\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 3.1087 - accuracy: 0.6180 - val_loss: 3.6027 - val_accuracy: 0.5380\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 3.0728 - accuracy: 0.6256 - val_loss: 3.4582 - val_accuracy: 0.5867\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 3.0219 - accuracy: 0.6440 - val_loss: 3.3666 - val_accuracy: 0.6106\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.9872 - accuracy: 0.6522 - val_loss: 3.6121 - val_accuracy: 0.5866\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.9449 - accuracy: 0.6610 - val_loss: 4.1492 - val_accuracy: 0.5438\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.9091 - accuracy: 0.6684 - val_loss: 3.5867 - val_accuracy: 0.5826\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.8869 - accuracy: 0.6730 - val_loss: 3.5437 - val_accuracy: 0.5802\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.8383 - accuracy: 0.6889 - val_loss: 3.4414 - val_accuracy: 0.6292\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.7960 - accuracy: 0.6993 - val_loss: 3.1528 - val_accuracy: 0.6464\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.7756 - accuracy: 0.7039 - val_loss: 3.2270 - val_accuracy: 0.6298\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.7433 - accuracy: 0.7140 - val_loss: 3.1473 - val_accuracy: 0.6660\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.7166 - accuracy: 0.7186 - val_loss: 3.0206 - val_accuracy: 0.6711\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.6981 - accuracy: 0.7224 - val_loss: 3.2222 - val_accuracy: 0.6576\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.6658 - accuracy: 0.7277 - val_loss: 3.0485 - val_accuracy: 0.6498\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.6338 - accuracy: 0.7360 - val_loss: 3.0674 - val_accuracy: 0.6779\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.5939 - accuracy: 0.7455 - val_loss: 3.0112 - val_accuracy: 0.6887\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5836 - accuracy: 0.7475 - val_loss: 2.9377 - val_accuracy: 0.6948\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.5594 - accuracy: 0.7520 - val_loss: 2.8035 - val_accuracy: 0.7123\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5324 - accuracy: 0.7548 - val_loss: 2.8317 - val_accuracy: 0.7060\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.5050 - accuracy: 0.7678 - val_loss: 2.7088 - val_accuracy: 0.7336\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.4950 - accuracy: 0.7656 - val_loss: 2.7331 - val_accuracy: 0.7294\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4624 - accuracy: 0.7687 - val_loss: 2.6759 - val_accuracy: 0.7402\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4494 - accuracy: 0.7740 - val_loss: 2.6144 - val_accuracy: 0.7523\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4288 - accuracy: 0.7778 - val_loss: 2.7729 - val_accuracy: 0.7281\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4031 - accuracy: 0.7821 - val_loss: 2.7052 - val_accuracy: 0.7392\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3808 - accuracy: 0.7888 - val_loss: 2.5052 - val_accuracy: 0.7715\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.3655 - accuracy: 0.7883 - val_loss: 2.5702 - val_accuracy: 0.7558\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.3395 - accuracy: 0.7947 - val_loss: 2.5591 - val_accuracy: 0.7630\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.3266 - accuracy: 0.7967 - val_loss: 2.6086 - val_accuracy: 0.7546\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.3037 - accuracy: 0.7997 - val_loss: 2.5158 - val_accuracy: 0.7604\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.2842 - accuracy: 0.7997 - val_loss: 2.4603 - val_accuracy: 0.7758\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.2714 - accuracy: 0.8035 - val_loss: 2.4441 - val_accuracy: 0.7861\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.2573 - accuracy: 0.8089 - val_loss: 2.4472 - val_accuracy: 0.7794\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.2384 - accuracy: 0.8088 - val_loss: 2.3758 - val_accuracy: 0.7940\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.2201 - accuracy: 0.8149 - val_loss: 2.3966 - val_accuracy: 0.7844\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.1979 - accuracy: 0.8153 - val_loss: 2.3503 - val_accuracy: 0.7937\n",
      "{'loss': [4.86023473739624, 4.270116329193115, 4.022495746612549, 3.8499581813812256, 3.751255512237549, 3.6515374183654785, 3.565810203552246, 3.4866371154785156, 3.419370651245117, 3.3514106273651123, 3.29795503616333, 3.23895263671875, 3.1916561126708984, 3.14701509475708, 3.0979537963867188, 3.054699420928955, 3.0140652656555176, 2.9794585704803467, 2.9409022331237793, 2.904130697250366, 2.8703112602233887, 2.84140682220459, 2.800581216812134, 2.776175022125244, 2.746169090270996, 2.706965684890747, 2.6844940185546875, 2.6594161987304688, 2.62917423248291, 2.6039679050445557, 2.5852718353271484, 2.5600688457489014, 2.532407522201538, 2.5072927474975586, 2.4843204021453857, 2.4718778133392334, 2.442185640335083, 2.425471067428589, 2.4017975330352783, 2.37955641746521, 2.363518476486206, 2.34059739112854, 2.321460247039795, 2.307896375656128, 2.284684419631958, 2.269371747970581, 2.2528481483459473, 2.2347593307495117, 2.2152180671691895, 2.195725679397583], 'accuracy': [0.18774999678134918, 0.267549991607666, 0.3268499970436096, 0.373075008392334, 0.40822499990463257, 0.43849998712539673, 0.468874990940094, 0.4968250095844269, 0.5217750072479248, 0.5412999987602234, 0.5611249804496765, 0.5773000121116638, 0.5942000150680542, 0.6049000024795532, 0.619949996471405, 0.6327000260353088, 0.6448249816894531, 0.6553999781608582, 0.6600750088691711, 0.6714500188827515, 0.6784499883651733, 0.6891999840736389, 0.6974499821662903, 0.702750027179718, 0.7117499709129333, 0.7184749841690063, 0.7261499762535095, 0.7296749949455261, 0.7369250059127808, 0.7425749897956848, 0.7466250061988831, 0.7496749758720398, 0.7554749846458435, 0.7633500099182129, 0.7674499750137329, 0.7670000195503235, 0.7755749821662903, 0.7773000001907349, 0.7820749878883362, 0.7869250178337097, 0.7884250283241272, 0.7929750084877014, 0.7972249984741211, 0.7977749705314636, 0.7994999885559082, 0.803974986076355, 0.8083000183105469, 0.8095750212669373, 0.8147249817848206, 0.8162500262260437], 'val_loss': [4.219939708709717, 3.994917154312134, 3.864849328994751, 4.37179708480835, 3.879319429397583, 4.619559288024902, 4.3209228515625, 5.113189220428467, 4.207429885864258, 4.404098033905029, 4.117606163024902, 4.359993934631348, 4.36944580078125, 4.3723907470703125, 3.602658987045288, 3.4582297801971436, 3.366604804992676, 3.6120641231536865, 4.149215221405029, 3.5866963863372803, 3.543748378753662, 3.4414379596710205, 3.152801036834717, 3.2269935607910156, 3.1472854614257812, 3.020594358444214, 3.222203016281128, 3.0485129356384277, 3.06740403175354, 3.0111894607543945, 2.9376792907714844, 2.803468942642212, 2.8316547870635986, 2.7087841033935547, 2.733109951019287, 2.6758644580841064, 2.61436128616333, 2.772928476333618, 2.7052035331726074, 2.5052437782287598, 2.570152521133423, 2.5590624809265137, 2.6085634231567383, 2.5157506465911865, 2.46026873588562, 2.444098711013794, 2.4471805095672607, 2.3758485317230225, 2.3965847492218018, 2.35025691986084], 'val_accuracy': [0.23109999299049377, 0.3133000135421753, 0.3711000084877014, 0.32690000534057617, 0.4099000096321106, 0.34529998898506165, 0.3709000051021576, 0.38440001010894775, 0.45399999618530273, 0.4717999994754791, 0.4885999858379364, 0.4733999967575073, 0.4302999973297119, 0.5077999830245972, 0.5379999876022339, 0.5867000222206116, 0.6105999946594238, 0.5866000056266785, 0.5437999963760376, 0.5825999975204468, 0.5802000164985657, 0.6291999816894531, 0.646399974822998, 0.629800021648407, 0.6660000085830688, 0.6711000204086304, 0.6575999855995178, 0.6498000025749207, 0.6779000163078308, 0.6887000203132629, 0.6948000192642212, 0.7123000025749207, 0.7059999704360962, 0.7336000204086304, 0.7293999791145325, 0.7401999831199646, 0.7523000240325928, 0.7281000018119812, 0.7391999959945679, 0.7714999914169312, 0.7558000087738037, 0.7630000114440918, 0.7545999884605408, 0.7603999972343445, 0.7757999897003174, 0.7860999703407288, 0.7793999910354614, 0.7940000295639038, 0.7843999862670898, 0.7936999797821045]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.7977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import regularizers\n",
    "\n",
    "def vgg16(act):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = vgg16('relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_vgg16_selu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
