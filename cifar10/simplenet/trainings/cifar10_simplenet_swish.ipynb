{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "ba4cf47c-2e49-40fb-a275-3760a92a7d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 108s 154ms/step - loss: 2.1885 - accuracy: 0.1850 - val_loss: 2.6981 - val_accuracy: 0.0991\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 1.7220 - accuracy: 0.3431 - val_loss: 3.3897 - val_accuracy: 0.1110\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 1.5547 - accuracy: 0.4154 - val_loss: 4.1795 - val_accuracy: 0.1207\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 1.3684 - accuracy: 0.4914 - val_loss: 3.9046 - val_accuracy: 0.1646\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 1.2067 - accuracy: 0.5537 - val_loss: 3.9161 - val_accuracy: 0.1869\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 1.0769 - accuracy: 0.6083 - val_loss: 2.8378 - val_accuracy: 0.2361\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.9770 - accuracy: 0.6443 - val_loss: 2.5375 - val_accuracy: 0.3144\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.9076 - accuracy: 0.6702 - val_loss: 2.7708 - val_accuracy: 0.2917\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.8461 - accuracy: 0.6949 - val_loss: 1.8916 - val_accuracy: 0.4252\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.8100 - accuracy: 0.7081 - val_loss: 2.4049 - val_accuracy: 0.3788\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.7587 - accuracy: 0.7315 - val_loss: 2.4082 - val_accuracy: 0.3711\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.7213 - accuracy: 0.7427 - val_loss: 2.2360 - val_accuracy: 0.3999\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.6967 - accuracy: 0.7512 - val_loss: 2.4109 - val_accuracy: 0.3778\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.6663 - accuracy: 0.7620 - val_loss: 2.1173 - val_accuracy: 0.4320\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.6273 - accuracy: 0.7769 - val_loss: 2.5440 - val_accuracy: 0.3770\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.6104 - accuracy: 0.7828 - val_loss: 1.5837 - val_accuracy: 0.5144\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.5802 - accuracy: 0.7936 - val_loss: 2.5390 - val_accuracy: 0.3924\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.5767 - accuracy: 0.7983 - val_loss: 1.6461 - val_accuracy: 0.5277\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.5521 - accuracy: 0.8057 - val_loss: 1.7297 - val_accuracy: 0.5273\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.5391 - accuracy: 0.8082 - val_loss: 1.5679 - val_accuracy: 0.5361\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.5158 - accuracy: 0.8186 - val_loss: 1.4101 - val_accuracy: 0.5837\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.4970 - accuracy: 0.8241 - val_loss: 1.3001 - val_accuracy: 0.5996\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.4888 - accuracy: 0.8279 - val_loss: 1.4406 - val_accuracy: 0.5746\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.4615 - accuracy: 0.8379 - val_loss: 1.2477 - val_accuracy: 0.6201\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.4571 - accuracy: 0.8417 - val_loss: 1.5565 - val_accuracy: 0.5700\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.4511 - accuracy: 0.8442 - val_loss: 1.1290 - val_accuracy: 0.6485\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.4440 - accuracy: 0.8449 - val_loss: 1.0948 - val_accuracy: 0.6582\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.4296 - accuracy: 0.8481 - val_loss: 1.2244 - val_accuracy: 0.6263\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.4243 - accuracy: 0.8538 - val_loss: 1.1583 - val_accuracy: 0.6466\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.4174 - accuracy: 0.8531 - val_loss: 1.2768 - val_accuracy: 0.6341\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.3950 - accuracy: 0.8615 - val_loss: 1.5936 - val_accuracy: 0.5608\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.3831 - accuracy: 0.8652 - val_loss: 1.2269 - val_accuracy: 0.6176\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.3816 - accuracy: 0.8653 - val_loss: 1.0552 - val_accuracy: 0.6796\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.3791 - accuracy: 0.8665 - val_loss: 1.0174 - val_accuracy: 0.6904\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.3622 - accuracy: 0.8735 - val_loss: 1.1106 - val_accuracy: 0.6681\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.3551 - accuracy: 0.8750 - val_loss: 0.9535 - val_accuracy: 0.7010\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.3520 - accuracy: 0.8760 - val_loss: 0.8193 - val_accuracy: 0.7457\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.3450 - accuracy: 0.8798 - val_loss: 1.0474 - val_accuracy: 0.6787\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.3440 - accuracy: 0.8785 - val_loss: 0.9663 - val_accuracy: 0.7017\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.3257 - accuracy: 0.8847 - val_loss: 1.0242 - val_accuracy: 0.6917\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.3315 - accuracy: 0.8866 - val_loss: 0.9696 - val_accuracy: 0.7049\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.3191 - accuracy: 0.8867 - val_loss: 0.9807 - val_accuracy: 0.7113\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.3134 - accuracy: 0.8894 - val_loss: 0.9528 - val_accuracy: 0.7154\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.3071 - accuracy: 0.8915 - val_loss: 1.3573 - val_accuracy: 0.6287\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.3024 - accuracy: 0.8927 - val_loss: 0.9695 - val_accuracy: 0.7036\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.2941 - accuracy: 0.8961 - val_loss: 1.0741 - val_accuracy: 0.6900\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.2943 - accuracy: 0.8965 - val_loss: 1.0307 - val_accuracy: 0.7056\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.2923 - accuracy: 0.8964 - val_loss: 0.8941 - val_accuracy: 0.7312\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.2902 - accuracy: 0.8969 - val_loss: 0.9892 - val_accuracy: 0.7112\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.2747 - accuracy: 0.9015 - val_loss: 0.8305 - val_accuracy: 0.7394\n",
      "{'loss': [2.051804780960083, 1.6814683675765991, 1.5120669603347778, 1.331717848777771, 1.1745798587799072, 1.0569740533828735, 0.96291583776474, 0.8914675712585449, 0.8346219658851624, 0.7911596298217773, 0.7520519495010376, 0.7173848152160645, 0.6853843331336975, 0.6614410877227783, 0.628750741481781, 0.6096063256263733, 0.5831466913223267, 0.5678207278251648, 0.5547469854354858, 0.5327656865119934, 0.5210683345794678, 0.5020487308502197, 0.4855961501598358, 0.47571495175361633, 0.4633850157260895, 0.45422059297561646, 0.4413636326789856, 0.4304887354373932, 0.42329883575439453, 0.4153389036655426, 0.39829227328300476, 0.39234402775764465, 0.3809589743614197, 0.3827345371246338, 0.36721277236938477, 0.3585039973258972, 0.3553304076194763, 0.34746336936950684, 0.34272339940071106, 0.3344719409942627, 0.3294309675693512, 0.3214842975139618, 0.31614363193511963, 0.3121185600757599, 0.3029032349586487, 0.29850542545318604, 0.29520291090011597, 0.2887710928916931, 0.28495749831199646, 0.2802610695362091], 'accuracy': [0.2350499927997589, 0.359375, 0.4327000081539154, 0.508525013923645, 0.569599986076355, 0.617775022983551, 0.6508499979972839, 0.6765249967575073, 0.6981250047683716, 0.7148000001907349, 0.732824981212616, 0.7435500025749207, 0.7564499974250793, 0.7646499872207642, 0.7752000093460083, 0.7843999862670898, 0.7941499948501587, 0.80035001039505, 0.8041750192642212, 0.8119500279426575, 0.8170999884605408, 0.8238750100135803, 0.8288499712944031, 0.8324000239372253, 0.8394250273704529, 0.8418750166893005, 0.8445249795913696, 0.8488500118255615, 0.8529750108718872, 0.8531749844551086, 0.8604000210762024, 0.8621249794960022, 0.8652999997138977, 0.8649250268936157, 0.871999979019165, 0.8733749985694885, 0.8750500082969666, 0.8790249824523926, 0.878849983215332, 0.8815749883651733, 0.8864250183105469, 0.8863499760627747, 0.888450026512146, 0.8905500173568726, 0.8931000232696533, 0.8948500156402588, 0.8965499997138977, 0.8985000252723694, 0.8988999724388123, 0.9010000228881836], 'val_loss': [2.6980791091918945, 3.389685869216919, 4.179522514343262, 3.9045610427856445, 3.916130781173706, 2.83782958984375, 2.537489175796509, 2.7708144187927246, 1.8916043043136597, 2.404909610748291, 2.408245086669922, 2.2359960079193115, 2.4108760356903076, 2.117305040359497, 2.544018507003784, 1.5836749076843262, 2.53895902633667, 1.6460505723953247, 1.7297296524047852, 1.5679078102111816, 1.41005539894104, 1.3000649213790894, 1.4405826330184937, 1.2476798295974731, 1.5565284490585327, 1.1289663314819336, 1.0948072671890259, 1.2243884801864624, 1.1582525968551636, 1.2768458127975464, 1.5935745239257812, 1.2269068956375122, 1.0552281141281128, 1.0174294710159302, 1.1105841398239136, 0.9534589052200317, 0.8193385601043701, 1.047445297241211, 0.966327428817749, 1.0242021083831787, 0.9696078896522522, 0.9806593060493469, 0.9527708292007446, 1.3573169708251953, 0.9695076942443848, 1.0741320848464966, 1.030733346939087, 0.8940778374671936, 0.989220142364502, 0.8305489420890808], 'val_accuracy': [0.09910000115633011, 0.11100000143051147, 0.12070000171661377, 0.16459999978542328, 0.18690000474452972, 0.2361000031232834, 0.31439998745918274, 0.29170000553131104, 0.4251999855041504, 0.37880000472068787, 0.3711000084877014, 0.39989998936653137, 0.37779998779296875, 0.4320000112056732, 0.37700000405311584, 0.5144000053405762, 0.39239999651908875, 0.5277000069618225, 0.5273000001907349, 0.5360999703407288, 0.5837000012397766, 0.5996000170707703, 0.5745999813079834, 0.6201000213623047, 0.5699999928474426, 0.6485000252723694, 0.6582000255584717, 0.6262999773025513, 0.6466000080108643, 0.6341000199317932, 0.5608000159263611, 0.6176000237464905, 0.6796000003814697, 0.6904000043869019, 0.6680999994277954, 0.7009999752044678, 0.7457000017166138, 0.6786999702453613, 0.70169997215271, 0.6916999816894531, 0.7049000263214111, 0.7113000154495239, 0.715399980545044, 0.6287000179290771, 0.7035999894142151, 0.6899999976158142, 0.7056000232696533, 0.7311999797821045, 0.7111999988555908, 0.7394000291824341]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.7418\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('swish')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_simplenet_swish.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
