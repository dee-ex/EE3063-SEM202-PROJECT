{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "9670ee58-56f3-4fea-d4c1-12208dc21307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 46s 134ms/step - loss: 2.0357 - accuracy: 0.2411 - val_loss: 3.0557 - val_accuracy: 0.1296\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.5508 - accuracy: 0.4141 - val_loss: 2.1311 - val_accuracy: 0.2615\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 1.3779 - accuracy: 0.4888 - val_loss: 1.7326 - val_accuracy: 0.3830\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.2209 - accuracy: 0.5546 - val_loss: 1.5216 - val_accuracy: 0.4516\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 1.1035 - accuracy: 0.5994 - val_loss: 1.6903 - val_accuracy: 0.4347\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.0144 - accuracy: 0.6376 - val_loss: 1.2665 - val_accuracy: 0.5469\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.9507 - accuracy: 0.6589 - val_loss: 1.5590 - val_accuracy: 0.4778\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.8974 - accuracy: 0.6761 - val_loss: 1.4051 - val_accuracy: 0.5129\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.8332 - accuracy: 0.7017 - val_loss: 1.1929 - val_accuracy: 0.5885\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.7932 - accuracy: 0.7158 - val_loss: 0.9934 - val_accuracy: 0.6454\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.7696 - accuracy: 0.7245 - val_loss: 1.2719 - val_accuracy: 0.5746\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.7374 - accuracy: 0.7390 - val_loss: 1.1223 - val_accuracy: 0.6077\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6956 - accuracy: 0.7529 - val_loss: 0.8530 - val_accuracy: 0.7033\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6813 - accuracy: 0.7579 - val_loss: 0.9086 - val_accuracy: 0.6805\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6626 - accuracy: 0.7665 - val_loss: 0.9405 - val_accuracy: 0.6836\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6394 - accuracy: 0.7760 - val_loss: 1.0444 - val_accuracy: 0.6421\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6315 - accuracy: 0.7758 - val_loss: 0.8151 - val_accuracy: 0.7133\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.6128 - accuracy: 0.7845 - val_loss: 0.8432 - val_accuracy: 0.7083\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.5812 - accuracy: 0.7944 - val_loss: 0.9200 - val_accuracy: 0.6902\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5735 - accuracy: 0.8004 - val_loss: 0.8039 - val_accuracy: 0.7184\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5579 - accuracy: 0.8004 - val_loss: 0.7868 - val_accuracy: 0.7309\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5539 - accuracy: 0.8040 - val_loss: 0.8637 - val_accuracy: 0.7026\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5357 - accuracy: 0.8116 - val_loss: 0.6680 - val_accuracy: 0.7716\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.5283 - accuracy: 0.8142 - val_loss: 0.8282 - val_accuracy: 0.7176\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.5196 - accuracy: 0.8192 - val_loss: 0.6444 - val_accuracy: 0.7773\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4963 - accuracy: 0.8229 - val_loss: 0.7167 - val_accuracy: 0.7543\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4990 - accuracy: 0.8250 - val_loss: 0.7280 - val_accuracy: 0.7516\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4802 - accuracy: 0.8324 - val_loss: 0.6229 - val_accuracy: 0.7820\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4734 - accuracy: 0.8327 - val_loss: 0.6620 - val_accuracy: 0.7717\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4638 - accuracy: 0.8359 - val_loss: 0.7050 - val_accuracy: 0.7613\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 41s 129ms/step - loss: 0.4688 - accuracy: 0.8364 - val_loss: 0.5941 - val_accuracy: 0.7933\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4641 - accuracy: 0.8383 - val_loss: 0.6598 - val_accuracy: 0.7762\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 41s 129ms/step - loss: 0.4492 - accuracy: 0.8443 - val_loss: 0.5530 - val_accuracy: 0.8100\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4394 - accuracy: 0.8447 - val_loss: 0.6272 - val_accuracy: 0.7875\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4321 - accuracy: 0.8474 - val_loss: 0.6913 - val_accuracy: 0.7632\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 41s 129ms/step - loss: 0.4140 - accuracy: 0.8534 - val_loss: 0.5648 - val_accuracy: 0.8053\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4090 - accuracy: 0.8584 - val_loss: 0.6685 - val_accuracy: 0.7727\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4124 - accuracy: 0.8573 - val_loss: 0.5542 - val_accuracy: 0.8088\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4035 - accuracy: 0.8607 - val_loss: 0.5709 - val_accuracy: 0.8035\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3946 - accuracy: 0.8647 - val_loss: 0.5909 - val_accuracy: 0.7942\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3930 - accuracy: 0.8613 - val_loss: 0.5757 - val_accuracy: 0.8025\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3872 - accuracy: 0.8632 - val_loss: 0.6107 - val_accuracy: 0.7974\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.3764 - accuracy: 0.8675 - val_loss: 0.7042 - val_accuracy: 0.7638\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3698 - accuracy: 0.8684 - val_loss: 0.5143 - val_accuracy: 0.8239\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3721 - accuracy: 0.8709 - val_loss: 0.6266 - val_accuracy: 0.7898\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.3671 - accuracy: 0.8724 - val_loss: 0.5648 - val_accuracy: 0.8107\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3512 - accuracy: 0.8779 - val_loss: 0.5120 - val_accuracy: 0.8243\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.3632 - accuracy: 0.8734 - val_loss: 0.5133 - val_accuracy: 0.8258\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3497 - accuracy: 0.8781 - val_loss: 0.5380 - val_accuracy: 0.8194\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.3464 - accuracy: 0.8799 - val_loss: 0.4877 - val_accuracy: 0.8330\n",
      "{'loss': [1.8534644842147827, 1.5149301290512085, 1.3426023721694946, 1.1955088376998901, 1.0836455821990967, 0.9986760020256042, 0.9387133717536926, 0.8835331201553345, 0.8296768665313721, 0.7919869422912598, 0.7641257047653198, 0.7290840148925781, 0.6999489665031433, 0.6840394735336304, 0.6637338399887085, 0.642533004283905, 0.6222341060638428, 0.6074017286300659, 0.5869656205177307, 0.5795511603355408, 0.5649641752243042, 0.5475966334342957, 0.5355036854743958, 0.5254300832748413, 0.5166221857070923, 0.5062403082847595, 0.4964236319065094, 0.4852405786514282, 0.48089584708213806, 0.46673330664634705, 0.4606110751628876, 0.45724087953567505, 0.444289892911911, 0.4366408586502075, 0.432171106338501, 0.4208999574184418, 0.4194682240486145, 0.4154540002346039, 0.40225154161453247, 0.40021735429763794, 0.3950120508670807, 0.3872848451137543, 0.3823045790195465, 0.374563992023468, 0.37161245942115784, 0.36970120668411255, 0.36173000931739807, 0.35547301173210144, 0.3482331931591034, 0.3467549681663513], 'accuracy': [0.3052250146865845, 0.4314500093460083, 0.5056999921798706, 0.5679749846458435, 0.6066250205039978, 0.6410999894142151, 0.6623749732971191, 0.6837999820709229, 0.7036749720573425, 0.7181749939918518, 0.7278000116348267, 0.741474986076355, 0.7512249946594238, 0.7592250108718872, 0.7652999758720398, 0.7743499875068665, 0.7804750204086304, 0.7874000072479248, 0.7914000153541565, 0.7969250082969666, 0.798799991607666, 0.8065249919891357, 0.8108999729156494, 0.8140000104904175, 0.8189749717712402, 0.8209499716758728, 0.8254250288009644, 0.8310999870300293, 0.8314250111579895, 0.8360249996185303, 0.8374249935150146, 0.8414999842643738, 0.8453249931335449, 0.8470500111579895, 0.8466749787330627, 0.8518499732017517, 0.8542749881744385, 0.8535500168800354, 0.8598750233650208, 0.8608999848365784, 0.8603249788284302, 0.864175021648407, 0.8667250275611877, 0.8665000200271606, 0.8712000250816345, 0.8711000084877014, 0.8738499879837036, 0.8745750188827515, 0.8784000277519226, 0.8784250020980835], 'val_loss': [3.0557174682617188, 2.1310954093933105, 1.7325611114501953, 1.521647334098816, 1.6903347969055176, 1.2664953470230103, 1.5589946508407593, 1.4050897359848022, 1.1929328441619873, 0.9934448003768921, 1.271914005279541, 1.1222895383834839, 0.8529588580131531, 0.9086369872093201, 0.9404749870300293, 1.0443660020828247, 0.8151335120201111, 0.8431954383850098, 0.919974684715271, 0.8039459586143494, 0.786821722984314, 0.8636863231658936, 0.6679647564888, 0.8281556367874146, 0.6444268822669983, 0.7166616320610046, 0.7280399799346924, 0.6229446530342102, 0.6620250344276428, 0.7050249576568604, 0.5940669775009155, 0.6598232984542847, 0.5530288815498352, 0.6271505355834961, 0.6913047432899475, 0.5647884607315063, 0.6685346961021423, 0.5542112588882446, 0.5708569288253784, 0.5908957123756409, 0.5756610631942749, 0.6106997728347778, 0.704153835773468, 0.5142698287963867, 0.6266294121742249, 0.5648192167282104, 0.5120328664779663, 0.5132922530174255, 0.5380009412765503, 0.4876815378665924], 'val_accuracy': [0.12960000336170197, 0.2615000009536743, 0.382999986410141, 0.45159998536109924, 0.43470001220703125, 0.5468999743461609, 0.47780001163482666, 0.5128999948501587, 0.5885000228881836, 0.6453999876976013, 0.5745999813079834, 0.607699990272522, 0.7032999992370605, 0.6804999709129333, 0.6836000084877014, 0.6420999765396118, 0.7132999897003174, 0.708299994468689, 0.6901999711990356, 0.7184000015258789, 0.73089998960495, 0.7026000022888184, 0.7716000080108643, 0.7175999879837036, 0.7773000001907349, 0.7542999982833862, 0.7516000270843506, 0.7820000052452087, 0.7717000246047974, 0.7613000273704529, 0.7932999730110168, 0.776199996471405, 0.8100000023841858, 0.7875000238418579, 0.7631999850273132, 0.8052999973297119, 0.7727000117301941, 0.8087999820709229, 0.8034999966621399, 0.7942000031471252, 0.8025000095367432, 0.7973999977111816, 0.7638000249862671, 0.8238999843597412, 0.7897999882698059, 0.810699999332428, 0.8242999911308289, 0.8258000016212463, 0.8194000124931335, 0.8330000042915344]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.8329\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('leaky-relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_simplenet_tanh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
