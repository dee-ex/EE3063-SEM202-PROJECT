{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "fc9b2f74-5ad0-4141-c4c5-0342fb28ece8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 6s 0us/step\n",
      "170508288/170498071 [==============================] - 6s 0us/step\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 168s 365ms/step - loss: 2.1498 - accuracy: 0.1807 - val_loss: 3.1431 - val_accuracy: 0.0976\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 1.6971 - accuracy: 0.3418 - val_loss: 3.3563 - val_accuracy: 0.1006\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 1.5324 - accuracy: 0.4165 - val_loss: 4.3640 - val_accuracy: 0.1299\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 1.3748 - accuracy: 0.4861 - val_loss: 4.1633 - val_accuracy: 0.1498\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 1.2255 - accuracy: 0.5484 - val_loss: 3.7204 - val_accuracy: 0.1600\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 1.1030 - accuracy: 0.6003 - val_loss: 2.8878 - val_accuracy: 0.2446\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.9920 - accuracy: 0.6413 - val_loss: 3.0447 - val_accuracy: 0.2565\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 112s 358ms/step - loss: 0.9203 - accuracy: 0.6693 - val_loss: 2.3972 - val_accuracy: 0.3199\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.8662 - accuracy: 0.6884 - val_loss: 2.4612 - val_accuracy: 0.3430\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.8077 - accuracy: 0.7116 - val_loss: 2.0471 - val_accuracy: 0.4183\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.7580 - accuracy: 0.7297 - val_loss: 2.6148 - val_accuracy: 0.3287\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.7223 - accuracy: 0.7423 - val_loss: 1.5662 - val_accuracy: 0.5171\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.6825 - accuracy: 0.7590 - val_loss: 1.6287 - val_accuracy: 0.4908\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.6559 - accuracy: 0.7657 - val_loss: 1.9817 - val_accuracy: 0.4045\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.6389 - accuracy: 0.7736 - val_loss: 1.3566 - val_accuracy: 0.5481\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.6041 - accuracy: 0.7875 - val_loss: 1.5675 - val_accuracy: 0.5164\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.5835 - accuracy: 0.7939 - val_loss: 1.3879 - val_accuracy: 0.5643\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.5642 - accuracy: 0.7992 - val_loss: 1.2286 - val_accuracy: 0.6010\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.5483 - accuracy: 0.8081 - val_loss: 0.9384 - val_accuracy: 0.6868\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.5323 - accuracy: 0.8132 - val_loss: 1.4222 - val_accuracy: 0.5537\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.5174 - accuracy: 0.8154 - val_loss: 1.1720 - val_accuracy: 0.6329\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 112s 357ms/step - loss: 0.5003 - accuracy: 0.8253 - val_loss: 1.0705 - val_accuracy: 0.6455\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 112s 358ms/step - loss: 0.4752 - accuracy: 0.8313 - val_loss: 1.2444 - val_accuracy: 0.6092\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 112s 358ms/step - loss: 0.4750 - accuracy: 0.8327 - val_loss: 0.9739 - val_accuracy: 0.6766\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 112s 358ms/step - loss: 0.4611 - accuracy: 0.8348 - val_loss: 0.7468 - val_accuracy: 0.7407\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 112s 358ms/step - loss: 0.4443 - accuracy: 0.8426 - val_loss: 0.8145 - val_accuracy: 0.7248\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 112s 358ms/step - loss: 0.4430 - accuracy: 0.8454 - val_loss: 0.8122 - val_accuracy: 0.7306\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 111s 355ms/step - loss: 0.4236 - accuracy: 0.8545 - val_loss: 0.9078 - val_accuracy: 0.6932\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.4245 - accuracy: 0.8523 - val_loss: 0.8462 - val_accuracy: 0.7216\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.4057 - accuracy: 0.8593 - val_loss: 0.7176 - val_accuracy: 0.7568\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.3979 - accuracy: 0.8576 - val_loss: 0.7359 - val_accuracy: 0.7525\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 110s 351ms/step - loss: 0.3925 - accuracy: 0.8623 - val_loss: 0.7066 - val_accuracy: 0.7674\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 110s 351ms/step - loss: 0.3836 - accuracy: 0.8635 - val_loss: 0.8116 - val_accuracy: 0.7336\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.3760 - accuracy: 0.8666 - val_loss: 0.8151 - val_accuracy: 0.7335\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 110s 351ms/step - loss: 0.3625 - accuracy: 0.8740 - val_loss: 0.7285 - val_accuracy: 0.7537\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 110s 351ms/step - loss: 0.3585 - accuracy: 0.8747 - val_loss: 0.6651 - val_accuracy: 0.7779\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.3469 - accuracy: 0.8775 - val_loss: 0.6782 - val_accuracy: 0.7753\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.3395 - accuracy: 0.8810 - val_loss: 0.6040 - val_accuracy: 0.7950\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.3442 - accuracy: 0.8776 - val_loss: 0.6665 - val_accuracy: 0.7797\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.3396 - accuracy: 0.8817 - val_loss: 0.5394 - val_accuracy: 0.8210\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 110s 351ms/step - loss: 0.3267 - accuracy: 0.8849 - val_loss: 0.7215 - val_accuracy: 0.7607\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 110s 351ms/step - loss: 0.3185 - accuracy: 0.8854 - val_loss: 0.5664 - val_accuracy: 0.8036\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.3036 - accuracy: 0.8935 - val_loss: 0.6571 - val_accuracy: 0.7857\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 110s 351ms/step - loss: 0.3010 - accuracy: 0.8935 - val_loss: 0.5995 - val_accuracy: 0.8003\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.3046 - accuracy: 0.8924 - val_loss: 0.6904 - val_accuracy: 0.7702\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 111s 353ms/step - loss: 0.2978 - accuracy: 0.8954 - val_loss: 0.6916 - val_accuracy: 0.7713\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 111s 354ms/step - loss: 0.2913 - accuracy: 0.8977 - val_loss: 0.6868 - val_accuracy: 0.7750\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 111s 354ms/step - loss: 0.2873 - accuracy: 0.8977 - val_loss: 0.5284 - val_accuracy: 0.8258\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 111s 355ms/step - loss: 0.2798 - accuracy: 0.8999 - val_loss: 0.5547 - val_accuracy: 0.8149\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 111s 354ms/step - loss: 0.2900 - accuracy: 0.8973 - val_loss: 0.5826 - val_accuracy: 0.8086\n",
      "{'loss': [1.9902347326278687, 1.6507782936096191, 1.4910252094268799, 1.3359673023223877, 1.1938211917877197, 1.070028305053711, 0.9742887616157532, 0.904801070690155, 0.8475791215896606, 0.7982940077781677, 0.7553648948669434, 0.7201043367385864, 0.6840183734893799, 0.6572226285934448, 0.6306028962135315, 0.6080293655395508, 0.5886638760566711, 0.5645037889480591, 0.5481009483337402, 0.5346497297286987, 0.512848973274231, 0.5006871819496155, 0.4880705177783966, 0.4749756455421448, 0.46210426092147827, 0.4493348002433777, 0.43951722979545593, 0.4280807673931122, 0.4224911630153656, 0.4112010598182678, 0.4014967679977417, 0.3938441574573517, 0.3888462483882904, 0.3817457854747772, 0.36872169375419617, 0.3578754663467407, 0.35118362307548523, 0.34489890933036804, 0.344046950340271, 0.3374042809009552, 0.33158519864082336, 0.32317352294921875, 0.31215551495552063, 0.3076743483543396, 0.30434006452560425, 0.3004533052444458, 0.29198983311653137, 0.29063111543655396, 0.2856033444404602, 0.2835640013217926], 'accuracy': [0.24165000021457672, 0.36515000462532043, 0.4374000132083893, 0.5026500225067139, 0.562250018119812, 0.6116499900817871, 0.647475004196167, 0.6761749982833862, 0.696025013923645, 0.7153000235557556, 0.7318500280380249, 0.7427250146865845, 0.7572749853134155, 0.7669000029563904, 0.7759749889373779, 0.7857249975204468, 0.7919999957084656, 0.7999749779701233, 0.8085749745368958, 0.8123499751091003, 0.8187500238418579, 0.823074996471405, 0.8271250128746033, 0.8328250050544739, 0.8359500169754028, 0.8420000076293945, 0.8460500240325928, 0.8510749936103821, 0.8523250222206116, 0.8552250266075134, 0.8577749729156494, 0.8599249720573425, 0.8629500269889832, 0.8662999868392944, 0.87152498960495, 0.8758249878883362, 0.8761749863624573, 0.878125011920929, 0.8790749907493591, 0.8816750049591064, 0.8841500282287598, 0.8854249715805054, 0.8909500241279602, 0.8916749954223633, 0.8917250037193298, 0.8947250247001648, 0.8964999914169312, 0.8969249725341797, 0.8981000185012817, 0.8994250297546387], 'val_loss': [3.1431126594543457, 3.3563132286071777, 4.364027976989746, 4.163252353668213, 3.7203593254089355, 2.8877716064453125, 3.044658899307251, 2.397240161895752, 2.4611570835113525, 2.0471413135528564, 2.6148159503936768, 1.5661653280258179, 1.628658652305603, 1.981703519821167, 1.356566309928894, 1.5674513578414917, 1.3879259824752808, 1.2286314964294434, 0.9384002685546875, 1.422202229499817, 1.1719887256622314, 1.070474624633789, 1.2443797588348389, 0.9738547801971436, 0.7468284964561462, 0.814500629901886, 0.8122196793556213, 0.9077741503715515, 0.8461833000183105, 0.7175683975219727, 0.7358895540237427, 0.7066459655761719, 0.8116499781608582, 0.8151127696037292, 0.7284644246101379, 0.665118396282196, 0.6781718730926514, 0.6040458083152771, 0.6664595007896423, 0.5394321084022522, 0.721473753452301, 0.5663943290710449, 0.6571248769760132, 0.5994699001312256, 0.6904489398002625, 0.6915971040725708, 0.6868245005607605, 0.528359591960907, 0.5546979904174805, 0.5825876593589783], 'val_accuracy': [0.09759999811649323, 0.1005999967455864, 0.1298999935388565, 0.14980000257492065, 0.1599999964237213, 0.24459999799728394, 0.2565000057220459, 0.3199000060558319, 0.34299999475479126, 0.41830000281333923, 0.3287000060081482, 0.5170999765396118, 0.49079999327659607, 0.40450000762939453, 0.5480999946594238, 0.5163999795913696, 0.564300000667572, 0.6010000109672546, 0.6868000030517578, 0.5536999702453613, 0.6328999996185303, 0.6455000042915344, 0.6092000007629395, 0.6765999794006348, 0.7407000064849854, 0.7247999906539917, 0.7305999994277954, 0.6931999921798706, 0.7215999960899353, 0.7567999958992004, 0.7524999976158142, 0.7674000263214111, 0.7336000204086304, 0.7335000038146973, 0.7537000179290771, 0.777899980545044, 0.7753000259399414, 0.7950000166893005, 0.779699981212616, 0.8209999799728394, 0.760699987411499, 0.803600013256073, 0.7857000231742859, 0.8003000020980835, 0.7702000141143799, 0.7713000178337097, 0.7749999761581421, 0.8258000016212463, 0.8148999810218811, 0.8086000084877014]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.8046\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('gelu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_simplenet_gelu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
