{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "706fbbd0-7413-41e6-d500-5b70b6c5ce2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 46s 135ms/step - loss: 1.9418 - accuracy: 0.2829 - val_loss: 2.0840 - val_accuracy: 0.2659\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 1.4801 - accuracy: 0.4518 - val_loss: 1.8846 - val_accuracy: 0.3533\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 1.2687 - accuracy: 0.5396 - val_loss: 1.7314 - val_accuracy: 0.4142\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 41s 129ms/step - loss: 1.1298 - accuracy: 0.5922 - val_loss: 1.4714 - val_accuracy: 0.5086\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 1.0350 - accuracy: 0.6245 - val_loss: 1.4942 - val_accuracy: 0.5051\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.9545 - accuracy: 0.6569 - val_loss: 1.2165 - val_accuracy: 0.5832\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.9002 - accuracy: 0.6776 - val_loss: 1.1912 - val_accuracy: 0.5861\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.8553 - accuracy: 0.6959 - val_loss: 1.1727 - val_accuracy: 0.5994\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.8022 - accuracy: 0.7145 - val_loss: 0.9823 - val_accuracy: 0.6546\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.7731 - accuracy: 0.7247 - val_loss: 0.9848 - val_accuracy: 0.6589\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.7437 - accuracy: 0.7355 - val_loss: 0.9789 - val_accuracy: 0.6555\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.7144 - accuracy: 0.7477 - val_loss: 0.8395 - val_accuracy: 0.7044\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.6872 - accuracy: 0.7549 - val_loss: 0.9991 - val_accuracy: 0.6589\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.6636 - accuracy: 0.7651 - val_loss: 0.7584 - val_accuracy: 0.7329\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.6309 - accuracy: 0.7768 - val_loss: 0.8178 - val_accuracy: 0.7140\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.6247 - accuracy: 0.7804 - val_loss: 0.7705 - val_accuracy: 0.7335\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.6016 - accuracy: 0.7857 - val_loss: 0.7826 - val_accuracy: 0.7289\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 41s 129ms/step - loss: 0.5948 - accuracy: 0.7908 - val_loss: 0.8193 - val_accuracy: 0.7162\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5785 - accuracy: 0.7932 - val_loss: 0.7012 - val_accuracy: 0.7574\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.5600 - accuracy: 0.8005 - val_loss: 0.8919 - val_accuracy: 0.6940\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5528 - accuracy: 0.8051 - val_loss: 0.7008 - val_accuracy: 0.7582\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.5393 - accuracy: 0.8118 - val_loss: 0.6873 - val_accuracy: 0.7631\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5271 - accuracy: 0.8147 - val_loss: 0.6205 - val_accuracy: 0.7851\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.5178 - accuracy: 0.8123 - val_loss: 0.7586 - val_accuracy: 0.7371\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5008 - accuracy: 0.8235 - val_loss: 0.7190 - val_accuracy: 0.7550\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4945 - accuracy: 0.8250 - val_loss: 0.6254 - val_accuracy: 0.7852\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.4782 - accuracy: 0.8310 - val_loss: 0.6930 - val_accuracy: 0.7593\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4759 - accuracy: 0.8331 - val_loss: 0.6356 - val_accuracy: 0.7839\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.4681 - accuracy: 0.8343 - val_loss: 0.5899 - val_accuracy: 0.8016\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4641 - accuracy: 0.8344 - val_loss: 0.6181 - val_accuracy: 0.7898\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.4476 - accuracy: 0.8435 - val_loss: 0.5987 - val_accuracy: 0.7936\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4382 - accuracy: 0.8453 - val_loss: 0.5516 - val_accuracy: 0.8117\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 41s 129ms/step - loss: 0.4336 - accuracy: 0.8449 - val_loss: 0.5742 - val_accuracy: 0.8011\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4272 - accuracy: 0.8498 - val_loss: 0.6386 - val_accuracy: 0.7821\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4170 - accuracy: 0.8522 - val_loss: 0.5408 - val_accuracy: 0.8153\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 41s 129ms/step - loss: 0.4081 - accuracy: 0.8531 - val_loss: 0.5546 - val_accuracy: 0.8103\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.3998 - accuracy: 0.8579 - val_loss: 0.5392 - val_accuracy: 0.8153\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4052 - accuracy: 0.8578 - val_loss: 0.5690 - val_accuracy: 0.8089\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3916 - accuracy: 0.8635 - val_loss: 0.5542 - val_accuracy: 0.8146\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 41s 129ms/step - loss: 0.3835 - accuracy: 0.8650 - val_loss: 0.4950 - val_accuracy: 0.8301\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3806 - accuracy: 0.8647 - val_loss: 0.4916 - val_accuracy: 0.8294\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.3776 - accuracy: 0.8658 - val_loss: 0.5099 - val_accuracy: 0.8252\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3668 - accuracy: 0.8719 - val_loss: 0.5306 - val_accuracy: 0.8206\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3685 - accuracy: 0.8697 - val_loss: 0.5571 - val_accuracy: 0.8149\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.3605 - accuracy: 0.8726 - val_loss: 0.5748 - val_accuracy: 0.8066\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.3488 - accuracy: 0.8781 - val_loss: 0.4864 - val_accuracy: 0.8335\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3448 - accuracy: 0.8785 - val_loss: 0.5095 - val_accuracy: 0.8276\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3434 - accuracy: 0.8787 - val_loss: 0.5382 - val_accuracy: 0.8197\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.3271 - accuracy: 0.8848 - val_loss: 0.5242 - val_accuracy: 0.8218\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.3304 - accuracy: 0.8853 - val_loss: 0.4710 - val_accuracy: 0.8417\n",
      "{'loss': [1.7482949495315552, 1.4251152276992798, 1.230191946029663, 1.1014127731323242, 1.0201839208602905, 0.9472122192382812, 0.888696014881134, 0.8413575291633606, 0.8032708764076233, 0.764207661151886, 0.7345844507217407, 0.70802903175354, 0.6837055683135986, 0.6583749055862427, 0.6397542357444763, 0.6294689178466797, 0.6038914918899536, 0.5968238115310669, 0.5785075426101685, 0.5640780329704285, 0.5504759550094604, 0.541938841342926, 0.527348518371582, 0.5188794732093811, 0.5061178803443909, 0.49645110964775085, 0.48450374603271484, 0.4813442826271057, 0.46892520785331726, 0.46060600876808167, 0.4471869170665741, 0.44353559613227844, 0.43803223967552185, 0.4268245995044708, 0.4214892089366913, 0.40748271346092224, 0.4065245985984802, 0.4032667279243469, 0.394459068775177, 0.38419029116630554, 0.38568392395973206, 0.3751242458820343, 0.3670320212841034, 0.3690044581890106, 0.35867154598236084, 0.35417109727859497, 0.34968286752700806, 0.34261322021484375, 0.3395995497703552, 0.33292651176452637], 'accuracy': [0.3493250012397766, 0.4749000072479248, 0.5539000034332275, 0.6024500131607056, 0.6314749717712402, 0.6605499982833862, 0.6812000274658203, 0.701200008392334, 0.7138500213623047, 0.7261499762535095, 0.7390000224113464, 0.7495250105857849, 0.7565500140190125, 0.7667499780654907, 0.7736250162124634, 0.7779250144958496, 0.7851499915122986, 0.7900000214576721, 0.7942749857902527, 0.799049973487854, 0.8058750033378601, 0.8100500106811523, 0.8149999976158142, 0.8147249817848206, 0.8210999965667725, 0.8252750039100647, 0.8279250264167786, 0.8313000202178955, 0.8345999717712402, 0.8368250131607056, 0.843999981880188, 0.8445000052452087, 0.8436999917030334, 0.8498749732971191, 0.8522499799728394, 0.8547000288963318, 0.8566499948501587, 0.8577749729156494, 0.8609750270843506, 0.8661500215530396, 0.8640999794006348, 0.8668249845504761, 0.8712499737739563, 0.8694750070571899, 0.8736249804496765, 0.8762249946594238, 0.8758999705314636, 0.879800021648407, 0.8791249990463257, 0.8834750056266785], 'val_loss': [2.084003210067749, 1.8845946788787842, 1.7313703298568726, 1.4714114665985107, 1.4942294359207153, 1.2164536714553833, 1.1912018060684204, 1.1726661920547485, 0.9823103547096252, 0.9848021268844604, 0.9789154529571533, 0.8395270705223083, 0.9991352558135986, 0.7583731412887573, 0.8178122639656067, 0.7704939246177673, 0.7826158404350281, 0.8192935585975647, 0.7011607885360718, 0.8919246196746826, 0.7007535099983215, 0.6872811913490295, 0.620538055896759, 0.7585864663124084, 0.7190231680870056, 0.6254076957702637, 0.6930219531059265, 0.6356102824211121, 0.5899109244346619, 0.618135929107666, 0.5986699461936951, 0.5516313314437866, 0.5742079019546509, 0.6385964155197144, 0.5408299565315247, 0.5545681715011597, 0.5391882061958313, 0.5689621567726135, 0.5542128682136536, 0.4950343668460846, 0.4915727972984314, 0.5099400877952576, 0.5305666327476501, 0.5571064949035645, 0.5748419165611267, 0.48637640476226807, 0.5094925761222839, 0.5381619930267334, 0.5242293477058411, 0.47102880477905273], 'val_accuracy': [0.26589998602867126, 0.353300005197525, 0.4142000079154968, 0.5085999965667725, 0.5051000118255615, 0.5831999778747559, 0.5860999822616577, 0.599399983882904, 0.6546000242233276, 0.6589000225067139, 0.6554999947547913, 0.7044000029563904, 0.6589000225067139, 0.7329000234603882, 0.7139999866485596, 0.7335000038146973, 0.7289000153541565, 0.7161999940872192, 0.7573999762535095, 0.6940000057220459, 0.7581999897956848, 0.7631000280380249, 0.785099983215332, 0.7371000051498413, 0.7549999952316284, 0.7851999998092651, 0.7592999935150146, 0.7839000225067139, 0.8015999794006348, 0.7897999882698059, 0.7936000227928162, 0.8116999864578247, 0.8011000156402588, 0.7821000218391418, 0.8152999877929688, 0.8102999925613403, 0.8152999877929688, 0.808899998664856, 0.8145999908447266, 0.8300999999046326, 0.8294000029563904, 0.8252000212669373, 0.8205999732017517, 0.8148999810218811, 0.8065999746322632, 0.8335000276565552, 0.8276000022888184, 0.8197000026702881, 0.8217999935150146, 0.84170001745224]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.8348\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('elu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_simplenet_tanh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
