{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "b3a1715e-6a29-45d7-b1c2-e13af1ef5039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "170508288/170498071 [==============================] - 4s 0us/step\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 93s 134ms/step - loss: 2.1249 - accuracy: 0.1889 - val_loss: 3.3294 - val_accuracy: 0.1029\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.6866 - accuracy: 0.3538 - val_loss: 3.6434 - val_accuracy: 0.1040\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 1.5126 - accuracy: 0.4236 - val_loss: 3.3601 - val_accuracy: 0.1360\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 1.3761 - accuracy: 0.4887 - val_loss: 3.6092 - val_accuracy: 0.1497\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.2429 - accuracy: 0.5408 - val_loss: 3.2165 - val_accuracy: 0.1943\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 1.1249 - accuracy: 0.5877 - val_loss: 2.1441 - val_accuracy: 0.3094\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 1.0550 - accuracy: 0.6200 - val_loss: 2.0991 - val_accuracy: 0.3353\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.9926 - accuracy: 0.6450 - val_loss: 2.5197 - val_accuracy: 0.2865\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.9302 - accuracy: 0.6642 - val_loss: 2.4456 - val_accuracy: 0.3215\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.8833 - accuracy: 0.6830 - val_loss: 2.5777 - val_accuracy: 0.2963\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.8451 - accuracy: 0.6957 - val_loss: 2.1547 - val_accuracy: 0.3769\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.8071 - accuracy: 0.7111 - val_loss: 1.7381 - val_accuracy: 0.4515\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.7747 - accuracy: 0.7221 - val_loss: 1.9626 - val_accuracy: 0.4267\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.7430 - accuracy: 0.7370 - val_loss: 2.0755 - val_accuracy: 0.3921\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.7240 - accuracy: 0.7405 - val_loss: 2.4227 - val_accuracy: 0.3186\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.6990 - accuracy: 0.7507 - val_loss: 1.2154 - val_accuracy: 0.5936\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.6780 - accuracy: 0.7586 - val_loss: 1.5468 - val_accuracy: 0.5055\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6607 - accuracy: 0.7657 - val_loss: 1.1668 - val_accuracy: 0.6001\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.6420 - accuracy: 0.7728 - val_loss: 1.5385 - val_accuracy: 0.5115\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6198 - accuracy: 0.7760 - val_loss: 1.5764 - val_accuracy: 0.5264\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.6119 - accuracy: 0.7859 - val_loss: 1.0001 - val_accuracy: 0.6518\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.5932 - accuracy: 0.7891 - val_loss: 1.5453 - val_accuracy: 0.5303\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.5690 - accuracy: 0.7985 - val_loss: 1.1952 - val_accuracy: 0.6094\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.5572 - accuracy: 0.8001 - val_loss: 1.3489 - val_accuracy: 0.5749\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5434 - accuracy: 0.8073 - val_loss: 1.1543 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.5238 - accuracy: 0.8139 - val_loss: 1.0255 - val_accuracy: 0.6535\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.5238 - accuracy: 0.8157 - val_loss: 1.2126 - val_accuracy: 0.6184\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.5101 - accuracy: 0.8208 - val_loss: 1.0884 - val_accuracy: 0.6470\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5059 - accuracy: 0.8215 - val_loss: 0.8483 - val_accuracy: 0.7180\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.4891 - accuracy: 0.8276 - val_loss: 1.1794 - val_accuracy: 0.6223\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.4783 - accuracy: 0.8323 - val_loss: 1.0905 - val_accuracy: 0.6423\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4658 - accuracy: 0.8370 - val_loss: 0.7619 - val_accuracy: 0.7399\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4576 - accuracy: 0.8427 - val_loss: 0.7448 - val_accuracy: 0.7436\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.4382 - accuracy: 0.8470 - val_loss: 1.2461 - val_accuracy: 0.6099\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4468 - accuracy: 0.8427 - val_loss: 0.8191 - val_accuracy: 0.7206\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.4336 - accuracy: 0.8484 - val_loss: 0.9684 - val_accuracy: 0.6801\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.4251 - accuracy: 0.8520 - val_loss: 1.0370 - val_accuracy: 0.6650\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4151 - accuracy: 0.8517 - val_loss: 0.8436 - val_accuracy: 0.7184\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.4115 - accuracy: 0.8558 - val_loss: 0.7641 - val_accuracy: 0.7413\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4048 - accuracy: 0.8577 - val_loss: 0.8915 - val_accuracy: 0.7108\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.3957 - accuracy: 0.8630 - val_loss: 0.5288 - val_accuracy: 0.8181\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.3932 - accuracy: 0.8639 - val_loss: 0.7502 - val_accuracy: 0.7471\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.3891 - accuracy: 0.8623 - val_loss: 1.0983 - val_accuracy: 0.6500\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.3817 - accuracy: 0.8666 - val_loss: 0.6669 - val_accuracy: 0.7812\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.3688 - accuracy: 0.8681 - val_loss: 0.6705 - val_accuracy: 0.7748\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.3735 - accuracy: 0.8687 - val_loss: 0.6549 - val_accuracy: 0.7785\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.3666 - accuracy: 0.8717 - val_loss: 0.7651 - val_accuracy: 0.7486\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.3602 - accuracy: 0.8747 - val_loss: 0.7057 - val_accuracy: 0.7579\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.3539 - accuracy: 0.8775 - val_loss: 0.9490 - val_accuracy: 0.6956\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.3530 - accuracy: 0.8760 - val_loss: 0.5483 - val_accuracy: 0.8094\n",
      "{'loss': [1.9421879053115845, 1.6376296281814575, 1.4752824306488037, 1.343739628791809, 1.2207505702972412, 1.1114853620529175, 1.031457781791687, 0.9760766625404358, 0.921629011631012, 0.8748853802680969, 0.8381074070930481, 0.8056820631027222, 0.7707988619804382, 0.7468958497047424, 0.7236367464065552, 0.6976594924926758, 0.6721287965774536, 0.6573477983474731, 0.638358473777771, 0.613972544670105, 0.6046949625015259, 0.5866498947143555, 0.5756338238716125, 0.5597378015518188, 0.550285816192627, 0.5310119390487671, 0.5279170274734497, 0.5124357342720032, 0.4990333020687103, 0.49002334475517273, 0.48022085428237915, 0.4713568389415741, 0.4664165675640106, 0.4483017921447754, 0.446338951587677, 0.4329676628112793, 0.4285382926464081, 0.4202083945274353, 0.41736260056495667, 0.4096306562423706, 0.3998681902885437, 0.39634454250335693, 0.3887339234352112, 0.3826926052570343, 0.37585195899009705, 0.37276139855384827, 0.3659401535987854, 0.36134275794029236, 0.35493481159210205, 0.35195446014404297], 'accuracy': [0.25209999084472656, 0.3739500045776367, 0.44312500953674316, 0.5029249787330627, 0.5510749816894531, 0.5945249795913696, 0.6273999810218811, 0.6488749980926514, 0.6678249835968018, 0.685824990272522, 0.6994500160217285, 0.7113249897956848, 0.7229499816894531, 0.7332749962806702, 0.7417500019073486, 0.7526000142097473, 0.7606250047683716, 0.7651749849319458, 0.7721250057220459, 0.7821750044822693, 0.786300003528595, 0.7918750047683716, 0.7974249720573425, 0.800849974155426, 0.8043749928474426, 0.8133500218391418, 0.8137000203132629, 0.8188999891281128, 0.8243499994277954, 0.8260999917984009, 0.8315250277519226, 0.8360750079154968, 0.8389250040054321, 0.8444499969482422, 0.8433499932289124, 0.8481749892234802, 0.8496999740600586, 0.8514249920845032, 0.8541749715805054, 0.8562250137329102, 0.8624500036239624, 0.8617749810218811, 0.8632000088691711, 0.8654999732971191, 0.8675500154495239, 0.8691999912261963, 0.8719750046730042, 0.8740749955177307, 0.875124990940094, 0.8760250210762024], 'val_loss': [3.329368829727173, 3.643428087234497, 3.3601105213165283, 3.6091725826263428, 3.216489315032959, 2.1440584659576416, 2.0991079807281494, 2.5196831226348877, 2.4456164836883545, 2.577684164047241, 2.1546690464019775, 1.7381303310394287, 1.962600827217102, 2.075453281402588, 2.4226620197296143, 1.2154209613800049, 1.5467665195465088, 1.1668142080307007, 1.5384650230407715, 1.576415777206421, 1.0001226663589478, 1.5453245639801025, 1.1951775550842285, 1.3488678932189941, 1.1542637348175049, 1.0254559516906738, 1.2125910520553589, 1.0883560180664062, 0.8482603430747986, 1.1794073581695557, 1.0904572010040283, 0.7618603706359863, 0.7448449730873108, 1.24608314037323, 0.8190878033638, 0.9683783054351807, 1.0370376110076904, 0.8435614109039307, 0.7641240954399109, 0.891496479511261, 0.5287882089614868, 0.7502029538154602, 1.098331093788147, 0.6668691635131836, 0.6704697012901306, 0.6549009680747986, 0.7651299834251404, 0.7056844830513, 0.9489759802818298, 0.5483081936836243], 'val_accuracy': [0.10289999842643738, 0.10400000214576721, 0.13600000739097595, 0.14970000088214874, 0.19429999589920044, 0.3093999922275543, 0.3352999985218048, 0.2865000069141388, 0.3215000033378601, 0.2962999939918518, 0.37689998745918274, 0.4514999985694885, 0.42669999599456787, 0.3921000063419342, 0.31859999895095825, 0.5935999751091003, 0.5055000185966492, 0.6000999808311462, 0.5115000009536743, 0.5264000296592712, 0.6517999768257141, 0.5303000211715698, 0.6093999743461609, 0.5748999714851379, 0.625, 0.6535000205039978, 0.618399977684021, 0.6470000147819519, 0.7179999947547913, 0.6223000288009644, 0.642300009727478, 0.7398999929428101, 0.7436000108718872, 0.6098999977111816, 0.7206000089645386, 0.6801000237464905, 0.6650000214576721, 0.7184000015258789, 0.7412999868392944, 0.7107999920845032, 0.8180999755859375, 0.7470999956130981, 0.6499999761581421, 0.7811999917030334, 0.7748000025749207, 0.7785000205039978, 0.7486000061035156, 0.7578999996185303, 0.6955999732017517, 0.8094000220298767]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.8097\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('relu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_simplenet_tanh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
