{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "c258e89e-e710-43be-abee-c9a39e00f245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "170508288/170498071 [==============================] - 4s 0us/step\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 93s 137ms/step - loss: 2.0746 - accuracy: 0.2337 - val_loss: 1.9503 - val_accuracy: 0.3094\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.7288 - accuracy: 0.3666 - val_loss: 2.0811 - val_accuracy: 0.3151\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.5194 - accuracy: 0.4433 - val_loss: 2.1048 - val_accuracy: 0.3393\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.4088 - accuracy: 0.4808 - val_loss: 2.2888 - val_accuracy: 0.3182\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.2916 - accuracy: 0.5260 - val_loss: 2.0738 - val_accuracy: 0.3535\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 1.2099 - accuracy: 0.5605 - val_loss: 2.0869 - val_accuracy: 0.3634\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 1.1460 - accuracy: 0.5849 - val_loss: 1.9866 - val_accuracy: 0.4088\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.0940 - accuracy: 0.6067 - val_loss: 1.4951 - val_accuracy: 0.4951\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.0502 - accuracy: 0.6229 - val_loss: 2.0325 - val_accuracy: 0.3865\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.0131 - accuracy: 0.6382 - val_loss: 1.6021 - val_accuracy: 0.4769\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.9980 - accuracy: 0.6390 - val_loss: 1.4591 - val_accuracy: 0.5171\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.9427 - accuracy: 0.6596 - val_loss: 1.5120 - val_accuracy: 0.5006\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.9387 - accuracy: 0.6643 - val_loss: 1.4636 - val_accuracy: 0.5174\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.9252 - accuracy: 0.6656 - val_loss: 1.4419 - val_accuracy: 0.5403\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.8995 - accuracy: 0.6753 - val_loss: 1.4409 - val_accuracy: 0.5365\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.8775 - accuracy: 0.6873 - val_loss: 1.2767 - val_accuracy: 0.5774\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.8646 - accuracy: 0.6926 - val_loss: 1.6721 - val_accuracy: 0.4786\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.8468 - accuracy: 0.6983 - val_loss: 1.2544 - val_accuracy: 0.5782\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.8356 - accuracy: 0.7013 - val_loss: 1.6271 - val_accuracy: 0.4980\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.8124 - accuracy: 0.7099 - val_loss: 1.3657 - val_accuracy: 0.5604\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.7895 - accuracy: 0.7190 - val_loss: 1.4072 - val_accuracy: 0.5600\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.7848 - accuracy: 0.7206 - val_loss: 1.3623 - val_accuracy: 0.5669\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.7675 - accuracy: 0.7262 - val_loss: 1.3507 - val_accuracy: 0.5701\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.7577 - accuracy: 0.7292 - val_loss: 1.2201 - val_accuracy: 0.5987\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.7440 - accuracy: 0.7363 - val_loss: 1.4430 - val_accuracy: 0.5491\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.7451 - accuracy: 0.7329 - val_loss: 1.1952 - val_accuracy: 0.6096\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.7248 - accuracy: 0.7425 - val_loss: 1.2571 - val_accuracy: 0.6014\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.7088 - accuracy: 0.7453 - val_loss: 1.1507 - val_accuracy: 0.6317\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.7047 - accuracy: 0.7522 - val_loss: 1.1528 - val_accuracy: 0.6231\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6841 - accuracy: 0.7578 - val_loss: 1.0090 - val_accuracy: 0.6613\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.6827 - accuracy: 0.7585 - val_loss: 1.3030 - val_accuracy: 0.5909\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6574 - accuracy: 0.7685 - val_loss: 1.1375 - val_accuracy: 0.6308\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6666 - accuracy: 0.7650 - val_loss: 1.1268 - val_accuracy: 0.6355\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6593 - accuracy: 0.7680 - val_loss: 1.3832 - val_accuracy: 0.5724\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.6459 - accuracy: 0.7725 - val_loss: 1.0581 - val_accuracy: 0.6580\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6308 - accuracy: 0.7759 - val_loss: 1.1088 - val_accuracy: 0.6407\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.6267 - accuracy: 0.7774 - val_loss: 1.0283 - val_accuracy: 0.6626\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6195 - accuracy: 0.7790 - val_loss: 0.9981 - val_accuracy: 0.6775\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6141 - accuracy: 0.7833 - val_loss: 1.0153 - val_accuracy: 0.6679\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6043 - accuracy: 0.7841 - val_loss: 0.9910 - val_accuracy: 0.6761\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.6032 - accuracy: 0.7867 - val_loss: 1.2307 - val_accuracy: 0.6132\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5929 - accuracy: 0.7875 - val_loss: 1.0009 - val_accuracy: 0.6739\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5946 - accuracy: 0.7885 - val_loss: 1.1461 - val_accuracy: 0.6305\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5806 - accuracy: 0.7936 - val_loss: 0.9105 - val_accuracy: 0.6964\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5698 - accuracy: 0.7952 - val_loss: 0.9403 - val_accuracy: 0.6968\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.5666 - accuracy: 0.7983 - val_loss: 0.9880 - val_accuracy: 0.6728\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5517 - accuracy: 0.8056 - val_loss: 1.1838 - val_accuracy: 0.6358\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5584 - accuracy: 0.8020 - val_loss: 1.0310 - val_accuracy: 0.6732\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.5544 - accuracy: 0.8048 - val_loss: 1.1085 - val_accuracy: 0.6516\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.5456 - accuracy: 0.8067 - val_loss: 0.7977 - val_accuracy: 0.7321\n",
      "{'loss': [1.9452495574951172, 1.6699048280715942, 1.4839705228805542, 1.3721951246261597, 1.2701785564422607, 1.195585012435913, 1.1292226314544678, 1.0846394300460815, 1.0474642515182495, 1.0102280378341675, 0.9876118302345276, 0.9572635889053345, 0.933464527130127, 0.9149179458618164, 0.8981339931488037, 0.8738487362861633, 0.863004207611084, 0.8462568521499634, 0.8320916295051575, 0.8124937415122986, 0.7966607809066772, 0.7873626351356506, 0.7721216082572937, 0.7578209638595581, 0.7475156188011169, 0.7372140288352966, 0.7236936688423157, 0.712873101234436, 0.7022504210472107, 0.6905031204223633, 0.6819136738777161, 0.6710719466209412, 0.6622142195701599, 0.6506727933883667, 0.6457207202911377, 0.6363021731376648, 0.6249274611473083, 0.6198804378509521, 0.6173688769340515, 0.6087080836296082, 0.5982039570808411, 0.5951817631721497, 0.595197319984436, 0.5830703377723694, 0.5723248720169067, 0.5675118565559387, 0.5635152459144592, 0.5548292398452759, 0.5532636642456055, 0.5482819080352783], 'accuracy': [0.28587499260902405, 0.3886750042438507, 0.4563499987125397, 0.49665001034736633, 0.5357999801635742, 0.5652750134468079, 0.5931249856948853, 0.6095749735832214, 0.6231750249862671, 0.6396999955177307, 0.6423749923706055, 0.6539250016212463, 0.6655750274658203, 0.6731250286102295, 0.6765000224113464, 0.6871500015258789, 0.6926249861717224, 0.6983749866485596, 0.7029500007629395, 0.7099249958992004, 0.7180749773979187, 0.7196249961853027, 0.7226250171661377, 0.7301999926567078, 0.7341750264167786, 0.7374500036239624, 0.7427999973297119, 0.7444000244140625, 0.7523249983787537, 0.7541249990463257, 0.7582250237464905, 0.7621250152587891, 0.7639250159263611, 0.7692750096321106, 0.7721499800682068, 0.7747499942779541, 0.7779250144958496, 0.7803999781608582, 0.7800999879837036, 0.783174991607666, 0.7876499891281128, 0.7876750230789185, 0.7892500162124634, 0.7924500107765198, 0.7963749766349792, 0.7975749969482422, 0.7992749810218811, 0.8041999936103821, 0.8037750124931335, 0.8053249716758728], 'val_loss': [1.9503170251846313, 2.0811386108398438, 2.104825973510742, 2.288820743560791, 2.07375168800354, 2.08689284324646, 1.9865710735321045, 1.4951293468475342, 2.032522678375244, 1.6020854711532593, 1.4590733051300049, 1.511975884437561, 1.463562250137329, 1.4419476985931396, 1.4408998489379883, 1.2766910791397095, 1.672121524810791, 1.2544304132461548, 1.6270833015441895, 1.3656790256500244, 1.40716552734375, 1.36226224899292, 1.350683331489563, 1.2201402187347412, 1.4429500102996826, 1.1951924562454224, 1.2570562362670898, 1.1506993770599365, 1.1527636051177979, 1.0090101957321167, 1.3030284643173218, 1.137532353401184, 1.1267578601837158, 1.3831835985183716, 1.0581214427947998, 1.108779788017273, 1.0282618999481201, 0.9981330037117004, 1.0153411626815796, 0.9909941554069519, 1.2306588888168335, 1.000868320465088, 1.1461195945739746, 0.9104869365692139, 0.9403054714202881, 0.9879999160766602, 1.183772325515747, 1.0310255289077759, 1.1085317134857178, 0.797692060470581], 'val_accuracy': [0.3093999922275543, 0.3151000142097473, 0.3393000066280365, 0.3181999921798706, 0.35350000858306885, 0.36340001225471497, 0.40880000591278076, 0.4950999915599823, 0.3865000009536743, 0.47690001130104065, 0.5170999765396118, 0.5005999803543091, 0.5174000263214111, 0.5403000116348267, 0.5364999771118164, 0.5774000287055969, 0.47859999537467957, 0.5781999826431274, 0.49799999594688416, 0.5604000091552734, 0.5600000023841858, 0.5669000148773193, 0.5701000094413757, 0.5986999869346619, 0.5490999817848206, 0.6096000075340271, 0.6014000177383423, 0.6316999793052673, 0.6230999827384949, 0.661300003528595, 0.5909000039100647, 0.6308000087738037, 0.6355000138282776, 0.5723999738693237, 0.6579999923706055, 0.6406999826431274, 0.6625999808311462, 0.6775000095367432, 0.667900025844574, 0.6761000156402588, 0.6132000088691711, 0.6739000082015991, 0.6305000185966492, 0.696399986743927, 0.6967999935150146, 0.6728000044822693, 0.6358000040054321, 0.6732000112533569, 0.6516000032424927, 0.7321000099182129]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('tanh')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_simplenet_tanh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
