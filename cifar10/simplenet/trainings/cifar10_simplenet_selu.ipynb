{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRf9TvwnLCw9",
    "outputId": "e493b0f0-a293-4fa9-bd65-4a6233f1af54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 44s 129ms/step - loss: 2.3857 - accuracy: 0.2457 - val_loss: 1.7273 - val_accuracy: 0.3964\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.5842 - accuracy: 0.4254 - val_loss: 2.2577 - val_accuracy: 0.3374\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 1.3801 - accuracy: 0.5001 - val_loss: 1.8848 - val_accuracy: 0.4140\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 1.2287 - accuracy: 0.5574 - val_loss: 1.5458 - val_accuracy: 0.5065\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.1162 - accuracy: 0.5971 - val_loss: 1.7895 - val_accuracy: 0.4713\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 1.0541 - accuracy: 0.6231 - val_loss: 2.0104 - val_accuracy: 0.4384\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.9929 - accuracy: 0.6453 - val_loss: 1.3992 - val_accuracy: 0.5402\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.9509 - accuracy: 0.6619 - val_loss: 1.1295 - val_accuracy: 0.6235\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.8891 - accuracy: 0.6814 - val_loss: 1.0551 - val_accuracy: 0.6387\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.8559 - accuracy: 0.6930 - val_loss: 1.2337 - val_accuracy: 0.6025\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.8360 - accuracy: 0.7006 - val_loss: 1.0371 - val_accuracy: 0.6532\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.8011 - accuracy: 0.7176 - val_loss: 1.0740 - val_accuracy: 0.6459\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.7751 - accuracy: 0.7224 - val_loss: 0.9986 - val_accuracy: 0.6715\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.7576 - accuracy: 0.7288 - val_loss: 1.1013 - val_accuracy: 0.6392\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.7275 - accuracy: 0.7428 - val_loss: 0.8549 - val_accuracy: 0.7050\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.7028 - accuracy: 0.7493 - val_loss: 1.0405 - val_accuracy: 0.6682\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6927 - accuracy: 0.7552 - val_loss: 0.7872 - val_accuracy: 0.7302\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.6758 - accuracy: 0.7595 - val_loss: 0.7521 - val_accuracy: 0.7407\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6454 - accuracy: 0.7732 - val_loss: 1.0052 - val_accuracy: 0.6779\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6384 - accuracy: 0.7731 - val_loss: 0.8029 - val_accuracy: 0.7284\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6146 - accuracy: 0.7824 - val_loss: 0.7963 - val_accuracy: 0.7350\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.6075 - accuracy: 0.7848 - val_loss: 0.6714 - val_accuracy: 0.7723\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6024 - accuracy: 0.7868 - val_loss: 0.8007 - val_accuracy: 0.7367\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5919 - accuracy: 0.7892 - val_loss: 0.7442 - val_accuracy: 0.7536\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5773 - accuracy: 0.7955 - val_loss: 0.7423 - val_accuracy: 0.7541\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.5614 - accuracy: 0.8017 - val_loss: 0.7543 - val_accuracy: 0.7505\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5562 - accuracy: 0.8014 - val_loss: 0.7356 - val_accuracy: 0.7549\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.5341 - accuracy: 0.8095 - val_loss: 0.7629 - val_accuracy: 0.7487\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5326 - accuracy: 0.8123 - val_loss: 0.6834 - val_accuracy: 0.7748\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.5201 - accuracy: 0.8157 - val_loss: 0.7810 - val_accuracy: 0.7410\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.5157 - accuracy: 0.8181 - val_loss: 0.6547 - val_accuracy: 0.7849\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.5151 - accuracy: 0.8179 - val_loss: 0.6526 - val_accuracy: 0.7787\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4974 - accuracy: 0.8247 - val_loss: 0.7147 - val_accuracy: 0.7702\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4946 - accuracy: 0.8252 - val_loss: 0.5968 - val_accuracy: 0.7966\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4878 - accuracy: 0.8302 - val_loss: 0.6606 - val_accuracy: 0.7820\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4766 - accuracy: 0.8294 - val_loss: 0.6662 - val_accuracy: 0.7815\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4648 - accuracy: 0.8337 - val_loss: 0.6950 - val_accuracy: 0.7741\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4722 - accuracy: 0.8337 - val_loss: 0.7567 - val_accuracy: 0.7562\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4570 - accuracy: 0.8380 - val_loss: 0.6265 - val_accuracy: 0.7924\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4506 - accuracy: 0.8415 - val_loss: 0.6071 - val_accuracy: 0.7974\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4368 - accuracy: 0.8434 - val_loss: 0.6621 - val_accuracy: 0.7900\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4362 - accuracy: 0.8468 - val_loss: 0.6516 - val_accuracy: 0.7921\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4390 - accuracy: 0.8438 - val_loss: 0.6666 - val_accuracy: 0.7838\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4233 - accuracy: 0.8498 - val_loss: 0.5965 - val_accuracy: 0.8043\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4153 - accuracy: 0.8553 - val_loss: 0.6320 - val_accuracy: 0.7964\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.4181 - accuracy: 0.8518 - val_loss: 0.6157 - val_accuracy: 0.7980\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4090 - accuracy: 0.8531 - val_loss: 0.5368 - val_accuracy: 0.8181\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.4035 - accuracy: 0.8566 - val_loss: 0.6467 - val_accuracy: 0.7909\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.3983 - accuracy: 0.8595 - val_loss: 0.5733 - val_accuracy: 0.8095\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.3962 - accuracy: 0.8597 - val_loss: 0.5889 - val_accuracy: 0.8091\n",
      "{'loss': [2.018742322921753, 1.5339374542236328, 1.3437656164169312, 1.2071815729141235, 1.1030006408691406, 1.0384571552276611, 0.9887981414794922, 0.9391041994094849, 0.8904860615730286, 0.8551691174507141, 0.8303385972976685, 0.7989476323127747, 0.7688318490982056, 0.7433638572692871, 0.7240963578224182, 0.7050368189811707, 0.6830805540084839, 0.6688429117202759, 0.6512757539749146, 0.6376841068267822, 0.6241381764411926, 0.6096201539039612, 0.6006255149841309, 0.5913522839546204, 0.5771743655204773, 0.565144419670105, 0.5544987320899963, 0.543754518032074, 0.5357821583747864, 0.5238112211227417, 0.5150439739227295, 0.5113067626953125, 0.49793368577957153, 0.49281787872314453, 0.48963090777397156, 0.4822005331516266, 0.470595121383667, 0.47042471170425415, 0.45633330941200256, 0.4518149495124817, 0.4421384334564209, 0.4400012791156769, 0.43703174591064453, 0.4277993142604828, 0.41997846961021423, 0.41898584365844727, 0.4110246002674103, 0.4044811427593231, 0.3999713063240051, 0.39676302671432495], 'accuracy': [0.30970001220703125, 0.44417500495910645, 0.5163499712944031, 0.5654249787330627, 0.6048499941825867, 0.6285499930381775, 0.6471250057220459, 0.6643249988555908, 0.6843000054359436, 0.6958500146865845, 0.7042999863624573, 0.7179499864578247, 0.7265250086784363, 0.7354249954223633, 0.7429500222206116, 0.7510499954223633, 0.7567499876022339, 0.7629250288009644, 0.7690500020980835, 0.7751749753952026, 0.7793999910354614, 0.7833750247955322, 0.788100004196167, 0.7890750169754028, 0.7955250144004822, 0.7992500066757202, 0.8035249710083008, 0.8059499859809875, 0.8095999956130981, 0.8142750263214111, 0.8169749975204468, 0.8198999762535095, 0.8240749835968018, 0.8259750008583069, 0.8274999856948853, 0.8281999826431274, 0.8317750096321106, 0.8324499726295471, 0.8375499844551086, 0.8390250205993652, 0.8427749872207642, 0.8446249961853027, 0.8446000218391418, 0.8484749794006348, 0.8522999882698059, 0.8521000146865845, 0.8541250228881836, 0.8570250272750854, 0.8582249879837036, 0.8590250015258789], 'val_loss': [1.7273355722427368, 2.257744550704956, 1.8847999572753906, 1.545802354812622, 1.7894651889801025, 2.0104219913482666, 1.3991906642913818, 1.1295108795166016, 1.0551317930221558, 1.2337450981140137, 1.0371166467666626, 1.0740398168563843, 0.998602032661438, 1.1013301610946655, 0.8548552989959717, 1.0404516458511353, 0.7872134447097778, 0.7521015405654907, 1.0052353143692017, 0.8029171228408813, 0.7963202595710754, 0.6714344024658203, 0.8007179498672485, 0.7441778779029846, 0.7423421740531921, 0.7543010115623474, 0.7356212139129639, 0.7629095315933228, 0.683391809463501, 0.7809536457061768, 0.654686689376831, 0.6526496410369873, 0.714679479598999, 0.5968068838119507, 0.6606378555297852, 0.6661536693572998, 0.6949965953826904, 0.7567180395126343, 0.6264568567276001, 0.6070875525474548, 0.6620815396308899, 0.6516236066818237, 0.6666365265846252, 0.5964550971984863, 0.6319832801818848, 0.6156505346298218, 0.5367679595947266, 0.646714985370636, 0.573297917842865, 0.5889269113540649], 'val_accuracy': [0.39640000462532043, 0.33739998936653137, 0.414000004529953, 0.5065000057220459, 0.47130000591278076, 0.438400000333786, 0.5401999950408936, 0.6234999895095825, 0.638700008392334, 0.6025000214576721, 0.6531999707221985, 0.6459000110626221, 0.671500027179718, 0.63919997215271, 0.7049999833106995, 0.6682000160217285, 0.7301999926567078, 0.7407000064849854, 0.6779000163078308, 0.7283999919891357, 0.7350000143051147, 0.7723000049591064, 0.7366999983787537, 0.753600001335144, 0.7541000247001648, 0.7505000233650208, 0.7548999786376953, 0.7487000226974487, 0.7748000025749207, 0.7409999966621399, 0.7849000096321106, 0.7786999940872192, 0.7702000141143799, 0.7965999841690063, 0.7820000052452087, 0.781499981880188, 0.7741000056266785, 0.7562000155448914, 0.7924000024795532, 0.7973999977111816, 0.7900000214576721, 0.7921000123023987, 0.7838000059127808, 0.8043000102043152, 0.7964000105857849, 0.7979999780654907, 0.8180999755859375, 0.7908999919891357, 0.809499979019165, 0.8090999722480774]}\n",
      "(10000,)\n",
      "(10000,)\n",
      "0.7952\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal, GlorotNormal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def simplenet(act, s = 2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=GlorotNormal(), input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=GlorotNormal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n",
    "\n",
    "# act_func = ['tanh', 'relu', 'leaky-relu', 'elu', 'selu', 'gelu', 'swish']\n",
    "\n",
    "model = simplenet('selu')\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                      validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), verbose=1)\n",
    "\n",
    "\n",
    "print(history.history)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.sum(y_pred == y_true) / y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cifar10_simplenet_selu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
